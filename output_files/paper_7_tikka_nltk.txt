1 --> 0       Elsevier Fingerprint  Engine  May 2016                1    Contents  Out-of-the-box text analytics functionality ......................................................................................... 2  A wide range of subject areas are covered by a collection of thesauri .......................................... 2  1. 


 ---- TOKENS ----

 ['0', 'Elsevier', 'Fingerprint', 'Engine', 'May', '2016', '1', 'Contents', 'Out-of-the-box', 'text', 'analytics', 'functionality', '.........................................................................................', '2', 'A', 'wide', 'range', 'of', 'subject', 'areas', 'are', 'covered', 'by', 'a', 'collection', 'of', 'thesauri', '..........................................', '2', '1', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('0', 'CD'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('May', 'NNP'), ('2016', 'CD'), ('1', 'CD'), ('Contents', 'NNS'), ('Out-of-the-box', 'JJ'), ('text', 'JJ'), ('analytics', 'NNS'), ('functionality', 'NN'), ('.........................................................................................', 'VBP'), ('2', 'CD'), ('A', 'NNP'), ('wide', 'JJ'), ('range', 'NN'), ('of', 'IN'), ('subject', 'JJ'), ('areas', 'NNS'), ('are', 'VBP'), ('covered', 'VBN'), ('by', 'IN'), ('a', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('thesauri', 'NN'), ('..........................................', 'NNP'), ('2', 'CD'), ('1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['0', 'Elsevier', 'Fingerprint', 'Engine', 'May', '2016', '1', 'Contents', 'Out-of-the-box', 'text', 'analytics', 'functionality', '.........................................................................................', '2', 'wide', 'range', 'subject', 'areas', 'covered', 'collection', 'thesauri', '..........................................', '2', '1', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('0', 'CD'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('May', 'NNP'), ('2016', 'CD'), ('1', 'CD'), ('Contents', 'NNS'), ('Out-of-the-box', 'JJ'), ('text', 'JJ'), ('analytics', 'NNS'), ('functionality', 'NN'), ('.........................................................................................', 'VBP'), ('2', 'CD'), ('wide', 'JJ'), ('range', 'NN'), ('subject', 'JJ'), ('areas', 'NNS'), ('covered', 'VBN'), ('collection', 'NN'), ('thesauri', 'NN'), ('..........................................', 'VBD'), ('2', 'CD'), ('1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['0 Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine May', 'May 2016', '2016 1', '1 Contents', 'Contents Out-of-the-box', 'Out-of-the-box text', 'text analytics', 'analytics functionality', 'functionality .........................................................................................', '......................................................................................... 2', '2 wide', 'wide range', 'range subject', 'subject areas', 'areas covered', 'covered collection', 'collection thesauri', 'thesauri ..........................................', '.......................................... 2', '2 1', '1 .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['0 Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine May', 'Engine May 2016', 'May 2016 1', '2016 1 Contents', '1 Contents Out-of-the-box', 'Contents Out-of-the-box text', 'Out-of-the-box text analytics', 'text analytics functionality', 'analytics functionality .........................................................................................', 'functionality ......................................................................................... 2', '......................................................................................... 2 wide', '2 wide range', 'wide range subject', 'range subject areas', 'subject areas covered', 'areas covered collection', 'covered collection thesauri', 'collection thesauri ..........................................', 'thesauri .......................................... 2', '.......................................... 2 1', '2 1 .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['functionality', 'wide range', 'collection', 'thesauri'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['0', 'elsevi', 'fingerprint', 'engin', 'may', '2016', '1', 'content', 'out-of-the-box', 'text', 'analyt', 'function', '.........................................................................................', '2', 'wide', 'rang', 'subject', 'area', 'cover', 'collect', 'thesauri', '..........................................', '2', '1', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['0', 'elsevi', 'fingerprint', 'engin', 'may', '2016', '1', 'content', 'out-of-the-box', 'text', 'analyt', 'function', '.........................................................................................', '2', 'wide', 'rang', 'subject', 'area', 'cover', 'collect', 'thesauri', '..........................................', '2', '1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['0', 'Elsevier', 'Fingerprint', 'Engine', 'May', '2016', '1', 'Contents', 'Out-of-the-box', 'text', 'analytics', 'functionality', '.........................................................................................', '2', 'wide', 'range', 'subject', 'area', 'covered', 'collection', 'thesaurus', '..........................................', '2', '1', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

2 --> A look inside the Elsevier Fingerprint Engine ............................................................................... 3  1.1. 


 ---- TOKENS ----

 ['A', 'look', 'inside', 'the', 'Elsevier', 'Fingerprint', 'Engine', '...............................................................................', '3', '1.1', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('A', 'DT'), ('look', 'NN'), ('inside', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('...............................................................................', 'NNP'), ('3', 'CD'), ('1.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['look', 'inside', 'Elsevier', 'Fingerprint', 'Engine', '...............................................................................', '3', '1.1', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('look', 'NN'), ('inside', 'IN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('...............................................................................', 'NNP'), ('3', 'CD'), ('1.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['look inside', 'inside Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine ...............................................................................', '............................................................................... 3', '3 1.1', '1.1 .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['look inside Elsevier', 'inside Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine ...............................................................................', 'Engine ............................................................................... 3', '............................................................................... 3 1.1', '3 1.1 .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['look'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['look', 'insid', 'elsevi', 'fingerprint', 'engin', '...............................................................................', '3', '1.1', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['look', 'insid', 'elsevi', 'fingerprint', 'engin', '...............................................................................', '3', '1.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['look', 'inside', 'Elsevier', 'Fingerprint', 'Engine', '...............................................................................', '3', '1.1', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

3 --> Workflow: Fingerprinting ............................................................................................................... 3  1.2. 


 ---- TOKENS ----

 ['Workflow', ':', 'Fingerprinting', '...............................................................................................................', '3', '1.2', '.'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('Workflow', 'IN'), (':', ':'), ('Fingerprinting', 'VBG'), ('...............................................................................................................', '$'), ('3', 'CD'), ('1.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Workflow', ':', 'Fingerprinting', '...............................................................................................................', '3', '1.2', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('Workflow', 'IN'), (':', ':'), ('Fingerprinting', 'VBG'), ('...............................................................................................................', '$'), ('3', 'CD'), ('1.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Workflow :', ': Fingerprinting', 'Fingerprinting ...............................................................................................................', '............................................................................................................... 3', '3 1.2', '1.2 .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['Workflow : Fingerprinting', ': Fingerprinting ...............................................................................................................', 'Fingerprinting ............................................................................................................... 3', '............................................................................................................... 3 1.2', '3 1.2 .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['workflow', ':', 'fingerprint', '...............................................................................................................', '3', '1.2', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['workflow', ':', 'fingerprint', '...............................................................................................................', '3', '1.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['Workflow', ':', 'Fingerprinting', '...............................................................................................................', '3', '1.2', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

4 --> Workflow: Generation of Controlled Vocabularies and Enrichment of Thesauri .......................... 3  1.3. 


 ---- TOKENS ----

 ['Workflow', ':', 'Generation', 'of', 'Controlled', 'Vocabularies', 'and', 'Enrichment', 'of', 'Thesauri', '..........................', '3', '1.3', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Workflow', 'IN'), (':', ':'), ('Generation', 'NN'), ('of', 'IN'), ('Controlled', 'NNP'), ('Vocabularies', 'NNP'), ('and', 'CC'), ('Enrichment', 'NNP'), ('of', 'IN'), ('Thesauri', 'NNP'), ('..........................', 'NNP'), ('3', 'CD'), ('1.3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Workflow', ':', 'Generation', 'Controlled', 'Vocabularies', 'Enrichment', 'Thesauri', '..........................', '3', '1.3', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Workflow', 'IN'), (':', ':'), ('Generation', 'NN'), ('Controlled', 'VBD'), ('Vocabularies', 'NNP'), ('Enrichment', 'NNP'), ('Thesauri', 'NNP'), ('..........................', 'VBD'), ('3', 'CD'), ('1.3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Workflow :', ': Generation', 'Generation Controlled', 'Controlled Vocabularies', 'Vocabularies Enrichment', 'Enrichment Thesauri', 'Thesauri ..........................', '.......................... 3', '3 1.3', '1.3 .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Workflow : Generation', ': Generation Controlled', 'Generation Controlled Vocabularies', 'Controlled Vocabularies Enrichment', 'Vocabularies Enrichment Thesauri', 'Enrichment Thesauri ..........................', 'Thesauri .......................... 3', '.......................... 3 1.3', '3 1.3 .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['Generation'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Vocabularies Enrichment Thesauri']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['workflow', ':', 'gener', 'control', 'vocabulari', 'enrich', 'thesauri', '..........................', '3', '1.3', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['workflow', ':', 'generat', 'control', 'vocabulari', 'enrich', 'thesauri', '..........................', '3', '1.3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Workflow', ':', 'Generation', 'Controlled', 'Vocabularies', 'Enrichment', 'Thesauri', '..........................', '3', '1.3', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

5 --> Framework and Natural Language Processing (NLP) Modules ................................................... 4  1.4. 


 ---- TOKENS ----

 ['Framework', 'and', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'Modules', '...................................................', '4', '1.4', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Framework', 'NN'), ('and', 'CC'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('Modules', 'NNP'), ('...................................................', '$'), ('4', 'CD'), ('1.4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Framework', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'Modules', '...................................................', '4', '1.4', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Framework', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('Modules', 'NNP'), ('...................................................', '$'), ('4', 'CD'), ('1.4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Framework Natural', 'Natural Language', 'Language Processing', 'Processing (', '( NLP', 'NLP )', ') Modules', 'Modules ...................................................', '................................................... 4', '4 1.4', '1.4 .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Framework Natural Language', 'Natural Language Processing', 'Language Processing (', 'Processing ( NLP', '( NLP )', 'NLP ) Modules', ') Modules ...................................................', 'Modules ................................................... 4', '................................................... 4 1.4', '4 1.4 .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['Natural Language']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Framework', 'Modules']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['framework', 'natur', 'languag', 'process', '(', 'nlp', ')', 'modul', '...................................................', '4', '1.4', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['framework', 'natur', 'languag', 'process', '(', 'nlp', ')', 'modul', '...................................................', '4', '1.4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Framework', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'Modules', '...................................................', '4', '1.4', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

6 --> Key Natural Language Processing components of the Elsevier Fingerprint Engine ................... 4  2. 


 ---- TOKENS ----

 ['Key', 'Natural', 'Language', 'Processing', 'components', 'of', 'the', 'Elsevier', 'Fingerprint', 'Engine', '...................', '4', '2', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Key', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('components', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('...................', 'NNP'), ('4', 'CD'), ('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Key', 'Natural', 'Language', 'Processing', 'components', 'Elsevier', 'Fingerprint', 'Engine', '...................', '4', '2', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Key', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('components', 'NNS'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('...................', 'NNP'), ('4', 'CD'), ('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Key Natural', 'Natural Language', 'Language Processing', 'Processing components', 'components Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine ...................', '................... 4', '4 2', '2 .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Key Natural Language', 'Natural Language Processing', 'Language Processing components', 'Processing components Elsevier', 'components Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine ...................', 'Engine ................... 4', '................... 4 2', '4 2 .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['Natural Language']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Key', 'Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['key', 'natur', 'languag', 'process', 'compon', 'elsevi', 'fingerprint', 'engin', '...................', '4', '2', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['key', 'natur', 'languag', 'process', 'compon', 'elsevi', 'fingerprint', 'engin', '...................', '4', '2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Key', 'Natural', 'Language', 'Processing', 'component', 'Elsevier', 'Fingerprint', 'Engine', '...................', '4', '2', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

7 --> Example solutions powered by the Elsevier Fingerprint Engine ................................................. 5  2.1. 


 ---- TOKENS ----

 ['Example', 'solutions', 'powered', 'by', 'the', 'Elsevier', 'Fingerprint', 'Engine', '.................................................', '5', '2.1', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('Example', 'JJ'), ('solutions', 'NNS'), ('powered', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('.................................................', 'NNP'), ('5', 'CD'), ('2.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Example', 'solutions', 'powered', 'Elsevier', 'Fingerprint', 'Engine', '.................................................', '5', '2.1', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Example', 'JJ'), ('solutions', 'NNS'), ('powered', 'VBN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('.................................................', 'NNP'), ('5', 'CD'), ('2.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Example solutions', 'solutions powered', 'powered Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine .................................................', '................................................. 5', '5 2.1', '2.1 .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Example solutions powered', 'solutions powered Elsevier', 'powered Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine .................................................', 'Engine ................................................. 5', '................................................. 5 2.1', '5 2.1 .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['exampl', 'solut', 'power', 'elsevi', 'fingerprint', 'engin', '.................................................', '5', '2.1', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['exampl', 'solut', 'power', 'elsevi', 'fingerprint', 'engin', '.................................................', '5', '2.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Example', 'solution', 'powered', 'Elsevier', 'Fingerprint', 'Engine', '.................................................', '5', '2.1', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

8 --> National Institutes of Health ......................................................................................................... 5  2.2. 


 ---- TOKENS ----

 ['National', 'Institutes', 'of', 'Health', '.........................................................................................................', '5', '2.2', '.'] 

 TOTAL TOKENS ==> 8

 ---- POST ----

 [('National', 'NNP'), ('Institutes', 'NNP'), ('of', 'IN'), ('Health', 'NNP'), ('.........................................................................................................', 'NNP'), ('5', 'CD'), ('2.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['National', 'Institutes', 'Health', '.........................................................................................................', '5', '2.2', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('National', 'NNP'), ('Institutes', 'NNP'), ('Health', 'NNP'), ('.........................................................................................................', 'VBD'), ('5', 'CD'), ('2.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['National Institutes', 'Institutes Health', 'Health .........................................................................................................', '......................................................................................................... 5', '5 2.2', '2.2 .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['National Institutes Health', 'Institutes Health .........................................................................................................', 'Health ......................................................................................................... 5', '......................................................................................................... 5 2.2', '5 2.2 .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['National Institutes Health']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['nation', 'institut', 'health', '.........................................................................................................', '5', '2.2', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['nation', 'institut', 'health', '.........................................................................................................', '5', '2.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['National', 'Institutes', 'Health', '.........................................................................................................', '5', '2.2', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

9 --> Wellcome Trust ............................................................................................................................. 5                       2  Elsevier Fingerprint Engine™  The Elsevier Fingerprint Engine is a back-end software system of state-of-the-art Natural Language  Processing (NLP) techniques to extract information from unstructured text. 


 ---- TOKENS ----

 ['Wellcome', 'Trust', '.............................................................................................................................', '5', '2', 'Elsevier', 'Fingerprint', 'Engine™', 'The', 'Elsevier', 'Fingerprint', 'Engine', 'is', 'a', 'back-end', 'software', 'system', 'of', 'state-of-the-art', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'techniques', 'to', 'extract', 'information', 'from', 'unstructured', 'text', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('Wellcome', 'NNP'), ('Trust', 'NNP'), ('.............................................................................................................................', 'VBD'), ('5', 'CD'), ('2', 'CD'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine™', 'NNP'), ('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('back-end', 'JJ'), ('software', 'NN'), ('system', 'NN'), ('of', 'IN'), ('state-of-the-art', 'JJ'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('techniques', 'VBZ'), ('to', 'TO'), ('extract', 'VB'), ('information', 'NN'), ('from', 'IN'), ('unstructured', 'JJ'), ('text', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Wellcome', 'Trust', '.............................................................................................................................', '5', '2', 'Elsevier', 'Fingerprint', 'Engine™', 'Elsevier', 'Fingerprint', 'Engine', 'back-end', 'software', 'system', 'state-of-the-art', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'techniques', 'extract', 'information', 'unstructured', 'text', '.']

 TOTAL FILTERED TOKENS ==>  27

 ---- POST FOR FILTERED TOKENS ----

 [('Wellcome', 'NNP'), ('Trust', 'NNP'), ('.............................................................................................................................', 'VBD'), ('5', 'CD'), ('2', 'CD'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine™', 'NNP'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('back-end', 'NN'), ('software', 'NN'), ('system', 'NN'), ('state-of-the-art', 'JJ'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('techniques', 'VBZ'), ('extract', 'JJ'), ('information', 'NN'), ('unstructured', 'VBD'), ('text', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Wellcome Trust', 'Trust .............................................................................................................................', '............................................................................................................................. 5', '5 2', '2 Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine™', 'Engine™ Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine back-end', 'back-end software', 'software system', 'system state-of-the-art', 'state-of-the-art Natural', 'Natural Language', 'Language Processing', 'Processing (', '( NLP', 'NLP )', ') techniques', 'techniques extract', 'extract information', 'information unstructured', 'unstructured text', 'text .'] 

 TOTAL BIGRAMS --> 26 



 ---- TRI-GRAMS ---- 

 ['Wellcome Trust .............................................................................................................................', 'Trust ............................................................................................................................. 5', '............................................................................................................................. 5 2', '5 2 Elsevier', '2 Elsevier Fingerprint', 'Elsevier Fingerprint Engine™', 'Fingerprint Engine™ Elsevier', 'Engine™ Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine back-end', 'Engine back-end software', 'back-end software system', 'software system state-of-the-art', 'system state-of-the-art Natural', 'state-of-the-art Natural Language', 'Natural Language Processing', 'Language Processing (', 'Processing ( NLP', '( NLP )', 'NLP ) techniques', ') techniques extract', 'techniques extract information', 'extract information unstructured', 'information unstructured text', 'unstructured text .'] 

 TOTAL TRIGRAMS --> 25 



 ---- NOUN PHRASES ---- 

 ['back-end', 'software', 'system', 'extract information', 'text'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['Natural Language']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Wellcome', 'Trust']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['wellcom', 'trust', '.............................................................................................................................', '5', '2', 'elsevi', 'fingerprint', 'engine™', 'elsevi', 'fingerprint', 'engin', 'back-end', 'softwar', 'system', 'state-of-the-art', 'natur', 'languag', 'process', '(', 'nlp', ')', 'techniqu', 'extract', 'inform', 'unstructur', 'text', '.']

 TOTAL PORTER STEM WORDS ==> 27



 ---- SNOWBALL STEMMING ----

['wellcom', 'trust', '.............................................................................................................................', '5', '2', 'elsevi', 'fingerprint', 'engine™', 'elsevi', 'fingerprint', 'engin', 'back-end', 'softwar', 'system', 'state-of-the-art', 'natur', 'languag', 'process', '(', 'nlp', ')', 'techniqu', 'extract', 'inform', 'unstructur', 'text', '.']

 TOTAL SNOWBALL STEM WORDS ==> 27



 ---- LEMMATIZATION ----

['Wellcome', 'Trust', '.............................................................................................................................', '5', '2', 'Elsevier', 'Fingerprint', 'Engine™', 'Elsevier', 'Fingerprint', 'Engine', 'back-end', 'software', 'system', 'state-of-the-art', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'technique', 'extract', 'information', 'unstructured', 'text', '.']

 TOTAL LEMMATIZE WORDS ==> 27

************************************************************************************************************************

10 --> Applying domain-relevant  thesauri to scientific publications of various types, the fingerprint engine creates an index of weighted  terms, called concepts,  which defines the text, known as a Fingerprint™ . 


 ---- TOKENS ----

 ['Applying', 'domain-relevant', 'thesauri', 'to', 'scientific', 'publications', 'of', 'various', 'types', ',', 'the', 'fingerprint', 'engine', 'creates', 'an', 'index', 'of', 'weighted', 'terms', ',', 'called', 'concepts', ',', 'which', 'defines', 'the', 'text', ',', 'known', 'as', 'a', 'Fingerprint™', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('Applying', 'VBG'), ('domain-relevant', 'JJ'), ('thesauri', 'NN'), ('to', 'TO'), ('scientific', 'JJ'), ('publications', 'NNS'), ('of', 'IN'), ('various', 'JJ'), ('types', 'NNS'), (',', ','), ('the', 'DT'), ('fingerprint', 'NN'), ('engine', 'NN'), ('creates', 'VBZ'), ('an', 'DT'), ('index', 'NN'), ('of', 'IN'), ('weighted', 'JJ'), ('terms', 'NNS'), (',', ','), ('called', 'VBN'), ('concepts', 'NNS'), (',', ','), ('which', 'WDT'), ('defines', 'VBZ'), ('the', 'DT'), ('text', 'NN'), (',', ','), ('known', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('Fingerprint™', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Applying', 'domain-relevant', 'thesauri', 'scientific', 'publications', 'various', 'types', ',', 'fingerprint', 'engine', 'creates', 'index', 'weighted', 'terms', ',', 'called', 'concepts', ',', 'defines', 'text', ',', 'known', 'Fingerprint™', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('Applying', 'VBG'), ('domain-relevant', 'JJ'), ('thesauri', 'NN'), ('scientific', 'JJ'), ('publications', 'NNS'), ('various', 'JJ'), ('types', 'NNS'), (',', ','), ('fingerprint', 'NN'), ('engine', 'NN'), ('creates', 'VBZ'), ('index', 'NN'), ('weighted', 'VBD'), ('terms', 'NNS'), (',', ','), ('called', 'VBN'), ('concepts', 'NNS'), (',', ','), ('defines', 'NNS'), ('text', 'NN'), (',', ','), ('known', 'VBN'), ('Fingerprint™', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Applying domain-relevant', 'domain-relevant thesauri', 'thesauri scientific', 'scientific publications', 'publications various', 'various types', 'types ,', ', fingerprint', 'fingerprint engine', 'engine creates', 'creates index', 'index weighted', 'weighted terms', 'terms ,', ', called', 'called concepts', 'concepts ,', ', defines', 'defines text', 'text ,', ', known', 'known Fingerprint™', 'Fingerprint™ .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['Applying domain-relevant thesauri', 'domain-relevant thesauri scientific', 'thesauri scientific publications', 'scientific publications various', 'publications various types', 'various types ,', 'types , fingerprint', ', fingerprint engine', 'fingerprint engine creates', 'engine creates index', 'creates index weighted', 'index weighted terms', 'weighted terms ,', 'terms , called', ', called concepts', 'called concepts ,', 'concepts , defines', ', defines text', 'defines text ,', 'text , known', ', known Fingerprint™', 'known Fingerprint™ .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['domain-relevant thesauri', 'fingerprint', 'engine', 'index', 'text'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['appli', 'domain-relev', 'thesauri', 'scientif', 'public', 'variou', 'type', ',', 'fingerprint', 'engin', 'creat', 'index', 'weight', 'term', ',', 'call', 'concept', ',', 'defin', 'text', ',', 'known', 'fingerprint™', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['appli', 'domain-relev', 'thesauri', 'scientif', 'public', 'various', 'type', ',', 'fingerprint', 'engin', 'creat', 'index', 'weight', 'term', ',', 'call', 'concept', ',', 'defin', 'text', ',', 'known', 'fingerprint™', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['Applying', 'domain-relevant', 'thesaurus', 'scientific', 'publication', 'various', 'type', ',', 'fingerprint', 'engine', 'creates', 'index', 'weighted', 'term', ',', 'called', 'concept', ',', 'defines', 'text', ',', 'known', 'Fingerprint™', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

11 --> Through the identification  and extraction of new concepts the Elsevier Fingerprint Engine can enrich thesauri and generate new  vocabularies. 


 ---- TOKENS ----

 ['Through', 'the', 'identification', 'and', 'extraction', 'of', 'new', 'concepts', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'can', 'enrich', 'thesauri', 'and', 'generate', 'new', 'vocabularies', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('Through', 'IN'), ('the', 'DT'), ('identification', 'NN'), ('and', 'CC'), ('extraction', 'NN'), ('of', 'IN'), ('new', 'JJ'), ('concepts', 'NNS'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('can', 'MD'), ('enrich', 'VB'), ('thesauri', 'NN'), ('and', 'CC'), ('generate', 'VB'), ('new', 'JJ'), ('vocabularies', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['identification', 'extraction', 'new', 'concepts', 'Elsevier', 'Fingerprint', 'Engine', 'enrich', 'thesauri', 'generate', 'new', 'vocabularies', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('identification', 'NN'), ('extraction', 'NN'), ('new', 'JJ'), ('concepts', 'NNS'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enrich', 'JJ'), ('thesauri', 'NN'), ('generate', 'VBP'), ('new', 'JJ'), ('vocabularies', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['identification extraction', 'extraction new', 'new concepts', 'concepts Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine enrich', 'enrich thesauri', 'thesauri generate', 'generate new', 'new vocabularies', 'vocabularies .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['identification extraction new', 'extraction new concepts', 'new concepts Elsevier', 'concepts Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine enrich', 'Engine enrich thesauri', 'enrich thesauri generate', 'thesauri generate new', 'generate new vocabularies', 'new vocabularies .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['identification', 'extraction', 'enrich thesauri'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['identif', 'extract', 'new', 'concept', 'elsevi', 'fingerprint', 'engin', 'enrich', 'thesauri', 'gener', 'new', 'vocabulari', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['identif', 'extract', 'new', 'concept', 'elsevi', 'fingerprint', 'engin', 'enrich', 'thesauri', 'generat', 'new', 'vocabulari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['identification', 'extraction', 'new', 'concept', 'Elsevier', 'Fingerprint', 'Engine', 'enrich', 'thesaurus', 'generate', 'new', 'vocabulary', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

12 --> By aggregating and comparing Fingerprints, the Elsevier Fingerprint Engine enables institutions to  look beyond metadata and expose valuable connections among people, publications, funding  opportunities and ideas. 


 ---- TOKENS ----

 ['By', 'aggregating', 'and', 'comparing', 'Fingerprints', ',', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'enables', 'institutions', 'to', 'look', 'beyond', 'metadata', 'and', 'expose', 'valuable', 'connections', 'among', 'people', ',', 'publications', ',', 'funding', 'opportunities', 'and', 'ideas', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('By', 'IN'), ('aggregating', 'VBG'), ('and', 'CC'), ('comparing', 'VBG'), ('Fingerprints', 'NNS'), (',', ','), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enables', 'VBZ'), ('institutions', 'NNS'), ('to', 'TO'), ('look', 'VB'), ('beyond', 'IN'), ('metadata', 'NNS'), ('and', 'CC'), ('expose', 'VB'), ('valuable', 'JJ'), ('connections', 'NNS'), ('among', 'IN'), ('people', 'NNS'), (',', ','), ('publications', 'NNS'), (',', ','), ('funding', 'VBG'), ('opportunities', 'NNS'), ('and', 'CC'), ('ideas', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['aggregating', 'comparing', 'Fingerprints', ',', 'Elsevier', 'Fingerprint', 'Engine', 'enables', 'institutions', 'look', 'beyond', 'metadata', 'expose', 'valuable', 'connections', 'among', 'people', ',', 'publications', ',', 'funding', 'opportunities', 'ideas', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('aggregating', 'VBG'), ('comparing', 'VBG'), ('Fingerprints', 'NNS'), (',', ','), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enables', 'VBZ'), ('institutions', 'NNS'), ('look', 'VBP'), ('beyond', 'IN'), ('metadata', 'NNS'), ('expose', 'RB'), ('valuable', 'JJ'), ('connections', 'NNS'), ('among', 'IN'), ('people', 'NNS'), (',', ','), ('publications', 'NNS'), (',', ','), ('funding', 'VBG'), ('opportunities', 'NNS'), ('ideas', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['aggregating comparing', 'comparing Fingerprints', 'Fingerprints ,', ', Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine enables', 'enables institutions', 'institutions look', 'look beyond', 'beyond metadata', 'metadata expose', 'expose valuable', 'valuable connections', 'connections among', 'among people', 'people ,', ', publications', 'publications ,', ', funding', 'funding opportunities', 'opportunities ideas', 'ideas .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['aggregating comparing Fingerprints', 'comparing Fingerprints ,', 'Fingerprints , Elsevier', ', Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine enables', 'Engine enables institutions', 'enables institutions look', 'institutions look beyond', 'look beyond metadata', 'beyond metadata expose', 'metadata expose valuable', 'expose valuable connections', 'valuable connections among', 'connections among people', 'among people ,', 'people , publications', ', publications ,', 'publications , funding', ', funding opportunities', 'funding opportunities ideas', 'opportunities ideas .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['aggreg', 'compar', 'fingerprint', ',', 'elsevi', 'fingerprint', 'engin', 'enabl', 'institut', 'look', 'beyond', 'metadata', 'expos', 'valuabl', 'connect', 'among', 'peopl', ',', 'public', ',', 'fund', 'opportun', 'idea', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['aggreg', 'compar', 'fingerprint', ',', 'elsevi', 'fingerprint', 'engin', 'enabl', 'institut', 'look', 'beyond', 'metadata', 'expos', 'valuabl', 'connect', 'among', 'peopl', ',', 'public', ',', 'fund', 'opportun', 'idea', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['aggregating', 'comparing', 'Fingerprints', ',', 'Elsevier', 'Fingerprint', 'Engine', 'enables', 'institution', 'look', 'beyond', 'metadata', 'expose', 'valuable', 'connection', 'among', 'people', ',', 'publication', ',', 'funding', 'opportunity', 'idea', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

13 --> The Elsevier Fingerprint Engine can be used as a back-office processing component of applications,  as it is for a number of Elsevier products, or as a stand-alone service. 


 ---- TOKENS ----

 ['The', 'Elsevier', 'Fingerprint', 'Engine', 'can', 'be', 'used', 'as', 'a', 'back-office', 'processing', 'component', 'of', 'applications', ',', 'as', 'it', 'is', 'for', 'a', 'number', 'of', 'Elsevier', 'products', ',', 'or', 'as', 'a', 'stand-alone', 'service', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('can', 'MD'), ('be', 'VB'), ('used', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('back-office', 'JJ'), ('processing', 'NN'), ('component', 'NN'), ('of', 'IN'), ('applications', 'NNS'), (',', ','), ('as', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('for', 'IN'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('products', 'NNS'), (',', ','), ('or', 'CC'), ('as', 'IN'), ('a', 'DT'), ('stand-alone', 'JJ'), ('service', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Elsevier', 'Fingerprint', 'Engine', 'used', 'back-office', 'processing', 'component', 'applications', ',', 'number', 'Elsevier', 'products', ',', 'stand-alone', 'service', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('used', 'VBD'), ('back-office', 'NN'), ('processing', 'NN'), ('component', 'NN'), ('applications', 'NNS'), (',', ','), ('number', 'NN'), ('Elsevier', 'NNP'), ('products', 'NNS'), (',', ','), ('stand-alone', 'JJ'), ('service', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Elsevier Fingerprint', 'Fingerprint Engine', 'Engine used', 'used back-office', 'back-office processing', 'processing component', 'component applications', 'applications ,', ', number', 'number Elsevier', 'Elsevier products', 'products ,', ', stand-alone', 'stand-alone service', 'service .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Elsevier Fingerprint Engine', 'Fingerprint Engine used', 'Engine used back-office', 'used back-office processing', 'back-office processing component', 'processing component applications', 'component applications ,', 'applications , number', ', number Elsevier', 'number Elsevier products', 'Elsevier products ,', 'products , stand-alone', ', stand-alone service', 'stand-alone service .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['back-office', 'processing', 'component', 'number', 'stand-alone service'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['Fingerprint Engine']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Elsevier']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['elsevi', 'fingerprint', 'engin', 'use', 'back-offic', 'process', 'compon', 'applic', ',', 'number', 'elsevi', 'product', ',', 'stand-alon', 'servic', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['elsevi', 'fingerprint', 'engin', 'use', 'back-offic', 'process', 'compon', 'applic', ',', 'number', 'elsevi', 'product', ',', 'stand-alon', 'servic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Elsevier', 'Fingerprint', 'Engine', 'used', 'back-office', 'processing', 'component', 'application', ',', 'number', 'Elsevier', 'product', ',', 'stand-alone', 'service', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

14 --> Out-of-the-box text analytics functionality  The Elsevier Fingerprint Engine offers out-of-the-box text analytics functionality that can be adapted  to meet each institution’s needs. 


 ---- TOKENS ----

 ['Out-of-the-box', 'text', 'analytics', 'functionality', 'The', 'Elsevier', 'Fingerprint', 'Engine', 'offers', 'out-of-the-box', 'text', 'analytics', 'functionality', 'that', 'can', 'be', 'adapted', 'to', 'meet', 'each', 'institution', '’', 's', 'needs', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Out-of-the-box', 'NNP'), ('text', 'NN'), ('analytics', 'NNS'), ('functionality', 'VBP'), ('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('offers', 'VBZ'), ('out-of-the-box', 'JJ'), ('text', 'NN'), ('analytics', 'NNS'), ('functionality', 'NN'), ('that', 'WDT'), ('can', 'MD'), ('be', 'VB'), ('adapted', 'VBN'), ('to', 'TO'), ('meet', 'VB'), ('each', 'DT'), ('institution', 'NN'), ('’', 'FW'), ('s', 'NN'), ('needs', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Out-of-the-box', 'text', 'analytics', 'functionality', 'Elsevier', 'Fingerprint', 'Engine', 'offers', 'out-of-the-box', 'text', 'analytics', 'functionality', 'adapted', 'meet', 'institution', '’', 'needs', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Out-of-the-box', 'NNP'), ('text', 'NN'), ('analytics', 'NNS'), ('functionality', 'NN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('offers', 'VBZ'), ('out-of-the-box', 'JJ'), ('text', 'NN'), ('analytics', 'NNS'), ('functionality', 'NN'), ('adapted', 'VBN'), ('meet', 'JJ'), ('institution', 'NN'), ('’', 'NNP'), ('needs', 'VBZ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Out-of-the-box text', 'text analytics', 'analytics functionality', 'functionality Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine offers', 'offers out-of-the-box', 'out-of-the-box text', 'text analytics', 'analytics functionality', 'functionality adapted', 'adapted meet', 'meet institution', 'institution ’', '’ needs', 'needs .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Out-of-the-box text analytics', 'text analytics functionality', 'analytics functionality Elsevier', 'functionality Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine offers', 'Engine offers out-of-the-box', 'offers out-of-the-box text', 'out-of-the-box text analytics', 'text analytics functionality', 'analytics functionality adapted', 'functionality adapted meet', 'adapted meet institution', 'meet institution ’', 'institution ’ needs', '’ needs .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['text', 'functionality', 'out-of-the-box text', 'functionality', 'meet institution'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['out-of-the-box', 'text', 'analyt', 'function', 'elsevi', 'fingerprint', 'engin', 'offer', 'out-of-the-box', 'text', 'analyt', 'function', 'adapt', 'meet', 'institut', '’', 'need', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['out-of-the-box', 'text', 'analyt', 'function', 'elsevi', 'fingerprint', 'engin', 'offer', 'out-of-the-box', 'text', 'analyt', 'function', 'adapt', 'meet', 'institut', '’', 'need', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Out-of-the-box', 'text', 'analytics', 'functionality', 'Elsevier', 'Fingerprint', 'Engine', 'offer', 'out-of-the-box', 'text', 'analytics', 'functionality', 'adapted', 'meet', 'institution', '’', 'need', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

15 --> Recognizing a growing need for more in- depth insight to support  strategic research-related decisions, Elsevier develops inventive semantic solutions for academic and  government institutions using the Elsevier Fingerprint Engine as an enabling technology. 


 ---- TOKENS ----

 ['Recognizing', 'a', 'growing', 'need', 'for', 'more', 'in-', 'depth', 'insight', 'to', 'support', 'strategic', 'research-related', 'decisions', ',', 'Elsevier', 'develops', 'inventive', 'semantic', 'solutions', 'for', 'academic', 'and', 'government', 'institutions', 'using', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'as', 'an', 'enabling', 'technology', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('Recognizing', 'VBG'), ('a', 'DT'), ('growing', 'VBG'), ('need', 'NN'), ('for', 'IN'), ('more', 'JJR'), ('in-', 'JJ'), ('depth', 'NN'), ('insight', 'NN'), ('to', 'TO'), ('support', 'VB'), ('strategic', 'JJ'), ('research-related', 'JJ'), ('decisions', 'NNS'), (',', ','), ('Elsevier', 'NNP'), ('develops', 'VBZ'), ('inventive', 'JJ'), ('semantic', 'JJ'), ('solutions', 'NNS'), ('for', 'IN'), ('academic', 'JJ'), ('and', 'CC'), ('government', 'NN'), ('institutions', 'NNS'), ('using', 'VBG'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('as', 'IN'), ('an', 'DT'), ('enabling', 'VBG'), ('technology', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Recognizing', 'growing', 'need', 'in-', 'depth', 'insight', 'support', 'strategic', 'research-related', 'decisions', ',', 'Elsevier', 'develops', 'inventive', 'semantic', 'solutions', 'academic', 'government', 'institutions', 'using', 'Elsevier', 'Fingerprint', 'Engine', 'enabling', 'technology', '.']

 TOTAL FILTERED TOKENS ==>  26

 ---- POST FOR FILTERED TOKENS ----

 [('Recognizing', 'VBG'), ('growing', 'VBG'), ('need', 'JJ'), ('in-', 'JJ'), ('depth', 'NN'), ('insight', 'JJ'), ('support', 'NN'), ('strategic', 'JJ'), ('research-related', 'JJ'), ('decisions', 'NNS'), (',', ','), ('Elsevier', 'NNP'), ('develops', 'VBZ'), ('inventive', 'JJ'), ('semantic', 'JJ'), ('solutions', 'NNS'), ('academic', 'JJ'), ('government', 'NN'), ('institutions', 'NNS'), ('using', 'VBG'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enabling', 'VBG'), ('technology', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Recognizing growing', 'growing need', 'need in-', 'in- depth', 'depth insight', 'insight support', 'support strategic', 'strategic research-related', 'research-related decisions', 'decisions ,', ', Elsevier', 'Elsevier develops', 'develops inventive', 'inventive semantic', 'semantic solutions', 'solutions academic', 'academic government', 'government institutions', 'institutions using', 'using Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine enabling', 'enabling technology', 'technology .'] 

 TOTAL BIGRAMS --> 25 



 ---- TRI-GRAMS ---- 

 ['Recognizing growing need', 'growing need in-', 'need in- depth', 'in- depth insight', 'depth insight support', 'insight support strategic', 'support strategic research-related', 'strategic research-related decisions', 'research-related decisions ,', 'decisions , Elsevier', ', Elsevier develops', 'Elsevier develops inventive', 'develops inventive semantic', 'inventive semantic solutions', 'semantic solutions academic', 'solutions academic government', 'academic government institutions', 'government institutions using', 'institutions using Elsevier', 'using Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine enabling', 'Engine enabling technology', 'enabling technology .'] 

 TOTAL TRIGRAMS --> 24 



 ---- NOUN PHRASES ---- 

 ['need in- depth', 'insight support', 'academic government', 'technology'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier', 'Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['recogn', 'grow', 'need', 'in-', 'depth', 'insight', 'support', 'strateg', 'research-rel', 'decis', ',', 'elsevi', 'develop', 'invent', 'semant', 'solut', 'academ', 'govern', 'institut', 'use', 'elsevi', 'fingerprint', 'engin', 'enabl', 'technolog', '.']

 TOTAL PORTER STEM WORDS ==> 26



 ---- SNOWBALL STEMMING ----

['recogn', 'grow', 'need', 'in-', 'depth', 'insight', 'support', 'strateg', 'research-rel', 'decis', ',', 'elsevi', 'develop', 'invent', 'semant', 'solut', 'academ', 'govern', 'institut', 'use', 'elsevi', 'fingerprint', 'engin', 'enabl', 'technolog', '.']

 TOTAL SNOWBALL STEM WORDS ==> 26



 ---- LEMMATIZATION ----

['Recognizing', 'growing', 'need', 'in-', 'depth', 'insight', 'support', 'strategic', 'research-related', 'decision', ',', 'Elsevier', 'develops', 'inventive', 'semantic', 'solution', 'academic', 'government', 'institution', 'using', 'Elsevier', 'Fingerprint', 'Engine', 'enabling', 'technology', '.']

 TOTAL LEMMATIZE WORDS ==> 26

************************************************************************************************************************

16 --> The Elsevier  Fingerprint Engine mines the unstructured text of scientific documents – publication abstracts, funding  announcements and awards, project summaries, patents, proposals, applications and other sources –  to map it to a ranked set of standardized, domain-specific concepts that define the text, known as a  Fingerprint. 


 ---- TOKENS ----

 ['The', 'Elsevier', 'Fingerprint', 'Engine', 'mines', 'the', 'unstructured', 'text', 'of', 'scientific', 'documents', '–', 'publication', 'abstracts', ',', 'funding', 'announcements', 'and', 'awards', ',', 'project', 'summaries', ',', 'patents', ',', 'proposals', ',', 'applications', 'and', 'other', 'sources', '–', 'to', 'map', 'it', 'to', 'a', 'ranked', 'set', 'of', 'standardized', ',', 'domain-specific', 'concepts', 'that', 'define', 'the', 'text', ',', 'known', 'as', 'a', 'Fingerprint', '.'] 

 TOTAL TOKENS ==> 54

 ---- POST ----

 [('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('mines', 'VBZ'), ('the', 'DT'), ('unstructured', 'JJ'), ('text', 'NN'), ('of', 'IN'), ('scientific', 'JJ'), ('documents', 'NNS'), ('–', 'POS'), ('publication', 'NN'), ('abstracts', 'NNS'), (',', ','), ('funding', 'VBG'), ('announcements', 'NNS'), ('and', 'CC'), ('awards', 'NNS'), (',', ','), ('project', 'NN'), ('summaries', 'NNS'), (',', ','), ('patents', 'NNS'), (',', ','), ('proposals', 'NNS'), (',', ','), ('applications', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('sources', 'NNS'), ('–', 'VBP'), ('to', 'TO'), ('map', 'VB'), ('it', 'PRP'), ('to', 'TO'), ('a', 'DT'), ('ranked', 'JJ'), ('set', 'NN'), ('of', 'IN'), ('standardized', 'JJ'), (',', ','), ('domain-specific', 'JJ'), ('concepts', 'NNS'), ('that', 'WDT'), ('define', 'VBP'), ('the', 'DT'), ('text', 'NN'), (',', ','), ('known', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('Fingerprint', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Elsevier', 'Fingerprint', 'Engine', 'mines', 'unstructured', 'text', 'scientific', 'documents', '–', 'publication', 'abstracts', ',', 'funding', 'announcements', 'awards', ',', 'project', 'summaries', ',', 'patents', ',', 'proposals', ',', 'applications', 'sources', '–', 'map', 'ranked', 'set', 'standardized', ',', 'domain-specific', 'concepts', 'define', 'text', ',', 'known', 'Fingerprint', '.']

 TOTAL FILTERED TOKENS ==>  39

 ---- POST FOR FILTERED TOKENS ----

 [('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('mines', 'NNS'), ('unstructured', 'VBD'), ('text', 'JJ'), ('scientific', 'JJ'), ('documents', 'NNS'), ('–', 'POS'), ('publication', 'NN'), ('abstracts', 'NNS'), (',', ','), ('funding', 'VBG'), ('announcements', 'NNS'), ('awards', 'NNS'), (',', ','), ('project', 'NN'), ('summaries', 'NNS'), (',', ','), ('patents', 'NNS'), (',', ','), ('proposals', 'NNS'), (',', ','), ('applications', 'NNS'), ('sources', 'NNS'), ('–', 'VBP'), ('map', 'NN'), ('ranked', 'VBN'), ('set', 'VBN'), ('standardized', 'VBN'), (',', ','), ('domain-specific', 'JJ'), ('concepts', 'NNS'), ('define', 'VBP'), ('text', 'NN'), (',', ','), ('known', 'VBN'), ('Fingerprint', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Elsevier Fingerprint', 'Fingerprint Engine', 'Engine mines', 'mines unstructured', 'unstructured text', 'text scientific', 'scientific documents', 'documents –', '– publication', 'publication abstracts', 'abstracts ,', ', funding', 'funding announcements', 'announcements awards', 'awards ,', ', project', 'project summaries', 'summaries ,', ', patents', 'patents ,', ', proposals', 'proposals ,', ', applications', 'applications sources', 'sources –', '– map', 'map ranked', 'ranked set', 'set standardized', 'standardized ,', ', domain-specific', 'domain-specific concepts', 'concepts define', 'define text', 'text ,', ', known', 'known Fingerprint', 'Fingerprint .'] 

 TOTAL BIGRAMS --> 38 



 ---- TRI-GRAMS ---- 

 ['Elsevier Fingerprint Engine', 'Fingerprint Engine mines', 'Engine mines unstructured', 'mines unstructured text', 'unstructured text scientific', 'text scientific documents', 'scientific documents –', 'documents – publication', '– publication abstracts', 'publication abstracts ,', 'abstracts , funding', ', funding announcements', 'funding announcements awards', 'announcements awards ,', 'awards , project', ', project summaries', 'project summaries ,', 'summaries , patents', ', patents ,', 'patents , proposals', ', proposals ,', 'proposals , applications', ', applications sources', 'applications sources –', 'sources – map', '– map ranked', 'map ranked set', 'ranked set standardized', 'set standardized ,', 'standardized , domain-specific', ', domain-specific concepts', 'domain-specific concepts define', 'concepts define text', 'define text ,', 'text , known', ', known Fingerprint', 'known Fingerprint .'] 

 TOTAL TRIGRAMS --> 37 



 ---- NOUN PHRASES ---- 

 ['publication', 'project', 'map', 'text'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['Fingerprint Engine']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Elsevier']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['elsevi', 'fingerprint', 'engin', 'mine', 'unstructur', 'text', 'scientif', 'document', '–', 'public', 'abstract', ',', 'fund', 'announc', 'award', ',', 'project', 'summari', ',', 'patent', ',', 'propos', ',', 'applic', 'sourc', '–', 'map', 'rank', 'set', 'standard', ',', 'domain-specif', 'concept', 'defin', 'text', ',', 'known', 'fingerprint', '.']

 TOTAL PORTER STEM WORDS ==> 39



 ---- SNOWBALL STEMMING ----

['elsevi', 'fingerprint', 'engin', 'mine', 'unstructur', 'text', 'scientif', 'document', '–', 'public', 'abstract', ',', 'fund', 'announc', 'award', ',', 'project', 'summari', ',', 'patent', ',', 'propos', ',', 'applic', 'sourc', '–', 'map', 'rank', 'set', 'standard', ',', 'domain-specif', 'concept', 'defin', 'text', ',', 'known', 'fingerprint', '.']

 TOTAL SNOWBALL STEM WORDS ==> 39



 ---- LEMMATIZATION ----

['Elsevier', 'Fingerprint', 'Engine', 'mine', 'unstructured', 'text', 'scientific', 'document', '–', 'publication', 'abstract', ',', 'funding', 'announcement', 'award', ',', 'project', 'summary', ',', 'patent', ',', 'proposal', ',', 'application', 'source', '–', 'map', 'ranked', 'set', 'standardized', ',', 'domain-specific', 'concept', 'define', 'text', ',', 'known', 'Fingerprint', '.']

 TOTAL LEMMATIZE WORDS ==> 39

************************************************************************************************************************

17 --> By aggregating and comparing Fingerprints, the Elsevier Fingerprint Engine enables  institutions to look beyond metadata. 


 ---- TOKENS ----

 ['By', 'aggregating', 'and', 'comparing', 'Fingerprints', ',', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'enables', 'institutions', 'to', 'look', 'beyond', 'metadata', '.'] 

 TOTAL TOKENS ==> 17

 ---- POST ----

 [('By', 'IN'), ('aggregating', 'VBG'), ('and', 'CC'), ('comparing', 'VBG'), ('Fingerprints', 'NNS'), (',', ','), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enables', 'VBZ'), ('institutions', 'NNS'), ('to', 'TO'), ('look', 'VB'), ('beyond', 'IN'), ('metadata', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['aggregating', 'comparing', 'Fingerprints', ',', 'Elsevier', 'Fingerprint', 'Engine', 'enables', 'institutions', 'look', 'beyond', 'metadata', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('aggregating', 'VBG'), ('comparing', 'VBG'), ('Fingerprints', 'NNS'), (',', ','), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enables', 'VBZ'), ('institutions', 'NNS'), ('look', 'VBP'), ('beyond', 'IN'), ('metadata', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['aggregating comparing', 'comparing Fingerprints', 'Fingerprints ,', ', Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine enables', 'enables institutions', 'institutions look', 'look beyond', 'beyond metadata', 'metadata .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['aggregating comparing Fingerprints', 'comparing Fingerprints ,', 'Fingerprints , Elsevier', ', Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine enables', 'Engine enables institutions', 'enables institutions look', 'institutions look beyond', 'look beyond metadata', 'beyond metadata .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['aggreg', 'compar', 'fingerprint', ',', 'elsevi', 'fingerprint', 'engin', 'enabl', 'institut', 'look', 'beyond', 'metadata', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['aggreg', 'compar', 'fingerprint', ',', 'elsevi', 'fingerprint', 'engin', 'enabl', 'institut', 'look', 'beyond', 'metadata', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['aggregating', 'comparing', 'Fingerprints', ',', 'Elsevier', 'Fingerprint', 'Engine', 'enables', 'institution', 'look', 'beyond', 'metadata', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

18 --> Based on ideas extracted from documents users can identify  trends and expose and analyze valuable connections between people (researchers, funders,  reviewers etc. 


 ---- TOKENS ----

 ['Based', 'on', 'ideas', 'extracted', 'from', 'documents', 'users', 'can', 'identify', 'trends', 'and', 'expose', 'and', 'analyze', 'valuable', 'connections', 'between', 'people', '(', 'researchers', ',', 'funders', ',', 'reviewers', 'etc', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Based', 'VBN'), ('on', 'IN'), ('ideas', 'NNS'), ('extracted', 'VBN'), ('from', 'IN'), ('documents', 'NNS'), ('users', 'NNS'), ('can', 'MD'), ('identify', 'VB'), ('trends', 'NNS'), ('and', 'CC'), ('expose', 'JJ'), ('and', 'CC'), ('analyze', 'JJ'), ('valuable', 'JJ'), ('connections', 'NNS'), ('between', 'IN'), ('people', 'NNS'), ('(', '('), ('researchers', 'NNS'), (',', ','), ('funders', 'NNS'), (',', ','), ('reviewers', 'NNS'), ('etc', 'VBP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Based', 'ideas', 'extracted', 'documents', 'users', 'identify', 'trends', 'expose', 'analyze', 'valuable', 'connections', 'people', '(', 'researchers', ',', 'funders', ',', 'reviewers', 'etc', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('Based', 'VBN'), ('ideas', 'NNS'), ('extracted', 'VBD'), ('documents', 'NNS'), ('users', 'NNS'), ('identify', 'VBP'), ('trends', 'NNS'), ('expose', 'JJ'), ('analyze', 'JJ'), ('valuable', 'JJ'), ('connections', 'NNS'), ('people', 'NNS'), ('(', '('), ('researchers', 'NNS'), (',', ','), ('funders', 'NNS'), (',', ','), ('reviewers', 'NNS'), ('etc', 'VBP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Based ideas', 'ideas extracted', 'extracted documents', 'documents users', 'users identify', 'identify trends', 'trends expose', 'expose analyze', 'analyze valuable', 'valuable connections', 'connections people', 'people (', '( researchers', 'researchers ,', ', funders', 'funders ,', ', reviewers', 'reviewers etc', 'etc .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['Based ideas extracted', 'ideas extracted documents', 'extracted documents users', 'documents users identify', 'users identify trends', 'identify trends expose', 'trends expose analyze', 'expose analyze valuable', 'analyze valuable connections', 'valuable connections people', 'connections people (', 'people ( researchers', '( researchers ,', 'researchers , funders', ', funders ,', 'funders , reviewers', ', reviewers etc', 'reviewers etc .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['base', 'idea', 'extract', 'document', 'user', 'identifi', 'trend', 'expos', 'analyz', 'valuabl', 'connect', 'peopl', '(', 'research', ',', 'funder', ',', 'review', 'etc', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['base', 'idea', 'extract', 'document', 'user', 'identifi', 'trend', 'expos', 'analyz', 'valuabl', 'connect', 'peopl', '(', 'research', ',', 'funder', ',', 'review', 'etc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['Based', 'idea', 'extracted', 'document', 'user', 'identify', 'trend', 'expose', 'analyze', 'valuable', 'connection', 'people', '(', 'researcher', ',', 'funders', ',', 'reviewer', 'etc', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

19 --> ), organizations (institutions, associations), geographic areas etc. 


 ---- TOKENS ----

 [')', ',', 'organizations', '(', 'institutions', ',', 'associations', ')', ',', 'geographic', 'areas', 'etc', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [(')', ')'), (',', ','), ('organizations', 'NNS'), ('(', '('), ('institutions', 'NNS'), (',', ','), ('associations', 'NNS'), (')', ')'), (',', ','), ('geographic', 'JJ'), ('areas', 'NNS'), ('etc', 'VBP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 [')', ',', 'organizations', '(', 'institutions', ',', 'associations', ')', ',', 'geographic', 'areas', 'etc', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [(')', ')'), (',', ','), ('organizations', 'NNS'), ('(', '('), ('institutions', 'NNS'), (',', ','), ('associations', 'NNS'), (')', ')'), (',', ','), ('geographic', 'JJ'), ('areas', 'NNS'), ('etc', 'VBP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 [') ,', ', organizations', 'organizations (', '( institutions', 'institutions ,', ', associations', 'associations )', ') ,', ', geographic', 'geographic areas', 'areas etc', 'etc .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 [') , organizations', ', organizations (', 'organizations ( institutions', '( institutions ,', 'institutions , associations', ', associations )', 'associations ) ,', ') , geographic', ', geographic areas', 'geographic areas etc', 'areas etc .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

[')', ',', 'organ', '(', 'institut', ',', 'associ', ')', ',', 'geograph', 'area', 'etc', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

[')', ',', 'organ', '(', 'institut', ',', 'associ', ')', ',', 'geograph', 'area', 'etc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

[')', ',', 'organization', '(', 'institution', ',', 'association', ')', ',', 'geographic', 'area', 'etc', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

20 --> Used as a key component in several Elsevier products, such as SciVal®, Pure and SciVal Analytics,  the Elsevier Fingerprint Engine computes semantic representations for publications and other data  types to allow for presentation, navigation and reporting on scientific output. 


 ---- TOKENS ----

 ['Used', 'as', 'a', 'key', 'component', 'in', 'several', 'Elsevier', 'products', ',', 'such', 'as', 'SciVal®', ',', 'Pure', 'and', 'SciVal', 'Analytics', ',', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'computes', 'semantic', 'representations', 'for', 'publications', 'and', 'other', 'data', 'types', 'to', 'allow', 'for', 'presentation', ',', 'navigation', 'and', 'reporting', 'on', 'scientific', 'output', '.'] 

 TOTAL TOKENS ==> 44

 ---- POST ----

 [('Used', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('key', 'JJ'), ('component', 'NN'), ('in', 'IN'), ('several', 'JJ'), ('Elsevier', 'NNP'), ('products', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('SciVal®', 'NNP'), (',', ','), ('Pure', 'NNP'), ('and', 'CC'), ('SciVal', 'NNP'), ('Analytics', 'NNP'), (',', ','), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('computes', 'VBZ'), ('semantic', 'JJ'), ('representations', 'NNS'), ('for', 'IN'), ('publications', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('data', 'NNS'), ('types', 'NNS'), ('to', 'TO'), ('allow', 'VB'), ('for', 'IN'), ('presentation', 'NN'), (',', ','), ('navigation', 'NN'), ('and', 'CC'), ('reporting', 'NN'), ('on', 'IN'), ('scientific', 'JJ'), ('output', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Used', 'key', 'component', 'several', 'Elsevier', 'products', ',', 'SciVal®', ',', 'Pure', 'SciVal', 'Analytics', ',', 'Elsevier', 'Fingerprint', 'Engine', 'computes', 'semantic', 'representations', 'publications', 'data', 'types', 'allow', 'presentation', ',', 'navigation', 'reporting', 'scientific', 'output', '.']

 TOTAL FILTERED TOKENS ==>  30

 ---- POST FOR FILTERED TOKENS ----

 [('Used', 'VBN'), ('key', 'JJ'), ('component', 'JJ'), ('several', 'JJ'), ('Elsevier', 'NNP'), ('products', 'NNS'), (',', ','), ('SciVal®', 'NNP'), (',', ','), ('Pure', 'NNP'), ('SciVal', 'NNP'), ('Analytics', 'NNP'), (',', ','), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('computes', 'VBZ'), ('semantic', 'JJ'), ('representations', 'NNS'), ('publications', 'NNS'), ('data', 'VBP'), ('types', 'NNS'), ('allow', 'JJ'), ('presentation', 'NN'), (',', ','), ('navigation', 'NN'), ('reporting', 'NN'), ('scientific', 'JJ'), ('output', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Used key', 'key component', 'component several', 'several Elsevier', 'Elsevier products', 'products ,', ', SciVal®', 'SciVal® ,', ', Pure', 'Pure SciVal', 'SciVal Analytics', 'Analytics ,', ', Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine computes', 'computes semantic', 'semantic representations', 'representations publications', 'publications data', 'data types', 'types allow', 'allow presentation', 'presentation ,', ', navigation', 'navigation reporting', 'reporting scientific', 'scientific output', 'output .'] 

 TOTAL BIGRAMS --> 29 



 ---- TRI-GRAMS ---- 

 ['Used key component', 'key component several', 'component several Elsevier', 'several Elsevier products', 'Elsevier products ,', 'products , SciVal®', ', SciVal® ,', 'SciVal® , Pure', ', Pure SciVal', 'Pure SciVal Analytics', 'SciVal Analytics ,', 'Analytics , Elsevier', ', Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine computes', 'Engine computes semantic', 'computes semantic representations', 'semantic representations publications', 'representations publications data', 'publications data types', 'data types allow', 'types allow presentation', 'allow presentation ,', 'presentation , navigation', ', navigation reporting', 'navigation reporting scientific', 'reporting scientific output', 'scientific output .'] 

 TOTAL TRIGRAMS --> 28 



 ---- NOUN PHRASES ---- 

 ['allow presentation', 'navigation', 'reporting', 'scientific output'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Pure SciVal Analytics', 'Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['use', 'key', 'compon', 'sever', 'elsevi', 'product', ',', 'scival®', ',', 'pure', 'scival', 'analyt', ',', 'elsevi', 'fingerprint', 'engin', 'comput', 'semant', 'represent', 'public', 'data', 'type', 'allow', 'present', ',', 'navig', 'report', 'scientif', 'output', '.']

 TOTAL PORTER STEM WORDS ==> 30



 ---- SNOWBALL STEMMING ----

['use', 'key', 'compon', 'sever', 'elsevi', 'product', ',', 'scival®', ',', 'pure', 'scival', 'analyt', ',', 'elsevi', 'fingerprint', 'engin', 'comput', 'semant', 'represent', 'public', 'data', 'type', 'allow', 'present', ',', 'navig', 'report', 'scientif', 'output', '.']

 TOTAL SNOWBALL STEM WORDS ==> 30



 ---- LEMMATIZATION ----

['Used', 'key', 'component', 'several', 'Elsevier', 'product', ',', 'SciVal®', ',', 'Pure', 'SciVal', 'Analytics', ',', 'Elsevier', 'Fingerprint', 'Engine', 'computes', 'semantic', 'representation', 'publication', 'data', 'type', 'allow', 'presentation', ',', 'navigation', 'reporting', 'scientific', 'output', '.']

 TOTAL LEMMATIZE WORDS ==> 30

************************************************************************************************************************

21 --> The Elsevier Fingerprint  Engine automatically generates author profiles for Pure (hosted edition) by scanning and analyzing  publications from the Scopus® database and additional content provided by the institution. 


 ---- TOKENS ----

 ['The', 'Elsevier', 'Fingerprint', 'Engine', 'automatically', 'generates', 'author', 'profiles', 'for', 'Pure', '(', 'hosted', 'edition', ')', 'by', 'scanning', 'and', 'analyzing', 'publications', 'from', 'the', 'Scopus®', 'database', 'and', 'additional', 'content', 'provided', 'by', 'the', 'institution', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('automatically', 'RB'), ('generates', 'VBZ'), ('author', 'NN'), ('profiles', 'NNS'), ('for', 'IN'), ('Pure', 'NNP'), ('(', '('), ('hosted', 'VBN'), ('edition', 'NN'), (')', ')'), ('by', 'IN'), ('scanning', 'VBG'), ('and', 'CC'), ('analyzing', 'VBG'), ('publications', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('Scopus®', 'NNP'), ('database', 'NN'), ('and', 'CC'), ('additional', 'JJ'), ('content', 'NN'), ('provided', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('institution', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Elsevier', 'Fingerprint', 'Engine', 'automatically', 'generates', 'author', 'profiles', 'Pure', '(', 'hosted', 'edition', ')', 'scanning', 'analyzing', 'publications', 'Scopus®', 'database', 'additional', 'content', 'provided', 'institution', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('automatically', 'RB'), ('generates', 'VBZ'), ('author', 'NN'), ('profiles', 'NNS'), ('Pure', 'NNP'), ('(', '('), ('hosted', 'VBN'), ('edition', 'NN'), (')', ')'), ('scanning', 'VBG'), ('analyzing', 'VBG'), ('publications', 'NNS'), ('Scopus®', 'NNP'), ('database', 'VBD'), ('additional', 'JJ'), ('content', 'NN'), ('provided', 'VBD'), ('institution', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Elsevier Fingerprint', 'Fingerprint Engine', 'Engine automatically', 'automatically generates', 'generates author', 'author profiles', 'profiles Pure', 'Pure (', '( hosted', 'hosted edition', 'edition )', ') scanning', 'scanning analyzing', 'analyzing publications', 'publications Scopus®', 'Scopus® database', 'database additional', 'additional content', 'content provided', 'provided institution', 'institution .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['Elsevier Fingerprint Engine', 'Fingerprint Engine automatically', 'Engine automatically generates', 'automatically generates author', 'generates author profiles', 'author profiles Pure', 'profiles Pure (', 'Pure ( hosted', '( hosted edition', 'hosted edition )', 'edition ) scanning', ') scanning analyzing', 'scanning analyzing publications', 'analyzing publications Scopus®', 'publications Scopus® database', 'Scopus® database additional', 'database additional content', 'additional content provided', 'content provided institution', 'provided institution .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['author', 'additional content', 'institution'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['Fingerprint Engine']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Elsevier']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Pure']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['elsevi', 'fingerprint', 'engin', 'automat', 'gener', 'author', 'profil', 'pure', '(', 'host', 'edit', ')', 'scan', 'analyz', 'public', 'scopus®', 'databas', 'addit', 'content', 'provid', 'institut', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['elsevi', 'fingerprint', 'engin', 'automat', 'generat', 'author', 'profil', 'pure', '(', 'host', 'edit', ')', 'scan', 'analyz', 'public', 'scopus®', 'databas', 'addit', 'content', 'provid', 'institut', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['Elsevier', 'Fingerprint', 'Engine', 'automatically', 'generates', 'author', 'profile', 'Pure', '(', 'hosted', 'edition', ')', 'scanning', 'analyzing', 'publication', 'Scopus®', 'database', 'additional', 'content', 'provided', 'institution', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

22 --> A directory  of research expertise, Pure enables researchers, administrators and managers to enable  collaboration within and outside of the organization. 


 ---- TOKENS ----

 ['A', 'directory', 'of', 'research', 'expertise', ',', 'Pure', 'enables', 'researchers', ',', 'administrators', 'and', 'managers', 'to', 'enable', 'collaboration', 'within', 'and', 'outside', 'of', 'the', 'organization', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('A', 'DT'), ('directory', 'NN'), ('of', 'IN'), ('research', 'NN'), ('expertise', 'NN'), (',', ','), ('Pure', 'NNP'), ('enables', 'VBZ'), ('researchers', 'NNS'), (',', ','), ('administrators', 'NNS'), ('and', 'CC'), ('managers', 'NNS'), ('to', 'TO'), ('enable', 'VB'), ('collaboration', 'NN'), ('within', 'IN'), ('and', 'CC'), ('outside', 'IN'), ('of', 'IN'), ('the', 'DT'), ('organization', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['directory', 'research', 'expertise', ',', 'Pure', 'enables', 'researchers', ',', 'administrators', 'managers', 'enable', 'collaboration', 'within', 'outside', 'organization', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('directory', 'NN'), ('research', 'NN'), ('expertise', 'NN'), (',', ','), ('Pure', 'NNP'), ('enables', 'VBZ'), ('researchers', 'NNS'), (',', ','), ('administrators', 'NNS'), ('managers', 'NNS'), ('enable', 'JJ'), ('collaboration', 'NN'), ('within', 'IN'), ('outside', 'JJ'), ('organization', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['directory research', 'research expertise', 'expertise ,', ', Pure', 'Pure enables', 'enables researchers', 'researchers ,', ', administrators', 'administrators managers', 'managers enable', 'enable collaboration', 'collaboration within', 'within outside', 'outside organization', 'organization .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['directory research expertise', 'research expertise ,', 'expertise , Pure', ', Pure enables', 'Pure enables researchers', 'enables researchers ,', 'researchers , administrators', ', administrators managers', 'administrators managers enable', 'managers enable collaboration', 'enable collaboration within', 'collaboration within outside', 'within outside organization', 'outside organization .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['directory', 'research', 'expertise', 'enable collaboration', 'outside organization'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Pure']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['directori', 'research', 'expertis', ',', 'pure', 'enabl', 'research', ',', 'administr', 'manag', 'enabl', 'collabor', 'within', 'outsid', 'organ', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['directori', 'research', 'expertis', ',', 'pure', 'enabl', 'research', ',', 'administr', 'manag', 'enabl', 'collabor', 'within', 'outsid', 'organ', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['directory', 'research', 'expertise', ',', 'Pure', 'enables', 'researcher', ',', 'administrator', 'manager', 'enable', 'collaboration', 'within', 'outside', 'organization', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

23 --> The Elsevier Fingerprint Engine also serves as  the framework for customized modules which enable funding agencies to find reviewers, analyze  grant portfolios and strategically plan which areas of research to fund next. 


 ---- TOKENS ----

 ['The', 'Elsevier', 'Fingerprint', 'Engine', 'also', 'serves', 'as', 'the', 'framework', 'for', 'customized', 'modules', 'which', 'enable', 'funding', 'agencies', 'to', 'find', 'reviewers', ',', 'analyze', 'grant', 'portfolios', 'and', 'strategically', 'plan', 'which', 'areas', 'of', 'research', 'to', 'fund', 'next', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('also', 'RB'), ('serves', 'VBZ'), ('as', 'IN'), ('the', 'DT'), ('framework', 'NN'), ('for', 'IN'), ('customized', 'JJ'), ('modules', 'NNS'), ('which', 'WDT'), ('enable', 'VBP'), ('funding', 'NN'), ('agencies', 'NNS'), ('to', 'TO'), ('find', 'VB'), ('reviewers', 'NNS'), (',', ','), ('analyze', 'VBP'), ('grant', 'JJ'), ('portfolios', 'NNS'), ('and', 'CC'), ('strategically', 'RB'), ('plan', 'NN'), ('which', 'WDT'), ('areas', 'NNS'), ('of', 'IN'), ('research', 'NN'), ('to', 'TO'), ('fund', 'VB'), ('next', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Elsevier', 'Fingerprint', 'Engine', 'also', 'serves', 'framework', 'customized', 'modules', 'enable', 'funding', 'agencies', 'find', 'reviewers', ',', 'analyze', 'grant', 'portfolios', 'strategically', 'plan', 'areas', 'research', 'fund', 'next', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('also', 'RB'), ('serves', 'VBZ'), ('framework', 'NN'), ('customized', 'JJ'), ('modules', 'NNS'), ('enable', 'JJ'), ('funding', 'NN'), ('agencies', 'NNS'), ('find', 'VBP'), ('reviewers', 'NNS'), (',', ','), ('analyze', 'VBP'), ('grant', 'JJ'), ('portfolios', 'NNS'), ('strategically', 'RB'), ('plan', 'VBP'), ('areas', 'NNS'), ('research', 'NN'), ('fund', 'NN'), ('next', 'IN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Elsevier Fingerprint', 'Fingerprint Engine', 'Engine also', 'also serves', 'serves framework', 'framework customized', 'customized modules', 'modules enable', 'enable funding', 'funding agencies', 'agencies find', 'find reviewers', 'reviewers ,', ', analyze', 'analyze grant', 'grant portfolios', 'portfolios strategically', 'strategically plan', 'plan areas', 'areas research', 'research fund', 'fund next', 'next .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['Elsevier Fingerprint Engine', 'Fingerprint Engine also', 'Engine also serves', 'also serves framework', 'serves framework customized', 'framework customized modules', 'customized modules enable', 'modules enable funding', 'enable funding agencies', 'funding agencies find', 'agencies find reviewers', 'find reviewers ,', 'reviewers , analyze', ', analyze grant', 'analyze grant portfolios', 'grant portfolios strategically', 'portfolios strategically plan', 'strategically plan areas', 'plan areas research', 'areas research fund', 'research fund next', 'fund next .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['framework', 'enable funding', 'research', 'fund'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['Fingerprint Engine']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Elsevier']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['elsevi', 'fingerprint', 'engin', 'also', 'serv', 'framework', 'custom', 'modul', 'enabl', 'fund', 'agenc', 'find', 'review', ',', 'analyz', 'grant', 'portfolio', 'strateg', 'plan', 'area', 'research', 'fund', 'next', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['elsevi', 'fingerprint', 'engin', 'also', 'serv', 'framework', 'custom', 'modul', 'enabl', 'fund', 'agenc', 'find', 'review', ',', 'analyz', 'grant', 'portfolio', 'strateg', 'plan', 'area', 'research', 'fund', 'next', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['Elsevier', 'Fingerprint', 'Engine', 'also', 'serf', 'framework', 'customized', 'module', 'enable', 'funding', 'agency', 'find', 'reviewer', ',', 'analyze', 'grant', 'portfolio', 'strategically', 'plan', 'area', 'research', 'fund', 'next', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

24 --> A flexible platform, the  Elsevier Fingerprint Engine can be applied in various ways to help each institution answer its most  significant questions. 


 ---- TOKENS ----

 ['A', 'flexible', 'platform', ',', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'can', 'be', 'applied', 'in', 'various', 'ways', 'to', 'help', 'each', 'institution', 'answer', 'its', 'most', 'significant', 'questions', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('A', 'DT'), ('flexible', 'JJ'), ('platform', 'NN'), (',', ','), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('can', 'MD'), ('be', 'VB'), ('applied', 'VBN'), ('in', 'IN'), ('various', 'JJ'), ('ways', 'NNS'), ('to', 'TO'), ('help', 'VB'), ('each', 'DT'), ('institution', 'NN'), ('answer', 'VBZ'), ('its', 'PRP$'), ('most', 'RBS'), ('significant', 'JJ'), ('questions', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['flexible', 'platform', ',', 'Elsevier', 'Fingerprint', 'Engine', 'applied', 'various', 'ways', 'help', 'institution', 'answer', 'significant', 'questions', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('flexible', 'JJ'), ('platform', 'NN'), (',', ','), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('applied', 'VBD'), ('various', 'JJ'), ('ways', 'NNS'), ('help', 'VBP'), ('institution', 'NN'), ('answer', 'NN'), ('significant', 'JJ'), ('questions', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['flexible platform', 'platform ,', ', Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine applied', 'applied various', 'various ways', 'ways help', 'help institution', 'institution answer', 'answer significant', 'significant questions', 'questions .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['flexible platform ,', 'platform , Elsevier', ', Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine applied', 'Engine applied various', 'applied various ways', 'various ways help', 'ways help institution', 'help institution answer', 'institution answer significant', 'answer significant questions', 'significant questions .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['flexible platform', 'institution', 'answer'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['flexibl', 'platform', ',', 'elsevi', 'fingerprint', 'engin', 'appli', 'variou', 'way', 'help', 'institut', 'answer', 'signific', 'question', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['flexibl', 'platform', ',', 'elsevi', 'fingerprint', 'engin', 'appli', 'various', 'way', 'help', 'institut', 'answer', 'signific', 'question', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['flexible', 'platform', ',', 'Elsevier', 'Fingerprint', 'Engine', 'applied', 'various', 'way', 'help', 'institution', 'answer', 'significant', 'question', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

25 --> A wide range of subject areas are covered by a collection of  thesauri  The Elsevier Fingerprint Engine integrates a range of thesauri to support applications pertaining to  different subject areas, including a number of traditional popular ones like the Medical Subject  Headings (MeSH), the National Agriculture Library's (NAL) thesaurus and Elsevier's Compendex  thesaurus. 


 ---- TOKENS ----

 ['A', 'wide', 'range', 'of', 'subject', 'areas', 'are', 'covered', 'by', 'a', 'collection', 'of', 'thesauri', 'The', 'Elsevier', 'Fingerprint', 'Engine', 'integrates', 'a', 'range', 'of', 'thesauri', 'to', 'support', 'applications', 'pertaining', 'to', 'different', 'subject', 'areas', ',', 'including', 'a', 'number', 'of', 'traditional', 'popular', 'ones', 'like', 'the', 'Medical', 'Subject', 'Headings', '(', 'MeSH', ')', ',', 'the', 'National', 'Agriculture', 'Library', "'s", '(', 'NAL', ')', 'thesaurus', 'and', 'Elsevier', "'s", 'Compendex', 'thesaurus', '.'] 

 TOTAL TOKENS ==> 62

 ---- POST ----

 [('A', 'DT'), ('wide', 'JJ'), ('range', 'NN'), ('of', 'IN'), ('subject', 'JJ'), ('areas', 'NNS'), ('are', 'VBP'), ('covered', 'VBN'), ('by', 'IN'), ('a', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('thesauri', 'NN'), ('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('integrates', 'VBZ'), ('a', 'DT'), ('range', 'NN'), ('of', 'IN'), ('thesauri', 'NN'), ('to', 'TO'), ('support', 'VB'), ('applications', 'NNS'), ('pertaining', 'VBG'), ('to', 'TO'), ('different', 'JJ'), ('subject', 'JJ'), ('areas', 'NNS'), (',', ','), ('including', 'VBG'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('traditional', 'JJ'), ('popular', 'JJ'), ('ones', 'NNS'), ('like', 'IN'), ('the', 'DT'), ('Medical', 'NNP'), ('Subject', 'NNP'), ('Headings', 'NNP'), ('(', '('), ('MeSH', 'NNP'), (')', ')'), (',', ','), ('the', 'DT'), ('National', 'NNP'), ('Agriculture', 'NNP'), ('Library', 'NNP'), ("'s", 'POS'), ('(', '('), ('NAL', 'NNP'), (')', ')'), ('thesaurus', 'NN'), ('and', 'CC'), ('Elsevier', 'NNP'), ("'s", 'POS'), ('Compendex', 'NNP'), ('thesaurus', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['wide', 'range', 'subject', 'areas', 'covered', 'collection', 'thesauri', 'Elsevier', 'Fingerprint', 'Engine', 'integrates', 'range', 'thesauri', 'support', 'applications', 'pertaining', 'different', 'subject', 'areas', ',', 'including', 'number', 'traditional', 'popular', 'ones', 'like', 'Medical', 'Subject', 'Headings', '(', 'MeSH', ')', ',', 'National', 'Agriculture', 'Library', "'s", '(', 'NAL', ')', 'thesaurus', 'Elsevier', "'s", 'Compendex', 'thesaurus', '.']

 TOTAL FILTERED TOKENS ==>  46

 ---- POST FOR FILTERED TOKENS ----

 [('wide', 'JJ'), ('range', 'NN'), ('subject', 'JJ'), ('areas', 'NNS'), ('covered', 'VBN'), ('collection', 'NN'), ('thesauri', 'NN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('integrates', 'VBZ'), ('range', 'VBP'), ('thesauri', 'JJ'), ('support', 'NN'), ('applications', 'NNS'), ('pertaining', 'VBG'), ('different', 'JJ'), ('subject', 'JJ'), ('areas', 'NNS'), (',', ','), ('including', 'VBG'), ('number', 'NN'), ('traditional', 'JJ'), ('popular', 'JJ'), ('ones', 'NNS'), ('like', 'IN'), ('Medical', 'NNP'), ('Subject', 'NNP'), ('Headings', 'NNP'), ('(', '('), ('MeSH', 'NNP'), (')', ')'), (',', ','), ('National', 'NNP'), ('Agriculture', 'NNP'), ('Library', 'NNP'), ("'s", 'POS'), ('(', '('), ('NAL', 'NNP'), (')', ')'), ('thesaurus', 'VBP'), ('Elsevier', 'NNP'), ("'s", 'POS'), ('Compendex', 'NNP'), ('thesaurus', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['wide range', 'range subject', 'subject areas', 'areas covered', 'covered collection', 'collection thesauri', 'thesauri Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine integrates', 'integrates range', 'range thesauri', 'thesauri support', 'support applications', 'applications pertaining', 'pertaining different', 'different subject', 'subject areas', 'areas ,', ', including', 'including number', 'number traditional', 'traditional popular', 'popular ones', 'ones like', 'like Medical', 'Medical Subject', 'Subject Headings', 'Headings (', '( MeSH', 'MeSH )', ') ,', ', National', 'National Agriculture', 'Agriculture Library', "Library 's", "'s (", '( NAL', 'NAL )', ') thesaurus', 'thesaurus Elsevier', "Elsevier 's", "'s Compendex", 'Compendex thesaurus', 'thesaurus .'] 

 TOTAL BIGRAMS --> 45 



 ---- TRI-GRAMS ---- 

 ['wide range subject', 'range subject areas', 'subject areas covered', 'areas covered collection', 'covered collection thesauri', 'collection thesauri Elsevier', 'thesauri Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine integrates', 'Engine integrates range', 'integrates range thesauri', 'range thesauri support', 'thesauri support applications', 'support applications pertaining', 'applications pertaining different', 'pertaining different subject', 'different subject areas', 'subject areas ,', 'areas , including', ', including number', 'including number traditional', 'number traditional popular', 'traditional popular ones', 'popular ones like', 'ones like Medical', 'like Medical Subject', 'Medical Subject Headings', 'Subject Headings (', 'Headings ( MeSH', '( MeSH )', 'MeSH ) ,', ') , National', ', National Agriculture', 'National Agriculture Library', "Agriculture Library 's", "Library 's (", "'s ( NAL", '( NAL )', 'NAL ) thesaurus', ') thesaurus Elsevier', "thesaurus Elsevier 's", "Elsevier 's Compendex", "'s Compendex thesaurus", 'Compendex thesaurus .'] 

 TOTAL TRIGRAMS --> 44 



 ---- NOUN PHRASES ---- 

 ['wide range', 'collection', 'thesauri', 'thesauri support', 'number', 'thesaurus'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['Medical Subject Headings', 'National Agriculture Library', 'Compendex']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> ['Elsevier Fingerprint Engine', 'Elsevier']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['wide', 'rang', 'subject', 'area', 'cover', 'collect', 'thesauri', 'elsevi', 'fingerprint', 'engin', 'integr', 'rang', 'thesauri', 'support', 'applic', 'pertain', 'differ', 'subject', 'area', ',', 'includ', 'number', 'tradit', 'popular', 'one', 'like', 'medic', 'subject', 'head', '(', 'mesh', ')', ',', 'nation', 'agricultur', 'librari', "'s", '(', 'nal', ')', 'thesauru', 'elsevi', "'s", 'compendex', 'thesauru', '.']

 TOTAL PORTER STEM WORDS ==> 46



 ---- SNOWBALL STEMMING ----

['wide', 'rang', 'subject', 'area', 'cover', 'collect', 'thesauri', 'elsevi', 'fingerprint', 'engin', 'integr', 'rang', 'thesauri', 'support', 'applic', 'pertain', 'differ', 'subject', 'area', ',', 'includ', 'number', 'tradit', 'popular', 'one', 'like', 'medic', 'subject', 'head', '(', 'mesh', ')', ',', 'nation', 'agricultur', 'librari', "'s", '(', 'nal', ')', 'thesaurus', 'elsevi', "'s", 'compendex', 'thesaurus', '.']

 TOTAL SNOWBALL STEM WORDS ==> 46



 ---- LEMMATIZATION ----

['wide', 'range', 'subject', 'area', 'covered', 'collection', 'thesaurus', 'Elsevier', 'Fingerprint', 'Engine', 'integrates', 'range', 'thesaurus', 'support', 'application', 'pertaining', 'different', 'subject', 'area', ',', 'including', 'number', 'traditional', 'popular', 'one', 'like', 'Medical', 'Subject', 'Headings', '(', 'MeSH', ')', ',', 'National', 'Agriculture', 'Library', "'s", '(', 'NAL', ')', 'thesaurus', 'Elsevier', "'s", 'Compendex', 'thesaurus', '.']

 TOTAL LEMMATIZE WORDS ==> 46

************************************************************************************************************************

26 --> To improve coverage we use the Fingerprint Engine to enrich existing thesauri (Cambridge  Math thesaurus, Geobase thesaurus) and develop stand-alone vocabularies (e.g., for the humanities). 


 ---- TOKENS ----

 ['To', 'improve', 'coverage', 'we', 'use', 'the', 'Fingerprint', 'Engine', 'to', 'enrich', 'existing', 'thesauri', '(', 'Cambridge', 'Math', 'thesaurus', ',', 'Geobase', 'thesaurus', ')', 'and', 'develop', 'stand-alone', 'vocabularies', '(', 'e.g.', ',', 'for', 'the', 'humanities', ')', '.'] 

 TOTAL TOKENS ==> 32

 ---- POST ----

 [('To', 'TO'), ('improve', 'VB'), ('coverage', 'NN'), ('we', 'PRP'), ('use', 'VBP'), ('the', 'DT'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('to', 'TO'), ('enrich', 'VB'), ('existing', 'VBG'), ('thesauri', 'NN'), ('(', '('), ('Cambridge', 'NNP'), ('Math', 'NNP'), ('thesaurus', 'NN'), (',', ','), ('Geobase', 'NNP'), ('thesaurus', 'NN'), (')', ')'), ('and', 'CC'), ('develop', 'VB'), ('stand-alone', 'JJ'), ('vocabularies', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('for', 'IN'), ('the', 'DT'), ('humanities', 'NNS'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['improve', 'coverage', 'use', 'Fingerprint', 'Engine', 'enrich', 'existing', 'thesauri', '(', 'Cambridge', 'Math', 'thesaurus', ',', 'Geobase', 'thesaurus', ')', 'develop', 'stand-alone', 'vocabularies', '(', 'e.g.', ',', 'humanities', ')', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('improve', 'VB'), ('coverage', 'NN'), ('use', 'NN'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enrich', 'VBZ'), ('existing', 'VBG'), ('thesauri', 'NN'), ('(', '('), ('Cambridge', 'NNP'), ('Math', 'NNP'), ('thesaurus', 'NN'), (',', ','), ('Geobase', 'NNP'), ('thesaurus', 'NN'), (')', ')'), ('develop', 'VB'), ('stand-alone', 'JJ'), ('vocabularies', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('humanities', 'NNS'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['improve coverage', 'coverage use', 'use Fingerprint', 'Fingerprint Engine', 'Engine enrich', 'enrich existing', 'existing thesauri', 'thesauri (', '( Cambridge', 'Cambridge Math', 'Math thesaurus', 'thesaurus ,', ', Geobase', 'Geobase thesaurus', 'thesaurus )', ') develop', 'develop stand-alone', 'stand-alone vocabularies', 'vocabularies (', '( e.g.', 'e.g. ,', ', humanities', 'humanities )', ') .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['improve coverage use', 'coverage use Fingerprint', 'use Fingerprint Engine', 'Fingerprint Engine enrich', 'Engine enrich existing', 'enrich existing thesauri', 'existing thesauri (', 'thesauri ( Cambridge', '( Cambridge Math', 'Cambridge Math thesaurus', 'Math thesaurus ,', 'thesaurus , Geobase', ', Geobase thesaurus', 'Geobase thesaurus )', 'thesaurus ) develop', ') develop stand-alone', 'develop stand-alone vocabularies', 'stand-alone vocabularies (', 'vocabularies ( e.g.', '( e.g. ,', 'e.g. , humanities', ', humanities )', 'humanities ) .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['coverage', 'use', 'thesauri'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['improv', 'coverag', 'use', 'fingerprint', 'engin', 'enrich', 'exist', 'thesauri', '(', 'cambridg', 'math', 'thesauru', ',', 'geobas', 'thesauru', ')', 'develop', 'stand-alon', 'vocabulari', '(', 'e.g.', ',', 'human', ')', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['improv', 'coverag', 'use', 'fingerprint', 'engin', 'enrich', 'exist', 'thesauri', '(', 'cambridg', 'math', 'thesaurus', ',', 'geobas', 'thesaurus', ')', 'develop', 'stand-alon', 'vocabulari', '(', 'e.g.', ',', 'human', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['improve', 'coverage', 'use', 'Fingerprint', 'Engine', 'enrich', 'existing', 'thesaurus', '(', 'Cambridge', 'Math', 'thesaurus', ',', 'Geobase', 'thesaurus', ')', 'develop', 'stand-alone', 'vocabulary', '(', 'e.g.', ',', 'humanity', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

27 --> 3  In its current standard configuration the Elsevier Fingerprint Engine covers the following domains:  Domain Thesaurus/Vocabulary  Life Sciences MeSH thesaurus  Physics NASA thesaurus  Agriculture NAL thesaurus  Economics Economics vocabulary  Social Sciences Gesis thesaurus  Mathematics Cambridge Math thesaurus, Math vocabulary  Geosciences Geobase thesaurus  Engineering Compendex thesaurus  Humanities Humanities vocabulary  Compounds (Chemistry) Compendex thesaurus, MeSH thesaurus    Subsets of thesauri/vocabularies can be employed, terminology sources provided by institutions can  be implemented. 


 ---- TOKENS ----

 ['3', 'In', 'its', 'current', 'standard', 'configuration', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'covers', 'the', 'following', 'domains', ':', 'Domain', 'Thesaurus/Vocabulary', 'Life', 'Sciences', 'MeSH', 'thesaurus', 'Physics', 'NASA', 'thesaurus', 'Agriculture', 'NAL', 'thesaurus', 'Economics', 'Economics', 'vocabulary', 'Social', 'Sciences', 'Gesis', 'thesaurus', 'Mathematics', 'Cambridge', 'Math', 'thesaurus', ',', 'Math', 'vocabulary', 'Geosciences', 'Geobase', 'thesaurus', 'Engineering', 'Compendex', 'thesaurus', 'Humanities', 'Humanities', 'vocabulary', 'Compounds', '(', 'Chemistry', ')', 'Compendex', 'thesaurus', ',', 'MeSH', 'thesaurus', 'Subsets', 'of', 'thesauri/vocabularies', 'can', 'be', 'employed', ',', 'terminology', 'sources', 'provided', 'by', 'institutions', 'can', 'be', 'implemented', '.'] 

 TOTAL TOKENS ==> 75

 ---- POST ----

 [('3', 'CD'), ('In', 'IN'), ('its', 'PRP$'), ('current', 'JJ'), ('standard', 'NN'), ('configuration', 'NN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('covers', 'VBZ'), ('the', 'DT'), ('following', 'JJ'), ('domains', 'NNS'), (':', ':'), ('Domain', 'NNP'), ('Thesaurus/Vocabulary', 'NNP'), ('Life', 'NNP'), ('Sciences', 'NNPS'), ('MeSH', 'NNP'), ('thesaurus', 'NN'), ('Physics', 'NNP'), ('NASA', 'NNP'), ('thesaurus', 'NN'), ('Agriculture', 'NNP'), ('NAL', 'NNP'), ('thesaurus', 'NN'), ('Economics', 'NNP'), ('Economics', 'NNP'), ('vocabulary', 'JJ'), ('Social', 'NNP'), ('Sciences', 'NNPS'), ('Gesis', 'NNP'), ('thesaurus', 'NN'), ('Mathematics', 'NNP'), ('Cambridge', 'NNP'), ('Math', 'NNP'), ('thesaurus', 'NN'), (',', ','), ('Math', 'NNP'), ('vocabulary', 'JJ'), ('Geosciences', 'NNP'), ('Geobase', 'NNP'), ('thesaurus', 'NN'), ('Engineering', 'NNP'), ('Compendex', 'NNP'), ('thesaurus', 'NN'), ('Humanities', 'NNP'), ('Humanities', 'NNP'), ('vocabulary', 'JJ'), ('Compounds', 'NNP'), ('(', '('), ('Chemistry', 'NNP'), (')', ')'), ('Compendex', 'NNP'), ('thesaurus', 'NN'), (',', ','), ('MeSH', 'NNP'), ('thesaurus', 'NNP'), ('Subsets', 'NNP'), ('of', 'IN'), ('thesauri/vocabularies', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('employed', 'VBN'), (',', ','), ('terminology', 'NN'), ('sources', 'NNS'), ('provided', 'VBN'), ('by', 'IN'), ('institutions', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('implemented', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3', 'current', 'standard', 'configuration', 'Elsevier', 'Fingerprint', 'Engine', 'covers', 'following', 'domains', ':', 'Domain', 'Thesaurus/Vocabulary', 'Life', 'Sciences', 'MeSH', 'thesaurus', 'Physics', 'NASA', 'thesaurus', 'Agriculture', 'NAL', 'thesaurus', 'Economics', 'Economics', 'vocabulary', 'Social', 'Sciences', 'Gesis', 'thesaurus', 'Mathematics', 'Cambridge', 'Math', 'thesaurus', ',', 'Math', 'vocabulary', 'Geosciences', 'Geobase', 'thesaurus', 'Engineering', 'Compendex', 'thesaurus', 'Humanities', 'Humanities', 'vocabulary', 'Compounds', '(', 'Chemistry', ')', 'Compendex', 'thesaurus', ',', 'MeSH', 'thesaurus', 'Subsets', 'thesauri/vocabularies', 'employed', ',', 'terminology', 'sources', 'provided', 'institutions', 'implemented', '.']

 TOTAL FILTERED TOKENS ==>  65

 ---- POST FOR FILTERED TOKENS ----

 [('3', 'CD'), ('current', 'JJ'), ('standard', 'NN'), ('configuration', 'NN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('covers', 'VBZ'), ('following', 'VBG'), ('domains', 'NNS'), (':', ':'), ('Domain', 'NNP'), ('Thesaurus/Vocabulary', 'NNP'), ('Life', 'NNP'), ('Sciences', 'NNPS'), ('MeSH', 'NNP'), ('thesaurus', 'NN'), ('Physics', 'NNP'), ('NASA', 'NNP'), ('thesaurus', 'NN'), ('Agriculture', 'NNP'), ('NAL', 'NNP'), ('thesaurus', 'NN'), ('Economics', 'NNP'), ('Economics', 'NNP'), ('vocabulary', 'JJ'), ('Social', 'NNP'), ('Sciences', 'NNPS'), ('Gesis', 'NNP'), ('thesaurus', 'NN'), ('Mathematics', 'NNP'), ('Cambridge', 'NNP'), ('Math', 'NNP'), ('thesaurus', 'NN'), (',', ','), ('Math', 'NNP'), ('vocabulary', 'JJ'), ('Geosciences', 'NNP'), ('Geobase', 'NNP'), ('thesaurus', 'NN'), ('Engineering', 'NNP'), ('Compendex', 'NNP'), ('thesaurus', 'NN'), ('Humanities', 'NNP'), ('Humanities', 'NNP'), ('vocabulary', 'JJ'), ('Compounds', 'NNP'), ('(', '('), ('Chemistry', 'NNP'), (')', ')'), ('Compendex', 'NNP'), ('thesaurus', 'NN'), (',', ','), ('MeSH', 'NNP'), ('thesaurus', 'NN'), ('Subsets', 'NNP'), ('thesauri/vocabularies', 'VBZ'), ('employed', 'VBN'), (',', ','), ('terminology', 'NN'), ('sources', 'NNS'), ('provided', 'VBD'), ('institutions', 'NNS'), ('implemented', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3 current', 'current standard', 'standard configuration', 'configuration Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine covers', 'covers following', 'following domains', 'domains :', ': Domain', 'Domain Thesaurus/Vocabulary', 'Thesaurus/Vocabulary Life', 'Life Sciences', 'Sciences MeSH', 'MeSH thesaurus', 'thesaurus Physics', 'Physics NASA', 'NASA thesaurus', 'thesaurus Agriculture', 'Agriculture NAL', 'NAL thesaurus', 'thesaurus Economics', 'Economics Economics', 'Economics vocabulary', 'vocabulary Social', 'Social Sciences', 'Sciences Gesis', 'Gesis thesaurus', 'thesaurus Mathematics', 'Mathematics Cambridge', 'Cambridge Math', 'Math thesaurus', 'thesaurus ,', ', Math', 'Math vocabulary', 'vocabulary Geosciences', 'Geosciences Geobase', 'Geobase thesaurus', 'thesaurus Engineering', 'Engineering Compendex', 'Compendex thesaurus', 'thesaurus Humanities', 'Humanities Humanities', 'Humanities vocabulary', 'vocabulary Compounds', 'Compounds (', '( Chemistry', 'Chemistry )', ') Compendex', 'Compendex thesaurus', 'thesaurus ,', ', MeSH', 'MeSH thesaurus', 'thesaurus Subsets', 'Subsets thesauri/vocabularies', 'thesauri/vocabularies employed', 'employed ,', ', terminology', 'terminology sources', 'sources provided', 'provided institutions', 'institutions implemented', 'implemented .'] 

 TOTAL BIGRAMS --> 64 



 ---- TRI-GRAMS ---- 

 ['3 current standard', 'current standard configuration', 'standard configuration Elsevier', 'configuration Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine covers', 'Engine covers following', 'covers following domains', 'following domains :', 'domains : Domain', ': Domain Thesaurus/Vocabulary', 'Domain Thesaurus/Vocabulary Life', 'Thesaurus/Vocabulary Life Sciences', 'Life Sciences MeSH', 'Sciences MeSH thesaurus', 'MeSH thesaurus Physics', 'thesaurus Physics NASA', 'Physics NASA thesaurus', 'NASA thesaurus Agriculture', 'thesaurus Agriculture NAL', 'Agriculture NAL thesaurus', 'NAL thesaurus Economics', 'thesaurus Economics Economics', 'Economics Economics vocabulary', 'Economics vocabulary Social', 'vocabulary Social Sciences', 'Social Sciences Gesis', 'Sciences Gesis thesaurus', 'Gesis thesaurus Mathematics', 'thesaurus Mathematics Cambridge', 'Mathematics Cambridge Math', 'Cambridge Math thesaurus', 'Math thesaurus ,', 'thesaurus , Math', ', Math vocabulary', 'Math vocabulary Geosciences', 'vocabulary Geosciences Geobase', 'Geosciences Geobase thesaurus', 'Geobase thesaurus Engineering', 'thesaurus Engineering Compendex', 'Engineering Compendex thesaurus', 'Compendex thesaurus Humanities', 'thesaurus Humanities Humanities', 'Humanities Humanities vocabulary', 'Humanities vocabulary Compounds', 'vocabulary Compounds (', 'Compounds ( Chemistry', '( Chemistry )', 'Chemistry ) Compendex', ') Compendex thesaurus', 'Compendex thesaurus ,', 'thesaurus , MeSH', ', MeSH thesaurus', 'MeSH thesaurus Subsets', 'thesaurus Subsets thesauri/vocabularies', 'Subsets thesauri/vocabularies employed', 'thesauri/vocabularies employed ,', 'employed , terminology', ', terminology sources', 'terminology sources provided', 'sources provided institutions', 'provided institutions implemented', 'institutions implemented .'] 

 TOTAL TRIGRAMS --> 63 



 ---- NOUN PHRASES ---- 

 ['current standard', 'configuration', 'thesaurus', 'thesaurus', 'thesaurus', 'thesaurus', 'thesaurus', 'thesaurus', 'thesaurus', 'thesaurus', 'thesaurus', 'terminology'] 

 TOTAL NOUN PHRASES --> 12 



 ---- NER ----

 
 ORGANIZATION ---> ['MeSH', 'NASA', 'Social Sciences Gesis', 'Compounds', 'Compendex', 'MeSH']
 TOTAL ORGANIZATION ENTITY --> 6 


 PERSON ---> ['Elsevier Fingerprint Engine', 'Domain', 'Physics', 'Agriculture NAL', 'Economics Economics', 'Mathematics Cambridge Math', 'Math', 'Humanities Humanities', 'Subsets']
 TOTAL PERSON ENTITY --> 9 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3', 'current', 'standard', 'configur', 'elsevi', 'fingerprint', 'engin', 'cover', 'follow', 'domain', ':', 'domain', 'thesaurus/vocabulari', 'life', 'scienc', 'mesh', 'thesauru', 'physic', 'nasa', 'thesauru', 'agricultur', 'nal', 'thesauru', 'econom', 'econom', 'vocabulari', 'social', 'scienc', 'gesi', 'thesauru', 'mathemat', 'cambridg', 'math', 'thesauru', ',', 'math', 'vocabulari', 'geoscienc', 'geobas', 'thesauru', 'engin', 'compendex', 'thesauru', 'human', 'human', 'vocabulari', 'compound', '(', 'chemistri', ')', 'compendex', 'thesauru', ',', 'mesh', 'thesauru', 'subset', 'thesauri/vocabulari', 'employ', ',', 'terminolog', 'sourc', 'provid', 'institut', 'implement', '.']

 TOTAL PORTER STEM WORDS ==> 65



 ---- SNOWBALL STEMMING ----

['3', 'current', 'standard', 'configur', 'elsevi', 'fingerprint', 'engin', 'cover', 'follow', 'domain', ':', 'domain', 'thesaurus/vocabulari', 'life', 'scienc', 'mesh', 'thesaurus', 'physic', 'nasa', 'thesaurus', 'agricultur', 'nal', 'thesaurus', 'econom', 'econom', 'vocabulari', 'social', 'scienc', 'gesi', 'thesaurus', 'mathemat', 'cambridg', 'math', 'thesaurus', ',', 'math', 'vocabulari', 'geoscienc', 'geobas', 'thesaurus', 'engin', 'compendex', 'thesaurus', 'human', 'human', 'vocabulari', 'compound', '(', 'chemistri', ')', 'compendex', 'thesaurus', ',', 'mesh', 'thesaurus', 'subset', 'thesauri/vocabulari', 'employ', ',', 'terminolog', 'sourc', 'provid', 'institut', 'implement', '.']

 TOTAL SNOWBALL STEM WORDS ==> 65



 ---- LEMMATIZATION ----

['3', 'current', 'standard', 'configuration', 'Elsevier', 'Fingerprint', 'Engine', 'cover', 'following', 'domain', ':', 'Domain', 'Thesaurus/Vocabulary', 'Life', 'Sciences', 'MeSH', 'thesaurus', 'Physics', 'NASA', 'thesaurus', 'Agriculture', 'NAL', 'thesaurus', 'Economics', 'Economics', 'vocabulary', 'Social', 'Sciences', 'Gesis', 'thesaurus', 'Mathematics', 'Cambridge', 'Math', 'thesaurus', ',', 'Math', 'vocabulary', 'Geosciences', 'Geobase', 'thesaurus', 'Engineering', 'Compendex', 'thesaurus', 'Humanities', 'Humanities', 'vocabulary', 'Compounds', '(', 'Chemistry', ')', 'Compendex', 'thesaurus', ',', 'MeSH', 'thesaurus', 'Subsets', 'thesauri/vocabularies', 'employed', ',', 'terminology', 'source', 'provided', 'institution', 'implemented', '.']

 TOTAL LEMMATIZE WORDS ==> 65

************************************************************************************************************************

28 --> Thesauri and vocabularies are continuously updated and enhanced. 


 ---- TOKENS ----

 ['Thesauri', 'and', 'vocabularies', 'are', 'continuously', 'updated', 'and', 'enhanced', '.'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('Thesauri', 'NNP'), ('and', 'CC'), ('vocabularies', 'NNS'), ('are', 'VBP'), ('continuously', 'RB'), ('updated', 'VBN'), ('and', 'CC'), ('enhanced', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Thesauri', 'vocabularies', 'continuously', 'updated', 'enhanced', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('Thesauri', 'NNP'), ('vocabularies', 'NNS'), ('continuously', 'RB'), ('updated', 'VBD'), ('enhanced', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Thesauri vocabularies', 'vocabularies continuously', 'continuously updated', 'updated enhanced', 'enhanced .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['Thesauri vocabularies continuously', 'vocabularies continuously updated', 'continuously updated enhanced', 'updated enhanced .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['thesauri', 'vocabulari', 'continu', 'updat', 'enhanc', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['thesauri', 'vocabulari', 'continu', 'updat', 'enhanc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['Thesauri', 'vocabulary', 'continuously', 'updated', 'enhanced', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

29 --> 1. 


 ---- TOKENS ----

 ['1', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

30 --> A look inside the Elsevier Fingerprint Engine  1.1. 


 ---- TOKENS ----

 ['A', 'look', 'inside', 'the', 'Elsevier', 'Fingerprint', 'Engine', '1.1', '.'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('A', 'DT'), ('look', 'NN'), ('inside', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('1.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['look', 'inside', 'Elsevier', 'Fingerprint', 'Engine', '1.1', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('look', 'NN'), ('inside', 'IN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('1.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['look inside', 'inside Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine 1.1', '1.1 .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['look inside Elsevier', 'inside Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine 1.1', 'Engine 1.1 .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['look'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['look', 'insid', 'elsevi', 'fingerprint', 'engin', '1.1', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['look', 'insid', 'elsevi', 'fingerprint', 'engin', '1.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['look', 'inside', 'Elsevier', 'Fingerprint', 'Engine', '1.1', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

31 --> Workflow: Fingerprinting  The Elsevier Fingerprint Engine identifies relevant technical concepts in a text based on a thesaurus  or vocabulary. 


 ---- TOKENS ----

 ['Workflow', ':', 'Fingerprinting', 'The', 'Elsevier', 'Fingerprint', 'Engine', 'identifies', 'relevant', 'technical', 'concepts', 'in', 'a', 'text', 'based', 'on', 'a', 'thesaurus', 'or', 'vocabulary', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Workflow', 'IN'), (':', ':'), ('Fingerprinting', 'VBG'), ('The', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('identifies', 'NNS'), ('relevant', 'VBP'), ('technical', 'JJ'), ('concepts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('text', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('thesaurus', 'NN'), ('or', 'CC'), ('vocabulary', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Workflow', ':', 'Fingerprinting', 'Elsevier', 'Fingerprint', 'Engine', 'identifies', 'relevant', 'technical', 'concepts', 'text', 'based', 'thesaurus', 'vocabulary', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Workflow', 'IN'), (':', ':'), ('Fingerprinting', 'VBG'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('identifies', 'NNS'), ('relevant', 'VBP'), ('technical', 'JJ'), ('concepts', 'NNS'), ('text', 'VBP'), ('based', 'VBN'), ('thesaurus', 'NN'), ('vocabulary', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Workflow :', ': Fingerprinting', 'Fingerprinting Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine identifies', 'identifies relevant', 'relevant technical', 'technical concepts', 'concepts text', 'text based', 'based thesaurus', 'thesaurus vocabulary', 'vocabulary .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Workflow : Fingerprinting', ': Fingerprinting Elsevier', 'Fingerprinting Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine identifies', 'Engine identifies relevant', 'identifies relevant technical', 'relevant technical concepts', 'technical concepts text', 'concepts text based', 'text based thesaurus', 'based thesaurus vocabulary', 'thesaurus vocabulary .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['thesaurus', 'vocabulary'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['workflow', ':', 'fingerprint', 'elsevi', 'fingerprint', 'engin', 'identifi', 'relev', 'technic', 'concept', 'text', 'base', 'thesauru', 'vocabulari', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['workflow', ':', 'fingerprint', 'elsevi', 'fingerprint', 'engin', 'identifi', 'relev', 'technic', 'concept', 'text', 'base', 'thesaurus', 'vocabulari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Workflow', ':', 'Fingerprinting', 'Elsevier', 'Fingerprint', 'Engine', 'identifies', 'relevant', 'technical', 'concept', 'text', 'based', 'thesaurus', 'vocabulary', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

32 --> The concept finding algorithm is sensitive to lexical and grammatical features - casing, word order,  part-of-speech and others - when it must be - e.g., to distinguish Windows(®) from windows, the noun  from the verb ‘lead', etc. 


 ---- TOKENS ----

 ['The', 'concept', 'finding', 'algorithm', 'is', 'sensitive', 'to', 'lexical', 'and', 'grammatical', 'features', '-', 'casing', ',', 'word', 'order', ',', 'part-of-speech', 'and', 'others', '-', 'when', 'it', 'must', 'be', '-', 'e.g.', ',', 'to', 'distinguish', 'Windows', '(', '®', ')', 'from', 'windows', ',', 'the', 'noun', 'from', 'the', 'verb', '‘', 'lead', "'", ',', 'etc', '.'] 

 TOTAL TOKENS ==> 48

 ---- POST ----

 [('The', 'DT'), ('concept', 'NN'), ('finding', 'VBG'), ('algorithm', 'NN'), ('is', 'VBZ'), ('sensitive', 'JJ'), ('to', 'TO'), ('lexical', 'JJ'), ('and', 'CC'), ('grammatical', 'JJ'), ('features', 'NNS'), ('-', ':'), ('casing', 'NN'), (',', ','), ('word', 'NN'), ('order', 'NN'), (',', ','), ('part-of-speech', 'NN'), ('and', 'CC'), ('others', 'NNS'), ('-', ':'), ('when', 'WRB'), ('it', 'PRP'), ('must', 'MD'), ('be', 'VB'), ('-', ':'), ('e.g.', 'NN'), (',', ','), ('to', 'TO'), ('distinguish', 'VB'), ('Windows', 'NNP'), ('(', '('), ('®', 'NNP'), (')', ')'), ('from', 'IN'), ('windows', 'NNS'), (',', ','), ('the', 'DT'), ('noun', 'NN'), ('from', 'IN'), ('the', 'DT'), ('verb', 'NN'), ('‘', 'NNP'), ('lead', 'NN'), ("'", "''"), (',', ','), ('etc', 'FW'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['concept', 'finding', 'algorithm', 'sensitive', 'lexical', 'grammatical', 'features', '-', 'casing', ',', 'word', 'order', ',', 'part-of-speech', 'others', '-', 'must', '-', 'e.g.', ',', 'distinguish', 'Windows', '(', '®', ')', 'windows', ',', 'noun', 'verb', '‘', 'lead', "'", ',', 'etc', '.']

 TOTAL FILTERED TOKENS ==>  35

 ---- POST FOR FILTERED TOKENS ----

 [('concept', 'NN'), ('finding', 'VBG'), ('algorithm', 'JJ'), ('sensitive', 'JJ'), ('lexical', 'JJ'), ('grammatical', 'NN'), ('features', 'NNS'), ('-', ':'), ('casing', 'NN'), (',', ','), ('word', 'NN'), ('order', 'NN'), (',', ','), ('part-of-speech', 'JJ'), ('others', 'NNS'), ('-', ':'), ('must', 'MD'), ('-', ':'), ('e.g.', 'NN'), (',', ','), ('distinguish', 'JJ'), ('Windows', 'NNP'), ('(', '('), ('®', 'NNP'), (')', ')'), ('windows', 'VBZ'), (',', ','), ('noun', 'JJ'), ('verb', 'NN'), ('‘', 'NNP'), ('lead', 'NN'), ("'", "''"), (',', ','), ('etc', 'FW'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['concept finding', 'finding algorithm', 'algorithm sensitive', 'sensitive lexical', 'lexical grammatical', 'grammatical features', 'features -', '- casing', 'casing ,', ', word', 'word order', 'order ,', ', part-of-speech', 'part-of-speech others', 'others -', '- must', 'must -', '- e.g.', 'e.g. ,', ', distinguish', 'distinguish Windows', 'Windows (', '( ®', '® )', ') windows', 'windows ,', ', noun', 'noun verb', 'verb ‘', '‘ lead', "lead '", "' ,", ', etc', 'etc .'] 

 TOTAL BIGRAMS --> 34 



 ---- TRI-GRAMS ---- 

 ['concept finding algorithm', 'finding algorithm sensitive', 'algorithm sensitive lexical', 'sensitive lexical grammatical', 'lexical grammatical features', 'grammatical features -', 'features - casing', '- casing ,', 'casing , word', ', word order', 'word order ,', 'order , part-of-speech', ', part-of-speech others', 'part-of-speech others -', 'others - must', '- must -', 'must - e.g.', '- e.g. ,', 'e.g. , distinguish', ', distinguish Windows', 'distinguish Windows (', 'Windows ( ®', '( ® )', '® ) windows', ') windows ,', 'windows , noun', ', noun verb', 'noun verb ‘', 'verb ‘ lead', "‘ lead '", "lead ' ,", "' , etc", ', etc .'] 

 TOTAL TRIGRAMS --> 33 



 ---- NOUN PHRASES ---- 

 ['concept', 'algorithm sensitive lexical grammatical', 'casing', 'word', 'order', 'e.g.', 'noun verb', 'lead'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['concept', 'find', 'algorithm', 'sensit', 'lexic', 'grammat', 'featur', '-', 'case', ',', 'word', 'order', ',', 'part-of-speech', 'other', '-', 'must', '-', 'e.g.', ',', 'distinguish', 'window', '(', '®', ')', 'window', ',', 'noun', 'verb', '‘', 'lead', "'", ',', 'etc', '.']

 TOTAL PORTER STEM WORDS ==> 35



 ---- SNOWBALL STEMMING ----

['concept', 'find', 'algorithm', 'sensit', 'lexic', 'grammat', 'featur', '-', 'case', ',', 'word', 'order', ',', 'part-of-speech', 'other', '-', 'must', '-', 'e.g.', ',', 'distinguish', 'window', '(', '®', ')', 'window', ',', 'noun', 'verb', '‘', 'lead', "'", ',', 'etc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 35



 ---- LEMMATIZATION ----

['concept', 'finding', 'algorithm', 'sensitive', 'lexical', 'grammatical', 'feature', '-', 'casing', ',', 'word', 'order', ',', 'part-of-speech', 'others', '-', 'must', '-', 'e.g.', ',', 'distinguish', 'Windows', '(', '®', ')', 'window', ',', 'noun', 'verb', '‘', 'lead', "'", ',', 'etc', '.']

 TOTAL LEMMATIZE WORDS ==> 35

************************************************************************************************************************

33 --> At the same time it ignores differences when they have no meaning - e.g.,  the differences between 'tumour' and 'tumor', between 'kidney failure' and 'failure of the kidney' etc. 


 ---- TOKENS ----

 ['At', 'the', 'same', 'time', 'it', 'ignores', 'differences', 'when', 'they', 'have', 'no', 'meaning', '-', 'e.g.', ',', 'the', 'differences', 'between', "'tumour", "'", 'and', "'tumor", "'", ',', 'between', "'kidney", 'failure', "'", 'and', "'failure", 'of', 'the', 'kidney', "'", 'etc', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('At', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('time', 'NN'), ('it', 'PRP'), ('ignores', 'VBZ'), ('differences', 'NNS'), ('when', 'WRB'), ('they', 'PRP'), ('have', 'VBP'), ('no', 'DT'), ('meaning', 'NN'), ('-', ':'), ('e.g.', 'NN'), (',', ','), ('the', 'DT'), ('differences', 'NNS'), ('between', 'IN'), ("'tumour", 'POS'), ("'", 'POS'), ('and', 'CC'), ("'tumor", 'NNP'), ("'", "''"), (',', ','), ('between', 'IN'), ("'kidney", 'POS'), ('failure', 'NN'), ("'", "''"), ('and', 'CC'), ("'failure", 'CD'), ('of', 'IN'), ('the', 'DT'), ('kidney', 'NN'), ("'", 'POS'), ('etc', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['time', 'ignores', 'differences', 'meaning', '-', 'e.g.', ',', 'differences', "'tumour", "'", "'tumor", "'", ',', "'kidney", 'failure', "'", "'failure", 'kidney', "'", 'etc', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('time', 'NN'), ('ignores', 'NNS'), ('differences', 'NNS'), ('meaning', 'VBG'), ('-', ':'), ('e.g.', 'NN'), (',', ','), ('differences', 'VBZ'), ("'tumour", 'POS'), ("'", "''"), ("'tumor", 'NN'), ("'", "''"), (',', ','), ("'kidney", "''"), ('failure', 'NN'), ("'", "''"), ("'failure", 'JJ'), ('kidney', 'NN'), ("'", 'POS'), ('etc', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['time ignores', 'ignores differences', 'differences meaning', 'meaning -', '- e.g.', 'e.g. ,', ', differences', "differences 'tumour", "'tumour '", "' 'tumor", "'tumor '", "' ,", ", 'kidney", "'kidney failure", "failure '", "' 'failure", "'failure kidney", "kidney '", "' etc", 'etc .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['time ignores differences', 'ignores differences meaning', 'differences meaning -', 'meaning - e.g.', '- e.g. ,', 'e.g. , differences', ", differences 'tumour", "differences 'tumour '", "'tumour ' 'tumor", "' 'tumor '", "'tumor ' ,", "' , 'kidney", ", 'kidney failure", "'kidney failure '", "failure ' 'failure", "' 'failure kidney", "'failure kidney '", "kidney ' etc", "' etc ."] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['time', 'e.g.', "'tumor", 'failure', "'failure kidney", 'etc'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['time', 'ignor', 'differ', 'mean', '-', 'e.g.', ',', 'differ', "'tumour", "'", "'tumor", "'", ',', "'kidney", 'failur', "'", "'failur", 'kidney', "'", 'etc', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['time', 'ignor', 'differ', 'mean', '-', 'e.g.', ',', 'differ', 'tumour', "'", 'tumor', "'", ',', 'kidney', 'failur', "'", 'failur', 'kidney', "'", 'etc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['time', 'ignores', 'difference', 'meaning', '-', 'e.g.', ',', 'difference', "'tumour", "'", "'tumor", "'", ',', "'kidney", 'failure', "'", "'failure", 'kidney', "'", 'etc', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

34 --> In addition, concept finding takes into account the context of terms. 


 ---- TOKENS ----

 ['In', 'addition', ',', 'concept', 'finding', 'takes', 'into', 'account', 'the', 'context', 'of', 'terms', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('concept', 'NN'), ('finding', 'VBG'), ('takes', 'VBZ'), ('into', 'IN'), ('account', 'NN'), ('the', 'DT'), ('context', 'NN'), ('of', 'IN'), ('terms', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['addition', ',', 'concept', 'finding', 'takes', 'account', 'context', 'terms', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('addition', 'NN'), (',', ','), ('concept', 'NN'), ('finding', 'VBG'), ('takes', 'VBZ'), ('account', 'NN'), ('context', 'NN'), ('terms', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['addition ,', ', concept', 'concept finding', 'finding takes', 'takes account', 'account context', 'context terms', 'terms .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['addition , concept', ', concept finding', 'concept finding takes', 'finding takes account', 'takes account context', 'account context terms', 'context terms .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['addition', 'concept', 'account', 'context'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['addit', ',', 'concept', 'find', 'take', 'account', 'context', 'term', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['addit', ',', 'concept', 'find', 'take', 'account', 'context', 'term', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['addition', ',', 'concept', 'finding', 'take', 'account', 'context', 'term', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

35 --> It looks at their neighbors and will,  e.g., not identify a “non-Hodgkin Lymphoma” as a Hodgkin Lymphoma or the ' tree of human ancestry'  as a plant, but also at their wider environment and will, e.g., not interpret 'administration' as  management in a text about a drug as a treatment for a disease. 


 ---- TOKENS ----

 ['It', 'looks', 'at', 'their', 'neighbors', 'and', 'will', ',', 'e.g.', ',', 'not', 'identify', 'a', '“', 'non-Hodgkin', 'Lymphoma', '”', 'as', 'a', 'Hodgkin', 'Lymphoma', 'or', 'the', "'", 'tree', 'of', 'human', 'ancestry', "'", 'as', 'a', 'plant', ',', 'but', 'also', 'at', 'their', 'wider', 'environment', 'and', 'will', ',', 'e.g.', ',', 'not', 'interpret', "'administration", "'", 'as', 'management', 'in', 'a', 'text', 'about', 'a', 'drug', 'as', 'a', 'treatment', 'for', 'a', 'disease', '.'] 

 TOTAL TOKENS ==> 63

 ---- POST ----

 [('It', 'PRP'), ('looks', 'VBZ'), ('at', 'IN'), ('their', 'PRP$'), ('neighbors', 'NNS'), ('and', 'CC'), ('will', 'MD'), (',', ','), ('e.g.', 'VB'), (',', ','), ('not', 'RB'), ('identify', 'VB'), ('a', 'DT'), ('“', 'JJ'), ('non-Hodgkin', 'JJ'), ('Lymphoma', 'NNP'), ('”', 'NNP'), ('as', 'IN'), ('a', 'DT'), ('Hodgkin', 'NNP'), ('Lymphoma', 'NNP'), ('or', 'CC'), ('the', 'DT'), ("'", "''"), ('tree', 'NN'), ('of', 'IN'), ('human', 'JJ'), ('ancestry', 'NN'), ("'", "''"), ('as', 'IN'), ('a', 'DT'), ('plant', 'NN'), (',', ','), ('but', 'CC'), ('also', 'RB'), ('at', 'IN'), ('their', 'PRP$'), ('wider', 'NN'), ('environment', 'NN'), ('and', 'CC'), ('will', 'MD'), (',', ','), ('e.g.', 'VB'), (',', ','), ('not', 'RB'), ('interpret', 'JJ'), ("'administration", 'NN'), ("'", 'POS'), ('as', 'IN'), ('management', 'NN'), ('in', 'IN'), ('a', 'DT'), ('text', 'NN'), ('about', 'IN'), ('a', 'DT'), ('drug', 'NN'), ('as', 'IN'), ('a', 'DT'), ('treatment', 'NN'), ('for', 'IN'), ('a', 'DT'), ('disease', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['looks', 'neighbors', ',', 'e.g.', ',', 'identify', '“', 'non-Hodgkin', 'Lymphoma', '”', 'Hodgkin', 'Lymphoma', "'", 'tree', 'human', 'ancestry', "'", 'plant', ',', 'also', 'wider', 'environment', ',', 'e.g.', ',', 'interpret', "'administration", "'", 'management', 'text', 'drug', 'treatment', 'disease', '.']

 TOTAL FILTERED TOKENS ==>  34

 ---- POST FOR FILTERED TOKENS ----

 [('looks', 'VBZ'), ('neighbors', 'NNS'), (',', ','), ('e.g.', 'NN'), (',', ','), ('identify', 'VB'), ('“', 'JJ'), ('non-Hodgkin', 'JJ'), ('Lymphoma', 'NNP'), ('”', 'NNP'), ('Hodgkin', 'NNP'), ('Lymphoma', 'NNP'), ("'", 'POS'), ('tree', 'JJ'), ('human', 'JJ'), ('ancestry', 'NN'), ("'", "''"), ('plant', 'NN'), (',', ','), ('also', 'RB'), ('wider', 'RBR'), ('environment', 'NN'), (',', ','), ('e.g.', 'NN'), (',', ','), ('interpret', 'JJ'), ("'administration", 'NN'), ("'", 'POS'), ('management', 'NN'), ('text', 'JJ'), ('drug', 'NN'), ('treatment', 'NN'), ('disease', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['looks neighbors', 'neighbors ,', ', e.g.', 'e.g. ,', ', identify', 'identify “', '“ non-Hodgkin', 'non-Hodgkin Lymphoma', 'Lymphoma ”', '” Hodgkin', 'Hodgkin Lymphoma', "Lymphoma '", "' tree", 'tree human', 'human ancestry', "ancestry '", "' plant", 'plant ,', ', also', 'also wider', 'wider environment', 'environment ,', ', e.g.', 'e.g. ,', ', interpret', "interpret 'administration", "'administration '", "' management", 'management text', 'text drug', 'drug treatment', 'treatment disease', 'disease .'] 

 TOTAL BIGRAMS --> 33 



 ---- TRI-GRAMS ---- 

 ['looks neighbors ,', 'neighbors , e.g.', ', e.g. ,', 'e.g. , identify', ', identify “', 'identify “ non-Hodgkin', '“ non-Hodgkin Lymphoma', 'non-Hodgkin Lymphoma ”', 'Lymphoma ” Hodgkin', '” Hodgkin Lymphoma', "Hodgkin Lymphoma '", "Lymphoma ' tree", "' tree human", 'tree human ancestry', "human ancestry '", "ancestry ' plant", "' plant ,", 'plant , also', ', also wider', 'also wider environment', 'wider environment ,', 'environment , e.g.', ', e.g. ,', 'e.g. , interpret', ", interpret 'administration", "interpret 'administration '", "'administration ' management", "' management text", 'management text drug', 'text drug treatment', 'drug treatment disease', 'treatment disease .'] 

 TOTAL TRIGRAMS --> 32 



 ---- NOUN PHRASES ---- 

 ['e.g.', 'tree human ancestry', 'plant', 'environment', 'e.g.', "interpret 'administration", 'management', 'text drug', 'treatment', 'disease'] 

 TOTAL NOUN PHRASES --> 10 



 ---- NER ----

 
 ORGANIZATION ---> ['Lymphoma']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Hodgkin Lymphoma']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['look', 'neighbor', ',', 'e.g.', ',', 'identifi', '“', 'non-hodgkin', 'lymphoma', '”', 'hodgkin', 'lymphoma', "'", 'tree', 'human', 'ancestri', "'", 'plant', ',', 'also', 'wider', 'environ', ',', 'e.g.', ',', 'interpret', "'administr", "'", 'manag', 'text', 'drug', 'treatment', 'diseas', '.']

 TOTAL PORTER STEM WORDS ==> 34



 ---- SNOWBALL STEMMING ----

['look', 'neighbor', ',', 'e.g.', ',', 'identifi', '“', 'non-hodgkin', 'lymphoma', '”', 'hodgkin', 'lymphoma', "'", 'tree', 'human', 'ancestri', "'", 'plant', ',', 'also', 'wider', 'environ', ',', 'e.g.', ',', 'interpret', 'administr', "'", 'manag', 'text', 'drug', 'treatment', 'diseas', '.']

 TOTAL SNOWBALL STEM WORDS ==> 34



 ---- LEMMATIZATION ----

['look', 'neighbor', ',', 'e.g.', ',', 'identify', '“', 'non-Hodgkin', 'Lymphoma', '”', 'Hodgkin', 'Lymphoma', "'", 'tree', 'human', 'ancestry', "'", 'plant', ',', 'also', 'wider', 'environment', ',', 'e.g.', ',', 'interpret', "'administration", "'", 'management', 'text', 'drug', 'treatment', 'disease', '.']

 TOTAL LEMMATIZE WORDS ==> 34

************************************************************************************************************************

36 --> Concepts found in documents are weighted according to their frequency, their occurrence in a text's  title or text body and, in a recent solution for Funding Opportunity Announcements, according to their  occurrence in automatically detected subsections of a text's body. 


 ---- TOKENS ----

 ['Concepts', 'found', 'in', 'documents', 'are', 'weighted', 'according', 'to', 'their', 'frequency', ',', 'their', 'occurrence', 'in', 'a', 'text', "'s", 'title', 'or', 'text', 'body', 'and', ',', 'in', 'a', 'recent', 'solution', 'for', 'Funding', 'Opportunity', 'Announcements', ',', 'according', 'to', 'their', 'occurrence', 'in', 'automatically', 'detected', 'subsections', 'of', 'a', 'text', "'s", 'body', '.'] 

 TOTAL TOKENS ==> 46

 ---- POST ----

 [('Concepts', 'NNS'), ('found', 'VBN'), ('in', 'IN'), ('documents', 'NNS'), ('are', 'VBP'), ('weighted', 'JJ'), ('according', 'VBG'), ('to', 'TO'), ('their', 'PRP$'), ('frequency', 'NN'), (',', ','), ('their', 'PRP$'), ('occurrence', 'NN'), ('in', 'IN'), ('a', 'DT'), ('text', 'NN'), ("'s", 'POS'), ('title', 'NN'), ('or', 'CC'), ('text', 'NN'), ('body', 'NN'), ('and', 'CC'), (',', ','), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('solution', 'NN'), ('for', 'IN'), ('Funding', 'NNP'), ('Opportunity', 'NNP'), ('Announcements', 'NNP'), (',', ','), ('according', 'VBG'), ('to', 'TO'), ('their', 'PRP$'), ('occurrence', 'NN'), ('in', 'IN'), ('automatically', 'RB'), ('detected', 'JJ'), ('subsections', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('text', 'NN'), ("'s", 'POS'), ('body', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Concepts', 'found', 'documents', 'weighted', 'according', 'frequency', ',', 'occurrence', 'text', "'s", 'title', 'text', 'body', ',', 'recent', 'solution', 'Funding', 'Opportunity', 'Announcements', ',', 'according', 'occurrence', 'automatically', 'detected', 'subsections', 'text', "'s", 'body', '.']

 TOTAL FILTERED TOKENS ==>  29

 ---- POST FOR FILTERED TOKENS ----

 [('Concepts', 'NNS'), ('found', 'VBD'), ('documents', 'NNS'), ('weighted', 'JJ'), ('according', 'VBG'), ('frequency', 'NN'), (',', ','), ('occurrence', 'NN'), ('text', 'NN'), ("'s", 'POS'), ('title', 'NN'), ('text', 'NN'), ('body', 'NN'), (',', ','), ('recent', 'JJ'), ('solution', 'NN'), ('Funding', 'NNP'), ('Opportunity', 'NNP'), ('Announcements', 'NNP'), (',', ','), ('according', 'VBG'), ('occurrence', 'NN'), ('automatically', 'RB'), ('detected', 'VBD'), ('subsections', 'NNS'), ('text', 'NN'), ("'s", 'POS'), ('body', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Concepts found', 'found documents', 'documents weighted', 'weighted according', 'according frequency', 'frequency ,', ', occurrence', 'occurrence text', "text 's", "'s title", 'title text', 'text body', 'body ,', ', recent', 'recent solution', 'solution Funding', 'Funding Opportunity', 'Opportunity Announcements', 'Announcements ,', ', according', 'according occurrence', 'occurrence automatically', 'automatically detected', 'detected subsections', 'subsections text', "text 's", "'s body", 'body .'] 

 TOTAL BIGRAMS --> 28 



 ---- TRI-GRAMS ---- 

 ['Concepts found documents', 'found documents weighted', 'documents weighted according', 'weighted according frequency', 'according frequency ,', 'frequency , occurrence', ', occurrence text', "occurrence text 's", "text 's title", "'s title text", 'title text body', 'text body ,', 'body , recent', ', recent solution', 'recent solution Funding', 'solution Funding Opportunity', 'Funding Opportunity Announcements', 'Opportunity Announcements ,', 'Announcements , according', ', according occurrence', 'according occurrence automatically', 'occurrence automatically detected', 'automatically detected subsections', 'detected subsections text', "subsections text 's", "text 's body", "'s body ."] 

 TOTAL TRIGRAMS --> 27 



 ---- NOUN PHRASES ---- 

 ['frequency', 'occurrence', 'text', 'title', 'text', 'body', 'recent solution', 'occurrence', 'text', 'body'] 

 TOTAL NOUN PHRASES --> 10 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['concept', 'found', 'document', 'weight', 'accord', 'frequenc', ',', 'occurr', 'text', "'s", 'titl', 'text', 'bodi', ',', 'recent', 'solut', 'fund', 'opportun', 'announc', ',', 'accord', 'occurr', 'automat', 'detect', 'subsect', 'text', "'s", 'bodi', '.']

 TOTAL PORTER STEM WORDS ==> 29



 ---- SNOWBALL STEMMING ----

['concept', 'found', 'document', 'weight', 'accord', 'frequenc', ',', 'occurr', 'text', "'s", 'titl', 'text', 'bodi', ',', 'recent', 'solut', 'fund', 'opportun', 'announc', ',', 'accord', 'occurr', 'automat', 'detect', 'subsect', 'text', "'s", 'bodi', '.']

 TOTAL SNOWBALL STEM WORDS ==> 29



 ---- LEMMATIZATION ----

['Concepts', 'found', 'document', 'weighted', 'according', 'frequency', ',', 'occurrence', 'text', "'s", 'title', 'text', 'body', ',', 'recent', 'solution', 'Funding', 'Opportunity', 'Announcements', ',', 'according', 'occurrence', 'automatically', 'detected', 'subsection', 'text', "'s", 'body', '.']

 TOTAL LEMMATIZE WORDS ==> 29

************************************************************************************************************************

37 --> The most highly ranked or all ranked concepts of document fingerprints can be aggregated to profiles  of individual researchers, institutions, regions etc. 


 ---- TOKENS ----

 ['The', 'most', 'highly', 'ranked', 'or', 'all', 'ranked', 'concepts', 'of', 'document', 'fingerprints', 'can', 'be', 'aggregated', 'to', 'profiles', 'of', 'individual', 'researchers', ',', 'institutions', ',', 'regions', 'etc', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('The', 'DT'), ('most', 'RBS'), ('highly', 'RB'), ('ranked', 'VBD'), ('or', 'CC'), ('all', 'DT'), ('ranked', 'JJ'), ('concepts', 'NNS'), ('of', 'IN'), ('document', 'NN'), ('fingerprints', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('aggregated', 'VBN'), ('to', 'TO'), ('profiles', 'NNS'), ('of', 'IN'), ('individual', 'JJ'), ('researchers', 'NNS'), (',', ','), ('institutions', 'NNS'), (',', ','), ('regions', 'NNS'), ('etc', 'VBP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['highly', 'ranked', 'ranked', 'concepts', 'document', 'fingerprints', 'aggregated', 'profiles', 'individual', 'researchers', ',', 'institutions', ',', 'regions', 'etc', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('highly', 'RB'), ('ranked', 'VBN'), ('ranked', 'JJ'), ('concepts', 'NNS'), ('document', 'JJ'), ('fingerprints', 'NNS'), ('aggregated', 'VBD'), ('profiles', 'NNS'), ('individual', 'JJ'), ('researchers', 'NNS'), (',', ','), ('institutions', 'NNS'), (',', ','), ('regions', 'NNS'), ('etc', 'VBP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['highly ranked', 'ranked ranked', 'ranked concepts', 'concepts document', 'document fingerprints', 'fingerprints aggregated', 'aggregated profiles', 'profiles individual', 'individual researchers', 'researchers ,', ', institutions', 'institutions ,', ', regions', 'regions etc', 'etc .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['highly ranked ranked', 'ranked ranked concepts', 'ranked concepts document', 'concepts document fingerprints', 'document fingerprints aggregated', 'fingerprints aggregated profiles', 'aggregated profiles individual', 'profiles individual researchers', 'individual researchers ,', 'researchers , institutions', ', institutions ,', 'institutions , regions', ', regions etc', 'regions etc .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['highli', 'rank', 'rank', 'concept', 'document', 'fingerprint', 'aggreg', 'profil', 'individu', 'research', ',', 'institut', ',', 'region', 'etc', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['high', 'rank', 'rank', 'concept', 'document', 'fingerprint', 'aggreg', 'profil', 'individu', 'research', ',', 'institut', ',', 'region', 'etc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['highly', 'ranked', 'ranked', 'concept', 'document', 'fingerprint', 'aggregated', 'profile', 'individual', 'researcher', ',', 'institution', ',', 'region', 'etc', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

38 --> (see above). 


 ---- TOKENS ----

 ['(', 'see', 'above', ')', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('(', '('), ('see', 'VB'), ('above', 'IN'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['(', 'see', ')', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('(', '('), ('see', 'NN'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['( see', 'see )', ') .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['( see )', 'see ) .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['(', 'see', ')', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['(', 'see', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['(', 'see', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

39 --> So-called Named Entities like the names of people ('John O'Keefe') and places ('Philadelphia,  Pennsylvania') are identified and disambiguated across thesauri and vocabularies and can be  presented separated from fingerprints proper. 


 ---- TOKENS ----

 ['So-called', 'Named', 'Entities', 'like', 'the', 'names', 'of', 'people', '(', "'John", "O'Keefe", "'", ')', 'and', 'places', '(', "'Philadelphia", ',', 'Pennsylvania', "'", ')', 'are', 'identified', 'and', 'disambiguated', 'across', 'thesauri', 'and', 'vocabularies', 'and', 'can', 'be', 'presented', 'separated', 'from', 'fingerprints', 'proper', '.'] 

 TOTAL TOKENS ==> 38

 ---- POST ----

 [('So-called', 'JJ'), ('Named', 'NNP'), ('Entities', 'NNS'), ('like', 'IN'), ('the', 'DT'), ('names', 'NNS'), ('of', 'IN'), ('people', 'NNS'), ('(', '('), ("'John", 'CD'), ("O'Keefe", 'NNP'), ("'", 'POS'), (')', ')'), ('and', 'CC'), ('places', 'NNS'), ('(', '('), ("'Philadelphia", 'CD'), (',', ','), ('Pennsylvania', 'NNP'), ("'", 'POS'), (')', ')'), ('are', 'VBP'), ('identified', 'VBN'), ('and', 'CC'), ('disambiguated', 'VBN'), ('across', 'IN'), ('thesauri', 'NN'), ('and', 'CC'), ('vocabularies', 'NNS'), ('and', 'CC'), ('can', 'MD'), ('be', 'VB'), ('presented', 'VBN'), ('separated', 'VBN'), ('from', 'IN'), ('fingerprints', 'NNS'), ('proper', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['So-called', 'Named', 'Entities', 'like', 'names', 'people', '(', "'John", "O'Keefe", "'", ')', 'places', '(', "'Philadelphia", ',', 'Pennsylvania', "'", ')', 'identified', 'disambiguated', 'across', 'thesauri', 'vocabularies', 'presented', 'separated', 'fingerprints', 'proper', '.']

 TOTAL FILTERED TOKENS ==>  28

 ---- POST FOR FILTERED TOKENS ----

 [('So-called', 'JJ'), ('Named', 'NNP'), ('Entities', 'NNS'), ('like', 'IN'), ('names', 'NNS'), ('people', 'NNS'), ('(', '('), ("'John", 'CD'), ("O'Keefe", 'NNP'), ("'", 'POS'), (')', ')'), ('places', 'NNS'), ('(', '('), ("'Philadelphia", 'CD'), (',', ','), ('Pennsylvania', 'NNP'), ("'", 'POS'), (')', ')'), ('identified', 'VBN'), ('disambiguated', 'VBN'), ('across', 'IN'), ('thesauri', 'NN'), ('vocabularies', 'NNS'), ('presented', 'VBN'), ('separated', 'JJ'), ('fingerprints', 'NNS'), ('proper', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['So-called Named', 'Named Entities', 'Entities like', 'like names', 'names people', 'people (', "( 'John", "'John O'Keefe", "O'Keefe '", "' )", ') places', 'places (', "( 'Philadelphia", "'Philadelphia ,", ', Pennsylvania', "Pennsylvania '", "' )", ') identified', 'identified disambiguated', 'disambiguated across', 'across thesauri', 'thesauri vocabularies', 'vocabularies presented', 'presented separated', 'separated fingerprints', 'fingerprints proper', 'proper .'] 

 TOTAL BIGRAMS --> 27 



 ---- TRI-GRAMS ---- 

 ['So-called Named Entities', 'Named Entities like', 'Entities like names', 'like names people', 'names people (', "people ( 'John", "( 'John O'Keefe", "'John O'Keefe '", "O'Keefe ' )", "' ) places", ') places (', "places ( 'Philadelphia", "( 'Philadelphia ,", "'Philadelphia , Pennsylvania", ", Pennsylvania '", "Pennsylvania ' )", "' ) identified", ') identified disambiguated', 'identified disambiguated across', 'disambiguated across thesauri', 'across thesauri vocabularies', 'thesauri vocabularies presented', 'vocabularies presented separated', 'presented separated fingerprints', 'separated fingerprints proper', 'fingerprints proper .'] 

 TOTAL TRIGRAMS --> 26 



 ---- NOUN PHRASES ---- 

 ['thesauri', 'proper'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['so-cal', 'name', 'entiti', 'like', 'name', 'peopl', '(', "'john", "o'keef", "'", ')', 'place', '(', "'philadelphia", ',', 'pennsylvania', "'", ')', 'identifi', 'disambigu', 'across', 'thesauri', 'vocabulari', 'present', 'separ', 'fingerprint', 'proper', '.']

 TOTAL PORTER STEM WORDS ==> 28



 ---- SNOWBALL STEMMING ----

['so-cal', 'name', 'entiti', 'like', 'name', 'peopl', '(', 'john', "o'keef", "'", ')', 'place', '(', 'philadelphia', ',', 'pennsylvania', "'", ')', 'identifi', 'disambigu', 'across', 'thesauri', 'vocabulari', 'present', 'separ', 'fingerprint', 'proper', '.']

 TOTAL SNOWBALL STEM WORDS ==> 28



 ---- LEMMATIZATION ----

['So-called', 'Named', 'Entities', 'like', 'name', 'people', '(', "'John", "O'Keefe", "'", ')', 'place', '(', "'Philadelphia", ',', 'Pennsylvania', "'", ')', 'identified', 'disambiguated', 'across', 'thesaurus', 'vocabulary', 'presented', 'separated', 'fingerprint', 'proper', '.']

 TOTAL LEMMATIZE WORDS ==> 28

************************************************************************************************************************

40 --> While the Fingerprint Engine is language insensitive technology and can technically handle all  language input, current applications focus on English language support as the scientific lingua franca. 


 ---- TOKENS ----

 ['While', 'the', 'Fingerprint', 'Engine', 'is', 'language', 'insensitive', 'technology', 'and', 'can', 'technically', 'handle', 'all', 'language', 'input', ',', 'current', 'applications', 'focus', 'on', 'English', 'language', 'support', 'as', 'the', 'scientific', 'lingua', 'franca', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('While', 'IN'), ('the', 'DT'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('is', 'VBZ'), ('language', 'NN'), ('insensitive', 'JJ'), ('technology', 'NN'), ('and', 'CC'), ('can', 'MD'), ('technically', 'RB'), ('handle', 'VB'), ('all', 'DT'), ('language', 'NN'), ('input', 'NN'), (',', ','), ('current', 'JJ'), ('applications', 'NNS'), ('focus', 'VBP'), ('on', 'IN'), ('English', 'NNP'), ('language', 'NN'), ('support', 'NN'), ('as', 'IN'), ('the', 'DT'), ('scientific', 'JJ'), ('lingua', 'NN'), ('franca', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Fingerprint', 'Engine', 'language', 'insensitive', 'technology', 'technically', 'handle', 'language', 'input', ',', 'current', 'applications', 'focus', 'English', 'language', 'support', 'scientific', 'lingua', 'franca', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('language', 'NN'), ('insensitive', 'JJ'), ('technology', 'NN'), ('technically', 'RB'), ('handle', 'JJ'), ('language', 'NN'), ('input', 'NN'), (',', ','), ('current', 'JJ'), ('applications', 'NNS'), ('focus', 'VBP'), ('English', 'JJ'), ('language', 'NN'), ('support', 'NN'), ('scientific', 'JJ'), ('lingua', 'NN'), ('franca', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Fingerprint Engine', 'Engine language', 'language insensitive', 'insensitive technology', 'technology technically', 'technically handle', 'handle language', 'language input', 'input ,', ', current', 'current applications', 'applications focus', 'focus English', 'English language', 'language support', 'support scientific', 'scientific lingua', 'lingua franca', 'franca .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['Fingerprint Engine language', 'Engine language insensitive', 'language insensitive technology', 'insensitive technology technically', 'technology technically handle', 'technically handle language', 'handle language input', 'language input ,', 'input , current', ', current applications', 'current applications focus', 'applications focus English', 'focus English language', 'English language support', 'language support scientific', 'support scientific lingua', 'scientific lingua franca', 'lingua franca .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['language', 'insensitive technology', 'handle language', 'input', 'English language', 'support', 'scientific lingua', 'franca'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['English']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['fingerprint', 'engin', 'languag', 'insensit', 'technolog', 'technic', 'handl', 'languag', 'input', ',', 'current', 'applic', 'focu', 'english', 'languag', 'support', 'scientif', 'lingua', 'franca', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['fingerprint', 'engin', 'languag', 'insensit', 'technolog', 'technic', 'handl', 'languag', 'input', ',', 'current', 'applic', 'focus', 'english', 'languag', 'support', 'scientif', 'lingua', 'franca', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['Fingerprint', 'Engine', 'language', 'insensitive', 'technology', 'technically', 'handle', 'language', 'input', ',', 'current', 'application', 'focus', 'English', 'language', 'support', 'scientific', 'lingua', 'franca', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

41 --> 1.2. 


 ---- TOKENS ----

 ['1.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

42 --> Workflow: Generation of Controlled Vocabularies and Enrichment of  Thesauri  In addition to identifying the concepts of given thesauri or vocabularies (see above) the Fingerprint  Engine can help to enrich existing terminology resources or to build new ones from scratch. 


 ---- TOKENS ----

 ['Workflow', ':', 'Generation', 'of', 'Controlled', 'Vocabularies', 'and', 'Enrichment', 'of', 'Thesauri', 'In', 'addition', 'to', 'identifying', 'the', 'concepts', 'of', 'given', 'thesauri', 'or', 'vocabularies', '(', 'see', 'above', ')', 'the', 'Fingerprint', 'Engine', 'can', 'help', 'to', 'enrich', 'existing', 'terminology', 'resources', 'or', 'to', 'build', 'new', 'ones', 'from', 'scratch', '.'] 

 TOTAL TOKENS ==> 43

 ---- POST ----

 [('Workflow', 'IN'), (':', ':'), ('Generation', 'NN'), ('of', 'IN'), ('Controlled', 'NNP'), ('Vocabularies', 'NNP'), ('and', 'CC'), ('Enrichment', 'NNP'), ('of', 'IN'), ('Thesauri', 'NNP'), ('In', 'IN'), ('addition', 'NN'), ('to', 'TO'), ('identifying', 'VBG'), ('the', 'DT'), ('concepts', 'NNS'), ('of', 'IN'), ('given', 'VBN'), ('thesauri', 'NN'), ('or', 'CC'), ('vocabularies', 'NNS'), ('(', '('), ('see', 'VB'), ('above', 'IN'), (')', ')'), ('the', 'DT'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('can', 'MD'), ('help', 'VB'), ('to', 'TO'), ('enrich', 'VB'), ('existing', 'VBG'), ('terminology', 'JJ'), ('resources', 'NNS'), ('or', 'CC'), ('to', 'TO'), ('build', 'VB'), ('new', 'JJ'), ('ones', 'NNS'), ('from', 'IN'), ('scratch', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Workflow', ':', 'Generation', 'Controlled', 'Vocabularies', 'Enrichment', 'Thesauri', 'addition', 'identifying', 'concepts', 'given', 'thesauri', 'vocabularies', '(', 'see', ')', 'Fingerprint', 'Engine', 'help', 'enrich', 'existing', 'terminology', 'resources', 'build', 'new', 'ones', 'scratch', '.']

 TOTAL FILTERED TOKENS ==>  28

 ---- POST FOR FILTERED TOKENS ----

 [('Workflow', 'IN'), (':', ':'), ('Generation', 'NN'), ('Controlled', 'VBD'), ('Vocabularies', 'NNP'), ('Enrichment', 'NNP'), ('Thesauri', 'NNP'), ('addition', 'NN'), ('identifying', 'VBG'), ('concepts', 'NNS'), ('given', 'VBN'), ('thesauri', 'JJ'), ('vocabularies', 'NNS'), ('(', '('), ('see', 'VB'), (')', ')'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('help', 'NN'), ('enrich', 'VB'), ('existing', 'VBG'), ('terminology', 'JJ'), ('resources', 'NNS'), ('build', 'VBP'), ('new', 'JJ'), ('ones', 'NNS'), ('scratch', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Workflow :', ': Generation', 'Generation Controlled', 'Controlled Vocabularies', 'Vocabularies Enrichment', 'Enrichment Thesauri', 'Thesauri addition', 'addition identifying', 'identifying concepts', 'concepts given', 'given thesauri', 'thesauri vocabularies', 'vocabularies (', '( see', 'see )', ') Fingerprint', 'Fingerprint Engine', 'Engine help', 'help enrich', 'enrich existing', 'existing terminology', 'terminology resources', 'resources build', 'build new', 'new ones', 'ones scratch', 'scratch .'] 

 TOTAL BIGRAMS --> 27 



 ---- TRI-GRAMS ---- 

 ['Workflow : Generation', ': Generation Controlled', 'Generation Controlled Vocabularies', 'Controlled Vocabularies Enrichment', 'Vocabularies Enrichment Thesauri', 'Enrichment Thesauri addition', 'Thesauri addition identifying', 'addition identifying concepts', 'identifying concepts given', 'concepts given thesauri', 'given thesauri vocabularies', 'thesauri vocabularies (', 'vocabularies ( see', '( see )', 'see ) Fingerprint', ') Fingerprint Engine', 'Fingerprint Engine help', 'Engine help enrich', 'help enrich existing', 'enrich existing terminology', 'existing terminology resources', 'terminology resources build', 'resources build new', 'build new ones', 'new ones scratch', 'ones scratch .'] 

 TOTAL TRIGRAMS --> 26 



 ---- NOUN PHRASES ---- 

 ['Generation', 'addition', 'help', 'scratch'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Vocabularies Enrichment Thesauri']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['workflow', ':', 'gener', 'control', 'vocabulari', 'enrich', 'thesauri', 'addit', 'identifi', 'concept', 'given', 'thesauri', 'vocabulari', '(', 'see', ')', 'fingerprint', 'engin', 'help', 'enrich', 'exist', 'terminolog', 'resourc', 'build', 'new', 'one', 'scratch', '.']

 TOTAL PORTER STEM WORDS ==> 28



 ---- SNOWBALL STEMMING ----

['workflow', ':', 'generat', 'control', 'vocabulari', 'enrich', 'thesauri', 'addit', 'identifi', 'concept', 'given', 'thesauri', 'vocabulari', '(', 'see', ')', 'fingerprint', 'engin', 'help', 'enrich', 'exist', 'terminolog', 'resourc', 'build', 'new', 'one', 'scratch', '.']

 TOTAL SNOWBALL STEM WORDS ==> 28



 ---- LEMMATIZATION ----

['Workflow', ':', 'Generation', 'Controlled', 'Vocabularies', 'Enrichment', 'Thesauri', 'addition', 'identifying', 'concept', 'given', 'thesaurus', 'vocabulary', '(', 'see', ')', 'Fingerprint', 'Engine', 'help', 'enrich', 'existing', 'terminology', 'resource', 'build', 'new', 'one', 'scratch', '.']

 TOTAL LEMMATIZE WORDS ==> 28

************************************************************************************************************************

43 --> Using a                4  subset of the Engine's NLP components a Noun Phrase Detector extracts putative technical terms  from document collections of specific domains. 


 ---- TOKENS ----

 ['Using', 'a', '4', 'subset', 'of', 'the', 'Engine', "'s", 'NLP', 'components', 'a', 'Noun', 'Phrase', 'Detector', 'extracts', 'putative', 'technical', 'terms', 'from', 'document', 'collections', 'of', 'specific', 'domains', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Using', 'VBG'), ('a', 'DT'), ('4', 'CD'), ('subset', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Engine', 'NNP'), ("'s", 'POS'), ('NLP', 'NNP'), ('components', 'VBZ'), ('a', 'DT'), ('Noun', 'NNP'), ('Phrase', 'NNP'), ('Detector', 'NNP'), ('extracts', 'VBZ'), ('putative', 'JJ'), ('technical', 'JJ'), ('terms', 'NNS'), ('from', 'IN'), ('document', 'NN'), ('collections', 'NNS'), ('of', 'IN'), ('specific', 'JJ'), ('domains', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Using', '4', 'subset', 'Engine', "'s", 'NLP', 'components', 'Noun', 'Phrase', 'Detector', 'extracts', 'putative', 'technical', 'terms', 'document', 'collections', 'specific', 'domains', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Using', 'VBG'), ('4', 'CD'), ('subset', 'JJ'), ('Engine', 'NNP'), ("'s", 'POS'), ('NLP', 'NNP'), ('components', 'NNS'), ('Noun', 'NNP'), ('Phrase', 'NNP'), ('Detector', 'NNP'), ('extracts', 'VBZ'), ('putative', 'JJ'), ('technical', 'JJ'), ('terms', 'NNS'), ('document', 'JJ'), ('collections', 'NNS'), ('specific', 'JJ'), ('domains', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Using 4', '4 subset', 'subset Engine', "Engine 's", "'s NLP", 'NLP components', 'components Noun', 'Noun Phrase', 'Phrase Detector', 'Detector extracts', 'extracts putative', 'putative technical', 'technical terms', 'terms document', 'document collections', 'collections specific', 'specific domains', 'domains .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Using 4 subset', '4 subset Engine', "subset Engine 's", "Engine 's NLP", "'s NLP components", 'NLP components Noun', 'components Noun Phrase', 'Noun Phrase Detector', 'Phrase Detector extracts', 'Detector extracts putative', 'extracts putative technical', 'putative technical terms', 'technical terms document', 'terms document collections', 'document collections specific', 'collections specific domains', 'specific domains .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Engine', 'Noun Phrase Detector']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['use', '4', 'subset', 'engin', "'s", 'nlp', 'compon', 'noun', 'phrase', 'detector', 'extract', 'put', 'technic', 'term', 'document', 'collect', 'specif', 'domain', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['use', '4', 'subset', 'engin', "'s", 'nlp', 'compon', 'noun', 'phrase', 'detector', 'extract', 'putat', 'technic', 'term', 'document', 'collect', 'specif', 'domain', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Using', '4', 'subset', 'Engine', "'s", 'NLP', 'component', 'Noun', 'Phrase', 'Detector', 'extract', 'putative', 'technical', 'term', 'document', 'collection', 'specific', 'domain', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

44 --> 1.3. 


 ---- TOKENS ----

 ['1.3', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1.3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.3', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1.3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.3 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.3', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1.3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1.3', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

45 --> Framework and Natural Language Processing (NLP) Modules  The NLP workbench framework facilitates configuration of a processing workflow where multiple  modules are executed sequentially, using processing results generated by previous modules. 


 ---- TOKENS ----

 ['Framework', 'and', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'Modules', 'The', 'NLP', 'workbench', 'framework', 'facilitates', 'configuration', 'of', 'a', 'processing', 'workflow', 'where', 'multiple', 'modules', 'are', 'executed', 'sequentially', ',', 'using', 'processing', 'results', 'generated', 'by', 'previous', 'modules', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('Framework', 'NN'), ('and', 'CC'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('Modules', 'VBZ'), ('The', 'DT'), ('NLP', 'NNP'), ('workbench', 'NN'), ('framework', 'NN'), ('facilitates', 'VBZ'), ('configuration', 'NN'), ('of', 'IN'), ('a', 'DT'), ('processing', 'NN'), ('workflow', 'NN'), ('where', 'WRB'), ('multiple', 'NN'), ('modules', 'NNS'), ('are', 'VBP'), ('executed', 'VBN'), ('sequentially', 'RB'), (',', ','), ('using', 'VBG'), ('processing', 'VBG'), ('results', 'NNS'), ('generated', 'VBN'), ('by', 'IN'), ('previous', 'JJ'), ('modules', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Framework', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'Modules', 'NLP', 'workbench', 'framework', 'facilitates', 'configuration', 'processing', 'workflow', 'multiple', 'modules', 'executed', 'sequentially', ',', 'using', 'processing', 'results', 'generated', 'previous', 'modules', '.']

 TOTAL FILTERED TOKENS ==>  27

 ---- POST FOR FILTERED TOKENS ----

 [('Framework', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('Modules', 'NNP'), ('NLP', 'NNP'), ('workbench', 'NN'), ('framework', 'NN'), ('facilitates', 'VBZ'), ('configuration', 'NN'), ('processing', 'VBG'), ('workflow', 'JJ'), ('multiple', 'JJ'), ('modules', 'NNS'), ('executed', 'VBN'), ('sequentially', 'RB'), (',', ','), ('using', 'VBG'), ('processing', 'VBG'), ('results', 'NNS'), ('generated', 'VBD'), ('previous', 'JJ'), ('modules', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Framework Natural', 'Natural Language', 'Language Processing', 'Processing (', '( NLP', 'NLP )', ') Modules', 'Modules NLP', 'NLP workbench', 'workbench framework', 'framework facilitates', 'facilitates configuration', 'configuration processing', 'processing workflow', 'workflow multiple', 'multiple modules', 'modules executed', 'executed sequentially', 'sequentially ,', ', using', 'using processing', 'processing results', 'results generated', 'generated previous', 'previous modules', 'modules .'] 

 TOTAL BIGRAMS --> 26 



 ---- TRI-GRAMS ---- 

 ['Framework Natural Language', 'Natural Language Processing', 'Language Processing (', 'Processing ( NLP', '( NLP )', 'NLP ) Modules', ') Modules NLP', 'Modules NLP workbench', 'NLP workbench framework', 'workbench framework facilitates', 'framework facilitates configuration', 'facilitates configuration processing', 'configuration processing workflow', 'processing workflow multiple', 'workflow multiple modules', 'multiple modules executed', 'modules executed sequentially', 'executed sequentially ,', 'sequentially , using', ', using processing', 'using processing results', 'processing results generated', 'results generated previous', 'generated previous modules', 'previous modules .'] 

 TOTAL TRIGRAMS --> 25 



 ---- NOUN PHRASES ---- 

 ['workbench', 'framework', 'configuration'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['Natural Language']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Framework', 'Modules NLP']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['framework', 'natur', 'languag', 'process', '(', 'nlp', ')', 'modul', 'nlp', 'workbench', 'framework', 'facilit', 'configur', 'process', 'workflow', 'multipl', 'modul', 'execut', 'sequenti', ',', 'use', 'process', 'result', 'gener', 'previou', 'modul', '.']

 TOTAL PORTER STEM WORDS ==> 27



 ---- SNOWBALL STEMMING ----

['framework', 'natur', 'languag', 'process', '(', 'nlp', ')', 'modul', 'nlp', 'workbench', 'framework', 'facilit', 'configur', 'process', 'workflow', 'multipl', 'modul', 'execut', 'sequenti', ',', 'use', 'process', 'result', 'generat', 'previous', 'modul', '.']

 TOTAL SNOWBALL STEM WORDS ==> 27



 ---- LEMMATIZATION ----

['Framework', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'Modules', 'NLP', 'workbench', 'framework', 'facilitates', 'configuration', 'processing', 'workflow', 'multiple', 'module', 'executed', 'sequentially', ',', 'using', 'processing', 'result', 'generated', 'previous', 'module', '.']

 TOTAL LEMMATIZE WORDS ==> 27

************************************************************************************************************************

46 --> The standard NLP facilities of the Elsevier Fingerprint Engine, described in more detail below, can be  complemented by third party text analytic modules, unlimited in type and number. 


 ---- TOKENS ----

 ['The', 'standard', 'NLP', 'facilities', 'of', 'the', 'Elsevier', 'Fingerprint', 'Engine', ',', 'described', 'in', 'more', 'detail', 'below', ',', 'can', 'be', 'complemented', 'by', 'third', 'party', 'text', 'analytic', 'modules', ',', 'unlimited', 'in', 'type', 'and', 'number', '.'] 

 TOTAL TOKENS ==> 32

 ---- POST ----

 [('The', 'DT'), ('standard', 'NN'), ('NLP', 'NNP'), ('facilities', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), (',', ','), ('described', 'VBD'), ('in', 'IN'), ('more', 'RBR'), ('detail', 'NN'), ('below', 'IN'), (',', ','), ('can', 'MD'), ('be', 'VB'), ('complemented', 'VBN'), ('by', 'IN'), ('third', 'JJ'), ('party', 'NN'), ('text', 'NN'), ('analytic', 'JJ'), ('modules', 'NNS'), (',', ','), ('unlimited', 'VBN'), ('in', 'IN'), ('type', 'NN'), ('and', 'CC'), ('number', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['standard', 'NLP', 'facilities', 'Elsevier', 'Fingerprint', 'Engine', ',', 'described', 'detail', ',', 'complemented', 'third', 'party', 'text', 'analytic', 'modules', ',', 'unlimited', 'type', 'number', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('standard', 'JJ'), ('NLP', 'NNP'), ('facilities', 'NNS'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), (',', ','), ('described', 'VBD'), ('detail', 'NN'), (',', ','), ('complemented', 'VBN'), ('third', 'JJ'), ('party', 'NN'), ('text', 'NN'), ('analytic', 'JJ'), ('modules', 'NNS'), (',', ','), ('unlimited', 'JJ'), ('type', 'NN'), ('number', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['standard NLP', 'NLP facilities', 'facilities Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine ,', ', described', 'described detail', 'detail ,', ', complemented', 'complemented third', 'third party', 'party text', 'text analytic', 'analytic modules', 'modules ,', ', unlimited', 'unlimited type', 'type number', 'number .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['standard NLP facilities', 'NLP facilities Elsevier', 'facilities Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine ,', 'Engine , described', ', described detail', 'described detail ,', 'detail , complemented', ', complemented third', 'complemented third party', 'third party text', 'party text analytic', 'text analytic modules', 'analytic modules ,', 'modules , unlimited', ', unlimited type', 'unlimited type number', 'type number .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['detail', 'third party', 'text', 'unlimited type', 'number'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['standard', 'nlp', 'facil', 'elsevi', 'fingerprint', 'engin', ',', 'describ', 'detail', ',', 'complement', 'third', 'parti', 'text', 'analyt', 'modul', ',', 'unlimit', 'type', 'number', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['standard', 'nlp', 'facil', 'elsevi', 'fingerprint', 'engin', ',', 'describ', 'detail', ',', 'complement', 'third', 'parti', 'text', 'analyt', 'modul', ',', 'unlimit', 'type', 'number', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['standard', 'NLP', 'facility', 'Elsevier', 'Fingerprint', 'Engine', ',', 'described', 'detail', ',', 'complemented', 'third', 'party', 'text', 'analytic', 'module', ',', 'unlimited', 'type', 'number', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

47 --> The infrastructure  enabling that consists of a .Net platform, a collection of text analysis modules and a host process. 


 ---- TOKENS ----

 ['The', 'infrastructure', 'enabling', 'that', 'consists', 'of', 'a', '.Net', 'platform', ',', 'a', 'collection', 'of', 'text', 'analysis', 'modules', 'and', 'a', 'host', 'process', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('The', 'DT'), ('infrastructure', 'NN'), ('enabling', 'VBG'), ('that', 'IN'), ('consists', 'VBZ'), ('of', 'IN'), ('a', 'DT'), ('.Net', 'JJ'), ('platform', 'NN'), (',', ','), ('a', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('analysis', 'NN'), ('modules', 'NNS'), ('and', 'CC'), ('a', 'DT'), ('host', 'NN'), ('process', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['infrastructure', 'enabling', 'consists', '.Net', 'platform', ',', 'collection', 'text', 'analysis', 'modules', 'host', 'process', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('infrastructure', 'NN'), ('enabling', 'VBG'), ('consists', 'NNS'), ('.Net', 'JJ'), ('platform', 'NN'), (',', ','), ('collection', 'NN'), ('text', 'NN'), ('analysis', 'NN'), ('modules', 'VBZ'), ('host', 'NN'), ('process', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['infrastructure enabling', 'enabling consists', 'consists .Net', '.Net platform', 'platform ,', ', collection', 'collection text', 'text analysis', 'analysis modules', 'modules host', 'host process', 'process .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['infrastructure enabling consists', 'enabling consists .Net', 'consists .Net platform', '.Net platform ,', 'platform , collection', ', collection text', 'collection text analysis', 'text analysis modules', 'analysis modules host', 'modules host process', 'host process .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['infrastructure', '.Net platform', 'collection', 'text', 'analysis', 'host', 'process'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['infrastructur', 'enabl', 'consist', '.net', 'platform', ',', 'collect', 'text', 'analysi', 'modul', 'host', 'process', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['infrastructur', 'enabl', 'consist', '.net', 'platform', ',', 'collect', 'text', 'analysi', 'modul', 'host', 'process', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['infrastructure', 'enabling', 'consists', '.Net', 'platform', ',', 'collection', 'text', 'analysis', 'module', 'host', 'process', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

48 --> 1.4. 


 ---- TOKENS ----

 ['1.4', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1.4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.4', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1.4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.4 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.4', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1.4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1.4', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

49 --> Key Natural Language Processing components of the Elsevier Fingerprint  Engine  Language Detection: Identifies the language in which a text is written. 


 ---- TOKENS ----

 ['Key', 'Natural', 'Language', 'Processing', 'components', 'of', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'Language', 'Detection', ':', 'Identifies', 'the', 'language', 'in', 'which', 'a', 'text', 'is', 'written', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Key', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('components', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('Language', 'NNP'), ('Detection', 'NNP'), (':', ':'), ('Identifies', 'VBZ'), ('the', 'DT'), ('language', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('a', 'DT'), ('text', 'NN'), ('is', 'VBZ'), ('written', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Key', 'Natural', 'Language', 'Processing', 'components', 'Elsevier', 'Fingerprint', 'Engine', 'Language', 'Detection', ':', 'Identifies', 'language', 'text', 'written', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Key', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('components', 'NNS'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('Language', 'NNP'), ('Detection', 'NNP'), (':', ':'), ('Identifies', 'NNS'), ('language', 'NN'), ('text', 'RB'), ('written', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Key Natural', 'Natural Language', 'Language Processing', 'Processing components', 'components Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine Language', 'Language Detection', 'Detection :', ': Identifies', 'Identifies language', 'language text', 'text written', 'written .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Key Natural Language', 'Natural Language Processing', 'Language Processing components', 'Processing components Elsevier', 'components Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine Language', 'Engine Language Detection', 'Language Detection :', 'Detection : Identifies', ': Identifies language', 'Identifies language text', 'language text written', 'text written .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['language'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Natural Language']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Key', 'Elsevier Fingerprint Engine Language']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['key', 'natur', 'languag', 'process', 'compon', 'elsevi', 'fingerprint', 'engin', 'languag', 'detect', ':', 'identifi', 'languag', 'text', 'written', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['key', 'natur', 'languag', 'process', 'compon', 'elsevi', 'fingerprint', 'engin', 'languag', 'detect', ':', 'identifi', 'languag', 'text', 'written', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Key', 'Natural', 'Language', 'Processing', 'component', 'Elsevier', 'Fingerprint', 'Engine', 'Language', 'Detection', ':', 'Identifies', 'language', 'text', 'written', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

50 --> Tokenization: Splits text in tokens like words, punctuation marks and sentences. 


 ---- TOKENS ----

 ['Tokenization', ':', 'Splits', 'text', 'in', 'tokens', 'like', 'words', ',', 'punctuation', 'marks', 'and', 'sentences', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Tokenization', 'NN'), (':', ':'), ('Splits', 'NNS'), ('text', 'VBP'), ('in', 'IN'), ('tokens', 'NNS'), ('like', 'IN'), ('words', 'NNS'), (',', ','), ('punctuation', 'NN'), ('marks', 'NNS'), ('and', 'CC'), ('sentences', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Tokenization', ':', 'Splits', 'text', 'tokens', 'like', 'words', ',', 'punctuation', 'marks', 'sentences', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Tokenization', 'NN'), (':', ':'), ('Splits', 'NNS'), ('text', 'VBP'), ('tokens', 'NNS'), ('like', 'IN'), ('words', 'NNS'), (',', ','), ('punctuation', 'NN'), ('marks', 'NNS'), ('sentences', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Tokenization :', ': Splits', 'Splits text', 'text tokens', 'tokens like', 'like words', 'words ,', ', punctuation', 'punctuation marks', 'marks sentences', 'sentences .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Tokenization : Splits', ': Splits text', 'Splits text tokens', 'text tokens like', 'tokens like words', 'like words ,', 'words , punctuation', ', punctuation marks', 'punctuation marks sentences', 'marks sentences .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['Tokenization', 'punctuation'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Tokenization']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['token', ':', 'split', 'text', 'token', 'like', 'word', ',', 'punctuat', 'mark', 'sentenc', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['token', ':', 'split', 'text', 'token', 'like', 'word', ',', 'punctuat', 'mark', 'sentenc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Tokenization', ':', 'Splits', 'text', 'token', 'like', 'word', ',', 'punctuation', 'mark', 'sentence', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

51 --> Dehyphenation: Recognizes sentence-final hyphenations and reconstructs the original words, for  instance replaces “dehyph- enation” with “dehyphenation”. 


 ---- TOKENS ----

 ['Dehyphenation', ':', 'Recognizes', 'sentence-final', 'hyphenations', 'and', 'reconstructs', 'the', 'original', 'words', ',', 'for', 'instance', 'replaces', '“', 'dehyph-', 'enation', '”', 'with', '“', 'dehyphenation', '”', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Dehyphenation', 'NN'), (':', ':'), ('Recognizes', 'NNP'), ('sentence-final', 'JJ'), ('hyphenations', 'NNS'), ('and', 'CC'), ('reconstructs', 'VBZ'), ('the', 'DT'), ('original', 'JJ'), ('words', 'NNS'), (',', ','), ('for', 'IN'), ('instance', 'NN'), ('replaces', 'NNS'), ('“', 'VBP'), ('dehyph-', 'JJ'), ('enation', 'NN'), ('”', 'NN'), ('with', 'IN'), ('“', 'JJ'), ('dehyphenation', 'NN'), ('”', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Dehyphenation', ':', 'Recognizes', 'sentence-final', 'hyphenations', 'reconstructs', 'original', 'words', ',', 'instance', 'replaces', '“', 'dehyph-', 'enation', '”', '“', 'dehyphenation', '”', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Dehyphenation', 'NN'), (':', ':'), ('Recognizes', 'NNP'), ('sentence-final', 'JJ'), ('hyphenations', 'NNS'), ('reconstructs', 'VBZ'), ('original', 'JJ'), ('words', 'NNS'), (',', ','), ('instance', 'NN'), ('replaces', 'NNS'), ('“', 'VBP'), ('dehyph-', 'JJ'), ('enation', 'NN'), ('”', 'NNP'), ('“', 'NNP'), ('dehyphenation', 'NN'), ('”', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Dehyphenation :', ': Recognizes', 'Recognizes sentence-final', 'sentence-final hyphenations', 'hyphenations reconstructs', 'reconstructs original', 'original words', 'words ,', ', instance', 'instance replaces', 'replaces “', '“ dehyph-', 'dehyph- enation', 'enation ”', '” “', '“ dehyphenation', 'dehyphenation ”', '” .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Dehyphenation : Recognizes', ': Recognizes sentence-final', 'Recognizes sentence-final hyphenations', 'sentence-final hyphenations reconstructs', 'hyphenations reconstructs original', 'reconstructs original words', 'original words ,', 'words , instance', ', instance replaces', 'instance replaces “', 'replaces “ dehyph-', '“ dehyph- enation', 'dehyph- enation ”', 'enation ” “', '” “ dehyphenation', '“ dehyphenation ”', 'dehyphenation ” .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['Dehyphenation', 'instance', 'dehyph- enation', 'dehyphenation', '”'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Dehyphenation']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['dehyphen', ':', 'recogn', 'sentence-fin', 'hyphen', 'reconstruct', 'origin', 'word', ',', 'instanc', 'replac', '“', 'dehyph-', 'enat', '”', '“', 'dehyphen', '”', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['dehyphen', ':', 'recogn', 'sentence-fin', 'hyphen', 'reconstruct', 'origin', 'word', ',', 'instanc', 'replac', '“', 'dehyph-', 'enat', '”', '“', 'dehyphen', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Dehyphenation', ':', 'Recognizes', 'sentence-final', 'hyphenation', 'reconstructs', 'original', 'word', ',', 'instance', 'replaces', '“', 'dehyph-', 'enation', '”', '“', 'dehyphenation', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

52 --> Coordination Expansion: Detects abbreviated coordinations and reconstructs full forms. 


 ---- TOKENS ----

 ['Coordination', 'Expansion', ':', 'Detects', 'abbreviated', 'coordinations', 'and', 'reconstructs', 'full', 'forms', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Coordination', 'NN'), ('Expansion', 'NN'), (':', ':'), ('Detects', 'NNS'), ('abbreviated', 'VBN'), ('coordinations', 'NNS'), ('and', 'CC'), ('reconstructs', 'NNS'), ('full', 'JJ'), ('forms', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Coordination', 'Expansion', ':', 'Detects', 'abbreviated', 'coordinations', 'reconstructs', 'full', 'forms', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Coordination', 'NN'), ('Expansion', 'NN'), (':', ':'), ('Detects', 'NNS'), ('abbreviated', 'VBD'), ('coordinations', 'NNS'), ('reconstructs', 'NNS'), ('full', 'JJ'), ('forms', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Coordination Expansion', 'Expansion :', ': Detects', 'Detects abbreviated', 'abbreviated coordinations', 'coordinations reconstructs', 'reconstructs full', 'full forms', 'forms .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Coordination Expansion :', 'Expansion : Detects', ': Detects abbreviated', 'Detects abbreviated coordinations', 'abbreviated coordinations reconstructs', 'coordinations reconstructs full', 'reconstructs full forms', 'full forms .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['Coordination', 'Expansion'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Expansion']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Coordination']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['coordin', 'expans', ':', 'detect', 'abbrevi', 'coordin', 'reconstruct', 'full', 'form', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['coordin', 'expans', ':', 'detect', 'abbrevi', 'coordin', 'reconstruct', 'full', 'form', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Coordination', 'Expansion', ':', 'Detects', 'abbreviated', 'coordination', 'reconstructs', 'full', 'form', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

53 --> For  instance, the phrase “intra- and extramural” is expanded to “intramural and extramural”. 


 ---- TOKENS ----

 ['For', 'instance', ',', 'the', 'phrase', '“', 'intra-', 'and', 'extramural', '”', 'is', 'expanded', 'to', '“', 'intramural', 'and', 'extramural', '”', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('the', 'DT'), ('phrase', 'NN'), ('“', 'NNP'), ('intra-', 'NN'), ('and', 'CC'), ('extramural', 'JJ'), ('”', 'NN'), ('is', 'VBZ'), ('expanded', 'VBN'), ('to', 'TO'), ('“', 'VB'), ('intramural', 'JJ'), ('and', 'CC'), ('extramural', 'JJ'), ('”', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['instance', ',', 'phrase', '“', 'intra-', 'extramural', '”', 'expanded', '“', 'intramural', 'extramural', '”', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('instance', 'NN'), (',', ','), ('phrase', 'NN'), ('“', 'NNP'), ('intra-', 'JJ'), ('extramural', 'JJ'), ('”', 'NN'), ('expanded', 'VBD'), ('“', 'JJ'), ('intramural', 'JJ'), ('extramural', 'JJ'), ('”', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['instance ,', ', phrase', 'phrase “', '“ intra-', 'intra- extramural', 'extramural ”', '” expanded', 'expanded “', '“ intramural', 'intramural extramural', 'extramural ”', '” .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['instance , phrase', ', phrase “', 'phrase “ intra-', '“ intra- extramural', 'intra- extramural ”', 'extramural ” expanded', '” expanded “', 'expanded “ intramural', '“ intramural extramural', 'intramural extramural ”', 'extramural ” .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['instance', 'phrase', 'intra- extramural ”', '“ intramural extramural ”'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['instanc', ',', 'phrase', '“', 'intra-', 'extramur', '”', 'expand', '“', 'intramur', 'extramur', '”', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['instanc', ',', 'phrase', '“', 'intra-', 'extramur', '”', 'expand', '“', 'intramur', 'extramur', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['instance', ',', 'phrase', '“', 'intra-', 'extramural', '”', 'expanded', '“', 'intramural', 'extramural', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

54 --> Similarly, full  noun phrases are reconstructed from compacted ones, e.g.- “Hepatitis A and B” is expanded to  “Hepatitis A and Hepatitis B”. 


 ---- TOKENS ----

 ['Similarly', ',', 'full', 'noun', 'phrases', 'are', 'reconstructed', 'from', 'compacted', 'ones', ',', 'e.g.-', '“', 'Hepatitis', 'A', 'and', 'B', '”', 'is', 'expanded', 'to', '“', 'Hepatitis', 'A', 'and', 'Hepatitis', 'B', '”', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('Similarly', 'RB'), (',', ','), ('full', 'JJ'), ('noun', 'NN'), ('phrases', 'NNS'), ('are', 'VBP'), ('reconstructed', 'VBN'), ('from', 'IN'), ('compacted', 'VBN'), ('ones', 'NNS'), (',', ','), ('e.g.-', 'JJ'), ('“', 'NNP'), ('Hepatitis', 'NNP'), ('A', 'NNP'), ('and', 'CC'), ('B', 'NNP'), ('”', 'NNP'), ('is', 'VBZ'), ('expanded', 'VBN'), ('to', 'TO'), ('“', 'VB'), ('Hepatitis', 'NNP'), ('A', 'NNP'), ('and', 'CC'), ('Hepatitis', 'NNP'), ('B', 'NNP'), ('”', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Similarly', ',', 'full', 'noun', 'phrases', 'reconstructed', 'compacted', 'ones', ',', 'e.g.-', '“', 'Hepatitis', 'B', '”', 'expanded', '“', 'Hepatitis', 'Hepatitis', 'B', '”', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('Similarly', 'RB'), (',', ','), ('full', 'JJ'), ('noun', 'NN'), ('phrases', 'NNS'), ('reconstructed', 'VBD'), ('compacted', 'JJ'), ('ones', 'NNS'), (',', ','), ('e.g.-', 'JJ'), ('“', 'NNP'), ('Hepatitis', 'NNP'), ('B', 'NNP'), ('”', 'NNP'), ('expanded', 'VBD'), ('“', 'NNP'), ('Hepatitis', 'NNP'), ('Hepatitis', 'NNP'), ('B', 'NNP'), ('”', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Similarly ,', ', full', 'full noun', 'noun phrases', 'phrases reconstructed', 'reconstructed compacted', 'compacted ones', 'ones ,', ', e.g.-', 'e.g.- “', '“ Hepatitis', 'Hepatitis B', 'B ”', '” expanded', 'expanded “', '“ Hepatitis', 'Hepatitis Hepatitis', 'Hepatitis B', 'B ”', '” .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['Similarly , full', ', full noun', 'full noun phrases', 'noun phrases reconstructed', 'phrases reconstructed compacted', 'reconstructed compacted ones', 'compacted ones ,', 'ones , e.g.-', ', e.g.- “', 'e.g.- “ Hepatitis', '“ Hepatitis B', 'Hepatitis B ”', 'B ” expanded', '” expanded “', 'expanded “ Hepatitis', '“ Hepatitis Hepatitis', 'Hepatitis Hepatitis B', 'Hepatitis B ”', 'B ” .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['full noun'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Hepatitis Hepatitis']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['similarli', ',', 'full', 'noun', 'phrase', 'reconstruct', 'compact', 'one', ',', 'e.g.-', '“', 'hepat', 'b', '”', 'expand', '“', 'hepat', 'hepat', 'b', '”', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['similar', ',', 'full', 'noun', 'phrase', 'reconstruct', 'compact', 'one', ',', 'e.g.-', '“', 'hepat', 'b', '”', 'expand', '“', 'hepat', 'hepat', 'b', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['Similarly', ',', 'full', 'noun', 'phrase', 'reconstructed', 'compacted', 'one', ',', 'e.g.-', '“', 'Hepatitis', 'B', '”', 'expanded', '“', 'Hepatitis', 'Hepatitis', 'B', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

55 --> Normalization: Produces normal forms converting plural to singular forms (children > child) and  British to American spelling variants (gynaecology > gynecology). 


 ---- TOKENS ----

 ['Normalization', ':', 'Produces', 'normal', 'forms', 'converting', 'plural', 'to', 'singular', 'forms', '(', 'children', '>', 'child', ')', 'and', 'British', 'to', 'American', 'spelling', 'variants', '(', 'gynaecology', '>', 'gynecology', ')', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('Normalization', 'NN'), (':', ':'), ('Produces', 'VBZ'), ('normal', 'JJ'), ('forms', 'NNS'), ('converting', 'VBG'), ('plural', 'JJ'), ('to', 'TO'), ('singular', 'VB'), ('forms', 'NNS'), ('(', '('), ('children', 'NNS'), ('>', 'VBP'), ('child', 'NN'), (')', ')'), ('and', 'CC'), ('British', 'JJ'), ('to', 'TO'), ('American', 'JJ'), ('spelling', 'NN'), ('variants', 'NNS'), ('(', '('), ('gynaecology', 'NN'), ('>', 'NNP'), ('gynecology', 'NN'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Normalization', ':', 'Produces', 'normal', 'forms', 'converting', 'plural', 'singular', 'forms', '(', 'children', '>', 'child', ')', 'British', 'American', 'spelling', 'variants', '(', 'gynaecology', '>', 'gynecology', ')', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('Normalization', 'NN'), (':', ':'), ('Produces', 'VBZ'), ('normal', 'JJ'), ('forms', 'NNS'), ('converting', 'VBG'), ('plural', 'JJ'), ('singular', 'JJ'), ('forms', 'NNS'), ('(', '('), ('children', 'NNS'), ('>', 'VBP'), ('child', 'NN'), (')', ')'), ('British', 'JJ'), ('American', 'JJ'), ('spelling', 'NN'), ('variants', 'NNS'), ('(', '('), ('gynaecology', 'NN'), ('>', 'NNP'), ('gynecology', 'NN'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Normalization :', ': Produces', 'Produces normal', 'normal forms', 'forms converting', 'converting plural', 'plural singular', 'singular forms', 'forms (', '( children', 'children >', '> child', 'child )', ') British', 'British American', 'American spelling', 'spelling variants', 'variants (', '( gynaecology', 'gynaecology >', '> gynecology', 'gynecology )', ') .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['Normalization : Produces', ': Produces normal', 'Produces normal forms', 'normal forms converting', 'forms converting plural', 'converting plural singular', 'plural singular forms', 'singular forms (', 'forms ( children', '( children >', 'children > child', '> child )', 'child ) British', ') British American', 'British American spelling', 'American spelling variants', 'spelling variants (', 'variants ( gynaecology', '( gynaecology >', 'gynaecology > gynecology', '> gynecology )', 'gynecology ) .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['Normalization', 'British American spelling'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Normalization', 'British', 'American']
 TOTAL GPE ENTITY --> 3 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['normal', ':', 'produc', 'normal', 'form', 'convert', 'plural', 'singular', 'form', '(', 'children', '>', 'child', ')', 'british', 'american', 'spell', 'variant', '(', 'gynaecolog', '>', 'gynecolog', ')', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['normal', ':', 'produc', 'normal', 'form', 'convert', 'plural', 'singular', 'form', '(', 'children', '>', 'child', ')', 'british', 'american', 'spell', 'variant', '(', 'gynaecolog', '>', 'gynecolog', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['Normalization', ':', 'Produces', 'normal', 'form', 'converting', 'plural', 'singular', 'form', '(', 'child', '>', 'child', ')', 'British', 'American', 'spelling', 'variant', '(', 'gynaecology', '>', 'gynecology', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

56 --> Abbreviation Expansion: Detects and expands abbreviations that are defined in a text. 


 ---- TOKENS ----

 ['Abbreviation', 'Expansion', ':', 'Detects', 'and', 'expands', 'abbreviations', 'that', 'are', 'defined', 'in', 'a', 'text', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Abbreviation', 'NN'), ('Expansion', 'NN'), (':', ':'), ('Detects', 'NNS'), ('and', 'CC'), ('expands', 'NNS'), ('abbreviations', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('defined', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('text', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Abbreviation', 'Expansion', ':', 'Detects', 'expands', 'abbreviations', 'defined', 'text', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Abbreviation', 'NN'), ('Expansion', 'NN'), (':', ':'), ('Detects', 'VBZ'), ('expands', 'NNS'), ('abbreviations', 'NNS'), ('defined', 'VBD'), ('text', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Abbreviation Expansion', 'Expansion :', ': Detects', 'Detects expands', 'expands abbreviations', 'abbreviations defined', 'defined text', 'text .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Abbreviation Expansion :', 'Expansion : Detects', ': Detects expands', 'Detects expands abbreviations', 'expands abbreviations defined', 'abbreviations defined text', 'defined text .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['Abbreviation', 'Expansion', 'text'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Expansion']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Abbreviation']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbrevi', 'expans', ':', 'detect', 'expand', 'abbrevi', 'defin', 'text', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['abbrevi', 'expans', ':', 'detect', 'expand', 'abbrevi', 'defin', 'text', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Abbreviation', 'Expansion', ':', 'Detects', 'expands', 'abbreviation', 'defined', 'text', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

57 --> For instance,  if the phrase “Blood group (BG)” is detected all occurrences of “BG” in the same text are expanded to  “Blood group”. 


 ---- TOKENS ----

 ['For', 'instance', ',', 'if', 'the', 'phrase', '“', 'Blood', 'group', '(', 'BG', ')', '”', 'is', 'detected', 'all', 'occurrences', 'of', '“', 'BG', '”', 'in', 'the', 'same', 'text', 'are', 'expanded', 'to', '“', 'Blood', 'group', '”', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('if', 'IN'), ('the', 'DT'), ('phrase', 'NN'), ('“', 'NNP'), ('Blood', 'NNP'), ('group', 'NN'), ('(', '('), ('BG', 'NNP'), (')', ')'), ('”', 'NN'), ('is', 'VBZ'), ('detected', 'VBN'), ('all', 'DT'), ('occurrences', 'NNS'), ('of', 'IN'), ('“', 'NNP'), ('BG', 'NNP'), ('”', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('text', 'NN'), ('are', 'VBP'), ('expanded', 'VBN'), ('to', 'TO'), ('“', 'VB'), ('Blood', 'NNP'), ('group', 'NN'), ('”', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['instance', ',', 'phrase', '“', 'Blood', 'group', '(', 'BG', ')', '”', 'detected', 'occurrences', '“', 'BG', '”', 'text', 'expanded', '“', 'Blood', 'group', '”', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('instance', 'NN'), (',', ','), ('phrase', 'NN'), ('“', 'NNP'), ('Blood', 'NNP'), ('group', 'NN'), ('(', '('), ('BG', 'NNP'), (')', ')'), ('”', 'NN'), ('detected', 'VBD'), ('occurrences', 'NNS'), ('“', 'NNP'), ('BG', 'NNP'), ('”', 'NNP'), ('text', 'NN'), ('expanded', 'VBD'), ('“', 'NNP'), ('Blood', 'NNP'), ('group', 'NN'), ('”', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['instance ,', ', phrase', 'phrase “', '“ Blood', 'Blood group', 'group (', '( BG', 'BG )', ') ”', '” detected', 'detected occurrences', 'occurrences “', '“ BG', 'BG ”', '” text', 'text expanded', 'expanded “', '“ Blood', 'Blood group', 'group ”', '” .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['instance , phrase', ', phrase “', 'phrase “ Blood', '“ Blood group', 'Blood group (', 'group ( BG', '( BG )', 'BG ) ”', ') ” detected', '” detected occurrences', 'detected occurrences “', 'occurrences “ BG', '“ BG ”', 'BG ” text', '” text expanded', 'text expanded “', 'expanded “ Blood', '“ Blood group', 'Blood group ”', 'group ” .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['instance', 'phrase', 'group', '”', 'text', 'group'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['instanc', ',', 'phrase', '“', 'blood', 'group', '(', 'bg', ')', '”', 'detect', 'occurr', '“', 'bg', '”', 'text', 'expand', '“', 'blood', 'group', '”', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['instanc', ',', 'phrase', '“', 'blood', 'group', '(', 'bg', ')', '”', 'detect', 'occurr', '“', 'bg', '”', 'text', 'expand', '“', 'blood', 'group', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['instance', ',', 'phrase', '“', 'Blood', 'group', '(', 'BG', ')', '”', 'detected', 'occurrence', '“', 'BG', '”', 'text', 'expanded', '“', 'Blood', 'group', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

58 --> Entity Recognition: Recognizes specific entities like email addresses, URLs, citations and chemicals  using regular expressions. 


 ---- TOKENS ----

 ['Entity', 'Recognition', ':', 'Recognizes', 'specific', 'entities', 'like', 'email', 'addresses', ',', 'URLs', ',', 'citations', 'and', 'chemicals', 'using', 'regular', 'expressions', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Entity', 'NN'), ('Recognition', 'NN'), (':', ':'), ('Recognizes', 'NNP'), ('specific', 'JJ'), ('entities', 'NNS'), ('like', 'IN'), ('email', 'NN'), ('addresses', 'NNS'), (',', ','), ('URLs', 'NNP'), (',', ','), ('citations', 'NNS'), ('and', 'CC'), ('chemicals', 'NNS'), ('using', 'VBG'), ('regular', 'JJ'), ('expressions', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Entity', 'Recognition', ':', 'Recognizes', 'specific', 'entities', 'like', 'email', 'addresses', ',', 'URLs', ',', 'citations', 'chemicals', 'using', 'regular', 'expressions', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Entity', 'NN'), ('Recognition', 'NN'), (':', ':'), ('Recognizes', 'NNP'), ('specific', 'JJ'), ('entities', 'NNS'), ('like', 'IN'), ('email', 'NN'), ('addresses', 'NNS'), (',', ','), ('URLs', 'NNP'), (',', ','), ('citations', 'NNS'), ('chemicals', 'NNS'), ('using', 'VBG'), ('regular', 'JJ'), ('expressions', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Entity Recognition', 'Recognition :', ': Recognizes', 'Recognizes specific', 'specific entities', 'entities like', 'like email', 'email addresses', 'addresses ,', ', URLs', 'URLs ,', ', citations', 'citations chemicals', 'chemicals using', 'using regular', 'regular expressions', 'expressions .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Entity Recognition :', 'Recognition : Recognizes', ': Recognizes specific', 'Recognizes specific entities', 'specific entities like', 'entities like email', 'like email addresses', 'email addresses ,', 'addresses , URLs', ', URLs ,', 'URLs , citations', ', citations chemicals', 'citations chemicals using', 'chemicals using regular', 'using regular expressions', 'regular expressions .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['Entity', 'Recognition', 'email'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['URLs']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Entity']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['entiti', 'recognit', ':', 'recogn', 'specif', 'entiti', 'like', 'email', 'address', ',', 'url', ',', 'citat', 'chemic', 'use', 'regular', 'express', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['entiti', 'recognit', ':', 'recogn', 'specif', 'entiti', 'like', 'email', 'address', ',', 'url', ',', 'citat', 'chemic', 'use', 'regular', 'express', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Entity', 'Recognition', ':', 'Recognizes', 'specific', 'entity', 'like', 'email', 'address', ',', 'URLs', ',', 'citation', 'chemical', 'using', 'regular', 'expression', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

59 --> For example “\b[a-z]+kinase\b” recognizes simple enzymes while “[A-Z][a- z]+ \([0-9]+\)” recognizes simple citations. 


 ---- TOKENS ----

 ['For', 'example', '“', '\\b', '[', 'a-z', ']', '+kinase\\b', '”', 'recognizes', 'simple', 'enzymes', 'while', '“', '[', 'A-Z', ']', '[', 'a-', 'z', ']', '+', '\\', '(', '[', '0-9', ']', '+\\', ')', '”', 'recognizes', 'simple', 'citations', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('For', 'IN'), ('example', 'NN'), ('“', 'NNP'), ('\\b', 'NNP'), ('[', 'NNP'), ('a-z', 'JJ'), (']', 'NNP'), ('+kinase\\b', 'NNP'), ('”', 'NNP'), ('recognizes', 'VBZ'), ('simple', 'JJ'), ('enzymes', 'NNS'), ('while', 'IN'), ('“', 'JJ'), ('[', 'JJ'), ('A-Z', 'NNP'), (']', 'NNP'), ('[', 'NNP'), ('a-', 'JJ'), ('z', 'NN'), (']', 'NNP'), ('+', 'NNP'), ('\\', 'NNP'), ('(', '('), ('[', 'JJ'), ('0-9', 'JJ'), (']', 'NNP'), ('+\\', 'NNP'), (')', ')'), ('”', 'NN'), ('recognizes', 'VBZ'), ('simple', 'JJ'), ('citations', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['example', '“', '\\b', '[', 'a-z', ']', '+kinase\\b', '”', 'recognizes', 'simple', 'enzymes', '“', '[', 'A-Z', ']', '[', 'a-', 'z', ']', '+', '\\', '(', '[', '0-9', ']', '+\\', ')', '”', 'recognizes', 'simple', 'citations', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('example', 'NN'), ('“', 'NNP'), ('\\b', 'NNP'), ('[', 'NNP'), ('a-z', 'JJ'), (']', 'NNP'), ('+kinase\\b', 'NNP'), ('”', 'NNP'), ('recognizes', 'VBZ'), ('simple', 'JJ'), ('enzymes', 'NNS'), ('“', 'JJ'), ('[', 'JJ'), ('A-Z', 'NNP'), (']', 'NNP'), ('[', 'NNP'), ('a-', 'JJ'), ('z', 'NN'), (']', 'NNP'), ('+', 'NNP'), ('\\', 'NNP'), ('(', '('), ('[', 'JJ'), ('0-9', 'JJ'), (']', 'NNP'), ('+\\', 'NNP'), (')', ')'), ('”', 'NN'), ('recognizes', 'VBZ'), ('simple', 'JJ'), ('citations', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['example “', '“ \\b', '\\b [', '[ a-z', 'a-z ]', '] +kinase\\b', '+kinase\\b ”', '” recognizes', 'recognizes simple', 'simple enzymes', 'enzymes “', '“ [', '[ A-Z', 'A-Z ]', '] [', '[ a-', 'a- z', 'z ]', '] +', '+ \\', '\\ (', '( [', '[ 0-9', '0-9 ]', '] +\\', '+\\ )', ') ”', '” recognizes', 'recognizes simple', 'simple citations', 'citations .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['example “ \\b', '“ \\b [', '\\b [ a-z', '[ a-z ]', 'a-z ] +kinase\\b', '] +kinase\\b ”', '+kinase\\b ” recognizes', '” recognizes simple', 'recognizes simple enzymes', 'simple enzymes “', 'enzymes “ [', '“ [ A-Z', '[ A-Z ]', 'A-Z ] [', '] [ a-', '[ a- z', 'a- z ]', 'z ] +', '] + \\', '+ \\ (', '\\ ( [', '( [ 0-9', '[ 0-9 ]', '0-9 ] +\\', '] +\\ )', '+\\ ) ”', ') ” recognizes', '” recognizes simple', 'recognizes simple citations', 'simple citations .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['example', 'a- z', '”'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['exampl', '“', '\\b', '[', 'a-z', ']', '+kinase\\b', '”', 'recogn', 'simpl', 'enzym', '“', '[', 'a-z', ']', '[', 'a-', 'z', ']', '+', '\\', '(', '[', '0-9', ']', '+\\', ')', '”', 'recogn', 'simpl', 'citat', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['exampl', '“', '\\b', '[', 'a-z', ']', '+kinase\\b', '”', 'recogn', 'simpl', 'enzym', '“', '[', 'a-z', ']', '[', 'a-', 'z', ']', '+', '\\', '(', '[', '0-9', ']', '+\\', ')', '”', 'recogn', 'simpl', 'citat', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['example', '“', '\\b', '[', 'a-z', ']', '+kinase\\b', '”', 'recognizes', 'simple', 'enzyme', '“', '[', 'A-Z', ']', '[', 'a-', 'z', ']', '+', '\\', '(', '[', '0-9', ']', '+\\', ')', '”', 'recognizes', 'simple', 'citation', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

60 --> Part-of-Speech Tagging: Tags tokens as linguistic parts of speech (verb, noun etc.) 


 ---- TOKENS ----

 ['Part-of-Speech', 'Tagging', ':', 'Tags', 'tokens', 'as', 'linguistic', 'parts', 'of', 'speech', '(', 'verb', ',', 'noun', 'etc', '.', ')'] 

 TOTAL TOKENS ==> 17

 ---- POST ----

 [('Part-of-Speech', 'JJ'), ('Tagging', 'NN'), (':', ':'), ('Tags', 'NNP'), ('tokens', 'VBZ'), ('as', 'IN'), ('linguistic', 'JJ'), ('parts', 'NNS'), ('of', 'IN'), ('speech', 'NN'), ('(', '('), ('verb', 'NN'), (',', ','), ('noun', 'JJ'), ('etc', 'FW'), ('.', '.'), (')', ')')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Part-of-Speech', 'Tagging', ':', 'Tags', 'tokens', 'linguistic', 'parts', 'speech', '(', 'verb', ',', 'noun', 'etc', '.', ')']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Part-of-Speech', 'JJ'), ('Tagging', 'NN'), (':', ':'), ('Tags', 'NNP'), ('tokens', 'VBZ'), ('linguistic', 'JJ'), ('parts', 'NNS'), ('speech', 'NN'), ('(', '('), ('verb', 'NN'), (',', ','), ('noun', 'JJ'), ('etc', 'FW'), ('.', '.'), (')', ')')] 



 ---- BI-GRAMS ---- 

 ['Part-of-Speech Tagging', 'Tagging :', ': Tags', 'Tags tokens', 'tokens linguistic', 'linguistic parts', 'parts speech', 'speech (', '( verb', 'verb ,', ', noun', 'noun etc', 'etc .', '. )'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Part-of-Speech Tagging :', 'Tagging : Tags', ': Tags tokens', 'Tags tokens linguistic', 'tokens linguistic parts', 'linguistic parts speech', 'parts speech (', 'speech ( verb', '( verb ,', 'verb , noun', ', noun etc', 'noun etc .', 'etc . )'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['Part-of-Speech Tagging', 'speech'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Tags']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['part-of-speech', 'tag', ':', 'tag', 'token', 'linguist', 'part', 'speech', '(', 'verb', ',', 'noun', 'etc', '.', ')']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['part-of-speech', 'tag', ':', 'tag', 'token', 'linguist', 'part', 'speech', '(', 'verb', ',', 'noun', 'etc', '.', ')']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Part-of-Speech', 'Tagging', ':', 'Tags', 'token', 'linguistic', 'part', 'speech', '(', 'verb', ',', 'noun', 'etc', '.', ')']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

61 --> depending on  their context. 


 ---- TOKENS ----

 ['depending', 'on', 'their', 'context', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('depending', 'VBG'), ('on', 'IN'), ('their', 'PRP$'), ('context', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['depending', 'context', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('depending', 'VBG'), ('context', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['depending context', 'context .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['depending context .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['context'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['depend', 'context', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['depend', 'context', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['depending', 'context', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

62 --> E.g., the word ‘lead’ will be tagged as verb in “This lead to the conclusion...”, as a noun  in “....where lead concentration was high”. 


 ---- TOKENS ----

 ['E.g.', ',', 'the', 'word', '‘', 'lead', '’', 'will', 'be', 'tagged', 'as', 'verb', 'in', '“', 'This', 'lead', 'to', 'the', 'conclusion', '...', '”', ',', 'as', 'a', 'noun', 'in', '“', '....', 'where', 'lead', 'concentration', 'was', 'high', '”', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('E.g.', 'NNP'), (',', ','), ('the', 'DT'), ('word', 'NN'), ('‘', 'NNP'), ('lead', 'NN'), ('’', 'NN'), ('will', 'MD'), ('be', 'VB'), ('tagged', 'VBN'), ('as', 'IN'), ('verb', 'NN'), ('in', 'IN'), ('“', 'NN'), ('This', 'DT'), ('lead', 'NN'), ('to', 'TO'), ('the', 'DT'), ('conclusion', 'NN'), ('...', ':'), ('”', 'RB'), (',', ','), ('as', 'IN'), ('a', 'DT'), ('noun', 'NN'), ('in', 'IN'), ('“', 'NN'), ('....', 'NN'), ('where', 'WRB'), ('lead', 'NN'), ('concentration', 'NN'), ('was', 'VBD'), ('high', 'JJ'), ('”', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['E.g.', ',', 'word', '‘', 'lead', '’', 'tagged', 'verb', '“', 'lead', 'conclusion', '...', '”', ',', 'noun', '“', '....', 'lead', 'concentration', 'high', '”', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('E.g.', 'NNP'), (',', ','), ('word', 'NN'), ('‘', 'NNP'), ('lead', 'NN'), ('’', 'NN'), ('tagged', 'VBD'), ('verb', 'NNS'), ('“', 'JJ'), ('lead', 'JJ'), ('conclusion', 'NN'), ('...', ':'), ('”', 'NN'), (',', ','), ('noun', 'JJ'), ('“', 'NN'), ('....', 'NNP'), ('lead', 'NN'), ('concentration', 'NN'), ('high', 'JJ'), ('”', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['E.g. ,', ', word', 'word ‘', '‘ lead', 'lead ’', '’ tagged', 'tagged verb', 'verb “', '“ lead', 'lead conclusion', 'conclusion ...', '... ”', '” ,', ', noun', 'noun “', '“ ....', '.... lead', 'lead concentration', 'concentration high', 'high ”', '” .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['E.g. , word', ', word ‘', 'word ‘ lead', '‘ lead ’', 'lead ’ tagged', '’ tagged verb', 'tagged verb “', 'verb “ lead', '“ lead conclusion', 'lead conclusion ...', 'conclusion ... ”', '... ” ,', '” , noun', ', noun “', 'noun “ ....', '“ .... lead', '.... lead concentration', 'lead concentration high', 'concentration high ”', 'high ” .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['word', 'lead', '’', '“ lead conclusion', '”', 'noun “', 'lead', 'concentration', 'high ”'] 

 TOTAL NOUN PHRASES --> 9 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['e.g.', ',', 'word', '‘', 'lead', '’', 'tag', 'verb', '“', 'lead', 'conclus', '...', '”', ',', 'noun', '“', '....', 'lead', 'concentr', 'high', '”', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['e.g.', ',', 'word', '‘', 'lead', '’', 'tag', 'verb', '“', 'lead', 'conclus', '...', '”', ',', 'noun', '“', '....', 'lead', 'concentr', 'high', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['E.g.', ',', 'word', '‘', 'lead', '’', 'tagged', 'verb', '“', 'lead', 'conclusion', '...', '”', ',', 'noun', '“', '....', 'lead', 'concentration', 'high', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

63 --> Noun Phrase Detection [Alternative Workflow, see above]: Detects noun phrases in preanalyzed text  (i.a. 


 ---- TOKENS ----

 ['Noun', 'Phrase', 'Detection', '[', 'Alternative', 'Workflow', ',', 'see', 'above', ']', ':', 'Detects', 'noun', 'phrases', 'in', 'preanalyzed', 'text', '(', 'i.a', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('Noun', 'NNP'), ('Phrase', 'NNP'), ('Detection', 'NNP'), ('[', 'NNP'), ('Alternative', 'NNP'), ('Workflow', 'NNP'), (',', ','), ('see', 'VBP'), ('above', 'IN'), (']', 'NN'), (':', ':'), ('Detects', 'NNS'), ('noun', 'VBP'), ('phrases', 'NNS'), ('in', 'IN'), ('preanalyzed', 'JJ'), ('text', 'NN'), ('(', '('), ('i.a', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Noun', 'Phrase', 'Detection', '[', 'Alternative', 'Workflow', ',', 'see', ']', ':', 'Detects', 'noun', 'phrases', 'preanalyzed', 'text', '(', 'i.a', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Noun', 'NNP'), ('Phrase', 'NNP'), ('Detection', 'NNP'), ('[', 'NNP'), ('Alternative', 'NNP'), ('Workflow', 'NNP'), (',', ','), ('see', 'VBP'), (']', 'JJ'), (':', ':'), ('Detects', 'NNS'), ('noun', 'VBP'), ('phrases', 'NNS'), ('preanalyzed', 'VBN'), ('text', 'NN'), ('(', '('), ('i.a', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Noun Phrase', 'Phrase Detection', 'Detection [', '[ Alternative', 'Alternative Workflow', 'Workflow ,', ', see', 'see ]', '] :', ': Detects', 'Detects noun', 'noun phrases', 'phrases preanalyzed', 'preanalyzed text', 'text (', '( i.a', 'i.a .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Noun Phrase Detection', 'Phrase Detection [', 'Detection [ Alternative', '[ Alternative Workflow', 'Alternative Workflow ,', 'Workflow , see', ', see ]', 'see ] :', '] : Detects', ': Detects noun', 'Detects noun phrases', 'noun phrases preanalyzed', 'phrases preanalyzed text', 'preanalyzed text (', 'text ( i.a', '( i.a .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['noun', 'phrase', 'detect', '[', 'altern', 'workflow', ',', 'see', ']', ':', 'detect', 'noun', 'phrase', 'preanalyz', 'text', '(', 'i.a', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['noun', 'phrase', 'detect', '[', 'altern', 'workflow', ',', 'see', ']', ':', 'detect', 'noun', 'phrase', 'preanalyz', 'text', '(', 'i.a', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Noun', 'Phrase', 'Detection', '[', 'Alternative', 'Workflow', ',', 'see', ']', ':', 'Detects', 'noun', 'phrase', 'preanalyzed', 'text', '(', 'i.a', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

64 --> by the modules described above), the first step of suggesting new terms for an existing or a new  thesaurus or vocabulary. 


 ---- TOKENS ----

 ['by', 'the', 'modules', 'described', 'above', ')', ',', 'the', 'first', 'step', 'of', 'suggesting', 'new', 'terms', 'for', 'an', 'existing', 'or', 'a', 'new', 'thesaurus', 'or', 'vocabulary', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('by', 'IN'), ('the', 'DT'), ('modules', 'NNS'), ('described', 'VBN'), ('above', 'IN'), (')', ')'), (',', ','), ('the', 'DT'), ('first', 'JJ'), ('step', 'NN'), ('of', 'IN'), ('suggesting', 'VBG'), ('new', 'JJ'), ('terms', 'NNS'), ('for', 'IN'), ('an', 'DT'), ('existing', 'VBG'), ('or', 'CC'), ('a', 'DT'), ('new', 'JJ'), ('thesaurus', 'NN'), ('or', 'CC'), ('vocabulary', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['modules', 'described', ')', ',', 'first', 'step', 'suggesting', 'new', 'terms', 'existing', 'new', 'thesaurus', 'vocabulary', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('modules', 'NNS'), ('described', 'VBN'), (')', ')'), (',', ','), ('first', 'JJ'), ('step', 'NN'), ('suggesting', 'VBG'), ('new', 'JJ'), ('terms', 'NNS'), ('existing', 'VBG'), ('new', 'JJ'), ('thesaurus', 'NN'), ('vocabulary', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['modules described', 'described )', ') ,', ', first', 'first step', 'step suggesting', 'suggesting new', 'new terms', 'terms existing', 'existing new', 'new thesaurus', 'thesaurus vocabulary', 'vocabulary .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['modules described )', 'described ) ,', ') , first', ', first step', 'first step suggesting', 'step suggesting new', 'suggesting new terms', 'new terms existing', 'terms existing new', 'existing new thesaurus', 'new thesaurus vocabulary', 'thesaurus vocabulary .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['modul', 'describ', ')', ',', 'first', 'step', 'suggest', 'new', 'term', 'exist', 'new', 'thesauru', 'vocabulari', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['modul', 'describ', ')', ',', 'first', 'step', 'suggest', 'new', 'term', 'exist', 'new', 'thesaurus', 'vocabulari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['module', 'described', ')', ',', 'first', 'step', 'suggesting', 'new', 'term', 'existing', 'new', 'thesaurus', 'vocabulary', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

65 --> For instance, processing “The novel association at the ABO locus provides  evidence” produces “novel association”, “ABO locus” and “evidence”. 


 ---- TOKENS ----

 ['For', 'instance', ',', 'processing', '“', 'The', 'novel', 'association', 'at', 'the', 'ABO', 'locus', 'provides', 'evidence', '”', 'produces', '“', 'novel', 'association', '”', ',', '“', 'ABO', 'locus', '”', 'and', '“', 'evidence', '”', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('processing', 'VBG'), ('“', 'PDT'), ('The', 'DT'), ('novel', 'JJ'), ('association', 'NN'), ('at', 'IN'), ('the', 'DT'), ('ABO', 'NNP'), ('locus', 'NN'), ('provides', 'VBZ'), ('evidence', 'NN'), ('”', 'NN'), ('produces', 'VBZ'), ('“', 'NNP'), ('novel', 'NN'), ('association', 'NN'), ('”', 'NNP'), (',', ','), ('“', 'NNP'), ('ABO', 'NNP'), ('locus', 'NN'), ('”', 'NN'), ('and', 'CC'), ('“', 'JJ'), ('evidence', 'NN'), ('”', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['instance', ',', 'processing', '“', 'novel', 'association', 'ABO', 'locus', 'provides', 'evidence', '”', 'produces', '“', 'novel', 'association', '”', ',', '“', 'ABO', 'locus', '”', '“', 'evidence', '”', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('instance', 'NN'), (',', ','), ('processing', 'VBG'), ('“', 'NNP'), ('novel', 'NN'), ('association', 'NN'), ('ABO', 'NNP'), ('locus', 'NN'), ('provides', 'VBZ'), ('evidence', 'NN'), ('”', 'NN'), ('produces', 'VBZ'), ('“', 'NNP'), ('novel', 'NN'), ('association', 'NN'), ('”', 'NNP'), (',', ','), ('“', 'NNP'), ('ABO', 'NNP'), ('locus', 'NN'), ('”', 'NNP'), ('“', 'NNP'), ('evidence', 'NN'), ('”', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['instance ,', ', processing', 'processing “', '“ novel', 'novel association', 'association ABO', 'ABO locus', 'locus provides', 'provides evidence', 'evidence ”', '” produces', 'produces “', '“ novel', 'novel association', 'association ”', '” ,', ', “', '“ ABO', 'ABO locus', 'locus ”', '” “', '“ evidence', 'evidence ”', '” .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['instance , processing', ', processing “', 'processing “ novel', '“ novel association', 'novel association ABO', 'association ABO locus', 'ABO locus provides', 'locus provides evidence', 'provides evidence ”', 'evidence ” produces', '” produces “', 'produces “ novel', '“ novel association', 'novel association ”', 'association ” ,', '” , “', ', “ ABO', '“ ABO locus', 'ABO locus ”', 'locus ” “', '” “ evidence', '“ evidence ”', 'evidence ” .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['instance', 'novel', 'association', 'locus', 'evidence', '”', 'novel', 'association', 'locus', 'evidence', '”'] 

 TOTAL NOUN PHRASES --> 11 



 ---- NER ----

 
 ORGANIZATION ---> ['ABO']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['instanc', ',', 'process', '“', 'novel', 'associ', 'abo', 'locu', 'provid', 'evid', '”', 'produc', '“', 'novel', 'associ', '”', ',', '“', 'abo', 'locu', '”', '“', 'evid', '”', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['instanc', ',', 'process', '“', 'novel', 'associ', 'abo', 'locus', 'provid', 'evid', '”', 'produc', '“', 'novel', 'associ', '”', ',', '“', 'abo', 'locus', '”', '“', 'evid', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['instance', ',', 'processing', '“', 'novel', 'association', 'ABO', 'locus', 'provides', 'evidence', '”', 'produce', '“', 'novel', 'association', '”', ',', '“', 'ABO', 'locus', '”', '“', 'evidence', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

66 --> Term Finder: Finds occurrences of the terms of a thesaurus or vocabulary in preanalyzed text (i.a. 


 ---- TOKENS ----

 ['Term', 'Finder', ':', 'Finds', 'occurrences', 'of', 'the', 'terms', 'of', 'a', 'thesaurus', 'or', 'vocabulary', 'in', 'preanalyzed', 'text', '(', 'i.a', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Term', 'JJ'), ('Finder', 'NNP'), (':', ':'), ('Finds', 'NNS'), ('occurrences', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('terms', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('thesaurus', 'NN'), ('or', 'CC'), ('vocabulary', 'NN'), ('in', 'IN'), ('preanalyzed', 'JJ'), ('text', 'NN'), ('(', '('), ('i.a', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Term', 'Finder', ':', 'Finds', 'occurrences', 'terms', 'thesaurus', 'vocabulary', 'preanalyzed', 'text', '(', 'i.a', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('Term', 'JJ'), ('Finder', 'NNP'), (':', ':'), ('Finds', 'NNS'), ('occurrences', 'NNS'), ('terms', 'NNS'), ('thesaurus', 'VBP'), ('vocabulary', 'JJ'), ('preanalyzed', 'VBN'), ('text', 'NN'), ('(', '('), ('i.a', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Term Finder', 'Finder :', ': Finds', 'Finds occurrences', 'occurrences terms', 'terms thesaurus', 'thesaurus vocabulary', 'vocabulary preanalyzed', 'preanalyzed text', 'text (', '( i.a', 'i.a .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['Term Finder :', 'Finder : Finds', ': Finds occurrences', 'Finds occurrences terms', 'occurrences terms thesaurus', 'terms thesaurus vocabulary', 'thesaurus vocabulary preanalyzed', 'vocabulary preanalyzed text', 'preanalyzed text (', 'text ( i.a', '( i.a .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['term', 'finder', ':', 'find', 'occurr', 'term', 'thesauru', 'vocabulari', 'preanalyz', 'text', '(', 'i.a', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['term', 'finder', ':', 'find', 'occurr', 'term', 'thesaurus', 'vocabulari', 'preanalyz', 'text', '(', 'i.a', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['Term', 'Finder', ':', 'Finds', 'occurrence', 'term', 'thesaurus', 'vocabulary', 'preanalyzed', 'text', '(', 'i.a', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

67 --> by  the modules described above). 


 ---- TOKENS ----

 ['by', 'the', 'modules', 'described', 'above', ')', '.'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('by', 'IN'), ('the', 'DT'), ('modules', 'NNS'), ('described', 'VBN'), ('above', 'IN'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['modules', 'described', ')', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('modules', 'NNS'), ('described', 'VBN'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['modules described', 'described )', ') .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['modules described )', 'described ) .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['modul', 'describ', ')', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['modul', 'describ', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['module', 'described', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

68 --> Term Annotation: Marks thesaurus terms identified in text with flags providing further information  about them, most notably to exclude terms from concept assignment (see below) when  disambiguation routines found its meaning in the given context to differ from its meaning in the  applied thesaurus. 


 ---- TOKENS ----

 ['Term', 'Annotation', ':', 'Marks', 'thesaurus', 'terms', 'identified', 'in', 'text', 'with', 'flags', 'providing', 'further', 'information', 'about', 'them', ',', 'most', 'notably', 'to', 'exclude', 'terms', 'from', 'concept', 'assignment', '(', 'see', 'below', ')', 'when', 'disambiguation', 'routines', 'found', 'its', 'meaning', 'in', 'the', 'given', 'context', 'to', 'differ', 'from', 'its', 'meaning', 'in', 'the', 'applied', 'thesaurus', '.'] 

 TOTAL TOKENS ==> 49

 ---- POST ----

 [('Term', 'JJ'), ('Annotation', 'NN'), (':', ':'), ('Marks', 'NNS'), ('thesaurus', 'VBP'), ('terms', 'NNS'), ('identified', 'VBN'), ('in', 'IN'), ('text', 'NN'), ('with', 'IN'), ('flags', 'NNS'), ('providing', 'VBG'), ('further', 'JJ'), ('information', 'NN'), ('about', 'IN'), ('them', 'PRP'), (',', ','), ('most', 'RBS'), ('notably', 'RB'), ('to', 'TO'), ('exclude', 'VB'), ('terms', 'NNS'), ('from', 'IN'), ('concept', 'NN'), ('assignment', 'NN'), ('(', '('), ('see', 'VB'), ('below', 'IN'), (')', ')'), ('when', 'WRB'), ('disambiguation', 'NN'), ('routines', 'VBZ'), ('found', 'VBD'), ('its', 'PRP$'), ('meaning', 'NN'), ('in', 'IN'), ('the', 'DT'), ('given', 'VBN'), ('context', 'NN'), ('to', 'TO'), ('differ', 'VB'), ('from', 'IN'), ('its', 'PRP$'), ('meaning', 'NN'), ('in', 'IN'), ('the', 'DT'), ('applied', 'JJ'), ('thesaurus', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Term', 'Annotation', ':', 'Marks', 'thesaurus', 'terms', 'identified', 'text', 'flags', 'providing', 'information', ',', 'notably', 'exclude', 'terms', 'concept', 'assignment', '(', 'see', ')', 'disambiguation', 'routines', 'found', 'meaning', 'given', 'context', 'differ', 'meaning', 'applied', 'thesaurus', '.']

 TOTAL FILTERED TOKENS ==>  31

 ---- POST FOR FILTERED TOKENS ----

 [('Term', 'JJ'), ('Annotation', 'NN'), (':', ':'), ('Marks', 'NNS'), ('thesaurus', 'VBP'), ('terms', 'NNS'), ('identified', 'VBN'), ('text', 'NN'), ('flags', 'NNS'), ('providing', 'VBG'), ('information', 'NN'), (',', ','), ('notably', 'RB'), ('exclude', 'VBP'), ('terms', 'NNS'), ('concept', 'VBP'), ('assignment', 'NN'), ('(', '('), ('see', 'VB'), (')', ')'), ('disambiguation', 'NN'), ('routines', 'NNS'), ('found', 'VBD'), ('meaning', 'VBG'), ('given', 'VBN'), ('context', 'JJ'), ('differ', 'NN'), ('meaning', 'NN'), ('applied', 'VBN'), ('thesaurus', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Term Annotation', 'Annotation :', ': Marks', 'Marks thesaurus', 'thesaurus terms', 'terms identified', 'identified text', 'text flags', 'flags providing', 'providing information', 'information ,', ', notably', 'notably exclude', 'exclude terms', 'terms concept', 'concept assignment', 'assignment (', '( see', 'see )', ') disambiguation', 'disambiguation routines', 'routines found', 'found meaning', 'meaning given', 'given context', 'context differ', 'differ meaning', 'meaning applied', 'applied thesaurus', 'thesaurus .'] 

 TOTAL BIGRAMS --> 30 



 ---- TRI-GRAMS ---- 

 ['Term Annotation :', 'Annotation : Marks', ': Marks thesaurus', 'Marks thesaurus terms', 'thesaurus terms identified', 'terms identified text', 'identified text flags', 'text flags providing', 'flags providing information', 'providing information ,', 'information , notably', ', notably exclude', 'notably exclude terms', 'exclude terms concept', 'terms concept assignment', 'concept assignment (', 'assignment ( see', '( see )', 'see ) disambiguation', ') disambiguation routines', 'disambiguation routines found', 'routines found meaning', 'found meaning given', 'meaning given context', 'given context differ', 'context differ meaning', 'differ meaning applied', 'meaning applied thesaurus', 'applied thesaurus .'] 

 TOTAL TRIGRAMS --> 29 



 ---- NOUN PHRASES ---- 

 ['Term Annotation', 'text', 'information', 'assignment', 'disambiguation', 'context differ', 'meaning', 'thesaurus'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['Annotation']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Term']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['term', 'annot', ':', 'mark', 'thesauru', 'term', 'identifi', 'text', 'flag', 'provid', 'inform', ',', 'notabl', 'exclud', 'term', 'concept', 'assign', '(', 'see', ')', 'disambigu', 'routin', 'found', 'mean', 'given', 'context', 'differ', 'mean', 'appli', 'thesauru', '.']

 TOTAL PORTER STEM WORDS ==> 31



 ---- SNOWBALL STEMMING ----

['term', 'annot', ':', 'mark', 'thesaurus', 'term', 'identifi', 'text', 'flag', 'provid', 'inform', ',', 'notabl', 'exclud', 'term', 'concept', 'assign', '(', 'see', ')', 'disambigu', 'routin', 'found', 'mean', 'given', 'context', 'differ', 'mean', 'appli', 'thesaurus', '.']

 TOTAL SNOWBALL STEM WORDS ==> 31



 ---- LEMMATIZATION ----

['Term', 'Annotation', ':', 'Marks', 'thesaurus', 'term', 'identified', 'text', 'flag', 'providing', 'information', ',', 'notably', 'exclude', 'term', 'concept', 'assignment', '(', 'see', ')', 'disambiguation', 'routine', 'found', 'meaning', 'given', 'context', 'differ', 'meaning', 'applied', 'thesaurus', '.']

 TOTAL LEMMATIZE WORDS ==> 31

************************************************************************************************************************

69 --> Idiom Removal: Excludes known idioms from concept assignment. 


 ---- TOKENS ----

 ['Idiom', 'Removal', ':', 'Excludes', 'known', 'idioms', 'from', 'concept', 'assignment', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('Idiom', 'NNP'), ('Removal', 'NNP'), (':', ':'), ('Excludes', 'NNS'), ('known', 'VBN'), ('idioms', 'NNS'), ('from', 'IN'), ('concept', 'JJ'), ('assignment', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Idiom', 'Removal', ':', 'Excludes', 'known', 'idioms', 'concept', 'assignment', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Idiom', 'NNP'), ('Removal', 'NNP'), (':', ':'), ('Excludes', 'NNS'), ('known', 'VBN'), ('idioms', 'NNS'), ('concept', 'JJ'), ('assignment', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Idiom Removal', 'Removal :', ': Excludes', 'Excludes known', 'known idioms', 'idioms concept', 'concept assignment', 'assignment .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Idiom Removal :', 'Removal : Excludes', ': Excludes known', 'Excludes known idioms', 'known idioms concept', 'idioms concept assignment', 'concept assignment .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['concept assignment'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Idiom', 'Removal']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['idiom', 'remov', ':', 'exclud', 'known', 'idiom', 'concept', 'assign', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['idiom', 'remov', ':', 'exclud', 'known', 'idiom', 'concept', 'assign', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Idiom', 'Removal', ':', 'Excludes', 'known', 'idiom', 'concept', 'assignment', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

70 --> For instance, “on the other hand”  will not produce the concept “hand”. 


 ---- TOKENS ----

 ['For', 'instance', ',', '“', 'on', 'the', 'other', 'hand', '”', 'will', 'not', 'produce', 'the', 'concept', '“', 'hand', '”', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('“', 'NN'), ('on', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('hand', 'NN'), ('”', 'NNP'), ('will', 'MD'), ('not', 'RB'), ('produce', 'VB'), ('the', 'DT'), ('concept', 'NN'), ('“', 'NNP'), ('hand', 'NN'), ('”', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['instance', ',', '“', 'hand', '”', 'produce', 'concept', '“', 'hand', '”', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('instance', 'NN'), (',', ','), ('“', 'JJ'), ('hand', 'NN'), ('”', 'NNP'), ('produce', 'VBP'), ('concept', 'NN'), ('“', 'NNP'), ('hand', 'NN'), ('”', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['instance ,', ', “', '“ hand', 'hand ”', '” produce', 'produce concept', 'concept “', '“ hand', 'hand ”', '” .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['instance , “', ', “ hand', '“ hand ”', 'hand ” produce', '” produce concept', 'produce concept “', 'concept “ hand', '“ hand ”', 'hand ” .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['instance', '“ hand', 'concept', 'hand'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['instanc', ',', '“', 'hand', '”', 'produc', 'concept', '“', 'hand', '”', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['instanc', ',', '“', 'hand', '”', 'produc', 'concept', '“', 'hand', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['instance', ',', '“', 'hand', '”', 'produce', 'concept', '“', 'hand', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

71 --> Fingerprint Creation: Assigns concepts to the remaining found terms and, based on a set of criteria  (see above), assigns a weight to each concept. 


 ---- TOKENS ----

 ['Fingerprint', 'Creation', ':', 'Assigns', 'concepts', 'to', 'the', 'remaining', 'found', 'terms', 'and', ',', 'based', 'on', 'a', 'set', 'of', 'criteria', '(', 'see', 'above', ')', ',', 'assigns', 'a', 'weight', 'to', 'each', 'concept', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('Fingerprint', 'JJ'), ('Creation', 'NN'), (':', ':'), ('Assigns', 'JJ'), ('concepts', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('remaining', 'VBG'), ('found', 'NN'), ('terms', 'NNS'), ('and', 'CC'), (',', ','), ('based', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('set', 'NN'), ('of', 'IN'), ('criteria', 'NNS'), ('(', '('), ('see', 'VB'), ('above', 'IN'), (')', ')'), (',', ','), ('assigns', 'VBZ'), ('a', 'DT'), ('weight', 'NN'), ('to', 'TO'), ('each', 'DT'), ('concept', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Fingerprint', 'Creation', ':', 'Assigns', 'concepts', 'remaining', 'found', 'terms', ',', 'based', 'set', 'criteria', '(', 'see', ')', ',', 'assigns', 'weight', 'concept', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('Fingerprint', 'JJ'), ('Creation', 'NN'), (':', ':'), ('Assigns', 'JJ'), ('concepts', 'NNS'), ('remaining', 'VBG'), ('found', 'NN'), ('terms', 'NNS'), (',', ','), ('based', 'VBN'), ('set', 'VBN'), ('criteria', 'NNS'), ('(', '('), ('see', 'NN'), (')', ')'), (',', ','), ('assigns', 'JJ'), ('weight', 'NN'), ('concept', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Fingerprint Creation', 'Creation :', ': Assigns', 'Assigns concepts', 'concepts remaining', 'remaining found', 'found terms', 'terms ,', ', based', 'based set', 'set criteria', 'criteria (', '( see', 'see )', ') ,', ', assigns', 'assigns weight', 'weight concept', 'concept .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['Fingerprint Creation :', 'Creation : Assigns', ': Assigns concepts', 'Assigns concepts remaining', 'concepts remaining found', 'remaining found terms', 'found terms ,', 'terms , based', ', based set', 'based set criteria', 'set criteria (', 'criteria ( see', '( see )', 'see ) ,', ') , assigns', ', assigns weight', 'assigns weight concept', 'weight concept .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['Fingerprint Creation', 'found', 'assigns weight', 'concept'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['Creation']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Fingerprint']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['fingerprint', 'creation', ':', 'assign', 'concept', 'remain', 'found', 'term', ',', 'base', 'set', 'criteria', '(', 'see', ')', ',', 'assign', 'weight', 'concept', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['fingerprint', 'creation', ':', 'assign', 'concept', 'remain', 'found', 'term', ',', 'base', 'set', 'criteria', '(', 'see', ')', ',', 'assign', 'weight', 'concept', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['Fingerprint', 'Creation', ':', 'Assigns', 'concept', 'remaining', 'found', 'term', ',', 'based', 'set', 'criterion', '(', 'see', ')', ',', 'assigns', 'weight', 'concept', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

72 --> 5  2. 


 ---- TOKENS ----

 ['5', '2', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('5', 'CD'), ('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['5', '2', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('5', 'CD'), ('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['5 2', '2 .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['5 2 .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['5', '2', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['5', '2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['5', '2', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

73 --> Example solutions powered by the Elsevier Fingerprint Engine  2.1. 


 ---- TOKENS ----

 ['Example', 'solutions', 'powered', 'by', 'the', 'Elsevier', 'Fingerprint', 'Engine', '2.1', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('Example', 'JJ'), ('solutions', 'NNS'), ('powered', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('2.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Example', 'solutions', 'powered', 'Elsevier', 'Fingerprint', 'Engine', '2.1', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Example', 'JJ'), ('solutions', 'NNS'), ('powered', 'VBN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('2.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Example solutions', 'solutions powered', 'powered Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine 2.1', '2.1 .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Example solutions powered', 'solutions powered Elsevier', 'powered Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine 2.1', 'Engine 2.1 .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Elsevier Fingerprint']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['exampl', 'solut', 'power', 'elsevi', 'fingerprint', 'engin', '2.1', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['exampl', 'solut', 'power', 'elsevi', 'fingerprint', 'engin', '2.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Example', 'solution', 'powered', 'Elsevier', 'Fingerprint', 'Engine', '2.1', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

74 --> National Institutes of Health  At the request of US Congress, in 2008 the National Institutes of Health (NIH) implemented a process  to provide more consistency and transparency in the reporting of its funded research. 


 ---- TOKENS ----

 ['National', 'Institutes', 'of', 'Health', 'At', 'the', 'request', 'of', 'US', 'Congress', ',', 'in', '2008', 'the', 'National', 'Institutes', 'of', 'Health', '(', 'NIH', ')', 'implemented', 'a', 'process', 'to', 'provide', 'more', 'consistency', 'and', 'transparency', 'in', 'the', 'reporting', 'of', 'its', 'funded', 'research', '.'] 

 TOTAL TOKENS ==> 38

 ---- POST ----

 [('National', 'NNP'), ('Institutes', 'NNP'), ('of', 'IN'), ('Health', 'NNP'), ('At', 'IN'), ('the', 'DT'), ('request', 'NN'), ('of', 'IN'), ('US', 'NNP'), ('Congress', 'NNP'), (',', ','), ('in', 'IN'), ('2008', 'CD'), ('the', 'DT'), ('National', 'NNP'), ('Institutes', 'NNPS'), ('of', 'IN'), ('Health', 'NNP'), ('(', '('), ('NIH', 'NNP'), (')', ')'), ('implemented', 'VBD'), ('a', 'DT'), ('process', 'NN'), ('to', 'TO'), ('provide', 'VB'), ('more', 'JJR'), ('consistency', 'NN'), ('and', 'CC'), ('transparency', 'NN'), ('in', 'IN'), ('the', 'DT'), ('reporting', 'NN'), ('of', 'IN'), ('its', 'PRP$'), ('funded', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['National', 'Institutes', 'Health', 'request', 'US', 'Congress', ',', '2008', 'National', 'Institutes', 'Health', '(', 'NIH', ')', 'implemented', 'process', 'provide', 'consistency', 'transparency', 'reporting', 'funded', 'research', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('National', 'NNP'), ('Institutes', 'NNP'), ('Health', 'NNP'), ('request', 'VB'), ('US', 'NNP'), ('Congress', 'NNP'), (',', ','), ('2008', 'CD'), ('National', 'NNP'), ('Institutes', 'NNPS'), ('Health', 'NNP'), ('(', '('), ('NIH', 'NNP'), (')', ')'), ('implemented', 'VBD'), ('process', 'NN'), ('provide', 'NN'), ('consistency', 'NN'), ('transparency', 'NN'), ('reporting', 'VBG'), ('funded', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['National Institutes', 'Institutes Health', 'Health request', 'request US', 'US Congress', 'Congress ,', ', 2008', '2008 National', 'National Institutes', 'Institutes Health', 'Health (', '( NIH', 'NIH )', ') implemented', 'implemented process', 'process provide', 'provide consistency', 'consistency transparency', 'transparency reporting', 'reporting funded', 'funded research', 'research .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['National Institutes Health', 'Institutes Health request', 'Health request US', 'request US Congress', 'US Congress ,', 'Congress , 2008', ', 2008 National', '2008 National Institutes', 'National Institutes Health', 'Institutes Health (', 'Health ( NIH', '( NIH )', 'NIH ) implemented', ') implemented process', 'implemented process provide', 'process provide consistency', 'provide consistency transparency', 'consistency transparency reporting', 'transparency reporting funded', 'reporting funded research', 'funded research .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['process', 'provide', 'consistency', 'transparency', 'funded research'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['National Institutes', 'US Congress', 'National Institutes Health']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['nation', 'institut', 'health', 'request', 'us', 'congress', ',', '2008', 'nation', 'institut', 'health', '(', 'nih', ')', 'implement', 'process', 'provid', 'consist', 'transpar', 'report', 'fund', 'research', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['nation', 'institut', 'health', 'request', 'us', 'congress', ',', '2008', 'nation', 'institut', 'health', '(', 'nih', ')', 'implement', 'process', 'provid', 'consist', 'transpar', 'report', 'fund', 'research', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['National', 'Institutes', 'Health', 'request', 'US', 'Congress', ',', '2008', 'National', 'Institutes', 'Health', '(', 'NIH', ')', 'implemented', 'process', 'provide', 'consistency', 'transparency', 'reporting', 'funded', 'research', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

75 --> This new  process uses the Research, Condition, and Disease Categorization (RCDC) system, a custom  solution powered by the Elsevier Fingerprint Engine, to mine the text of grant titles, abstracts, and  specific aims, extract the terms used to describe the research being performed, and apply these  terms to match projects to NIH-wide category definitions. 


 ---- TOKENS ----

 ['This', 'new', 'process', 'uses', 'the', 'Research', ',', 'Condition', ',', 'and', 'Disease', 'Categorization', '(', 'RCDC', ')', 'system', ',', 'a', 'custom', 'solution', 'powered', 'by', 'the', 'Elsevier', 'Fingerprint', 'Engine', ',', 'to', 'mine', 'the', 'text', 'of', 'grant', 'titles', ',', 'abstracts', ',', 'and', 'specific', 'aims', ',', 'extract', 'the', 'terms', 'used', 'to', 'describe', 'the', 'research', 'being', 'performed', ',', 'and', 'apply', 'these', 'terms', 'to', 'match', 'projects', 'to', 'NIH-wide', 'category', 'definitions', '.'] 

 TOTAL TOKENS ==> 64

 ---- POST ----

 [('This', 'DT'), ('new', 'JJ'), ('process', 'NN'), ('uses', 'VBZ'), ('the', 'DT'), ('Research', 'NNP'), (',', ','), ('Condition', 'NNP'), (',', ','), ('and', 'CC'), ('Disease', 'NNP'), ('Categorization', 'NNP'), ('(', '('), ('RCDC', 'NNP'), (')', ')'), ('system', 'NN'), (',', ','), ('a', 'DT'), ('custom', 'JJ'), ('solution', 'NN'), ('powered', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), (',', ','), ('to', 'TO'), ('mine', 'VB'), ('the', 'DT'), ('text', 'NN'), ('of', 'IN'), ('grant', 'NN'), ('titles', 'NNS'), (',', ','), ('abstracts', 'NNS'), (',', ','), ('and', 'CC'), ('specific', 'JJ'), ('aims', 'NNS'), (',', ','), ('extract', 'VB'), ('the', 'DT'), ('terms', 'NNS'), ('used', 'VBN'), ('to', 'TO'), ('describe', 'VB'), ('the', 'DT'), ('research', 'NN'), ('being', 'VBG'), ('performed', 'VBN'), (',', ','), ('and', 'CC'), ('apply', 'VB'), ('these', 'DT'), ('terms', 'NNS'), ('to', 'TO'), ('match', 'VB'), ('projects', 'NNS'), ('to', 'TO'), ('NIH-wide', 'NNP'), ('category', 'NN'), ('definitions', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['new', 'process', 'uses', 'Research', ',', 'Condition', ',', 'Disease', 'Categorization', '(', 'RCDC', ')', 'system', ',', 'custom', 'solution', 'powered', 'Elsevier', 'Fingerprint', 'Engine', ',', 'mine', 'text', 'grant', 'titles', ',', 'abstracts', ',', 'specific', 'aims', ',', 'extract', 'terms', 'used', 'describe', 'research', 'performed', ',', 'apply', 'terms', 'match', 'projects', 'NIH-wide', 'category', 'definitions', '.']

 TOTAL FILTERED TOKENS ==>  46

 ---- POST FOR FILTERED TOKENS ----

 [('new', 'JJ'), ('process', 'NN'), ('uses', 'VBZ'), ('Research', 'NNP'), (',', ','), ('Condition', 'NNP'), (',', ','), ('Disease', 'NNP'), ('Categorization', 'NNP'), ('(', '('), ('RCDC', 'NNP'), (')', ')'), ('system', 'NN'), (',', ','), ('custom', 'JJ'), ('solution', 'NN'), ('powered', 'VBN'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), (',', ','), ('mine', 'NN'), ('text', 'NN'), ('grant', 'NN'), ('titles', 'NNS'), (',', ','), ('abstracts', 'NNS'), (',', ','), ('specific', 'JJ'), ('aims', 'NNS'), (',', ','), ('extract', 'NN'), ('terms', 'NNS'), ('used', 'VBD'), ('describe', 'NN'), ('research', 'NN'), ('performed', 'VBD'), (',', ','), ('apply', 'VB'), ('terms', 'NNS'), ('match', 'JJ'), ('projects', 'NNS'), ('NIH-wide', 'NNP'), ('category', 'NN'), ('definitions', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['new process', 'process uses', 'uses Research', 'Research ,', ', Condition', 'Condition ,', ', Disease', 'Disease Categorization', 'Categorization (', '( RCDC', 'RCDC )', ') system', 'system ,', ', custom', 'custom solution', 'solution powered', 'powered Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine ,', ', mine', 'mine text', 'text grant', 'grant titles', 'titles ,', ', abstracts', 'abstracts ,', ', specific', 'specific aims', 'aims ,', ', extract', 'extract terms', 'terms used', 'used describe', 'describe research', 'research performed', 'performed ,', ', apply', 'apply terms', 'terms match', 'match projects', 'projects NIH-wide', 'NIH-wide category', 'category definitions', 'definitions .'] 

 TOTAL BIGRAMS --> 45 



 ---- TRI-GRAMS ---- 

 ['new process uses', 'process uses Research', 'uses Research ,', 'Research , Condition', ', Condition ,', 'Condition , Disease', ', Disease Categorization', 'Disease Categorization (', 'Categorization ( RCDC', '( RCDC )', 'RCDC ) system', ') system ,', 'system , custom', ', custom solution', 'custom solution powered', 'solution powered Elsevier', 'powered Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine ,', 'Engine , mine', ', mine text', 'mine text grant', 'text grant titles', 'grant titles ,', 'titles , abstracts', ', abstracts ,', 'abstracts , specific', ', specific aims', 'specific aims ,', 'aims , extract', ', extract terms', 'extract terms used', 'terms used describe', 'used describe research', 'describe research performed', 'research performed ,', 'performed , apply', ', apply terms', 'apply terms match', 'terms match projects', 'match projects NIH-wide', 'projects NIH-wide category', 'NIH-wide category definitions', 'category definitions .'] 

 TOTAL TRIGRAMS --> 44 



 ---- NOUN PHRASES ---- 

 ['new process', 'system', 'custom solution', 'mine', 'text', 'grant', 'extract', 'describe', 'research', 'category'] 

 TOTAL NOUN PHRASES --> 10 



 ---- NER ----

 
 ORGANIZATION ---> ['Condition']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Research', 'Disease Categorization', 'Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 3 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['new', 'process', 'use', 'research', ',', 'condit', ',', 'diseas', 'categor', '(', 'rcdc', ')', 'system', ',', 'custom', 'solut', 'power', 'elsevi', 'fingerprint', 'engin', ',', 'mine', 'text', 'grant', 'titl', ',', 'abstract', ',', 'specif', 'aim', ',', 'extract', 'term', 'use', 'describ', 'research', 'perform', ',', 'appli', 'term', 'match', 'project', 'nih-wid', 'categori', 'definit', '.']

 TOTAL PORTER STEM WORDS ==> 46



 ---- SNOWBALL STEMMING ----

['new', 'process', 'use', 'research', ',', 'condit', ',', 'diseas', 'categor', '(', 'rcdc', ')', 'system', ',', 'custom', 'solut', 'power', 'elsevi', 'fingerprint', 'engin', ',', 'mine', 'text', 'grant', 'titl', ',', 'abstract', ',', 'specif', 'aim', ',', 'extract', 'term', 'use', 'describ', 'research', 'perform', ',', 'appli', 'term', 'match', 'project', 'nih-wid', 'categori', 'definit', '.']

 TOTAL SNOWBALL STEM WORDS ==> 46



 ---- LEMMATIZATION ----

['new', 'process', 'us', 'Research', ',', 'Condition', ',', 'Disease', 'Categorization', '(', 'RCDC', ')', 'system', ',', 'custom', 'solution', 'powered', 'Elsevier', 'Fingerprint', 'Engine', ',', 'mine', 'text', 'grant', 'title', ',', 'abstract', ',', 'specific', 'aim', ',', 'extract', 'term', 'used', 'describe', 'research', 'performed', ',', 'apply', 'term', 'match', 'project', 'NIH-wide', 'category', 'definition', '.']

 TOTAL LEMMATIZE WORDS ==> 46

************************************************************************************************************************

76 --> The total funding for all projects in each  research category represents NIH’s best estimate based on the category definition. 


 ---- TOKENS ----

 ['The', 'total', 'funding', 'for', 'all', 'projects', 'in', 'each', 'research', 'category', 'represents', 'NIH', '’', 's', 'best', 'estimate', 'based', 'on', 'the', 'category', 'definition', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('The', 'DT'), ('total', 'JJ'), ('funding', 'NN'), ('for', 'IN'), ('all', 'DT'), ('projects', 'NNS'), ('in', 'IN'), ('each', 'DT'), ('research', 'NN'), ('category', 'NN'), ('represents', 'VBZ'), ('NIH', 'NNP'), ('’', 'NNP'), ('s', 'NN'), ('best', 'JJS'), ('estimate', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('category', 'NN'), ('definition', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['total', 'funding', 'projects', 'research', 'category', 'represents', 'NIH', '’', 'best', 'estimate', 'based', 'category', 'definition', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('total', 'JJ'), ('funding', 'NN'), ('projects', 'NNS'), ('research', 'NN'), ('category', 'NN'), ('represents', 'VBZ'), ('NIH', 'NNP'), ('’', 'NNP'), ('best', 'JJS'), ('estimate', 'NN'), ('based', 'VBN'), ('category', 'JJ'), ('definition', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['total funding', 'funding projects', 'projects research', 'research category', 'category represents', 'represents NIH', 'NIH ’', '’ best', 'best estimate', 'estimate based', 'based category', 'category definition', 'definition .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['total funding projects', 'funding projects research', 'projects research category', 'research category represents', 'category represents NIH', 'represents NIH ’', 'NIH ’ best', '’ best estimate', 'best estimate based', 'estimate based category', 'based category definition', 'category definition .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['total funding', 'research', 'category', 'estimate', 'category definition'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['NIH']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['total', 'fund', 'project', 'research', 'categori', 'repres', 'nih', '’', 'best', 'estim', 'base', 'categori', 'definit', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['total', 'fund', 'project', 'research', 'categori', 'repres', 'nih', '’', 'best', 'estim', 'base', 'categori', 'definit', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['total', 'funding', 'project', 'research', 'category', 'represents', 'NIH', '’', 'best', 'estimate', 'based', 'category', 'definition', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

77 --> The NIH uses the  system to categorize approximately $29 billion USD of research funding per year. 


 ---- TOKENS ----

 ['The', 'NIH', 'uses', 'the', 'system', 'to', 'categorize', 'approximately', '$', '29', 'billion', 'USD', 'of', 'research', 'funding', 'per', 'year', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('The', 'DT'), ('NIH', 'NNP'), ('uses', 'VBZ'), ('the', 'DT'), ('system', 'NN'), ('to', 'TO'), ('categorize', 'VB'), ('approximately', 'RB'), ('$', '$'), ('29', 'CD'), ('billion', 'CD'), ('USD', 'NNP'), ('of', 'IN'), ('research', 'NN'), ('funding', 'NN'), ('per', 'IN'), ('year', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['NIH', 'uses', 'system', 'categorize', 'approximately', '$', '29', 'billion', 'USD', 'research', 'funding', 'per', 'year', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('NIH', 'NNP'), ('uses', 'VBZ'), ('system', 'NN'), ('categorize', 'VB'), ('approximately', 'RB'), ('$', '$'), ('29', 'CD'), ('billion', 'CD'), ('USD', 'NNP'), ('research', 'NN'), ('funding', 'NN'), ('per', 'IN'), ('year', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['NIH uses', 'uses system', 'system categorize', 'categorize approximately', 'approximately $', '$ 29', '29 billion', 'billion USD', 'USD research', 'research funding', 'funding per', 'per year', 'year .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['NIH uses system', 'uses system categorize', 'system categorize approximately', 'categorize approximately $', 'approximately $ 29', '$ 29 billion', '29 billion USD', 'billion USD research', 'USD research funding', 'research funding per', 'funding per year', 'per year .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['system', 'research', 'funding', 'year'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['NIH', 'USD']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['nih', 'use', 'system', 'categor', 'approxim', '$', '29', 'billion', 'usd', 'research', 'fund', 'per', 'year', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['nih', 'use', 'system', 'categor', 'approxim', '$', '29', 'billion', 'usd', 'research', 'fund', 'per', 'year', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['NIH', 'us', 'system', 'categorize', 'approximately', '$', '29', 'billion', 'USD', 'research', 'funding', 'per', 'year', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

78 --> 2.2. 


 ---- TOKENS ----

 ['2.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

79 --> Wellcome Trust  The Wellcome Trust uses solutions driven by the Elsevier Fingerprint Engine to enhance its reporting  capabilities. 


 ---- TOKENS ----

 ['Wellcome', 'Trust', 'The', 'Wellcome', 'Trust', 'uses', 'solutions', 'driven', 'by', 'the', 'Elsevier', 'Fingerprint', 'Engine', 'to', 'enhance', 'its', 'reporting', 'capabilities', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Wellcome', 'NNP'), ('Trust', 'NNP'), ('The', 'DT'), ('Wellcome', 'NNP'), ('Trust', 'NNP'), ('uses', 'VBZ'), ('solutions', 'NNS'), ('driven', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('to', 'TO'), ('enhance', 'VB'), ('its', 'PRP$'), ('reporting', 'NN'), ('capabilities', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Wellcome', 'Trust', 'Wellcome', 'Trust', 'uses', 'solutions', 'driven', 'Elsevier', 'Fingerprint', 'Engine', 'enhance', 'reporting', 'capabilities', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('Wellcome', 'NNP'), ('Trust', 'NNP'), ('Wellcome', 'NNP'), ('Trust', 'NNP'), ('uses', 'VBZ'), ('solutions', 'NNS'), ('driven', 'RB'), ('Elsevier', 'NNP'), ('Fingerprint', 'NNP'), ('Engine', 'NNP'), ('enhance', 'NN'), ('reporting', 'NN'), ('capabilities', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Wellcome Trust', 'Trust Wellcome', 'Wellcome Trust', 'Trust uses', 'uses solutions', 'solutions driven', 'driven Elsevier', 'Elsevier Fingerprint', 'Fingerprint Engine', 'Engine enhance', 'enhance reporting', 'reporting capabilities', 'capabilities .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['Wellcome Trust Wellcome', 'Trust Wellcome Trust', 'Wellcome Trust uses', 'Trust uses solutions', 'uses solutions driven', 'solutions driven Elsevier', 'driven Elsevier Fingerprint', 'Elsevier Fingerprint Engine', 'Fingerprint Engine enhance', 'Engine enhance reporting', 'enhance reporting capabilities', 'reporting capabilities .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['enhance', 'reporting'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Wellcome', 'Trust Wellcome Trust', 'Elsevier Fingerprint Engine']
 TOTAL PERSON ENTITY --> 3 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['wellcom', 'trust', 'wellcom', 'trust', 'use', 'solut', 'driven', 'elsevi', 'fingerprint', 'engin', 'enhanc', 'report', 'capabl', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['wellcom', 'trust', 'wellcom', 'trust', 'use', 'solut', 'driven', 'elsevi', 'fingerprint', 'engin', 'enhanc', 'report', 'capabl', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['Wellcome', 'Trust', 'Wellcome', 'Trust', 'us', 'solution', 'driven', 'Elsevier', 'Fingerprint', 'Engine', 'enhance', 'reporting', 'capability', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

80 --> Restricted by inflexible, inconsistent and static reporting based on manually applied  keyword terms, the Wellcome Trust introduced Elsevier’s Fingerprint technology to allow them to  define their own search categories for up to date, accurate, flexible and consistent reporting. 


 ---- TOKENS ----

 ['Restricted', 'by', 'inflexible', ',', 'inconsistent', 'and', 'static', 'reporting', 'based', 'on', 'manually', 'applied', 'keyword', 'terms', ',', 'the', 'Wellcome', 'Trust', 'introduced', 'Elsevier', '’', 's', 'Fingerprint', 'technology', 'to', 'allow', 'them', 'to', 'define', 'their', 'own', 'search', 'categories', 'for', 'up', 'to', 'date', ',', 'accurate', ',', 'flexible', 'and', 'consistent', 'reporting', '.'] 

 TOTAL TOKENS ==> 45

 ---- POST ----

 [('Restricted', 'VBN'), ('by', 'IN'), ('inflexible', 'JJ'), (',', ','), ('inconsistent', 'JJ'), ('and', 'CC'), ('static', 'JJ'), ('reporting', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('manually', 'RB'), ('applied', 'VBN'), ('keyword', 'NN'), ('terms', 'NNS'), (',', ','), ('the', 'DT'), ('Wellcome', 'NNP'), ('Trust', 'NNP'), ('introduced', 'VBD'), ('Elsevier', 'NNP'), ('’', 'NNP'), ('s', 'PRP'), ('Fingerprint', 'NNP'), ('technology', 'NN'), ('to', 'TO'), ('allow', 'VB'), ('them', 'PRP'), ('to', 'TO'), ('define', 'VB'), ('their', 'PRP$'), ('own', 'JJ'), ('search', 'NN'), ('categories', 'NNS'), ('for', 'IN'), ('up', 'IN'), ('to', 'TO'), ('date', 'NN'), (',', ','), ('accurate', 'NN'), (',', ','), ('flexible', 'JJ'), ('and', 'CC'), ('consistent', 'JJ'), ('reporting', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Restricted', 'inflexible', ',', 'inconsistent', 'static', 'reporting', 'based', 'manually', 'applied', 'keyword', 'terms', ',', 'Wellcome', 'Trust', 'introduced', 'Elsevier', '’', 'Fingerprint', 'technology', 'allow', 'define', 'search', 'categories', 'date', ',', 'accurate', ',', 'flexible', 'consistent', 'reporting', '.']

 TOTAL FILTERED TOKENS ==>  31

 ---- POST FOR FILTERED TOKENS ----

 [('Restricted', 'VBN'), ('inflexible', 'JJ'), (',', ','), ('inconsistent', 'JJ'), ('static', 'JJ'), ('reporting', 'NN'), ('based', 'VBN'), ('manually', 'RB'), ('applied', 'JJ'), ('keyword', 'NN'), ('terms', 'NNS'), (',', ','), ('Wellcome', 'NNP'), ('Trust', 'NNP'), ('introduced', 'VBD'), ('Elsevier', 'NNP'), ('’', 'NNP'), ('Fingerprint', 'NNP'), ('technology', 'NN'), ('allow', 'VBP'), ('define', 'NN'), ('search', 'NN'), ('categories', 'NNS'), ('date', 'NN'), (',', ','), ('accurate', 'NN'), (',', ','), ('flexible', 'JJ'), ('consistent', 'JJ'), ('reporting', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Restricted inflexible', 'inflexible ,', ', inconsistent', 'inconsistent static', 'static reporting', 'reporting based', 'based manually', 'manually applied', 'applied keyword', 'keyword terms', 'terms ,', ', Wellcome', 'Wellcome Trust', 'Trust introduced', 'introduced Elsevier', 'Elsevier ’', '’ Fingerprint', 'Fingerprint technology', 'technology allow', 'allow define', 'define search', 'search categories', 'categories date', 'date ,', ', accurate', 'accurate ,', ', flexible', 'flexible consistent', 'consistent reporting', 'reporting .'] 

 TOTAL BIGRAMS --> 30 



 ---- TRI-GRAMS ---- 

 ['Restricted inflexible ,', 'inflexible , inconsistent', ', inconsistent static', 'inconsistent static reporting', 'static reporting based', 'reporting based manually', 'based manually applied', 'manually applied keyword', 'applied keyword terms', 'keyword terms ,', 'terms , Wellcome', ', Wellcome Trust', 'Wellcome Trust introduced', 'Trust introduced Elsevier', 'introduced Elsevier ’', 'Elsevier ’ Fingerprint', '’ Fingerprint technology', 'Fingerprint technology allow', 'technology allow define', 'allow define search', 'define search categories', 'search categories date', 'categories date ,', 'date , accurate', ', accurate ,', 'accurate , flexible', ', flexible consistent', 'flexible consistent reporting', 'consistent reporting .'] 

 TOTAL TRIGRAMS --> 29 



 ---- NOUN PHRASES ---- 

 ['inconsistent static reporting', 'applied keyword', 'technology', 'define', 'search', 'date', 'accurate', 'flexible consistent reporting'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Wellcome Trust', 'Elsevier']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['restrict', 'inflex', ',', 'inconsist', 'static', 'report', 'base', 'manual', 'appli', 'keyword', 'term', ',', 'wellcom', 'trust', 'introduc', 'elsevi', '’', 'fingerprint', 'technolog', 'allow', 'defin', 'search', 'categori', 'date', ',', 'accur', ',', 'flexibl', 'consist', 'report', '.']

 TOTAL PORTER STEM WORDS ==> 31



 ---- SNOWBALL STEMMING ----

['restrict', 'inflex', ',', 'inconsist', 'static', 'report', 'base', 'manual', 'appli', 'keyword', 'term', ',', 'wellcom', 'trust', 'introduc', 'elsevi', '’', 'fingerprint', 'technolog', 'allow', 'defin', 'search', 'categori', 'date', ',', 'accur', ',', 'flexibl', 'consist', 'report', '.']

 TOTAL SNOWBALL STEM WORDS ==> 31



 ---- LEMMATIZATION ----

['Restricted', 'inflexible', ',', 'inconsistent', 'static', 'reporting', 'based', 'manually', 'applied', 'keyword', 'term', ',', 'Wellcome', 'Trust', 'introduced', 'Elsevier', '’', 'Fingerprint', 'technology', 'allow', 'define', 'search', 'category', 'date', ',', 'accurate', ',', 'flexible', 'consistent', 'reporting', '.']

 TOTAL LEMMATIZE WORDS ==> 31

************************************************************************************************************************

81 --> The  Wellcome Trust has also used the Reviewer Finder to mine the text of grant proposals, extract the  terms used to describe each submission, and apply these terms to match applications to potential  reviewers. 


 ---- TOKENS ----

 ['The', 'Wellcome', 'Trust', 'has', 'also', 'used', 'the', 'Reviewer', 'Finder', 'to', 'mine', 'the', 'text', 'of', 'grant', 'proposals', ',', 'extract', 'the', 'terms', 'used', 'to', 'describe', 'each', 'submission', ',', 'and', 'apply', 'these', 'terms', 'to', 'match', 'applications', 'to', 'potential', 'reviewers', '.'] 

 TOTAL TOKENS ==> 37

 ---- POST ----

 [('The', 'DT'), ('Wellcome', 'NNP'), ('Trust', 'NNP'), ('has', 'VBZ'), ('also', 'RB'), ('used', 'VBN'), ('the', 'DT'), ('Reviewer', 'NNP'), ('Finder', 'NNP'), ('to', 'TO'), ('mine', 'VB'), ('the', 'DT'), ('text', 'NN'), ('of', 'IN'), ('grant', 'NN'), ('proposals', 'NNS'), (',', ','), ('extract', 'VBP'), ('the', 'DT'), ('terms', 'NNS'), ('used', 'VBN'), ('to', 'TO'), ('describe', 'VB'), ('each', 'DT'), ('submission', 'NN'), (',', ','), ('and', 'CC'), ('apply', 'VB'), ('these', 'DT'), ('terms', 'NNS'), ('to', 'TO'), ('match', 'VB'), ('applications', 'NNS'), ('to', 'TO'), ('potential', 'JJ'), ('reviewers', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Wellcome', 'Trust', 'also', 'used', 'Reviewer', 'Finder', 'mine', 'text', 'grant', 'proposals', ',', 'extract', 'terms', 'used', 'describe', 'submission', ',', 'apply', 'terms', 'match', 'applications', 'potential', 'reviewers', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('Wellcome', 'NNP'), ('Trust', 'NNP'), ('also', 'RB'), ('used', 'VBD'), ('Reviewer', 'NNP'), ('Finder', 'NNP'), ('mine', 'NN'), ('text', 'NN'), ('grant', 'NN'), ('proposals', 'NNS'), (',', ','), ('extract', 'NN'), ('terms', 'NNS'), ('used', 'VBD'), ('describe', 'NN'), ('submission', 'NN'), (',', ','), ('apply', 'VB'), ('terms', 'NNS'), ('match', 'VB'), ('applications', 'NNS'), ('potential', 'JJ'), ('reviewers', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Wellcome Trust', 'Trust also', 'also used', 'used Reviewer', 'Reviewer Finder', 'Finder mine', 'mine text', 'text grant', 'grant proposals', 'proposals ,', ', extract', 'extract terms', 'terms used', 'used describe', 'describe submission', 'submission ,', ', apply', 'apply terms', 'terms match', 'match applications', 'applications potential', 'potential reviewers', 'reviewers .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['Wellcome Trust also', 'Trust also used', 'also used Reviewer', 'used Reviewer Finder', 'Reviewer Finder mine', 'Finder mine text', 'mine text grant', 'text grant proposals', 'grant proposals ,', 'proposals , extract', ', extract terms', 'extract terms used', 'terms used describe', 'used describe submission', 'describe submission ,', 'submission , apply', ', apply terms', 'apply terms match', 'terms match applications', 'match applications potential', 'applications potential reviewers', 'potential reviewers .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['mine', 'text', 'grant', 'extract', 'describe', 'submission'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Wellcome', 'Trust', 'Reviewer Finder']
 TOTAL PERSON ENTITY --> 3 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['wellcom', 'trust', 'also', 'use', 'review', 'finder', 'mine', 'text', 'grant', 'propos', ',', 'extract', 'term', 'use', 'describ', 'submiss', ',', 'appli', 'term', 'match', 'applic', 'potenti', 'review', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['wellcom', 'trust', 'also', 'use', 'review', 'finder', 'mine', 'text', 'grant', 'propos', ',', 'extract', 'term', 'use', 'describ', 'submiss', ',', 'appli', 'term', 'match', 'applic', 'potenti', 'review', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['Wellcome', 'Trust', 'also', 'used', 'Reviewer', 'Finder', 'mine', 'text', 'grant', 'proposal', ',', 'extract', 'term', 'used', 'describe', 'submission', ',', 'apply', 'term', 'match', 'application', 'potential', 'reviewer', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

