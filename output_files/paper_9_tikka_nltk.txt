1 --> Better, Faster Biomedical Text Translations  Accelerating Natural Language Processing  Inference Models using Processor  Optimized Capabilities Healthcare Biopharmaceutical Research  AbbVie Uses Intel® Xeon® Processors and the Intel® Distribution of OpenVINO™ Toolkit  to Accelerate Natural Language Processing Models for Biopharmaceutical Research Executive Summary  AbbVie is a research-based biopharmaceutical company that serves more than  30 million patients in 175 countries. 


 ---- TOKENS ----

 ['Better', ',', 'Faster', 'Biomedical', 'Text', 'Translations', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Healthcare', 'Biopharmaceutical', 'Research', 'AbbVie', 'Uses', 'Intel®', 'Xeon®', 'Processors', 'and', 'the', 'Intel®', 'Distribution', 'of', 'OpenVINO™', 'Toolkit', 'to', 'Accelerate', 'Natural', 'Language', 'Processing', 'Models', 'for', 'Biopharmaceutical', 'Research', 'Executive', 'Summary', 'AbbVie', 'is', 'a', 'research-based', 'biopharmaceutical', 'company', 'that', 'serves', 'more', 'than', '30', 'million', 'patients', 'in', '175', 'countries', '.'] 

 TOTAL TOKENS ==> 59

 ---- POST ----

 [('Better', 'RBR'), (',', ','), ('Faster', 'NNP'), ('Biomedical', 'NNP'), ('Text', 'NNP'), ('Translations', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNP'), ('Healthcare', 'NNP'), ('Biopharmaceutical', 'NNP'), ('Research', 'NNP'), ('AbbVie', 'NNP'), ('Uses', 'VBZ'), ('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Processors', 'NNPS'), ('and', 'CC'), ('the', 'DT'), ('Intel®', 'NNP'), ('Distribution', 'NNP'), ('of', 'IN'), ('OpenVINO™', 'NNP'), ('Toolkit', 'NNP'), ('to', 'TO'), ('Accelerate', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Models', 'NNP'), ('for', 'IN'), ('Biopharmaceutical', 'NNP'), ('Research', 'NNP'), ('Executive', 'NNP'), ('Summary', 'NNP'), ('AbbVie', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('research-based', 'JJ'), ('biopharmaceutical', 'JJ'), ('company', 'NN'), ('that', 'WDT'), ('serves', 'VBZ'), ('more', 'JJR'), ('than', 'IN'), ('30', 'CD'), ('million', 'CD'), ('patients', 'NNS'), ('in', 'IN'), ('175', 'CD'), ('countries', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Better', ',', 'Faster', 'Biomedical', 'Text', 'Translations', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Healthcare', 'Biopharmaceutical', 'Research', 'AbbVie', 'Uses', 'Intel®', 'Xeon®', 'Processors', 'Intel®', 'Distribution', 'OpenVINO™', 'Toolkit', 'Accelerate', 'Natural', 'Language', 'Processing', 'Models', 'Biopharmaceutical', 'Research', 'Executive', 'Summary', 'AbbVie', 'research-based', 'biopharmaceutical', 'company', 'serves', '30', 'million', 'patients', '175', 'countries', '.']

 TOTAL FILTERED TOKENS ==>  48

 ---- POST FOR FILTERED TOKENS ----

 [('Better', 'RBR'), (',', ','), ('Faster', 'NNP'), ('Biomedical', 'NNP'), ('Text', 'NNP'), ('Translations', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNP'), ('Healthcare', 'NNP'), ('Biopharmaceutical', 'NNP'), ('Research', 'NNP'), ('AbbVie', 'NNP'), ('Uses', 'VBZ'), ('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Processors', 'NNP'), ('Intel®', 'NNP'), ('Distribution', 'NNP'), ('OpenVINO™', 'NNP'), ('Toolkit', 'NNP'), ('Accelerate', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Models', 'NNP'), ('Biopharmaceutical', 'NNP'), ('Research', 'NNP'), ('Executive', 'NNP'), ('Summary', 'NNP'), ('AbbVie', 'NNP'), ('research-based', 'JJ'), ('biopharmaceutical', 'JJ'), ('company', 'NN'), ('serves', 'VBZ'), ('30', 'CD'), ('million', 'CD'), ('patients', 'NNS'), ('175', 'CD'), ('countries', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Better ,', ', Faster', 'Faster Biomedical', 'Biomedical Text', 'Text Translations', 'Translations Accelerating', 'Accelerating Natural', 'Natural Language', 'Language Processing', 'Processing Inference', 'Inference Models', 'Models using', 'using Processor', 'Processor Optimized', 'Optimized Capabilities', 'Capabilities Healthcare', 'Healthcare Biopharmaceutical', 'Biopharmaceutical Research', 'Research AbbVie', 'AbbVie Uses', 'Uses Intel®', 'Intel® Xeon®', 'Xeon® Processors', 'Processors Intel®', 'Intel® Distribution', 'Distribution OpenVINO™', 'OpenVINO™ Toolkit', 'Toolkit Accelerate', 'Accelerate Natural', 'Natural Language', 'Language Processing', 'Processing Models', 'Models Biopharmaceutical', 'Biopharmaceutical Research', 'Research Executive', 'Executive Summary', 'Summary AbbVie', 'AbbVie research-based', 'research-based biopharmaceutical', 'biopharmaceutical company', 'company serves', 'serves 30', '30 million', 'million patients', 'patients 175', '175 countries', 'countries .'] 

 TOTAL BIGRAMS --> 47 



 ---- TRI-GRAMS ---- 

 ['Better , Faster', ', Faster Biomedical', 'Faster Biomedical Text', 'Biomedical Text Translations', 'Text Translations Accelerating', 'Translations Accelerating Natural', 'Accelerating Natural Language', 'Natural Language Processing', 'Language Processing Inference', 'Processing Inference Models', 'Inference Models using', 'Models using Processor', 'using Processor Optimized', 'Processor Optimized Capabilities', 'Optimized Capabilities Healthcare', 'Capabilities Healthcare Biopharmaceutical', 'Healthcare Biopharmaceutical Research', 'Biopharmaceutical Research AbbVie', 'Research AbbVie Uses', 'AbbVie Uses Intel®', 'Uses Intel® Xeon®', 'Intel® Xeon® Processors', 'Xeon® Processors Intel®', 'Processors Intel® Distribution', 'Intel® Distribution OpenVINO™', 'Distribution OpenVINO™ Toolkit', 'OpenVINO™ Toolkit Accelerate', 'Toolkit Accelerate Natural', 'Accelerate Natural Language', 'Natural Language Processing', 'Language Processing Models', 'Processing Models Biopharmaceutical', 'Models Biopharmaceutical Research', 'Biopharmaceutical Research Executive', 'Research Executive Summary', 'Executive Summary AbbVie', 'Summary AbbVie research-based', 'AbbVie research-based biopharmaceutical', 'research-based biopharmaceutical company', 'biopharmaceutical company serves', 'company serves 30', 'serves 30 million', '30 million patients', 'million patients 175', 'patients 175 countries', '175 countries .'] 

 TOTAL TRIGRAMS --> 46 



 ---- NOUN PHRASES ---- 

 ['research-based biopharmaceutical company'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Faster Biomedical Text Translations Accelerating Natural Language', 'Processor Optimized Capabilities Healthcare Biopharmaceutical Research']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['better', ',', 'faster', 'biomed', 'text', 'translat', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'healthcar', 'biopharmaceut', 'research', 'abbvi', 'use', 'intel®', 'xeon®', 'processor', 'intel®', 'distribut', 'openvino™', 'toolkit', 'acceler', 'natur', 'languag', 'process', 'model', 'biopharmaceut', 'research', 'execut', 'summari', 'abbvi', 'research-bas', 'biopharmaceut', 'compani', 'serv', '30', 'million', 'patient', '175', 'countri', '.']

 TOTAL PORTER STEM WORDS ==> 48



 ---- SNOWBALL STEMMING ----

['better', ',', 'faster', 'biomed', 'text', 'translat', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'healthcar', 'biopharmaceut', 'research', 'abbvi', 'use', 'intel®', 'xeon®', 'processor', 'intel®', 'distribut', 'openvino™', 'toolkit', 'acceler', 'natur', 'languag', 'process', 'model', 'biopharmaceut', 'research', 'execut', 'summari', 'abbvi', 'research-bas', 'biopharmaceut', 'compani', 'serv', '30', 'million', 'patient', '175', 'countri', '.']

 TOTAL SNOWBALL STEM WORDS ==> 48



 ---- LEMMATIZATION ----

['Better', ',', 'Faster', 'Biomedical', 'Text', 'Translations', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Healthcare', 'Biopharmaceutical', 'Research', 'AbbVie', 'Uses', 'Intel®', 'Xeon®', 'Processors', 'Intel®', 'Distribution', 'OpenVINO™', 'Toolkit', 'Accelerate', 'Natural', 'Language', 'Processing', 'Models', 'Biopharmaceutical', 'Research', 'Executive', 'Summary', 'AbbVie', 'research-based', 'biopharmaceutical', 'company', 'serf', '30', 'million', 'patient', '175', 'country', '.']

 TOTAL LEMMATIZE WORDS ==> 48

************************************************************************************************************************

2 --> With its global scale, AbbVie partnered with  Intel to optimize processes for its more than 47,000 employees. 


 ---- TOKENS ----

 ['With', 'its', 'global', 'scale', ',', 'AbbVie', 'partnered', 'with', 'Intel', 'to', 'optimize', 'processes', 'for', 'its', 'more', 'than', '47,000', 'employees', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('With', 'IN'), ('its', 'PRP$'), ('global', 'JJ'), ('scale', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('partnered', 'VBD'), ('with', 'IN'), ('Intel', 'NNP'), ('to', 'TO'), ('optimize', 'VB'), ('processes', 'NNS'), ('for', 'IN'), ('its', 'PRP$'), ('more', 'JJR'), ('than', 'IN'), ('47,000', 'CD'), ('employees', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['global', 'scale', ',', 'AbbVie', 'partnered', 'Intel', 'optimize', 'processes', '47,000', 'employees', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('global', 'JJ'), ('scale', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('partnered', 'VBD'), ('Intel', 'NNP'), ('optimize', 'NN'), ('processes', 'VBZ'), ('47,000', 'CD'), ('employees', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['global scale', 'scale ,', ', AbbVie', 'AbbVie partnered', 'partnered Intel', 'Intel optimize', 'optimize processes', 'processes 47,000', '47,000 employees', 'employees .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['global scale ,', 'scale , AbbVie', ', AbbVie partnered', 'AbbVie partnered Intel', 'partnered Intel optimize', 'Intel optimize processes', 'optimize processes 47,000', 'processes 47,000 employees', '47,000 employees .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['global scale', 'optimize'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'Intel']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['global', 'scale', ',', 'abbvi', 'partner', 'intel', 'optim', 'process', '47,000', 'employe', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['global', 'scale', ',', 'abbvi', 'partner', 'intel', 'optim', 'process', '47,000', 'employe', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['global', 'scale', ',', 'AbbVie', 'partnered', 'Intel', 'optimize', 'process', '47,000', 'employee', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

3 --> This whitepaper  highlights two use cases that are important to AbbVie’s research. 


 ---- TOKENS ----

 ['This', 'whitepaper', 'highlights', 'two', 'use', 'cases', 'that', 'are', 'important', 'to', 'AbbVie', '’', 's', 'research', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('This', 'DT'), ('whitepaper', 'JJ'), ('highlights', 'NNS'), ('two', 'CD'), ('use', 'VBP'), ('cases', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('important', 'JJ'), ('to', 'TO'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('research', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['whitepaper', 'highlights', 'two', 'use', 'cases', 'important', 'AbbVie', '’', 'research', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('whitepaper', 'JJ'), ('highlights', 'NNS'), ('two', 'CD'), ('use', 'VBP'), ('cases', 'NNS'), ('important', 'JJ'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('research', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['whitepaper highlights', 'highlights two', 'two use', 'use cases', 'cases important', 'important AbbVie', 'AbbVie ’', '’ research', 'research .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['whitepaper highlights two', 'highlights two use', 'two use cases', 'use cases important', 'cases important AbbVie', 'important AbbVie ’', 'AbbVie ’ research', '’ research .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['research'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['whitepap', 'highlight', 'two', 'use', 'case', 'import', 'abbvi', '’', 'research', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['whitepap', 'highlight', 'two', 'use', 'case', 'import', 'abbvi', '’', 'research', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['whitepaper', 'highlight', 'two', 'use', 'case', 'important', 'AbbVie', '’', 'research', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

4 --> The first is  Abbelfish Machine Translation, AbbVie’s language translation service based on the  Transformer NLP model, that leverages second-generation Intel® Xeon® Scalable  processors and the Intel® Optimization for TensorFlow with Intel oneAPI Deep  Neural Network Library (oneDNN). 


 ---- TOKENS ----

 ['The', 'first', 'is', 'Abbelfish', 'Machine', 'Translation', ',', 'AbbVie', '’', 's', 'language', 'translation', 'service', 'based', 'on', 'the', 'Transformer', 'NLP', 'model', ',', 'that', 'leverages', 'second-generation', 'Intel®', 'Xeon®', 'Scalable', 'processors', 'and', 'the', 'Intel®', 'Optimization', 'for', 'TensorFlow', 'with', 'Intel', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', '.'] 

 TOTAL TOKENS ==> 44

 ---- POST ----

 [('The', 'DT'), ('first', 'JJ'), ('is', 'VBZ'), ('Abbelfish', 'JJ'), ('Machine', 'NNP'), ('Translation', 'NNP'), (',', ','), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'JJ'), ('language', 'NN'), ('translation', 'NN'), ('service', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('Transformer', 'NNP'), ('NLP', 'NNP'), ('model', 'NN'), (',', ','), ('that', 'IN'), ('leverages', 'VBZ'), ('second-generation', 'NN'), ('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Scalable', 'NNP'), ('processors', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('Intel®', 'NNP'), ('Optimization', 'NNP'), ('for', 'IN'), ('TensorFlow', 'NNP'), ('with', 'IN'), ('Intel', 'NNP'), ('oneAPI', 'VBP'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('(', '('), ('oneDNN', 'NN'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['first', 'Abbelfish', 'Machine', 'Translation', ',', 'AbbVie', '’', 'language', 'translation', 'service', 'based', 'Transformer', 'NLP', 'model', ',', 'leverages', 'second-generation', 'Intel®', 'Xeon®', 'Scalable', 'processors', 'Intel®', 'Optimization', 'TensorFlow', 'Intel', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', '.']

 TOTAL FILTERED TOKENS ==>  34

 ---- POST FOR FILTERED TOKENS ----

 [('first', 'RB'), ('Abbelfish', 'JJ'), ('Machine', 'NNP'), ('Translation', 'NNP'), (',', ','), ('AbbVie', 'NNP'), ('’', 'NNP'), ('language', 'NN'), ('translation', 'NN'), ('service', 'NN'), ('based', 'VBN'), ('Transformer', 'NNP'), ('NLP', 'NNP'), ('model', 'NN'), (',', ','), ('leverages', 'VBZ'), ('second-generation', 'NN'), ('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Scalable', 'NNP'), ('processors', 'NNS'), ('Intel®', 'NNP'), ('Optimization', 'NNP'), ('TensorFlow', 'NNP'), ('Intel', 'NNP'), ('oneAPI', 'MD'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('(', '('), ('oneDNN', 'NN'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['first Abbelfish', 'Abbelfish Machine', 'Machine Translation', 'Translation ,', ', AbbVie', 'AbbVie ’', '’ language', 'language translation', 'translation service', 'service based', 'based Transformer', 'Transformer NLP', 'NLP model', 'model ,', ', leverages', 'leverages second-generation', 'second-generation Intel®', 'Intel® Xeon®', 'Xeon® Scalable', 'Scalable processors', 'processors Intel®', 'Intel® Optimization', 'Optimization TensorFlow', 'TensorFlow Intel', 'Intel oneAPI', 'oneAPI Deep', 'Deep Neural', 'Neural Network', 'Network Library', 'Library (', '( oneDNN', 'oneDNN )', ') .'] 

 TOTAL BIGRAMS --> 33 



 ---- TRI-GRAMS ---- 

 ['first Abbelfish Machine', 'Abbelfish Machine Translation', 'Machine Translation ,', 'Translation , AbbVie', ', AbbVie ’', 'AbbVie ’ language', '’ language translation', 'language translation service', 'translation service based', 'service based Transformer', 'based Transformer NLP', 'Transformer NLP model', 'NLP model ,', 'model , leverages', ', leverages second-generation', 'leverages second-generation Intel®', 'second-generation Intel® Xeon®', 'Intel® Xeon® Scalable', 'Xeon® Scalable processors', 'Scalable processors Intel®', 'processors Intel® Optimization', 'Intel® Optimization TensorFlow', 'Optimization TensorFlow Intel', 'TensorFlow Intel oneAPI', 'Intel oneAPI Deep', 'oneAPI Deep Neural', 'Deep Neural Network', 'Neural Network Library', 'Network Library (', 'Library ( oneDNN', '( oneDNN )', 'oneDNN ) .'] 

 TOTAL TRIGRAMS --> 32 



 ---- NOUN PHRASES ---- 

 ['language', 'translation', 'service', 'model', 'second-generation'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'Transformer', 'TensorFlow Intel']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> ['Abbelfish Machine Translation', 'Deep Neural Network Library']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['first', 'abbelfish', 'machin', 'translat', ',', 'abbvi', '’', 'languag', 'translat', 'servic', 'base', 'transform', 'nlp', 'model', ',', 'leverag', 'second-gener', 'intel®', 'xeon®', 'scalabl', 'processor', 'intel®', 'optim', 'tensorflow', 'intel', 'oneapi', 'deep', 'neural', 'network', 'librari', '(', 'onednn', ')', '.']

 TOTAL PORTER STEM WORDS ==> 34



 ---- SNOWBALL STEMMING ----

['first', 'abbelfish', 'machin', 'translat', ',', 'abbvi', '’', 'languag', 'translat', 'servic', 'base', 'transform', 'nlp', 'model', ',', 'leverag', 'second-gener', 'intel®', 'xeon®', 'scalabl', 'processor', 'intel®', 'optim', 'tensorflow', 'intel', 'oneapi', 'deep', 'neural', 'network', 'librari', '(', 'onednn', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 34



 ---- LEMMATIZATION ----

['first', 'Abbelfish', 'Machine', 'Translation', ',', 'AbbVie', '’', 'language', 'translation', 'service', 'based', 'Transformer', 'NLP', 'model', ',', 'leverage', 'second-generation', 'Intel®', 'Xeon®', 'Scalable', 'processor', 'Intel®', 'Optimization', 'TensorFlow', 'Intel', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 34

************************************************************************************************************************

5 --> AbbVie was able to achieve a 1.9x improvement  in throughput for Abbelfish language translation using Intel Optimization for  TensorFlow 1.15 with oneAPI Deep Neural Network Library when compared to  TensorFlow 1.15 without oneDNN.1 The second use case is AbbVie Search, which  is a BERT-based NLP model. 


 ---- TOKENS ----

 ['AbbVie', 'was', 'able', 'to', 'achieve', 'a', '1.9x', 'improvement', 'in', 'throughput', 'for', 'Abbelfish', 'language', 'translation', 'using', 'Intel', 'Optimization', 'for', 'TensorFlow', '1.15', 'with', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', 'when', 'compared', 'to', 'TensorFlow', '1.15', 'without', 'oneDNN.1', 'The', 'second', 'use', 'case', 'is', 'AbbVie', 'Search', ',', 'which', 'is', 'a', 'BERT-based', 'NLP', 'model', '.'] 

 TOTAL TOKENS ==> 48

 ---- POST ----

 [('AbbVie', 'NNP'), ('was', 'VBD'), ('able', 'JJ'), ('to', 'TO'), ('achieve', 'VB'), ('a', 'DT'), ('1.9x', 'CD'), ('improvement', 'NN'), ('in', 'IN'), ('throughput', 'NN'), ('for', 'IN'), ('Abbelfish', 'JJ'), ('language', 'NN'), ('translation', 'NN'), ('using', 'VBG'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('for', 'IN'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('with', 'IN'), ('oneAPI', 'JJ'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('when', 'WRB'), ('compared', 'VBN'), ('to', 'TO'), ('TensorFlow', 'VB'), ('1.15', 'CD'), ('without', 'IN'), ('oneDNN.1', 'PRP'), ('The', 'DT'), ('second', 'JJ'), ('use', 'NN'), ('case', 'NN'), ('is', 'VBZ'), ('AbbVie', 'NNP'), ('Search', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('a', 'DT'), ('BERT-based', 'JJ'), ('NLP', 'NNP'), ('model', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'able', 'achieve', '1.9x', 'improvement', 'throughput', 'Abbelfish', 'language', 'translation', 'using', 'Intel', 'Optimization', 'TensorFlow', '1.15', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', 'compared', 'TensorFlow', '1.15', 'without', 'oneDNN.1', 'second', 'use', 'case', 'AbbVie', 'Search', ',', 'BERT-based', 'NLP', 'model', '.']

 TOTAL FILTERED TOKENS ==>  34

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('able', 'JJ'), ('achieve', 'VBP'), ('1.9x', 'CD'), ('improvement', 'NN'), ('throughput', 'NN'), ('Abbelfish', 'NNP'), ('language', 'NN'), ('translation', 'NN'), ('using', 'VBG'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('oneAPI', 'JJ'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('compared', 'VBN'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('without', 'IN'), ('oneDNN.1', 'JJ'), ('second', 'JJ'), ('use', 'NN'), ('case', 'NN'), ('AbbVie', 'NNP'), ('Search', 'NNP'), (',', ','), ('BERT-based', 'JJ'), ('NLP', 'NNP'), ('model', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie able', 'able achieve', 'achieve 1.9x', '1.9x improvement', 'improvement throughput', 'throughput Abbelfish', 'Abbelfish language', 'language translation', 'translation using', 'using Intel', 'Intel Optimization', 'Optimization TensorFlow', 'TensorFlow 1.15', '1.15 oneAPI', 'oneAPI Deep', 'Deep Neural', 'Neural Network', 'Network Library', 'Library compared', 'compared TensorFlow', 'TensorFlow 1.15', '1.15 without', 'without oneDNN.1', 'oneDNN.1 second', 'second use', 'use case', 'case AbbVie', 'AbbVie Search', 'Search ,', ', BERT-based', 'BERT-based NLP', 'NLP model', 'model .'] 

 TOTAL BIGRAMS --> 33 



 ---- TRI-GRAMS ---- 

 ['AbbVie able achieve', 'able achieve 1.9x', 'achieve 1.9x improvement', '1.9x improvement throughput', 'improvement throughput Abbelfish', 'throughput Abbelfish language', 'Abbelfish language translation', 'language translation using', 'translation using Intel', 'using Intel Optimization', 'Intel Optimization TensorFlow', 'Optimization TensorFlow 1.15', 'TensorFlow 1.15 oneAPI', '1.15 oneAPI Deep', 'oneAPI Deep Neural', 'Deep Neural Network', 'Neural Network Library', 'Network Library compared', 'Library compared TensorFlow', 'compared TensorFlow 1.15', 'TensorFlow 1.15 without', '1.15 without oneDNN.1', 'without oneDNN.1 second', 'oneDNN.1 second use', 'second use case', 'use case AbbVie', 'case AbbVie Search', 'AbbVie Search ,', 'Search , BERT-based', ', BERT-based NLP', 'BERT-based NLP model', 'NLP model .'] 

 TOTAL TRIGRAMS --> 32 



 ---- NOUN PHRASES ---- 

 ['improvement', 'throughput', 'language', 'translation', 'oneDNN.1 second use', 'case', 'model'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Optimization', 'oneAPI Deep', 'TensorFlow', 'AbbVie Search', 'NLP']
 TOTAL ORGANIZATION ENTITY --> 5 


 PERSON ---> ['Network Library']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['AbbVie', 'Abbelfish']
 TOTAL GPE ENTITY --> 2 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'abl', 'achiev', '1.9x', 'improv', 'throughput', 'abbelfish', 'languag', 'translat', 'use', 'intel', 'optim', 'tensorflow', '1.15', 'oneapi', 'deep', 'neural', 'network', 'librari', 'compar', 'tensorflow', '1.15', 'without', 'onednn.1', 'second', 'use', 'case', 'abbvi', 'search', ',', 'bert-bas', 'nlp', 'model', '.']

 TOTAL PORTER STEM WORDS ==> 34



 ---- SNOWBALL STEMMING ----

['abbvi', 'abl', 'achiev', '1.9x', 'improv', 'throughput', 'abbelfish', 'languag', 'translat', 'use', 'intel', 'optim', 'tensorflow', '1.15', 'oneapi', 'deep', 'neural', 'network', 'librari', 'compar', 'tensorflow', '1.15', 'without', 'onednn.1', 'second', 'use', 'case', 'abbvi', 'search', ',', 'bert-bas', 'nlp', 'model', '.']

 TOTAL SNOWBALL STEM WORDS ==> 34



 ---- LEMMATIZATION ----

['AbbVie', 'able', 'achieve', '1.9x', 'improvement', 'throughput', 'Abbelfish', 'language', 'translation', 'using', 'Intel', 'Optimization', 'TensorFlow', '1.15', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', 'compared', 'TensorFlow', '1.15', 'without', 'oneDNN.1', 'second', 'use', 'case', 'AbbVie', 'Search', ',', 'BERT-based', 'NLP', 'model', '.']

 TOTAL LEMMATIZE WORDS ==> 34

************************************************************************************************************************

6 --> AbbVie Search scans research documents based on  scientific questions and returns relevant results that enable the discovery of new  treatments for patients pharmaceuticals and manufacturing methods. 


 ---- TOKENS ----

 ['AbbVie', 'Search', 'scans', 'research', 'documents', 'based', 'on', 'scientific', 'questions', 'and', 'returns', 'relevant', 'results', 'that', 'enable', 'the', 'discovery', 'of', 'new', 'treatments', 'for', 'patients', 'pharmaceuticals', 'and', 'manufacturing', 'methods', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('scans', 'VBZ'), ('research', 'NN'), ('documents', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('scientific', 'JJ'), ('questions', 'NNS'), ('and', 'CC'), ('returns', 'NNS'), ('relevant', 'JJ'), ('results', 'NNS'), ('that', 'WDT'), ('enable', 'VBP'), ('the', 'DT'), ('discovery', 'NN'), ('of', 'IN'), ('new', 'JJ'), ('treatments', 'NNS'), ('for', 'IN'), ('patients', 'NNS'), ('pharmaceuticals', 'NNS'), ('and', 'CC'), ('manufacturing', 'VBG'), ('methods', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'Search', 'scans', 'research', 'documents', 'based', 'scientific', 'questions', 'returns', 'relevant', 'results', 'enable', 'discovery', 'new', 'treatments', 'patients', 'pharmaceuticals', 'manufacturing', 'methods', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('scans', 'VBZ'), ('research', 'NN'), ('documents', 'NNS'), ('based', 'VBN'), ('scientific', 'JJ'), ('questions', 'NNS'), ('returns', 'NNS'), ('relevant', 'JJ'), ('results', 'NNS'), ('enable', 'JJ'), ('discovery', 'JJ'), ('new', 'JJ'), ('treatments', 'NNS'), ('patients', 'NNS'), ('pharmaceuticals', 'NNS'), ('manufacturing', 'VBG'), ('methods', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie Search', 'Search scans', 'scans research', 'research documents', 'documents based', 'based scientific', 'scientific questions', 'questions returns', 'returns relevant', 'relevant results', 'results enable', 'enable discovery', 'discovery new', 'new treatments', 'treatments patients', 'patients pharmaceuticals', 'pharmaceuticals manufacturing', 'manufacturing methods', 'methods .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['AbbVie Search scans', 'Search scans research', 'scans research documents', 'research documents based', 'documents based scientific', 'based scientific questions', 'scientific questions returns', 'questions returns relevant', 'returns relevant results', 'relevant results enable', 'results enable discovery', 'enable discovery new', 'discovery new treatments', 'new treatments patients', 'treatments patients pharmaceuticals', 'patients pharmaceuticals manufacturing', 'pharmaceuticals manufacturing methods', 'manufacturing methods .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['research'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie Search']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'search', 'scan', 'research', 'document', 'base', 'scientif', 'question', 'return', 'relev', 'result', 'enabl', 'discoveri', 'new', 'treatment', 'patient', 'pharmaceut', 'manufactur', 'method', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['abbvi', 'search', 'scan', 'research', 'document', 'base', 'scientif', 'question', 'return', 'relev', 'result', 'enabl', 'discoveri', 'new', 'treatment', 'patient', 'pharmaceut', 'manufactur', 'method', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['AbbVie', 'Search', 'scan', 'research', 'document', 'based', 'scientific', 'question', 'return', 'relevant', 'result', 'enable', 'discovery', 'new', 'treatment', 'patient', 'pharmaceutical', 'manufacturing', 'method', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

7 --> Using the  Intel Distribution of OpenVINO toolkit, AbbVie Search was accelerated by 5.3x  over unoptimized TensorFlow 1.15 on the same second-generation Intel Xeon  processor hardware.1 AbbVie’s NLP AI deployments demonstrate how CPUs can be  highly effective for e.g.- AI inference in a large organization without the need for  additional hardware acceleration. 


 ---- TOKENS ----

 ['Using', 'the', 'Intel', 'Distribution', 'of', 'OpenVINO', 'toolkit', ',', 'AbbVie', 'Search', 'was', 'accelerated', 'by', '5.3x', 'over', 'unoptimized', 'TensorFlow', '1.15', 'on', 'the', 'same', 'second-generation', 'Intel', 'Xeon', 'processor', 'hardware.1', 'AbbVie', '’', 's', 'NLP', 'AI', 'deployments', 'demonstrate', 'how', 'CPUs', 'can', 'be', 'highly', 'effective', 'for', 'e.g.-', 'AI', 'inference', 'in', 'a', 'large', 'organization', 'without', 'the', 'need', 'for', 'additional', 'hardware', 'acceleration', '.'] 

 TOTAL TOKENS ==> 55

 ---- POST ----

 [('Using', 'VBG'), ('the', 'DT'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('of', 'IN'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('was', 'VBD'), ('accelerated', 'VBN'), ('by', 'IN'), ('5.3x', 'CD'), ('over', 'IN'), ('unoptimized', 'JJ'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('on', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('second-generation', 'JJ'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor', 'NN'), ('hardware.1', 'NN'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('NLP', 'NNP'), ('AI', 'NNP'), ('deployments', 'NNS'), ('demonstrate', 'VB'), ('how', 'WRB'), ('CPUs', 'NNP'), ('can', 'MD'), ('be', 'VB'), ('highly', 'RB'), ('effective', 'JJ'), ('for', 'IN'), ('e.g.-', 'JJ'), ('AI', 'NNP'), ('inference', 'NN'), ('in', 'IN'), ('a', 'DT'), ('large', 'JJ'), ('organization', 'NN'), ('without', 'IN'), ('the', 'DT'), ('need', 'NN'), ('for', 'IN'), ('additional', 'JJ'), ('hardware', 'NN'), ('acceleration', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Using', 'Intel', 'Distribution', 'OpenVINO', 'toolkit', ',', 'AbbVie', 'Search', 'accelerated', '5.3x', 'unoptimized', 'TensorFlow', '1.15', 'second-generation', 'Intel', 'Xeon', 'processor', 'hardware.1', 'AbbVie', '’', 'NLP', 'AI', 'deployments', 'demonstrate', 'CPUs', 'highly', 'effective', 'e.g.-', 'AI', 'inference', 'large', 'organization', 'without', 'need', 'additional', 'hardware', 'acceleration', '.']

 TOTAL FILTERED TOKENS ==>  38

 ---- POST FOR FILTERED TOKENS ----

 [('Using', 'VBG'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('accelerated', 'VBD'), ('5.3x', 'CD'), ('unoptimized', 'JJ'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('second-generation', 'NN'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor', 'NN'), ('hardware.1', 'NN'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('NLP', 'NNP'), ('AI', 'NNP'), ('deployments', 'NNS'), ('demonstrate', 'VBP'), ('CPUs', 'NNP'), ('highly', 'RB'), ('effective', 'JJ'), ('e.g.-', 'JJ'), ('AI', 'NNP'), ('inference', 'NN'), ('large', 'JJ'), ('organization', 'NN'), ('without', 'IN'), ('need', 'VBP'), ('additional', 'JJ'), ('hardware', 'NN'), ('acceleration', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Using Intel', 'Intel Distribution', 'Distribution OpenVINO', 'OpenVINO toolkit', 'toolkit ,', ', AbbVie', 'AbbVie Search', 'Search accelerated', 'accelerated 5.3x', '5.3x unoptimized', 'unoptimized TensorFlow', 'TensorFlow 1.15', '1.15 second-generation', 'second-generation Intel', 'Intel Xeon', 'Xeon processor', 'processor hardware.1', 'hardware.1 AbbVie', 'AbbVie ’', '’ NLP', 'NLP AI', 'AI deployments', 'deployments demonstrate', 'demonstrate CPUs', 'CPUs highly', 'highly effective', 'effective e.g.-', 'e.g.- AI', 'AI inference', 'inference large', 'large organization', 'organization without', 'without need', 'need additional', 'additional hardware', 'hardware acceleration', 'acceleration .'] 

 TOTAL BIGRAMS --> 37 



 ---- TRI-GRAMS ---- 

 ['Using Intel Distribution', 'Intel Distribution OpenVINO', 'Distribution OpenVINO toolkit', 'OpenVINO toolkit ,', 'toolkit , AbbVie', ', AbbVie Search', 'AbbVie Search accelerated', 'Search accelerated 5.3x', 'accelerated 5.3x unoptimized', '5.3x unoptimized TensorFlow', 'unoptimized TensorFlow 1.15', 'TensorFlow 1.15 second-generation', '1.15 second-generation Intel', 'second-generation Intel Xeon', 'Intel Xeon processor', 'Xeon processor hardware.1', 'processor hardware.1 AbbVie', 'hardware.1 AbbVie ’', 'AbbVie ’ NLP', '’ NLP AI', 'NLP AI deployments', 'AI deployments demonstrate', 'deployments demonstrate CPUs', 'demonstrate CPUs highly', 'CPUs highly effective', 'highly effective e.g.-', 'effective e.g.- AI', 'e.g.- AI inference', 'AI inference large', 'inference large organization', 'large organization without', 'organization without need', 'without need additional', 'need additional hardware', 'additional hardware acceleration', 'hardware acceleration .'] 

 TOTAL TRIGRAMS --> 36 



 ---- NOUN PHRASES ---- 

 ['toolkit', 'second-generation', 'processor', 'hardware.1', 'inference', 'large organization', 'additional hardware', 'acceleration'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Distribution', 'AbbVie Search', 'TensorFlow', 'Intel Xeon', 'AbbVie', 'CPUs']
 TOTAL ORGANIZATION ENTITY --> 6 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['use', 'intel', 'distribut', 'openvino', 'toolkit', ',', 'abbvi', 'search', 'acceler', '5.3x', 'unoptim', 'tensorflow', '1.15', 'second-gener', 'intel', 'xeon', 'processor', 'hardware.1', 'abbvi', '’', 'nlp', 'ai', 'deploy', 'demonstr', 'cpu', 'highli', 'effect', 'e.g.-', 'ai', 'infer', 'larg', 'organ', 'without', 'need', 'addit', 'hardwar', 'acceler', '.']

 TOTAL PORTER STEM WORDS ==> 38



 ---- SNOWBALL STEMMING ----

['use', 'intel', 'distribut', 'openvino', 'toolkit', ',', 'abbvi', 'search', 'acceler', '5.3x', 'unoptim', 'tensorflow', '1.15', 'second-gener', 'intel', 'xeon', 'processor', 'hardware.1', 'abbvi', '’', 'nlp', 'ai', 'deploy', 'demonstr', 'cpus', 'high', 'effect', 'e.g.-', 'ai', 'infer', 'larg', 'organ', 'without', 'need', 'addit', 'hardwar', 'acceler', '.']

 TOTAL SNOWBALL STEM WORDS ==> 38



 ---- LEMMATIZATION ----

['Using', 'Intel', 'Distribution', 'OpenVINO', 'toolkit', ',', 'AbbVie', 'Search', 'accelerated', '5.3x', 'unoptimized', 'TensorFlow', '1.15', 'second-generation', 'Intel', 'Xeon', 'processor', 'hardware.1', 'AbbVie', '’', 'NLP', 'AI', 'deployment', 'demonstrate', 'CPUs', 'highly', 'effective', 'e.g.-', 'AI', 'inference', 'large', 'organization', 'without', 'need', 'additional', 'hardware', 'acceleration', '.']

 TOTAL LEMMATIZE WORDS ==> 38

************************************************************************************************************************

8 --> Enabling Data-Driven Research AbbVie is a global research-based biopharmaceutical company that serves more  than 30 million patients in 175 countries (AbbVie, 2020). 


 ---- TOKENS ----

 ['Enabling', 'Data-Driven', 'Research', 'AbbVie', 'is', 'a', 'global', 'research-based', 'biopharmaceutical', 'company', 'that', 'serves', 'more', 'than', '30', 'million', 'patients', 'in', '175', 'countries', '(', 'AbbVie', ',', '2020', ')', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Enabling', 'VBG'), ('Data-Driven', 'NNP'), ('Research', 'NNP'), ('AbbVie', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('global', 'JJ'), ('research-based', 'JJ'), ('biopharmaceutical', 'JJ'), ('company', 'NN'), ('that', 'WDT'), ('serves', 'VBZ'), ('more', 'JJR'), ('than', 'IN'), ('30', 'CD'), ('million', 'CD'), ('patients', 'NNS'), ('in', 'IN'), ('175', 'CD'), ('countries', 'NNS'), ('(', '('), ('AbbVie', 'NNP'), (',', ','), ('2020', 'CD'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Enabling', 'Data-Driven', 'Research', 'AbbVie', 'global', 'research-based', 'biopharmaceutical', 'company', 'serves', '30', 'million', 'patients', '175', 'countries', '(', 'AbbVie', ',', '2020', ')', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('Enabling', 'VBG'), ('Data-Driven', 'NNP'), ('Research', 'NNP'), ('AbbVie', 'NNP'), ('global', 'JJ'), ('research-based', 'JJ'), ('biopharmaceutical', 'JJ'), ('company', 'NN'), ('serves', 'VBZ'), ('30', 'CD'), ('million', 'CD'), ('patients', 'NNS'), ('175', 'CD'), ('countries', 'NNS'), ('(', '('), ('AbbVie', 'NNP'), (',', ','), ('2020', 'CD'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Enabling Data-Driven', 'Data-Driven Research', 'Research AbbVie', 'AbbVie global', 'global research-based', 'research-based biopharmaceutical', 'biopharmaceutical company', 'company serves', 'serves 30', '30 million', 'million patients', 'patients 175', '175 countries', 'countries (', '( AbbVie', 'AbbVie ,', ', 2020', '2020 )', ') .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['Enabling Data-Driven Research', 'Data-Driven Research AbbVie', 'Research AbbVie global', 'AbbVie global research-based', 'global research-based biopharmaceutical', 'research-based biopharmaceutical company', 'biopharmaceutical company serves', 'company serves 30', 'serves 30 million', '30 million patients', 'million patients 175', 'patients 175 countries', '175 countries (', 'countries ( AbbVie', '( AbbVie ,', 'AbbVie , 2020', ', 2020 )', '2020 ) .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['global research-based biopharmaceutical company'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['enabl', 'data-driven', 'research', 'abbvi', 'global', 'research-bas', 'biopharmaceut', 'compani', 'serv', '30', 'million', 'patient', '175', 'countri', '(', 'abbvi', ',', '2020', ')', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['enabl', 'data-driven', 'research', 'abbvi', 'global', 'research-bas', 'biopharmaceut', 'compani', 'serv', '30', 'million', 'patient', '175', 'countri', '(', 'abbvi', ',', '2020', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['Enabling', 'Data-Driven', 'Research', 'AbbVie', 'global', 'research-based', 'biopharmaceutical', 'company', 'serf', '30', 'million', 'patient', '175', 'country', '(', 'AbbVie', ',', '2020', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

9 --> Biopharmaceutical  research generates a great number of scientific articles and clinical trial reports—in  fact, AbbVie researchers alone have produced more than 1,100. 


 ---- TOKENS ----

 ['Biopharmaceutical', 'research', 'generates', 'a', 'great', 'number', 'of', 'scientific', 'articles', 'and', 'clinical', 'trial', 'reports—in', 'fact', ',', 'AbbVie', 'researchers', 'alone', 'have', 'produced', 'more', 'than', '1,100', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Biopharmaceutical', 'NNP'), ('research', 'NN'), ('generates', 'VBZ'), ('a', 'DT'), ('great', 'JJ'), ('number', 'NN'), ('of', 'IN'), ('scientific', 'JJ'), ('articles', 'NNS'), ('and', 'CC'), ('clinical', 'JJ'), ('trial', 'NN'), ('reports—in', 'NN'), ('fact', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('researchers', 'NNS'), ('alone', 'RB'), ('have', 'VBP'), ('produced', 'VBN'), ('more', 'JJR'), ('than', 'IN'), ('1,100', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Biopharmaceutical', 'research', 'generates', 'great', 'number', 'scientific', 'articles', 'clinical', 'trial', 'reports—in', 'fact', ',', 'AbbVie', 'researchers', 'alone', 'produced', '1,100', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Biopharmaceutical', 'NNP'), ('research', 'NN'), ('generates', 'VBZ'), ('great', 'JJ'), ('number', 'NN'), ('scientific', 'JJ'), ('articles', 'VBZ'), ('clinical', 'JJ'), ('trial', 'NN'), ('reports—in', 'NN'), ('fact', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('researchers', 'NNS'), ('alone', 'RB'), ('produced', 'VBD'), ('1,100', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Biopharmaceutical research', 'research generates', 'generates great', 'great number', 'number scientific', 'scientific articles', 'articles clinical', 'clinical trial', 'trial reports—in', 'reports—in fact', 'fact ,', ', AbbVie', 'AbbVie researchers', 'researchers alone', 'alone produced', 'produced 1,100', '1,100 .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Biopharmaceutical research generates', 'research generates great', 'generates great number', 'great number scientific', 'number scientific articles', 'scientific articles clinical', 'articles clinical trial', 'clinical trial reports—in', 'trial reports—in fact', 'reports—in fact ,', 'fact , AbbVie', ', AbbVie researchers', 'AbbVie researchers alone', 'researchers alone produced', 'alone produced 1,100', 'produced 1,100 .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['research', 'great number', 'clinical trial', 'reports—in', 'fact'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Biopharmaceutical']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['biopharmaceut', 'research', 'gener', 'great', 'number', 'scientif', 'articl', 'clinic', 'trial', 'reports—in', 'fact', ',', 'abbvi', 'research', 'alon', 'produc', '1,100', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['biopharmaceut', 'research', 'generat', 'great', 'number', 'scientif', 'articl', 'clinic', 'trial', 'reports—in', 'fact', ',', 'abbvi', 'research', 'alon', 'produc', '1,100', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Biopharmaceutical', 'research', 'generates', 'great', 'number', 'scientific', 'article', 'clinical', 'trial', 'reports—in', 'fact', ',', 'AbbVie', 'researcher', 'alone', 'produced', '1,100', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

10 --> To keep up with the scale of the data, AbbVie utilizes the latest AbbVie takes advantage  of the latest NLP algorithms to allow researchers to quickly return relevant data for  its biomedical research and development. 


 ---- TOKENS ----

 ['To', 'keep', 'up', 'with', 'the', 'scale', 'of', 'the', 'data', ',', 'AbbVie', 'utilizes', 'the', 'latest', 'AbbVie', 'takes', 'advantage', 'of', 'the', 'latest', 'NLP', 'algorithms', 'to', 'allow', 'researchers', 'to', 'quickly', 'return', 'relevant', 'data', 'for', 'its', 'biomedical', 'research', 'and', 'development', '.'] 

 TOTAL TOKENS ==> 37

 ---- POST ----

 [('To', 'TO'), ('keep', 'VB'), ('up', 'RP'), ('with', 'IN'), ('the', 'DT'), ('scale', 'NN'), ('of', 'IN'), ('the', 'DT'), ('data', 'NNS'), (',', ','), ('AbbVie', 'NNP'), ('utilizes', 'VBZ'), ('the', 'DT'), ('latest', 'JJS'), ('AbbVie', 'NNP'), ('takes', 'VBZ'), ('advantage', 'NN'), ('of', 'IN'), ('the', 'DT'), ('latest', 'JJS'), ('NLP', 'NN'), ('algorithms', 'NN'), ('to', 'TO'), ('allow', 'VB'), ('researchers', 'NNS'), ('to', 'TO'), ('quickly', 'RB'), ('return', 'VB'), ('relevant', 'JJ'), ('data', 'NNS'), ('for', 'IN'), ('its', 'PRP$'), ('biomedical', 'JJ'), ('research', 'NN'), ('and', 'CC'), ('development', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['keep', 'scale', 'data', ',', 'AbbVie', 'utilizes', 'latest', 'AbbVie', 'takes', 'advantage', 'latest', 'NLP', 'algorithms', 'allow', 'researchers', 'quickly', 'return', 'relevant', 'data', 'biomedical', 'research', 'development', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('keep', 'VB'), ('scale', 'NN'), ('data', 'NNS'), (',', ','), ('AbbVie', 'NNP'), ('utilizes', 'VBZ'), ('latest', 'JJS'), ('AbbVie', 'NNP'), ('takes', 'VBZ'), ('advantage', 'NN'), ('latest', 'JJS'), ('NLP', 'NNP'), ('algorithms', 'NN'), ('allow', 'NN'), ('researchers', 'NNS'), ('quickly', 'RB'), ('return', 'VBP'), ('relevant', 'JJ'), ('data', 'NNS'), ('biomedical', 'JJ'), ('research', 'NN'), ('development', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['keep scale', 'scale data', 'data ,', ', AbbVie', 'AbbVie utilizes', 'utilizes latest', 'latest AbbVie', 'AbbVie takes', 'takes advantage', 'advantage latest', 'latest NLP', 'NLP algorithms', 'algorithms allow', 'allow researchers', 'researchers quickly', 'quickly return', 'return relevant', 'relevant data', 'data biomedical', 'biomedical research', 'research development', 'development .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['keep scale data', 'scale data ,', 'data , AbbVie', ', AbbVie utilizes', 'AbbVie utilizes latest', 'utilizes latest AbbVie', 'latest AbbVie takes', 'AbbVie takes advantage', 'takes advantage latest', 'advantage latest NLP', 'latest NLP algorithms', 'NLP algorithms allow', 'algorithms allow researchers', 'allow researchers quickly', 'researchers quickly return', 'quickly return relevant', 'return relevant data', 'relevant data biomedical', 'data biomedical research', 'biomedical research development', 'research development .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['scale', 'advantage', 'algorithms', 'allow', 'biomedical research', 'development'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'AbbVie', 'NLP']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['keep', 'scale', 'data', ',', 'abbvi', 'util', 'latest', 'abbvi', 'take', 'advantag', 'latest', 'nlp', 'algorithm', 'allow', 'research', 'quickli', 'return', 'relev', 'data', 'biomed', 'research', 'develop', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['keep', 'scale', 'data', ',', 'abbvi', 'util', 'latest', 'abbvi', 'take', 'advantag', 'latest', 'nlp', 'algorithm', 'allow', 'research', 'quick', 'return', 'relev', 'data', 'biomed', 'research', 'develop', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['keep', 'scale', 'data', ',', 'AbbVie', 'utilizes', 'latest', 'AbbVie', 'take', 'advantage', 'latest', 'NLP', 'algorithm', 'allow', 'researcher', 'quickly', 'return', 'relevant', 'data', 'biomedical', 'research', 'development', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

11 --> Given the recent breakthroughs in deep- learning-based Transformer NLP models, such as BERT, the Bidirectional Encoder  Representations from Transformers (Devlin et al., 2018), AbbVie partnered with Intel to  optimize Transformer NLP models in their deployments across the company. 


 ---- TOKENS ----

 ['Given', 'the', 'recent', 'breakthroughs', 'in', 'deep-', 'learning-based', 'Transformer', 'NLP', 'models', ',', 'such', 'as', 'BERT', ',', 'the', 'Bidirectional', 'Encoder', 'Representations', 'from', 'Transformers', '(', 'Devlin', 'et', 'al.', ',', '2018', ')', ',', 'AbbVie', 'partnered', 'with', 'Intel', 'to', 'optimize', 'Transformer', 'NLP', 'models', 'in', 'their', 'deployments', 'across', 'the', 'company', '.'] 

 TOTAL TOKENS ==> 45

 ---- POST ----

 [('Given', 'VBN'), ('the', 'DT'), ('recent', 'JJ'), ('breakthroughs', 'NNS'), ('in', 'IN'), ('deep-', 'JJ'), ('learning-based', 'JJ'), ('Transformer', 'NNP'), ('NLP', 'NNP'), ('models', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('BERT', 'NNP'), (',', ','), ('the', 'DT'), ('Bidirectional', 'NNP'), ('Encoder', 'NNP'), ('Representations', 'NNP'), ('from', 'IN'), ('Transformers', 'NNP'), ('(', '('), ('Devlin', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), (',', ','), ('AbbVie', 'NNP'), ('partnered', 'VBD'), ('with', 'IN'), ('Intel', 'NNP'), ('to', 'TO'), ('optimize', 'VB'), ('Transformer', 'NNP'), ('NLP', 'NNP'), ('models', 'NNS'), ('in', 'IN'), ('their', 'PRP$'), ('deployments', 'NNS'), ('across', 'IN'), ('the', 'DT'), ('company', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Given', 'recent', 'breakthroughs', 'deep-', 'learning-based', 'Transformer', 'NLP', 'models', ',', 'BERT', ',', 'Bidirectional', 'Encoder', 'Representations', 'Transformers', '(', 'Devlin', 'et', 'al.', ',', '2018', ')', ',', 'AbbVie', 'partnered', 'Intel', 'optimize', 'Transformer', 'NLP', 'models', 'deployments', 'across', 'company', '.']

 TOTAL FILTERED TOKENS ==>  34

 ---- POST FOR FILTERED TOKENS ----

 [('Given', 'VBN'), ('recent', 'JJ'), ('breakthroughs', 'NNS'), ('deep-', 'JJ'), ('learning-based', 'JJ'), ('Transformer', 'NNP'), ('NLP', 'NNP'), ('models', 'NNS'), (',', ','), ('BERT', 'NNP'), (',', ','), ('Bidirectional', 'NNP'), ('Encoder', 'NNP'), ('Representations', 'NNP'), ('Transformers', 'NNP'), ('(', '('), ('Devlin', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), (',', ','), ('AbbVie', 'NNP'), ('partnered', 'VBD'), ('Intel', 'NNP'), ('optimize', 'VB'), ('Transformer', 'NNP'), ('NLP', 'NNP'), ('models', 'NNS'), ('deployments', 'NNS'), ('across', 'IN'), ('company', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Given recent', 'recent breakthroughs', 'breakthroughs deep-', 'deep- learning-based', 'learning-based Transformer', 'Transformer NLP', 'NLP models', 'models ,', ', BERT', 'BERT ,', ', Bidirectional', 'Bidirectional Encoder', 'Encoder Representations', 'Representations Transformers', 'Transformers (', '( Devlin', 'Devlin et', 'et al.', 'al. ,', ', 2018', '2018 )', ') ,', ', AbbVie', 'AbbVie partnered', 'partnered Intel', 'Intel optimize', 'optimize Transformer', 'Transformer NLP', 'NLP models', 'models deployments', 'deployments across', 'across company', 'company .'] 

 TOTAL BIGRAMS --> 33 



 ---- TRI-GRAMS ---- 

 ['Given recent breakthroughs', 'recent breakthroughs deep-', 'breakthroughs deep- learning-based', 'deep- learning-based Transformer', 'learning-based Transformer NLP', 'Transformer NLP models', 'NLP models ,', 'models , BERT', ', BERT ,', 'BERT , Bidirectional', ', Bidirectional Encoder', 'Bidirectional Encoder Representations', 'Encoder Representations Transformers', 'Representations Transformers (', 'Transformers ( Devlin', '( Devlin et', 'Devlin et al.', 'et al. ,', 'al. , 2018', ', 2018 )', '2018 ) ,', ') , AbbVie', ', AbbVie partnered', 'AbbVie partnered Intel', 'partnered Intel optimize', 'Intel optimize Transformer', 'optimize Transformer NLP', 'Transformer NLP models', 'NLP models deployments', 'models deployments across', 'deployments across company', 'across company .'] 

 TOTAL TRIGRAMS --> 32 



 ---- NOUN PHRASES ---- 

 ['company'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['BERT', 'Bidirectional Encoder Representations', 'AbbVie', 'Intel', 'Transformer']
 TOTAL ORGANIZATION ENTITY --> 5 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['given', 'recent', 'breakthrough', 'deep-', 'learning-bas', 'transform', 'nlp', 'model', ',', 'bert', ',', 'bidirect', 'encod', 'represent', 'transform', '(', 'devlin', 'et', 'al.', ',', '2018', ')', ',', 'abbvi', 'partner', 'intel', 'optim', 'transform', 'nlp', 'model', 'deploy', 'across', 'compani', '.']

 TOTAL PORTER STEM WORDS ==> 34



 ---- SNOWBALL STEMMING ----

['given', 'recent', 'breakthrough', 'deep-', 'learning-bas', 'transform', 'nlp', 'model', ',', 'bert', ',', 'bidirect', 'encod', 'represent', 'transform', '(', 'devlin', 'et', 'al.', ',', '2018', ')', ',', 'abbvi', 'partner', 'intel', 'optim', 'transform', 'nlp', 'model', 'deploy', 'across', 'compani', '.']

 TOTAL SNOWBALL STEM WORDS ==> 34



 ---- LEMMATIZATION ----

['Given', 'recent', 'breakthrough', 'deep-', 'learning-based', 'Transformer', 'NLP', 'model', ',', 'BERT', ',', 'Bidirectional', 'Encoder', 'Representations', 'Transformers', '(', 'Devlin', 'et', 'al.', ',', '2018', ')', ',', 'AbbVie', 'partnered', 'Intel', 'optimize', 'Transformer', 'NLP', 'model', 'deployment', 'across', 'company', '.']

 TOTAL LEMMATIZE WORDS ==> 34

************************************************************************************************************************

12 --> The Challenge With large amounts of biopharmaceutical data being produced in different languages  worldwide, it is crucial to ensure that the right data is quickly accessible at the right  time. 


 ---- TOKENS ----

 ['The', 'Challenge', 'With', 'large', 'amounts', 'of', 'biopharmaceutical', 'data', 'being', 'produced', 'in', 'different', 'languages', 'worldwide', ',', 'it', 'is', 'crucial', 'to', 'ensure', 'that', 'the', 'right', 'data', 'is', 'quickly', 'accessible', 'at', 'the', 'right', 'time', '.'] 

 TOTAL TOKENS ==> 32

 ---- POST ----

 [('The', 'DT'), ('Challenge', 'NNP'), ('With', 'IN'), ('large', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('biopharmaceutical', 'JJ'), ('data', 'NNS'), ('being', 'VBG'), ('produced', 'VBN'), ('in', 'IN'), ('different', 'JJ'), ('languages', 'NNS'), ('worldwide', 'RB'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('crucial', 'JJ'), ('to', 'TO'), ('ensure', 'VB'), ('that', 'IN'), ('the', 'DT'), ('right', 'JJ'), ('data', 'NN'), ('is', 'VBZ'), ('quickly', 'RB'), ('accessible', 'JJ'), ('at', 'IN'), ('the', 'DT'), ('right', 'JJ'), ('time', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Challenge', 'large', 'amounts', 'biopharmaceutical', 'data', 'produced', 'different', 'languages', 'worldwide', ',', 'crucial', 'ensure', 'right', 'data', 'quickly', 'accessible', 'right', 'time', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Challenge', 'NNP'), ('large', 'JJ'), ('amounts', 'NNS'), ('biopharmaceutical', 'JJ'), ('data', 'NNS'), ('produced', 'VBD'), ('different', 'JJ'), ('languages', 'NNS'), ('worldwide', 'VBP'), (',', ','), ('crucial', 'JJ'), ('ensure', 'VB'), ('right', 'JJ'), ('data', 'NNS'), ('quickly', 'RB'), ('accessible', 'VB'), ('right', 'JJ'), ('time', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Challenge large', 'large amounts', 'amounts biopharmaceutical', 'biopharmaceutical data', 'data produced', 'produced different', 'different languages', 'languages worldwide', 'worldwide ,', ', crucial', 'crucial ensure', 'ensure right', 'right data', 'data quickly', 'quickly accessible', 'accessible right', 'right time', 'time .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Challenge large amounts', 'large amounts biopharmaceutical', 'amounts biopharmaceutical data', 'biopharmaceutical data produced', 'data produced different', 'produced different languages', 'different languages worldwide', 'languages worldwide ,', 'worldwide , crucial', ', crucial ensure', 'crucial ensure right', 'ensure right data', 'right data quickly', 'data quickly accessible', 'quickly accessible right', 'accessible right time', 'right time .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['right time'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['challeng', 'larg', 'amount', 'biopharmaceut', 'data', 'produc', 'differ', 'languag', 'worldwid', ',', 'crucial', 'ensur', 'right', 'data', 'quickli', 'access', 'right', 'time', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['challeng', 'larg', 'amount', 'biopharmaceut', 'data', 'produc', 'differ', 'languag', 'worldwid', ',', 'crucial', 'ensur', 'right', 'data', 'quick', 'access', 'right', 'time', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Challenge', 'large', 'amount', 'biopharmaceutical', 'data', 'produced', 'different', 'language', 'worldwide', ',', 'crucial', 'ensure', 'right', 'data', 'quickly', 'accessible', 'right', 'time', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

13 --> AbbVie found that commercially available language translation services did  not always provide the most accurate translations for its highly domain-specific  biomedical text. 


 ---- TOKENS ----

 ['AbbVie', 'found', 'that', 'commercially', 'available', 'language', 'translation', 'services', 'did', 'not', 'always', 'provide', 'the', 'most', 'accurate', 'translations', 'for', 'its', 'highly', 'domain-specific', 'biomedical', 'text', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('AbbVie', 'NNP'), ('found', 'VBD'), ('that', 'IN'), ('commercially', 'RB'), ('available', 'JJ'), ('language', 'NN'), ('translation', 'NN'), ('services', 'NNS'), ('did', 'VBD'), ('not', 'RB'), ('always', 'RB'), ('provide', 'VBP'), ('the', 'DT'), ('most', 'RBS'), ('accurate', 'JJ'), ('translations', 'NNS'), ('for', 'IN'), ('its', 'PRP$'), ('highly', 'RB'), ('domain-specific', 'JJ'), ('biomedical', 'JJ'), ('text', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'found', 'commercially', 'available', 'language', 'translation', 'services', 'always', 'provide', 'accurate', 'translations', 'highly', 'domain-specific', 'biomedical', 'text', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('found', 'VBD'), ('commercially', 'RB'), ('available', 'JJ'), ('language', 'NN'), ('translation', 'NN'), ('services', 'NNS'), ('always', 'RB'), ('provide', 'VBP'), ('accurate', 'JJ'), ('translations', 'NNS'), ('highly', 'RB'), ('domain-specific', 'JJ'), ('biomedical', 'JJ'), ('text', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie found', 'found commercially', 'commercially available', 'available language', 'language translation', 'translation services', 'services always', 'always provide', 'provide accurate', 'accurate translations', 'translations highly', 'highly domain-specific', 'domain-specific biomedical', 'biomedical text', 'text .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['AbbVie found commercially', 'found commercially available', 'commercially available language', 'available language translation', 'language translation services', 'translation services always', 'services always provide', 'always provide accurate', 'provide accurate translations', 'accurate translations highly', 'translations highly domain-specific', 'highly domain-specific biomedical', 'domain-specific biomedical text', 'biomedical text .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['available language', 'translation', 'domain-specific biomedical text'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'found', 'commerci', 'avail', 'languag', 'translat', 'servic', 'alway', 'provid', 'accur', 'translat', 'highli', 'domain-specif', 'biomed', 'text', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['abbvi', 'found', 'commerci', 'avail', 'languag', 'translat', 'servic', 'alway', 'provid', 'accur', 'translat', 'high', 'domain-specif', 'biomed', 'text', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['AbbVie', 'found', 'commercially', 'available', 'language', 'translation', 'service', 'always', 'provide', 'accurate', 'translation', 'highly', 'domain-specific', 'biomedical', 'text', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

14 --> To solve this problem, AbbVie decided to create its own translation  and search tools. 


 ---- TOKENS ----

 ['To', 'solve', 'this', 'problem', ',', 'AbbVie', 'decided', 'to', 'create', 'its', 'own', 'translation', 'and', 'search', 'tools', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('To', 'TO'), ('solve', 'VB'), ('this', 'DT'), ('problem', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('decided', 'VBD'), ('to', 'TO'), ('create', 'VB'), ('its', 'PRP$'), ('own', 'JJ'), ('translation', 'NN'), ('and', 'CC'), ('search', 'NN'), ('tools', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['solve', 'problem', ',', 'AbbVie', 'decided', 'create', 'translation', 'search', 'tools', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('solve', 'NN'), ('problem', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('decided', 'VBD'), ('create', 'JJ'), ('translation', 'NN'), ('search', 'NN'), ('tools', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['solve problem', 'problem ,', ', AbbVie', 'AbbVie decided', 'decided create', 'create translation', 'translation search', 'search tools', 'tools .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['solve problem ,', 'problem , AbbVie', ', AbbVie decided', 'AbbVie decided create', 'decided create translation', 'create translation search', 'translation search tools', 'search tools .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['solve', 'problem', 'create translation', 'search'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['solv', 'problem', ',', 'abbvi', 'decid', 'creat', 'translat', 'search', 'tool', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['solv', 'problem', ',', 'abbvi', 'decid', 'creat', 'translat', 'search', 'tool', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['solve', 'problem', ',', 'AbbVie', 'decided', 'create', 'translation', 'search', 'tool', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

15 --> Table of Contents Executive Summary ......................... 1 Enabling Data-Driven Research ...... 1 The Challenge .................................. 1 The Solution     Abbelfish Machine Translation ....... 2     AbbVie Search   ................................ 2 Results     Abbelfish Machine Translation ........ 3      AbbVie Search .................................. 3 Conclusion ......................................... 4 References ......................................... 4 Authors G Anthony Reina  Chief AI Architect for Health & Life  Sciences - Intel Corporation Mehmed Sariyildiz   Data Scientist for AI and NLP - AbbVie  Brian Martin  Head of AI in R&D Information Research  – AbbVie Andrew Lamkin  Platform Solutions Architect - Intel  Corporation Jason Lee  Software Engineer - Intel Corporation 1See backup for configuration details. 


 ---- TOKENS ----

 ['Table', 'of', 'Contents', 'Executive', 'Summary', '.........................', '1', 'Enabling', 'Data-Driven', 'Research', '......', '1', 'The', 'Challenge', '..................................', '1', 'The', 'Solution', 'Abbelfish', 'Machine', 'Translation', '.......', '2', 'AbbVie', 'Search', '................................', '2', 'Results', 'Abbelfish', 'Machine', 'Translation', '........', '3', 'AbbVie', 'Search', '..................................', '3', 'Conclusion', '.........................................', '4', 'References', '.........................................', '4', 'Authors', 'G', 'Anthony', 'Reina', 'Chief', 'AI', 'Architect', 'for', 'Health', '&', 'Life', 'Sciences', '-', 'Intel', 'Corporation', 'Mehmed', 'Sariyildiz', 'Data', 'Scientist', 'for', 'AI', 'and', 'NLP', '-', 'AbbVie', 'Brian', 'Martin', 'Head', 'of', 'AI', 'in', 'R', '&', 'D', 'Information', 'Research', '–', 'AbbVie', 'Andrew', 'Lamkin', 'Platform', 'Solutions', 'Architect', '-', 'Intel', 'Corporation', 'Jason', 'Lee', 'Software', 'Engineer', '-', 'Intel', 'Corporation', '1See', 'backup', 'for', 'configuration', 'details', '.'] 

 TOTAL TOKENS ==> 102

 ---- POST ----

 [('Table', 'NN'), ('of', 'IN'), ('Contents', 'NNP'), ('Executive', 'NNP'), ('Summary', 'NNP'), ('.........................', 'VBD'), ('1', 'CD'), ('Enabling', 'NNP'), ('Data-Driven', 'NNP'), ('Research', 'NNP'), ('......', 'VBZ'), ('1', 'CD'), ('The', 'DT'), ('Challenge', 'NNP'), ('..................................', 'NNP'), ('1', 'CD'), ('The', 'DT'), ('Solution', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('.......', 'VBD'), ('2', 'CD'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('................................', 'VBD'), ('2', 'CD'), ('Results', 'NNS'), ('Abbelfish', 'JJ'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('........', 'VBD'), ('3', 'CD'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('..................................', 'VBD'), ('3', 'CD'), ('Conclusion', 'NNP'), ('.........................................', 'VBD'), ('4', 'CD'), ('References', 'NNPS'), ('.........................................', '$'), ('4', 'CD'), ('Authors', 'NNPS'), ('G', 'NNP'), ('Anthony', 'NNP'), ('Reina', 'NNP'), ('Chief', 'NNP'), ('AI', 'NNP'), ('Architect', 'NNP'), ('for', 'IN'), ('Health', 'NNP'), ('&', 'CC'), ('Life', 'NNP'), ('Sciences', 'NNPS'), ('-', ':'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('Mehmed', 'NNP'), ('Sariyildiz', 'NNP'), ('Data', 'NNP'), ('Scientist', 'NNP'), ('for', 'IN'), ('AI', 'NNP'), ('and', 'CC'), ('NLP', 'NNP'), ('-', ':'), ('AbbVie', 'NNP'), ('Brian', 'NNP'), ('Martin', 'NNP'), ('Head', 'NNP'), ('of', 'IN'), ('AI', 'NNP'), ('in', 'IN'), ('R', 'NNP'), ('&', 'CC'), ('D', 'NNP'), ('Information', 'NNP'), ('Research', 'NNP'), ('–', 'NNP'), ('AbbVie', 'NNP'), ('Andrew', 'NNP'), ('Lamkin', 'NNP'), ('Platform', 'NNP'), ('Solutions', 'NNP'), ('Architect', 'NNP'), ('-', ':'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('Jason', 'NNP'), ('Lee', 'NNP'), ('Software', 'NNP'), ('Engineer', 'NNP'), ('-', ':'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('1See', 'CD'), ('backup', 'NN'), ('for', 'IN'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Table', 'Contents', 'Executive', 'Summary', '.........................', '1', 'Enabling', 'Data-Driven', 'Research', '......', '1', 'Challenge', '..................................', '1', 'Solution', 'Abbelfish', 'Machine', 'Translation', '.......', '2', 'AbbVie', 'Search', '................................', '2', 'Results', 'Abbelfish', 'Machine', 'Translation', '........', '3', 'AbbVie', 'Search', '..................................', '3', 'Conclusion', '.........................................', '4', 'References', '.........................................', '4', 'Authors', 'G', 'Anthony', 'Reina', 'Chief', 'AI', 'Architect', 'Health', '&', 'Life', 'Sciences', '-', 'Intel', 'Corporation', 'Mehmed', 'Sariyildiz', 'Data', 'Scientist', 'AI', 'NLP', '-', 'AbbVie', 'Brian', 'Martin', 'Head', 'AI', 'R', '&', 'Information', 'Research', '–', 'AbbVie', 'Andrew', 'Lamkin', 'Platform', 'Solutions', 'Architect', '-', 'Intel', 'Corporation', 'Jason', 'Lee', 'Software', 'Engineer', '-', 'Intel', 'Corporation', '1See', 'backup', 'configuration', 'details', '.']

 TOTAL FILTERED TOKENS ==>  92

 ---- POST FOR FILTERED TOKENS ----

 [('Table', 'JJ'), ('Contents', 'NNP'), ('Executive', 'NNP'), ('Summary', 'NNP'), ('.........................', 'VBD'), ('1', 'CD'), ('Enabling', 'NNP'), ('Data-Driven', 'NNP'), ('Research', 'NNP'), ('......', 'POS'), ('1', 'CD'), ('Challenge', 'NNP'), ('..................................', 'VBD'), ('1', 'CD'), ('Solution', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('.......', 'VBD'), ('2', 'CD'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('................................', 'VBD'), ('2', 'CD'), ('Results', 'NNS'), ('Abbelfish', 'JJ'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('........', 'VBD'), ('3', 'CD'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('..................................', 'VBD'), ('3', 'CD'), ('Conclusion', 'NNP'), ('.........................................', 'VBD'), ('4', 'CD'), ('References', 'NNPS'), ('.........................................', '$'), ('4', 'CD'), ('Authors', 'NNPS'), ('G', 'NNP'), ('Anthony', 'NNP'), ('Reina', 'NNP'), ('Chief', 'NNP'), ('AI', 'NNP'), ('Architect', 'NNP'), ('Health', 'NNP'), ('&', 'CC'), ('Life', 'NNP'), ('Sciences', 'NNPS'), ('-', ':'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('Mehmed', 'NNP'), ('Sariyildiz', 'NNP'), ('Data', 'NNP'), ('Scientist', 'NNP'), ('AI', 'NNP'), ('NLP', 'NNP'), ('-', ':'), ('AbbVie', 'NNP'), ('Brian', 'NNP'), ('Martin', 'NNP'), ('Head', 'NNP'), ('AI', 'NNP'), ('R', 'NNP'), ('&', 'CC'), ('Information', 'NNP'), ('Research', 'NNP'), ('–', 'NNP'), ('AbbVie', 'NNP'), ('Andrew', 'NNP'), ('Lamkin', 'NNP'), ('Platform', 'NNP'), ('Solutions', 'NNP'), ('Architect', 'NNP'), ('-', ':'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('Jason', 'NNP'), ('Lee', 'NNP'), ('Software', 'NNP'), ('Engineer', 'NNP'), ('-', ':'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('1See', 'CD'), ('backup', 'NN'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Table Contents', 'Contents Executive', 'Executive Summary', 'Summary .........................', '......................... 1', '1 Enabling', 'Enabling Data-Driven', 'Data-Driven Research', 'Research ......', '...... 1', '1 Challenge', 'Challenge ..................................', '.................................. 1', '1 Solution', 'Solution Abbelfish', 'Abbelfish Machine', 'Machine Translation', 'Translation .......', '....... 2', '2 AbbVie', 'AbbVie Search', 'Search ................................', '................................ 2', '2 Results', 'Results Abbelfish', 'Abbelfish Machine', 'Machine Translation', 'Translation ........', '........ 3', '3 AbbVie', 'AbbVie Search', 'Search ..................................', '.................................. 3', '3 Conclusion', 'Conclusion .........................................', '......................................... 4', '4 References', 'References .........................................', '......................................... 4', '4 Authors', 'Authors G', 'G Anthony', 'Anthony Reina', 'Reina Chief', 'Chief AI', 'AI Architect', 'Architect Health', 'Health &', '& Life', 'Life Sciences', 'Sciences -', '- Intel', 'Intel Corporation', 'Corporation Mehmed', 'Mehmed Sariyildiz', 'Sariyildiz Data', 'Data Scientist', 'Scientist AI', 'AI NLP', 'NLP -', '- AbbVie', 'AbbVie Brian', 'Brian Martin', 'Martin Head', 'Head AI', 'AI R', 'R &', '& Information', 'Information Research', 'Research –', '– AbbVie', 'AbbVie Andrew', 'Andrew Lamkin', 'Lamkin Platform', 'Platform Solutions', 'Solutions Architect', 'Architect -', '- Intel', 'Intel Corporation', 'Corporation Jason', 'Jason Lee', 'Lee Software', 'Software Engineer', 'Engineer -', '- Intel', 'Intel Corporation', 'Corporation 1See', '1See backup', 'backup configuration', 'configuration details', 'details .'] 

 TOTAL BIGRAMS --> 91 



 ---- TRI-GRAMS ---- 

 ['Table Contents Executive', 'Contents Executive Summary', 'Executive Summary .........................', 'Summary ......................... 1', '......................... 1 Enabling', '1 Enabling Data-Driven', 'Enabling Data-Driven Research', 'Data-Driven Research ......', 'Research ...... 1', '...... 1 Challenge', '1 Challenge ..................................', 'Challenge .................................. 1', '.................................. 1 Solution', '1 Solution Abbelfish', 'Solution Abbelfish Machine', 'Abbelfish Machine Translation', 'Machine Translation .......', 'Translation ....... 2', '....... 2 AbbVie', '2 AbbVie Search', 'AbbVie Search ................................', 'Search ................................ 2', '................................ 2 Results', '2 Results Abbelfish', 'Results Abbelfish Machine', 'Abbelfish Machine Translation', 'Machine Translation ........', 'Translation ........ 3', '........ 3 AbbVie', '3 AbbVie Search', 'AbbVie Search ..................................', 'Search .................................. 3', '.................................. 3 Conclusion', '3 Conclusion .........................................', 'Conclusion ......................................... 4', '......................................... 4 References', '4 References .........................................', 'References ......................................... 4', '......................................... 4 Authors', '4 Authors G', 'Authors G Anthony', 'G Anthony Reina', 'Anthony Reina Chief', 'Reina Chief AI', 'Chief AI Architect', 'AI Architect Health', 'Architect Health &', 'Health & Life', '& Life Sciences', 'Life Sciences -', 'Sciences - Intel', '- Intel Corporation', 'Intel Corporation Mehmed', 'Corporation Mehmed Sariyildiz', 'Mehmed Sariyildiz Data', 'Sariyildiz Data Scientist', 'Data Scientist AI', 'Scientist AI NLP', 'AI NLP -', 'NLP - AbbVie', '- AbbVie Brian', 'AbbVie Brian Martin', 'Brian Martin Head', 'Martin Head AI', 'Head AI R', 'AI R &', 'R & Information', '& Information Research', 'Information Research –', 'Research – AbbVie', '– AbbVie Andrew', 'AbbVie Andrew Lamkin', 'Andrew Lamkin Platform', 'Lamkin Platform Solutions', 'Platform Solutions Architect', 'Solutions Architect -', 'Architect - Intel', '- Intel Corporation', 'Intel Corporation Jason', 'Corporation Jason Lee', 'Jason Lee Software', 'Lee Software Engineer', 'Software Engineer -', 'Engineer - Intel', '- Intel Corporation', 'Intel Corporation 1See', 'Corporation 1See backup', '1See backup configuration', 'backup configuration details', 'configuration details .'] 

 TOTAL TRIGRAMS --> 90 



 ---- NOUN PHRASES ---- 

 ['backup', 'configuration'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['Contents', 'AbbVie Search', 'AbbVie Search', 'Life Sciences', 'Intel Corporation Mehmed Sariyildiz Data Scientist', 'NLP', 'AbbVie Brian Martin Head', 'Information Research', 'Intel Corporation Jason Lee Software Engineer', 'Intel']
 TOTAL ORGANIZATION ENTITY --> 10 


 PERSON ---> ['Table', 'Machine Translation', 'Abbelfish Machine Translation', 'Anthony Reina', 'Andrew Lamkin Platform Solutions Architect']
 TOTAL PERSON ENTITY --> 5 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['tabl', 'content', 'execut', 'summari', '.........................', '1', 'enabl', 'data-driven', 'research', '......', '1', 'challeng', '..................................', '1', 'solut', 'abbelfish', 'machin', 'translat', '.......', '2', 'abbvi', 'search', '................................', '2', 'result', 'abbelfish', 'machin', 'translat', '........', '3', 'abbvi', 'search', '..................................', '3', 'conclus', '.........................................', '4', 'refer', '.........................................', '4', 'author', 'g', 'anthoni', 'reina', 'chief', 'ai', 'architect', 'health', '&', 'life', 'scienc', '-', 'intel', 'corpor', 'mehm', 'sariyildiz', 'data', 'scientist', 'ai', 'nlp', '-', 'abbvi', 'brian', 'martin', 'head', 'ai', 'r', '&', 'inform', 'research', '–', 'abbvi', 'andrew', 'lamkin', 'platform', 'solut', 'architect', '-', 'intel', 'corpor', 'jason', 'lee', 'softwar', 'engin', '-', 'intel', 'corpor', '1see', 'backup', 'configur', 'detail', '.']

 TOTAL PORTER STEM WORDS ==> 92



 ---- SNOWBALL STEMMING ----

['tabl', 'content', 'execut', 'summari', '.........................', '1', 'enabl', 'data-driven', 'research', '......', '1', 'challeng', '..................................', '1', 'solut', 'abbelfish', 'machin', 'translat', '.......', '2', 'abbvi', 'search', '................................', '2', 'result', 'abbelfish', 'machin', 'translat', '........', '3', 'abbvi', 'search', '..................................', '3', 'conclus', '.........................................', '4', 'refer', '.........................................', '4', 'author', 'g', 'anthoni', 'reina', 'chief', 'ai', 'architect', 'health', '&', 'life', 'scienc', '-', 'intel', 'corpor', 'mehm', 'sariyildiz', 'data', 'scientist', 'ai', 'nlp', '-', 'abbvi', 'brian', 'martin', 'head', 'ai', 'r', '&', 'inform', 'research', '–', 'abbvi', 'andrew', 'lamkin', 'platform', 'solut', 'architect', '-', 'intel', 'corpor', 'jason', 'lee', 'softwar', 'engin', '-', 'intel', 'corpor', '1see', 'backup', 'configur', 'detail', '.']

 TOTAL SNOWBALL STEM WORDS ==> 92



 ---- LEMMATIZATION ----

['Table', 'Contents', 'Executive', 'Summary', '.........................', '1', 'Enabling', 'Data-Driven', 'Research', '......', '1', 'Challenge', '..................................', '1', 'Solution', 'Abbelfish', 'Machine', 'Translation', '.......', '2', 'AbbVie', 'Search', '................................', '2', 'Results', 'Abbelfish', 'Machine', 'Translation', '........', '3', 'AbbVie', 'Search', '..................................', '3', 'Conclusion', '.........................................', '4', 'References', '.........................................', '4', 'Authors', 'G', 'Anthony', 'Reina', 'Chief', 'AI', 'Architect', 'Health', '&', 'Life', 'Sciences', '-', 'Intel', 'Corporation', 'Mehmed', 'Sariyildiz', 'Data', 'Scientist', 'AI', 'NLP', '-', 'AbbVie', 'Brian', 'Martin', 'Head', 'AI', 'R', '&', 'Information', 'Research', '–', 'AbbVie', 'Andrew', 'Lamkin', 'Platform', 'Solutions', 'Architect', '-', 'Intel', 'Corporation', 'Jason', 'Lee', 'Software', 'Engineer', '-', 'Intel', 'Corporation', '1See', 'backup', 'configuration', 'detail', '.']

 TOTAL LEMMATIZE WORDS ==> 92

************************************************************************************************************************

16 --> For more complete information about performance and benchmark results, visit www.intel.com/benchmarks. 


 ---- TOKENS ----

 ['For', 'more', 'complete', 'information', 'about', 'performance', 'and', 'benchmark', 'results', ',', 'visit', 'www.intel.com/benchmarks', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('For', 'IN'), ('more', 'JJR'), ('complete', 'JJ'), ('information', 'NN'), ('about', 'IN'), ('performance', 'NN'), ('and', 'CC'), ('benchmark', 'NN'), ('results', 'NNS'), (',', ','), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['complete', 'information', 'performance', 'benchmark', 'results', ',', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('complete', 'JJ'), ('information', 'NN'), ('performance', 'NN'), ('benchmark', 'NN'), ('results', 'NNS'), (',', ','), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['complete information', 'information performance', 'performance benchmark', 'benchmark results', 'results ,', ', visit', 'visit www.intel.com/benchmarks', 'www.intel.com/benchmarks .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['complete information performance', 'information performance benchmark', 'performance benchmark results', 'benchmark results ,', 'results , visit', ', visit www.intel.com/benchmarks', 'visit www.intel.com/benchmarks .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['complete information', 'performance', 'benchmark', 'visit'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['complet', 'inform', 'perform', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['complet', 'inform', 'perform', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['complete', 'information', 'performance', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

17 --> White Paper http://arxiv.org/pdf/1810.04805.pdf  White Paper | Accelerating Natural Language Processing Inference Models using Processor Optimized Capabilities The Solution  Abbelfish Machine Translation Abbelfish Machine Translation is a language translation  service that AbbVie originally created for its 2,600 researchers  in Germany. 


 ---- TOKENS ----

 ['White', 'Paper', 'http', ':', '//arxiv.org/pdf/1810.04805.pdf', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'The', 'Solution', 'Abbelfish', 'Machine', 'Translation', 'Abbelfish', 'Machine', 'Translation', 'is', 'a', 'language', 'translation', 'service', 'that', 'AbbVie', 'originally', 'created', 'for', 'its', '2,600', 'researchers', 'in', 'Germany', '.'] 

 TOTAL TOKENS ==> 42

 ---- POST ----

 [('White', 'NNP'), ('Paper', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/pdf/1810.04805.pdf', 'JJ'), ('White', 'NNP'), ('Paper', 'NNP'), ('|', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNPS'), ('The', 'DT'), ('Solution', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('language', 'NN'), ('translation', 'NN'), ('service', 'NN'), ('that', 'WDT'), ('AbbVie', 'NNP'), ('originally', 'RB'), ('created', 'VBD'), ('for', 'IN'), ('its', 'PRP$'), ('2,600', 'CD'), ('researchers', 'NNS'), ('in', 'IN'), ('Germany', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['White', 'Paper', 'http', ':', '//arxiv.org/pdf/1810.04805.pdf', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Solution', 'Abbelfish', 'Machine', 'Translation', 'Abbelfish', 'Machine', 'Translation', 'language', 'translation', 'service', 'AbbVie', 'originally', 'created', '2,600', 'researchers', 'Germany', '.']

 TOTAL FILTERED TOKENS ==>  35

 ---- POST FOR FILTERED TOKENS ----

 [('White', 'NNP'), ('Paper', 'NNP'), ('http', 'NN'), (':', ':'), ('//arxiv.org/pdf/1810.04805.pdf', 'JJ'), ('White', 'NNP'), ('Paper', 'NNP'), ('|', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNP'), ('Solution', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('language', 'NN'), ('translation', 'NN'), ('service', 'NN'), ('AbbVie', 'NNP'), ('originally', 'RB'), ('created', 'VBD'), ('2,600', 'CD'), ('researchers', 'NNS'), ('Germany', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['White Paper', 'Paper http', 'http :', ': //arxiv.org/pdf/1810.04805.pdf', '//arxiv.org/pdf/1810.04805.pdf White', 'White Paper', 'Paper |', '| Accelerating', 'Accelerating Natural', 'Natural Language', 'Language Processing', 'Processing Inference', 'Inference Models', 'Models using', 'using Processor', 'Processor Optimized', 'Optimized Capabilities', 'Capabilities Solution', 'Solution Abbelfish', 'Abbelfish Machine', 'Machine Translation', 'Translation Abbelfish', 'Abbelfish Machine', 'Machine Translation', 'Translation language', 'language translation', 'translation service', 'service AbbVie', 'AbbVie originally', 'originally created', 'created 2,600', '2,600 researchers', 'researchers Germany', 'Germany .'] 

 TOTAL BIGRAMS --> 34 



 ---- TRI-GRAMS ---- 

 ['White Paper http', 'Paper http :', 'http : //arxiv.org/pdf/1810.04805.pdf', ': //arxiv.org/pdf/1810.04805.pdf White', '//arxiv.org/pdf/1810.04805.pdf White Paper', 'White Paper |', 'Paper | Accelerating', '| Accelerating Natural', 'Accelerating Natural Language', 'Natural Language Processing', 'Language Processing Inference', 'Processing Inference Models', 'Inference Models using', 'Models using Processor', 'using Processor Optimized', 'Processor Optimized Capabilities', 'Optimized Capabilities Solution', 'Capabilities Solution Abbelfish', 'Solution Abbelfish Machine', 'Abbelfish Machine Translation', 'Machine Translation Abbelfish', 'Translation Abbelfish Machine', 'Abbelfish Machine Translation', 'Machine Translation language', 'Translation language translation', 'language translation service', 'translation service AbbVie', 'service AbbVie originally', 'AbbVie originally created', 'originally created 2,600', 'created 2,600 researchers', '2,600 researchers Germany', 'researchers Germany .'] 

 TOTAL TRIGRAMS --> 33 



 ---- NOUN PHRASES ---- 

 ['http', 'language', 'translation', 'service'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['Paper', 'AbbVie']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> ['Processor Optimized Capabilities Solution Abbelfish Machine', 'Machine Translation']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> ['Germany']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['white', 'paper', 'http', ':', '//arxiv.org/pdf/1810.04805.pdf', 'white', 'paper', '|', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'solut', 'abbelfish', 'machin', 'translat', 'abbelfish', 'machin', 'translat', 'languag', 'translat', 'servic', 'abbvi', 'origin', 'creat', '2,600', 'research', 'germani', '.']

 TOTAL PORTER STEM WORDS ==> 35



 ---- SNOWBALL STEMMING ----

['white', 'paper', 'http', ':', '//arxiv.org/pdf/1810.04805.pdf', 'white', 'paper', '|', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'solut', 'abbelfish', 'machin', 'translat', 'abbelfish', 'machin', 'translat', 'languag', 'translat', 'servic', 'abbvi', 'origin', 'creat', '2,600', 'research', 'germani', '.']

 TOTAL SNOWBALL STEM WORDS ==> 35



 ---- LEMMATIZATION ----

['White', 'Paper', 'http', ':', '//arxiv.org/pdf/1810.04805.pdf', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Solution', 'Abbelfish', 'Machine', 'Translation', 'Abbelfish', 'Machine', 'Translation', 'language', 'translation', 'service', 'AbbVie', 'originally', 'created', '2,600', 'researcher', 'Germany', '.']

 TOTAL LEMMATIZE WORDS ==> 35

************************************************************************************************************************

18 --> AbbVie has customized their model to provide  better translation for biomedical terminology that might not  be found in standard English/German translation models. 


 ---- TOKENS ----

 ['AbbVie', 'has', 'customized', 'their', 'model', 'to', 'provide', 'better', 'translation', 'for', 'biomedical', 'terminology', 'that', 'might', 'not', 'be', 'found', 'in', 'standard', 'English/German', 'translation', 'models', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('AbbVie', 'NNP'), ('has', 'VBZ'), ('customized', 'VBN'), ('their', 'PRP$'), ('model', 'NN'), ('to', 'TO'), ('provide', 'VB'), ('better', 'JJR'), ('translation', 'NN'), ('for', 'IN'), ('biomedical', 'JJ'), ('terminology', 'NN'), ('that', 'WDT'), ('might', 'MD'), ('not', 'RB'), ('be', 'VB'), ('found', 'VBN'), ('in', 'IN'), ('standard', 'JJ'), ('English/German', 'NNP'), ('translation', 'NN'), ('models', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'customized', 'model', 'provide', 'better', 'translation', 'biomedical', 'terminology', 'might', 'found', 'standard', 'English/German', 'translation', 'models', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('customized', 'VBD'), ('model', 'NN'), ('provide', 'RB'), ('better', 'JJR'), ('translation', 'NN'), ('biomedical', 'JJ'), ('terminology', 'NN'), ('might', 'MD'), ('found', 'VB'), ('standard', 'JJ'), ('English/German', 'NNP'), ('translation', 'NN'), ('models', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie customized', 'customized model', 'model provide', 'provide better', 'better translation', 'translation biomedical', 'biomedical terminology', 'terminology might', 'might found', 'found standard', 'standard English/German', 'English/German translation', 'translation models', 'models .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['AbbVie customized model', 'customized model provide', 'model provide better', 'provide better translation', 'better translation biomedical', 'translation biomedical terminology', 'biomedical terminology might', 'terminology might found', 'might found standard', 'found standard English/German', 'standard English/German translation', 'English/German translation models', 'translation models .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['model', 'translation', 'biomedical terminology', 'translation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'custom', 'model', 'provid', 'better', 'translat', 'biomed', 'terminolog', 'might', 'found', 'standard', 'english/german', 'translat', 'model', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['abbvi', 'custom', 'model', 'provid', 'better', 'translat', 'biomed', 'terminolog', 'might', 'found', 'standard', 'english/german', 'translat', 'model', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['AbbVie', 'customized', 'model', 'provide', 'better', 'translation', 'biomedical', 'terminology', 'might', 'found', 'standard', 'English/German', 'translation', 'model', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

19 --> Over one million texts are currently translated each year with  the Abbelfish service using up to 10 concurrent translations  per minute. 


 ---- TOKENS ----

 ['Over', 'one', 'million', 'texts', 'are', 'currently', 'translated', 'each', 'year', 'with', 'the', 'Abbelfish', 'service', 'using', 'up', 'to', '10', 'concurrent', 'translations', 'per', 'minute', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Over', 'IN'), ('one', 'CD'), ('million', 'CD'), ('texts', 'NN'), ('are', 'VBP'), ('currently', 'RB'), ('translated', 'VBN'), ('each', 'DT'), ('year', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Abbelfish', 'NNP'), ('service', 'NN'), ('using', 'VBG'), ('up', 'RP'), ('to', 'TO'), ('10', 'CD'), ('concurrent', 'NN'), ('translations', 'NNS'), ('per', 'IN'), ('minute', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['one', 'million', 'texts', 'currently', 'translated', 'year', 'Abbelfish', 'service', 'using', '10', 'concurrent', 'translations', 'per', 'minute', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('one', 'CD'), ('million', 'CD'), ('texts', 'NN'), ('currently', 'RB'), ('translated', 'VBN'), ('year', 'NN'), ('Abbelfish', 'NNP'), ('service', 'NN'), ('using', 'VBG'), ('10', 'CD'), ('concurrent', 'JJ'), ('translations', 'NNS'), ('per', 'IN'), ('minute', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['one million', 'million texts', 'texts currently', 'currently translated', 'translated year', 'year Abbelfish', 'Abbelfish service', 'service using', 'using 10', '10 concurrent', 'concurrent translations', 'translations per', 'per minute', 'minute .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['one million texts', 'million texts currently', 'texts currently translated', 'currently translated year', 'translated year Abbelfish', 'year Abbelfish service', 'Abbelfish service using', 'service using 10', 'using 10 concurrent', '10 concurrent translations', 'concurrent translations per', 'translations per minute', 'per minute .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['texts', 'year', 'service', 'minute'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Abbelfish']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['one', 'million', 'text', 'current', 'translat', 'year', 'abbelfish', 'servic', 'use', '10', 'concurr', 'translat', 'per', 'minut', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['one', 'million', 'text', 'current', 'translat', 'year', 'abbelfish', 'servic', 'use', '10', 'concurr', 'translat', 'per', 'minut', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['one', 'million', 'text', 'currently', 'translated', 'year', 'Abbelfish', 'service', 'using', '10', 'concurrent', 'translation', 'per', 'minute', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

20 --> The service is hosted on Intel Xeon processor- based servers. 


 ---- TOKENS ----

 ['The', 'service', 'is', 'hosted', 'on', 'Intel', 'Xeon', 'processor-', 'based', 'servers', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('The', 'DT'), ('service', 'NN'), ('is', 'VBZ'), ('hosted', 'VBN'), ('on', 'IN'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-', 'NN'), ('based', 'VBN'), ('servers', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['service', 'hosted', 'Intel', 'Xeon', 'processor-', 'based', 'servers', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('service', 'NN'), ('hosted', 'VBD'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-', 'NN'), ('based', 'VBN'), ('servers', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['service hosted', 'hosted Intel', 'Intel Xeon', 'Xeon processor-', 'processor- based', 'based servers', 'servers .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['service hosted Intel', 'hosted Intel Xeon', 'Intel Xeon processor-', 'Xeon processor- based', 'processor- based servers', 'based servers .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['service', 'processor-'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Xeon']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['servic', 'host', 'intel', 'xeon', 'processor-', 'base', 'server', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['servic', 'host', 'intel', 'xeon', 'processor-', 'base', 'server', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['service', 'hosted', 'Intel', 'Xeon', 'processor-', 'based', 'server', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

21 --> AbbVie parallelized the inference requests by  serving a copy of the model on every core. 


 ---- TOKENS ----

 ['AbbVie', 'parallelized', 'the', 'inference', 'requests', 'by', 'serving', 'a', 'copy', 'of', 'the', 'model', 'on', 'every', 'core', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('AbbVie', 'NNP'), ('parallelized', 'VBD'), ('the', 'DT'), ('inference', 'NN'), ('requests', 'NNS'), ('by', 'IN'), ('serving', 'VBG'), ('a', 'DT'), ('copy', 'NN'), ('of', 'IN'), ('the', 'DT'), ('model', 'NN'), ('on', 'IN'), ('every', 'DT'), ('core', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'parallelized', 'inference', 'requests', 'serving', 'copy', 'model', 'every', 'core', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('parallelized', 'VBD'), ('inference', 'NN'), ('requests', 'NNS'), ('serving', 'VBG'), ('copy', 'NN'), ('model', 'NN'), ('every', 'DT'), ('core', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie parallelized', 'parallelized inference', 'inference requests', 'requests serving', 'serving copy', 'copy model', 'model every', 'every core', 'core .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['AbbVie parallelized inference', 'parallelized inference requests', 'inference requests serving', 'requests serving copy', 'serving copy model', 'copy model every', 'model every core', 'every core .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['inference', 'copy', 'model', 'every core'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'parallel', 'infer', 'request', 'serv', 'copi', 'model', 'everi', 'core', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['abbvi', 'parallel', 'infer', 'request', 'serv', 'copi', 'model', 'everi', 'core', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['AbbVie', 'parallelized', 'inference', 'request', 'serving', 'copy', 'model', 'every', 'core', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

22 --> They divide the  input text into 300-word sections chunks and serve each  section chunk to a different CPU core separately. 


 ---- TOKENS ----

 ['They', 'divide', 'the', 'input', 'text', 'into', '300-word', 'sections', 'chunks', 'and', 'serve', 'each', 'section', 'chunk', 'to', 'a', 'different', 'CPU', 'core', 'separately', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('They', 'PRP'), ('divide', 'VBP'), ('the', 'DT'), ('input', 'NN'), ('text', 'NN'), ('into', 'IN'), ('300-word', 'JJ'), ('sections', 'NNS'), ('chunks', 'NNS'), ('and', 'CC'), ('serve', 'VBP'), ('each', 'DT'), ('section', 'NN'), ('chunk', 'NN'), ('to', 'TO'), ('a', 'DT'), ('different', 'JJ'), ('CPU', 'NNP'), ('core', 'NN'), ('separately', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['divide', 'input', 'text', '300-word', 'sections', 'chunks', 'serve', 'section', 'chunk', 'different', 'CPU', 'core', 'separately', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('divide', 'NN'), ('input', 'NN'), ('text', 'IN'), ('300-word', 'JJ'), ('sections', 'NNS'), ('chunks', 'NNS'), ('serve', 'VBP'), ('section', 'NN'), ('chunk', 'NN'), ('different', 'JJ'), ('CPU', 'NNP'), ('core', 'NN'), ('separately', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['divide input', 'input text', 'text 300-word', '300-word sections', 'sections chunks', 'chunks serve', 'serve section', 'section chunk', 'chunk different', 'different CPU', 'CPU core', 'core separately', 'separately .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['divide input text', 'input text 300-word', 'text 300-word sections', '300-word sections chunks', 'sections chunks serve', 'chunks serve section', 'serve section chunk', 'section chunk different', 'chunk different CPU', 'different CPU core', 'CPU core separately', 'core separately .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['divide', 'input', 'section', 'chunk', 'core'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['CPU']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['divid', 'input', 'text', '300-word', 'section', 'chunk', 'serv', 'section', 'chunk', 'differ', 'cpu', 'core', 'separ', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['divid', 'input', 'text', '300-word', 'section', 'chunk', 'serv', 'section', 'chunk', 'differ', 'cpu', 'core', 'separ', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['divide', 'input', 'text', '300-word', 'section', 'chunk', 'serve', 'section', 'chunk', 'different', 'CPU', 'core', 'separately', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

23 --> This allows  them to stream the translation service with low latency. 


 ---- TOKENS ----

 ['This', 'allows', 'them', 'to', 'stream', 'the', 'translation', 'service', 'with', 'low', 'latency', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('This', 'DT'), ('allows', 'VBZ'), ('them', 'PRP'), ('to', 'TO'), ('stream', 'VB'), ('the', 'DT'), ('translation', 'NN'), ('service', 'NN'), ('with', 'IN'), ('low', 'JJ'), ('latency', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['allows', 'stream', 'translation', 'service', 'low', 'latency', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('allows', 'NNS'), ('stream', 'VBP'), ('translation', 'NN'), ('service', 'NN'), ('low', 'JJ'), ('latency', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['allows stream', 'stream translation', 'translation service', 'service low', 'low latency', 'latency .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['allows stream translation', 'stream translation service', 'translation service low', 'service low latency', 'low latency .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['translation', 'service', 'low latency'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['allow', 'stream', 'translat', 'servic', 'low', 'latenc', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['allow', 'stream', 'translat', 'servic', 'low', 'latenc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['allows', 'stream', 'translation', 'service', 'low', 'latency', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

24 --> In  addition to input batching, the Abbelfish model is trained on  paragraphs instead of sentences, which allows the model to  generate more accurate translations for the overall document. 


 ---- TOKENS ----

 ['In', 'addition', 'to', 'input', 'batching', ',', 'the', 'Abbelfish', 'model', 'is', 'trained', 'on', 'paragraphs', 'instead', 'of', 'sentences', ',', 'which', 'allows', 'the', 'model', 'to', 'generate', 'more', 'accurate', 'translations', 'for', 'the', 'overall', 'document', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('In', 'IN'), ('addition', 'NN'), ('to', 'TO'), ('input', 'VB'), ('batching', 'NN'), (',', ','), ('the', 'DT'), ('Abbelfish', 'JJ'), ('model', 'NN'), ('is', 'VBZ'), ('trained', 'VBN'), ('on', 'IN'), ('paragraphs', 'NN'), ('instead', 'RB'), ('of', 'IN'), ('sentences', 'NNS'), (',', ','), ('which', 'WDT'), ('allows', 'VBZ'), ('the', 'DT'), ('model', 'NN'), ('to', 'TO'), ('generate', 'VB'), ('more', 'JJR'), ('accurate', 'JJ'), ('translations', 'NNS'), ('for', 'IN'), ('the', 'DT'), ('overall', 'JJ'), ('document', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['addition', 'input', 'batching', ',', 'Abbelfish', 'model', 'trained', 'paragraphs', 'instead', 'sentences', ',', 'allows', 'model', 'generate', 'accurate', 'translations', 'overall', 'document', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('addition', 'NN'), ('input', 'NN'), ('batching', 'NN'), (',', ','), ('Abbelfish', 'JJ'), ('model', 'NN'), ('trained', 'VBD'), ('paragraphs', 'JJ'), ('instead', 'RB'), ('sentences', 'NNS'), (',', ','), ('allows', 'VBZ'), ('model', 'NN'), ('generate', 'NN'), ('accurate', 'JJ'), ('translations', 'NNS'), ('overall', 'JJ'), ('document', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['addition input', 'input batching', 'batching ,', ', Abbelfish', 'Abbelfish model', 'model trained', 'trained paragraphs', 'paragraphs instead', 'instead sentences', 'sentences ,', ', allows', 'allows model', 'model generate', 'generate accurate', 'accurate translations', 'translations overall', 'overall document', 'document .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['addition input batching', 'input batching ,', 'batching , Abbelfish', ', Abbelfish model', 'Abbelfish model trained', 'model trained paragraphs', 'trained paragraphs instead', 'paragraphs instead sentences', 'instead sentences ,', 'sentences , allows', ', allows model', 'allows model generate', 'model generate accurate', 'generate accurate translations', 'accurate translations overall', 'translations overall document', 'overall document .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['addition', 'input', 'batching', 'Abbelfish model', 'model', 'generate', 'overall document'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Abbelfish']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['addit', 'input', 'batch', ',', 'abbelfish', 'model', 'train', 'paragraph', 'instead', 'sentenc', ',', 'allow', 'model', 'gener', 'accur', 'translat', 'overal', 'document', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['addit', 'input', 'batch', ',', 'abbelfish', 'model', 'train', 'paragraph', 'instead', 'sentenc', ',', 'allow', 'model', 'generat', 'accur', 'translat', 'overal', 'document', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['addition', 'input', 'batching', ',', 'Abbelfish', 'model', 'trained', 'paragraph', 'instead', 'sentence', ',', 'allows', 'model', 'generate', 'accurate', 'translation', 'overall', 'document', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

25 --> Abbelfish will soon expand its translation capabilities  to include Spanish, Italian, French, Portuguese, Russian,  Chinese, and Japanese languages. 


 ---- TOKENS ----

 ['Abbelfish', 'will', 'soon', 'expand', 'its', 'translation', 'capabilities', 'to', 'include', 'Spanish', ',', 'Italian', ',', 'French', ',', 'Portuguese', ',', 'Russian', ',', 'Chinese', ',', 'and', 'Japanese', 'languages', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Abbelfish', 'NNP'), ('will', 'MD'), ('soon', 'RB'), ('expand', 'VB'), ('its', 'PRP$'), ('translation', 'NN'), ('capabilities', 'NNS'), ('to', 'TO'), ('include', 'VB'), ('Spanish', 'JJ'), (',', ','), ('Italian', 'JJ'), (',', ','), ('French', 'JJ'), (',', ','), ('Portuguese', 'NNP'), (',', ','), ('Russian', 'NNP'), (',', ','), ('Chinese', 'NNP'), (',', ','), ('and', 'CC'), ('Japanese', 'JJ'), ('languages', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Abbelfish', 'soon', 'expand', 'translation', 'capabilities', 'include', 'Spanish', ',', 'Italian', ',', 'French', ',', 'Portuguese', ',', 'Russian', ',', 'Chinese', ',', 'Japanese', 'languages', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('Abbelfish', 'JJ'), ('soon', 'RB'), ('expand', 'VBP'), ('translation', 'NN'), ('capabilities', 'NNS'), ('include', 'VBP'), ('Spanish', 'JJ'), (',', ','), ('Italian', 'JJ'), (',', ','), ('French', 'JJ'), (',', ','), ('Portuguese', 'NNP'), (',', ','), ('Russian', 'NNP'), (',', ','), ('Chinese', 'NNP'), (',', ','), ('Japanese', 'JJ'), ('languages', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Abbelfish soon', 'soon expand', 'expand translation', 'translation capabilities', 'capabilities include', 'include Spanish', 'Spanish ,', ', Italian', 'Italian ,', ', French', 'French ,', ', Portuguese', 'Portuguese ,', ', Russian', 'Russian ,', ', Chinese', 'Chinese ,', ', Japanese', 'Japanese languages', 'languages .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['Abbelfish soon expand', 'soon expand translation', 'expand translation capabilities', 'translation capabilities include', 'capabilities include Spanish', 'include Spanish ,', 'Spanish , Italian', ', Italian ,', 'Italian , French', ', French ,', 'French , Portuguese', ', Portuguese ,', 'Portuguese , Russian', ', Russian ,', 'Russian , Chinese', ', Chinese ,', 'Chinese , Japanese', ', Japanese languages', 'Japanese languages .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['translation'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Abbelfish', 'Spanish', 'Italian', 'French', 'Portuguese', 'Russian', 'Chinese', 'Japanese']
 TOTAL GPE ENTITY --> 8 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbelfish', 'soon', 'expand', 'translat', 'capabl', 'includ', 'spanish', ',', 'italian', ',', 'french', ',', 'portugues', ',', 'russian', ',', 'chines', ',', 'japanes', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['abbelfish', 'soon', 'expand', 'translat', 'capabl', 'includ', 'spanish', ',', 'italian', ',', 'french', ',', 'portugues', ',', 'russian', ',', 'chines', ',', 'japanes', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['Abbelfish', 'soon', 'expand', 'translation', 'capability', 'include', 'Spanish', ',', 'Italian', ',', 'French', ',', 'Portuguese', ',', 'Russian', ',', 'Chinese', ',', 'Japanese', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

26 --> For this updated model, a  multidirectional, multilingual, Transformer-based topology  has been created to work with AbbVie’s scientific language  translations. 


 ---- TOKENS ----

 ['For', 'this', 'updated', 'model', ',', 'a', 'multidirectional', ',', 'multilingual', ',', 'Transformer-based', 'topology', 'has', 'been', 'created', 'to', 'work', 'with', 'AbbVie', '’', 's', 'scientific', 'language', 'translations', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('For', 'IN'), ('this', 'DT'), ('updated', 'JJ'), ('model', 'NN'), (',', ','), ('a', 'DT'), ('multidirectional', 'JJ'), (',', ','), ('multilingual', 'JJ'), (',', ','), ('Transformer-based', 'JJ'), ('topology', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('created', 'VBN'), ('to', 'TO'), ('work', 'VB'), ('with', 'IN'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('scientific', 'JJ'), ('language', 'NN'), ('translations', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['updated', 'model', ',', 'multidirectional', ',', 'multilingual', ',', 'Transformer-based', 'topology', 'created', 'work', 'AbbVie', '’', 'scientific', 'language', 'translations', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('updated', 'JJ'), ('model', 'NN'), (',', ','), ('multidirectional', 'JJ'), (',', ','), ('multilingual', 'JJ'), (',', ','), ('Transformer-based', 'JJ'), ('topology', 'NN'), ('created', 'VBD'), ('work', 'NN'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('scientific', 'JJ'), ('language', 'NN'), ('translations', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['updated model', 'model ,', ', multidirectional', 'multidirectional ,', ', multilingual', 'multilingual ,', ', Transformer-based', 'Transformer-based topology', 'topology created', 'created work', 'work AbbVie', 'AbbVie ’', '’ scientific', 'scientific language', 'language translations', 'translations .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['updated model ,', 'model , multidirectional', ', multidirectional ,', 'multidirectional , multilingual', ', multilingual ,', 'multilingual , Transformer-based', ', Transformer-based topology', 'Transformer-based topology created', 'topology created work', 'created work AbbVie', 'work AbbVie ’', 'AbbVie ’ scientific', '’ scientific language', 'scientific language translations', 'language translations .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['updated model', 'Transformer-based topology', 'work', 'scientific language'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['updat', 'model', ',', 'multidirect', ',', 'multilingu', ',', 'transformer-bas', 'topolog', 'creat', 'work', 'abbvi', '’', 'scientif', 'languag', 'translat', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['updat', 'model', ',', 'multidirect', ',', 'multilingu', ',', 'transformer-bas', 'topolog', 'creat', 'work', 'abbvi', '’', 'scientif', 'languag', 'translat', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['updated', 'model', ',', 'multidirectional', ',', 'multilingual', ',', 'Transformer-based', 'topology', 'created', 'work', 'AbbVie', '’', 'scientific', 'language', 'translation', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

27 --> The model includes 24 layers and over 500  million parameters, which took over four months to train. 


 ---- TOKENS ----

 ['The', 'model', 'includes', '24', 'layers', 'and', 'over', '500', 'million', 'parameters', ',', 'which', 'took', 'over', 'four', 'months', 'to', 'train', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('The', 'DT'), ('model', 'NN'), ('includes', 'VBZ'), ('24', 'CD'), ('layers', 'NNS'), ('and', 'CC'), ('over', '$'), ('500', 'CD'), ('million', 'CD'), ('parameters', 'NNS'), (',', ','), ('which', 'WDT'), ('took', 'VBD'), ('over', 'RP'), ('four', 'CD'), ('months', 'NNS'), ('to', 'TO'), ('train', 'VB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['model', 'includes', '24', 'layers', '500', 'million', 'parameters', ',', 'took', 'four', 'months', 'train', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('model', 'NN'), ('includes', 'VBZ'), ('24', 'CD'), ('layers', 'NNS'), ('500', 'CD'), ('million', 'CD'), ('parameters', 'NNS'), (',', ','), ('took', 'VBD'), ('four', 'CD'), ('months', 'NNS'), ('train', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['model includes', 'includes 24', '24 layers', 'layers 500', '500 million', 'million parameters', 'parameters ,', ', took', 'took four', 'four months', 'months train', 'train .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['model includes 24', 'includes 24 layers', '24 layers 500', 'layers 500 million', '500 million parameters', 'million parameters ,', 'parameters , took', ', took four', 'took four months', 'four months train', 'months train .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['model', 'train'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['model', 'includ', '24', 'layer', '500', 'million', 'paramet', ',', 'took', 'four', 'month', 'train', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['model', 'includ', '24', 'layer', '500', 'million', 'paramet', ',', 'took', 'four', 'month', 'train', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['model', 'includes', '24', 'layer', '500', 'million', 'parameter', ',', 'took', 'four', 'month', 'train', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

28 --> Abbelfish’s custom topology provides significantly more  accurate translations than commercially available translation  models (BLEU 38.41 versus 34.92 for Japanese ↔ English and  BLEU 41.36 versus 36.91 for English ↔ German). 


 ---- TOKENS ----

 ['Abbelfish', '’', 's', 'custom', 'topology', 'provides', 'significantly', 'more', 'accurate', 'translations', 'than', 'commercially', 'available', 'translation', 'models', '(', 'BLEU', '38.41', 'versus', '34.92', 'for', 'Japanese', '↔', 'English', 'and', 'BLEU', '41.36', 'versus', '36.91', 'for', 'English', '↔', 'German', ')', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('Abbelfish', 'JJ'), ('’', 'NNP'), ('s', 'NN'), ('custom', 'NN'), ('topology', 'NN'), ('provides', 'VBZ'), ('significantly', 'RB'), ('more', 'RBR'), ('accurate', 'JJ'), ('translations', 'NNS'), ('than', 'IN'), ('commercially', 'RB'), ('available', 'JJ'), ('translation', 'NN'), ('models', 'NNS'), ('(', '('), ('BLEU', 'NNP'), ('38.41', 'CD'), ('versus', 'NN'), ('34.92', 'CD'), ('for', 'IN'), ('Japanese', 'JJ'), ('↔', 'JJ'), ('English', 'NNP'), ('and', 'CC'), ('BLEU', 'NNP'), ('41.36', 'CD'), ('versus', 'NN'), ('36.91', 'CD'), ('for', 'IN'), ('English', 'NNP'), ('↔', 'NNP'), ('German', 'NNP'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Abbelfish', '’', 'custom', 'topology', 'provides', 'significantly', 'accurate', 'translations', 'commercially', 'available', 'translation', 'models', '(', 'BLEU', '38.41', 'versus', '34.92', 'Japanese', '↔', 'English', 'BLEU', '41.36', 'versus', '36.91', 'English', '↔', 'German', ')', '.']

 TOTAL FILTERED TOKENS ==>  29

 ---- POST FOR FILTERED TOKENS ----

 [('Abbelfish', 'JJ'), ('’', 'NNP'), ('custom', 'NN'), ('topology', 'NN'), ('provides', 'VBZ'), ('significantly', 'RB'), ('accurate', 'JJ'), ('translations', 'NNS'), ('commercially', 'RB'), ('available', 'JJ'), ('translation', 'NN'), ('models', 'NNS'), ('(', '('), ('BLEU', 'NNP'), ('38.41', 'CD'), ('versus', 'NN'), ('34.92', 'CD'), ('Japanese', 'JJ'), ('↔', 'JJ'), ('English', 'NNP'), ('BLEU', 'NNP'), ('41.36', 'CD'), ('versus', 'NN'), ('36.91', 'CD'), ('English', 'NNP'), ('↔', 'JJ'), ('German', 'NNP'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Abbelfish ’', '’ custom', 'custom topology', 'topology provides', 'provides significantly', 'significantly accurate', 'accurate translations', 'translations commercially', 'commercially available', 'available translation', 'translation models', 'models (', '( BLEU', 'BLEU 38.41', '38.41 versus', 'versus 34.92', '34.92 Japanese', 'Japanese ↔', '↔ English', 'English BLEU', 'BLEU 41.36', '41.36 versus', 'versus 36.91', '36.91 English', 'English ↔', '↔ German', 'German )', ') .'] 

 TOTAL BIGRAMS --> 28 



 ---- TRI-GRAMS ---- 

 ['Abbelfish ’ custom', '’ custom topology', 'custom topology provides', 'topology provides significantly', 'provides significantly accurate', 'significantly accurate translations', 'accurate translations commercially', 'translations commercially available', 'commercially available translation', 'available translation models', 'translation models (', 'models ( BLEU', '( BLEU 38.41', 'BLEU 38.41 versus', '38.41 versus 34.92', 'versus 34.92 Japanese', '34.92 Japanese ↔', 'Japanese ↔ English', '↔ English BLEU', 'English BLEU 41.36', 'BLEU 41.36 versus', '41.36 versus 36.91', 'versus 36.91 English', '36.91 English ↔', 'English ↔ German', '↔ German )', 'German ) .'] 

 TOTAL TRIGRAMS --> 27 



 ---- NOUN PHRASES ---- 

 ['custom', 'topology', 'available translation'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Abbelfish']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbelfish', '’', 'custom', 'topolog', 'provid', 'significantli', 'accur', 'translat', 'commerci', 'avail', 'translat', 'model', '(', 'bleu', '38.41', 'versu', '34.92', 'japanes', '↔', 'english', 'bleu', '41.36', 'versu', '36.91', 'english', '↔', 'german', ')', '.']

 TOTAL PORTER STEM WORDS ==> 29



 ---- SNOWBALL STEMMING ----

['abbelfish', '’', 'custom', 'topolog', 'provid', 'signific', 'accur', 'translat', 'commerci', 'avail', 'translat', 'model', '(', 'bleu', '38.41', 'versus', '34.92', 'japanes', '↔', 'english', 'bleu', '41.36', 'versus', '36.91', 'english', '↔', 'german', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 29



 ---- LEMMATIZATION ----

['Abbelfish', '’', 'custom', 'topology', 'provides', 'significantly', 'accurate', 'translation', 'commercially', 'available', 'translation', 'model', '(', 'BLEU', '38.41', 'versus', '34.92', 'Japanese', '↔', 'English', 'BLEU', '41.36', 'versus', '36.91', 'English', '↔', 'German', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 29

************************************************************************************************************************

29 --> AbbVie Search AbbVie Search is a question/answer-based search tool for  biomedical research. 


 ---- TOKENS ----

 ['AbbVie', 'Search', 'AbbVie', 'Search', 'is', 'a', 'question/answer-based', 'search', 'tool', 'for', 'biomedical', 'research', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('question/answer-based', 'JJ'), ('search', 'NN'), ('tool', 'NN'), ('for', 'IN'), ('biomedical', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'Search', 'AbbVie', 'Search', 'question/answer-based', 'search', 'tool', 'biomedical', 'research', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('question/answer-based', 'JJ'), ('search', 'NN'), ('tool', 'NN'), ('biomedical', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie Search', 'Search AbbVie', 'AbbVie Search', 'Search question/answer-based', 'question/answer-based search', 'search tool', 'tool biomedical', 'biomedical research', 'research .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['AbbVie Search AbbVie', 'Search AbbVie Search', 'AbbVie Search question/answer-based', 'Search question/answer-based search', 'question/answer-based search tool', 'search tool biomedical', 'tool biomedical research', 'biomedical research .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['question search', 'tool', 'biomedical research'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Search AbbVie Search']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'search', 'abbvi', 'search', 'question/answer-bas', 'search', 'tool', 'biomed', 'research', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['abbvi', 'search', 'abbvi', 'search', 'question/answer-bas', 'search', 'tool', 'biomed', 'research', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['AbbVie', 'Search', 'AbbVie', 'Search', 'question/answer-based', 'search', 'tool', 'biomedical', 'research', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

30 --> It is based on the BioBERT transformer  model (Lee et al., 2020). 


 ---- TOKENS ----

 ['It', 'is', 'based', 'on', 'the', 'BioBERT', 'transformer', 'model', '(', 'Lee', 'et', 'al.', ',', '2020', ')', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('It', 'PRP'), ('is', 'VBZ'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('BioBERT', 'NNP'), ('transformer', 'NN'), ('model', 'NN'), ('(', '('), ('Lee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2020', 'CD'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['based', 'BioBERT', 'transformer', 'model', '(', 'Lee', 'et', 'al.', ',', '2020', ')', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('based', 'VBN'), ('BioBERT', 'NNP'), ('transformer', 'JJ'), ('model', 'NN'), ('(', '('), ('Lee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2020', 'CD'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['based BioBERT', 'BioBERT transformer', 'transformer model', 'model (', '( Lee', 'Lee et', 'et al.', 'al. ,', ', 2020', '2020 )', ') .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['based BioBERT transformer', 'BioBERT transformer model', 'transformer model (', 'model ( Lee', '( Lee et', 'Lee et al.', 'et al. ,', 'al. , 2020', ', 2020 )', '2020 ) .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['transformer model'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['BioBERT']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['base', 'biobert', 'transform', 'model', '(', 'lee', 'et', 'al.', ',', '2020', ')', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['base', 'biobert', 'transform', 'model', '(', 'lee', 'et', 'al.', ',', '2020', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['based', 'BioBERT', 'transformer', 'model', '(', 'Lee', 'et', 'al.', ',', '2020', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

31 --> BioBERT starts with a base BERT  model that has been fine-tuned on the SQuAD 1.1 dataset  (Figure 1). 


 ---- TOKENS ----

 ['BioBERT', 'starts', 'with', 'a', 'base', 'BERT', 'model', 'that', 'has', 'been', 'fine-tuned', 'on', 'the', 'SQuAD', '1.1', 'dataset', '(', 'Figure', '1', ')', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('BioBERT', 'NNP'), ('starts', 'VBZ'), ('with', 'IN'), ('a', 'DT'), ('base', 'NN'), ('BERT', 'NNP'), ('model', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('been', 'VBN'), ('fine-tuned', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('SQuAD', 'NNP'), ('1.1', 'CD'), ('dataset', 'NN'), ('(', '('), ('Figure', 'NNP'), ('1', 'CD'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['BioBERT', 'starts', 'base', 'BERT', 'model', 'fine-tuned', 'SQuAD', '1.1', 'dataset', '(', 'Figure', '1', ')', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('BioBERT', 'NNP'), ('starts', 'VBZ'), ('base', 'NN'), ('BERT', 'NNP'), ('model', 'NN'), ('fine-tuned', 'JJ'), ('SQuAD', 'NNP'), ('1.1', 'CD'), ('dataset', 'NN'), ('(', '('), ('Figure', 'NNP'), ('1', 'CD'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['BioBERT starts', 'starts base', 'base BERT', 'BERT model', 'model fine-tuned', 'fine-tuned SQuAD', 'SQuAD 1.1', '1.1 dataset', 'dataset (', '( Figure', 'Figure 1', '1 )', ') .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['BioBERT starts base', 'starts base BERT', 'base BERT model', 'BERT model fine-tuned', 'model fine-tuned SQuAD', 'fine-tuned SQuAD 1.1', 'SQuAD 1.1 dataset', '1.1 dataset (', 'dataset ( Figure', '( Figure 1', 'Figure 1 )', '1 ) .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['base', 'model', 'dataset'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['BioBERT', 'BERT']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['biobert', 'start', 'base', 'bert', 'model', 'fine-tun', 'squad', '1.1', 'dataset', '(', 'figur', '1', ')', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['biobert', 'start', 'base', 'bert', 'model', 'fine-tun', 'squad', '1.1', 'dataset', '(', 'figur', '1', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['BioBERT', 'start', 'base', 'BERT', 'model', 'fine-tuned', 'SQuAD', '1.1', 'dataset', '(', 'Figure', '1', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

32 --> It further refines the question/answer model by fine- tuning on AbbVie’s internal datasets and the BioASQ 6b and  7b datasets, which are an open-source collection of semantic  indexing and question/answer texts based on biomedical  research articles (Tsatsaronis et al., 2015). 


 ---- TOKENS ----

 ['It', 'further', 'refines', 'the', 'question/answer', 'model', 'by', 'fine-', 'tuning', 'on', 'AbbVie', '’', 's', 'internal', 'datasets', 'and', 'the', 'BioASQ', '6b', 'and', '7b', 'datasets', ',', 'which', 'are', 'an', 'open-source', 'collection', 'of', 'semantic', 'indexing', 'and', 'question/answer', 'texts', 'based', 'on', 'biomedical', 'research', 'articles', '(', 'Tsatsaronis', 'et', 'al.', ',', '2015', ')', '.'] 

 TOTAL TOKENS ==> 47

 ---- POST ----

 [('It', 'PRP'), ('further', 'RBR'), ('refines', 'VBZ'), ('the', 'DT'), ('question/answer', 'JJR'), ('model', 'NN'), ('by', 'IN'), ('fine-', 'JJ'), ('tuning', 'NN'), ('on', 'IN'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('internal', 'JJ'), ('datasets', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('BioASQ', 'NNP'), ('6b', 'CD'), ('and', 'CC'), ('7b', 'CD'), ('datasets', 'NNS'), (',', ','), ('which', 'WDT'), ('are', 'VBP'), ('an', 'DT'), ('open-source', 'JJ'), ('collection', 'NN'), ('of', 'IN'), ('semantic', 'JJ'), ('indexing', 'NN'), ('and', 'CC'), ('question/answer', 'JJR'), ('texts', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('biomedical', 'JJ'), ('research', 'NN'), ('articles', 'NNS'), ('(', '('), ('Tsatsaronis', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['refines', 'question/answer', 'model', 'fine-', 'tuning', 'AbbVie', '’', 'internal', 'datasets', 'BioASQ', '6b', '7b', 'datasets', ',', 'open-source', 'collection', 'semantic', 'indexing', 'question/answer', 'texts', 'based', 'biomedical', 'research', 'articles', '(', 'Tsatsaronis', 'et', 'al.', ',', '2015', ')', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('refines', 'NNS'), ('question/answer', 'JJR'), ('model', 'NN'), ('fine-', 'JJ'), ('tuning', 'VBG'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('internal', 'JJ'), ('datasets', 'NNS'), ('BioASQ', 'NNP'), ('6b', 'CD'), ('7b', 'CD'), ('datasets', 'NNS'), (',', ','), ('open-source', 'JJ'), ('collection', 'NN'), ('semantic', 'JJ'), ('indexing', 'VBG'), ('question/answer', 'JJR'), ('texts', 'NNS'), ('based', 'VBN'), ('biomedical', 'JJ'), ('research', 'NN'), ('articles', 'NNS'), ('(', '('), ('Tsatsaronis', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['refines question/answer', 'question/answer model', 'model fine-', 'fine- tuning', 'tuning AbbVie', 'AbbVie ’', '’ internal', 'internal datasets', 'datasets BioASQ', 'BioASQ 6b', '6b 7b', '7b datasets', 'datasets ,', ', open-source', 'open-source collection', 'collection semantic', 'semantic indexing', 'indexing question/answer', 'question/answer texts', 'texts based', 'based biomedical', 'biomedical research', 'research articles', 'articles (', '( Tsatsaronis', 'Tsatsaronis et', 'et al.', 'al. ,', ', 2015', '2015 )', ') .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['refines question/answer model', 'question/answer model fine-', 'model fine- tuning', 'fine- tuning AbbVie', 'tuning AbbVie ’', 'AbbVie ’ internal', '’ internal datasets', 'internal datasets BioASQ', 'datasets BioASQ 6b', 'BioASQ 6b 7b', '6b 7b datasets', '7b datasets ,', 'datasets , open-source', ', open-source collection', 'open-source collection semantic', 'collection semantic indexing', 'semantic indexing question/answer', 'indexing question/answer texts', 'question/answer texts based', 'texts based biomedical', 'based biomedical research', 'biomedical research articles', 'research articles (', 'articles ( Tsatsaronis', '( Tsatsaronis et', 'Tsatsaronis et al.', 'et al. ,', 'al. , 2015', ', 2015 )', '2015 ) .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['model', 'open-source collection', 'biomedical research'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'BioASQ']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['refin', 'question/answ', 'model', 'fine-', 'tune', 'abbvi', '’', 'intern', 'dataset', 'bioasq', '6b', '7b', 'dataset', ',', 'open-sourc', 'collect', 'semant', 'index', 'question/answ', 'text', 'base', 'biomed', 'research', 'articl', '(', 'tsatsaroni', 'et', 'al.', ',', '2015', ')', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['refin', 'question/answ', 'model', 'fine-', 'tune', 'abbvi', '’', 'intern', 'dataset', 'bioasq', '6b', '7b', 'dataset', ',', 'open-sourc', 'collect', 'semant', 'index', 'question/answ', 'text', 'base', 'biomed', 'research', 'articl', '(', 'tsatsaroni', 'et', 'al.', ',', '2015', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['refines', 'question/answer', 'model', 'fine-', 'tuning', 'AbbVie', '’', 'internal', 'datasets', 'BioASQ', '6b', '7b', 'datasets', ',', 'open-source', 'collection', 'semantic', 'indexing', 'question/answer', 'text', 'based', 'biomedical', 'research', 'article', '(', 'Tsatsaronis', 'et', 'al.', ',', '2015', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

33 --> Figure 2 shows an example of how the question/answer  model works. 


 ---- TOKENS ----

 ['Figure', '2', 'shows', 'an', 'example', 'of', 'how', 'the', 'question/answer', 'model', 'works', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('Figure', 'NN'), ('2', 'CD'), ('shows', 'VBZ'), ('an', 'DT'), ('example', 'NN'), ('of', 'IN'), ('how', 'WRB'), ('the', 'DT'), ('question/answer', 'JJR'), ('model', 'NN'), ('works', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Figure', '2', 'shows', 'example', 'question/answer', 'model', 'works', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Figure', 'NN'), ('2', 'CD'), ('shows', 'VBZ'), ('example', 'NN'), ('question/answer', 'JJR'), ('model', 'NN'), ('works', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Figure 2', '2 shows', 'shows example', 'example question/answer', 'question/answer model', 'model works', 'works .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Figure 2 shows', '2 shows example', 'shows example question/answer', 'example question/answer model', 'question/answer model works', 'model works .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['Figure', 'example', 'model'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['figur', '2', 'show', 'exampl', 'question/answ', 'model', 'work', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['figur', '2', 'show', 'exampl', 'question/answ', 'model', 'work', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Figure', '2', 'show', 'example', 'question/answer', 'model', 'work', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

34 --> When AbbVie researchers submit a question to  AbbVie Search, both this question and a collection of research  articles/clinical notes (also known as context) are fed into  the transformer-based model. 


 ---- TOKENS ----

 ['When', 'AbbVie', 'researchers', 'submit', 'a', 'question', 'to', 'AbbVie', 'Search', ',', 'both', 'this', 'question', 'and', 'a', 'collection', 'of', 'research', 'articles/clinical', 'notes', '(', 'also', 'known', 'as', 'context', ')', 'are', 'fed', 'into', 'the', 'transformer-based', 'model', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('When', 'WRB'), ('AbbVie', 'NNP'), ('researchers', 'NNS'), ('submit', 'VBP'), ('a', 'DT'), ('question', 'NN'), ('to', 'TO'), ('AbbVie', 'NNP'), ('Search', 'NNP'), (',', ','), ('both', 'DT'), ('this', 'DT'), ('question', 'NN'), ('and', 'CC'), ('a', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('research', 'NN'), ('articles/clinical', 'JJ'), ('notes', 'NNS'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('as', 'IN'), ('context', 'NN'), (')', ')'), ('are', 'VBP'), ('fed', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('transformer-based', 'JJ'), ('model', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'researchers', 'submit', 'question', 'AbbVie', 'Search', ',', 'question', 'collection', 'research', 'articles/clinical', 'notes', '(', 'also', 'known', 'context', ')', 'fed', 'transformer-based', 'model', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('researchers', 'NNS'), ('submit', 'VBP'), ('question', 'NN'), ('AbbVie', 'NNP'), ('Search', 'NNP'), (',', ','), ('question', 'NN'), ('collection', 'NN'), ('research', 'NN'), ('articles/clinical', 'JJ'), ('notes', 'NNS'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('context', 'NN'), (')', ')'), ('fed', 'VBD'), ('transformer-based', 'JJ'), ('model', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie researchers', 'researchers submit', 'submit question', 'question AbbVie', 'AbbVie Search', 'Search ,', ', question', 'question collection', 'collection research', 'research articles/clinical', 'articles/clinical notes', 'notes (', '( also', 'also known', 'known context', 'context )', ') fed', 'fed transformer-based', 'transformer-based model', 'model .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['AbbVie researchers submit', 'researchers submit question', 'submit question AbbVie', 'question AbbVie Search', 'AbbVie Search ,', 'Search , question', ', question collection', 'question collection research', 'collection research articles/clinical', 'research articles/clinical notes', 'articles/clinical notes (', 'notes ( also', '( also known', 'also known context', 'known context )', 'context ) fed', ') fed transformer-based', 'fed transformer-based model', 'transformer-based model .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['question', 'question', 'collection', 'research', 'transformer-based model'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie Search']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['AbbVie']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'research', 'submit', 'question', 'abbvi', 'search', ',', 'question', 'collect', 'research', 'articles/clin', 'note', '(', 'also', 'known', 'context', ')', 'fed', 'transformer-bas', 'model', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['abbvi', 'research', 'submit', 'question', 'abbvi', 'search', ',', 'question', 'collect', 'research', 'articles/clin', 'note', '(', 'also', 'known', 'context', ')', 'fed', 'transformer-bas', 'model', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['AbbVie', 'researcher', 'submit', 'question', 'AbbVie', 'Search', ',', 'question', 'collection', 'research', 'articles/clinical', 'note', '(', 'also', 'known', 'context', ')', 'fed', 'transformer-based', 'model', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

35 --> The model predicts the most  likely character position in the context where the answer can  be found (highlighted section of the context). 


 ---- TOKENS ----

 ['The', 'model', 'predicts', 'the', 'most', 'likely', 'character', 'position', 'in', 'the', 'context', 'where', 'the', 'answer', 'can', 'be', 'found', '(', 'highlighted', 'section', 'of', 'the', 'context', ')', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('The', 'DT'), ('model', 'NN'), ('predicts', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('likely', 'JJ'), ('character', 'NN'), ('position', 'NN'), ('in', 'IN'), ('the', 'DT'), ('context', 'NN'), ('where', 'WRB'), ('the', 'DT'), ('answer', 'NN'), ('can', 'MD'), ('be', 'VB'), ('found', 'VBN'), ('(', '('), ('highlighted', 'JJ'), ('section', 'NN'), ('of', 'IN'), ('the', 'DT'), ('context', 'NN'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['model', 'predicts', 'likely', 'character', 'position', 'context', 'answer', 'found', '(', 'highlighted', 'section', 'context', ')', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('model', 'NN'), ('predicts', 'VBZ'), ('likely', 'JJ'), ('character', 'NN'), ('position', 'NN'), ('context', 'NN'), ('answer', 'NN'), ('found', 'VBD'), ('(', '('), ('highlighted', 'VBN'), ('section', 'NN'), ('context', 'NN'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['model predicts', 'predicts likely', 'likely character', 'character position', 'position context', 'context answer', 'answer found', 'found (', '( highlighted', 'highlighted section', 'section context', 'context )', ') .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['model predicts likely', 'predicts likely character', 'likely character position', 'character position context', 'position context answer', 'context answer found', 'answer found (', 'found ( highlighted', '( highlighted section', 'highlighted section context', 'section context )', 'context ) .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['model', 'likely character', 'position', 'context', 'answer'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['model', 'predict', 'like', 'charact', 'posit', 'context', 'answer', 'found', '(', 'highlight', 'section', 'context', ')', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['model', 'predict', 'like', 'charact', 'posit', 'context', 'answer', 'found', '(', 'highlight', 'section', 'context', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['model', 'predicts', 'likely', 'character', 'position', 'context', 'answer', 'found', '(', 'highlighted', 'section', 'context', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

36 --> One benefit of  this approach is that the model is only able to create answers  based on the context. 


 ---- TOKENS ----

 ['One', 'benefit', 'of', 'this', 'approach', 'is', 'that', 'the', 'model', 'is', 'only', 'able', 'to', 'create', 'answers', 'based', 'on', 'the', 'context', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('One', 'CD'), ('benefit', 'NN'), ('of', 'IN'), ('this', 'DT'), ('approach', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('only', 'RB'), ('able', 'JJ'), ('to', 'TO'), ('create', 'VB'), ('answers', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('context', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['One', 'benefit', 'approach', 'model', 'able', 'create', 'answers', 'based', 'context', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('One', 'CD'), ('benefit', 'NN'), ('approach', 'NN'), ('model', 'NN'), ('able', 'JJ'), ('create', 'NN'), ('answers', 'NNS'), ('based', 'VBN'), ('context', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['One benefit', 'benefit approach', 'approach model', 'model able', 'able create', 'create answers', 'answers based', 'based context', 'context .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['One benefit approach', 'benefit approach model', 'approach model able', 'model able create', 'able create answers', 'create answers based', 'answers based context', 'based context .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['benefit', 'approach', 'model', 'able create', 'context'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['one', 'benefit', 'approach', 'model', 'abl', 'creat', 'answer', 'base', 'context', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['one', 'benefit', 'approach', 'model', 'abl', 'creat', 'answer', 'base', 'context', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['One', 'benefit', 'approach', 'model', 'able', 'create', 'answer', 'based', 'context', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

37 --> Therefore, the answers AbbVie Search  returns are immediately verifiable by a quick scan of the  original scientific article. 


 ---- TOKENS ----

 ['Therefore', ',', 'the', 'answers', 'AbbVie', 'Search', 'returns', 'are', 'immediately', 'verifiable', 'by', 'a', 'quick', 'scan', 'of', 'the', 'original', 'scientific', 'article', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('Therefore', 'RB'), (',', ','), ('the', 'DT'), ('answers', 'NNS'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('returns', 'NNS'), ('are', 'VBP'), ('immediately', 'RB'), ('verifiable', 'JJ'), ('by', 'IN'), ('a', 'DT'), ('quick', 'JJ'), ('scan', 'NN'), ('of', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('scientific', 'JJ'), ('article', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Therefore', ',', 'answers', 'AbbVie', 'Search', 'returns', 'immediately', 'verifiable', 'quick', 'scan', 'original', 'scientific', 'article', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('Therefore', 'RB'), (',', ','), ('answers', 'NNS'), ('AbbVie', 'VBP'), ('Search', 'NNP'), ('returns', 'NNS'), ('immediately', 'RB'), ('verifiable', 'JJ'), ('quick', 'JJ'), ('scan', 'JJ'), ('original', 'JJ'), ('scientific', 'JJ'), ('article', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Therefore ,', ', answers', 'answers AbbVie', 'AbbVie Search', 'Search returns', 'returns immediately', 'immediately verifiable', 'verifiable quick', 'quick scan', 'scan original', 'original scientific', 'scientific article', 'article .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['Therefore , answers', ', answers AbbVie', 'answers AbbVie Search', 'AbbVie Search returns', 'Search returns immediately', 'returns immediately verifiable', 'immediately verifiable quick', 'verifiable quick scan', 'quick scan original', 'scan original scientific', 'original scientific article', 'scientific article .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['verifiable quick scan original scientific article'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Search']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['therefor', ',', 'answer', 'abbvi', 'search', 'return', 'immedi', 'verifi', 'quick', 'scan', 'origin', 'scientif', 'articl', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['therefor', ',', 'answer', 'abbvi', 'search', 'return', 'immedi', 'verifi', 'quick', 'scan', 'origin', 'scientif', 'articl', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['Therefore', ',', 'answer', 'AbbVie', 'Search', 'return', 'immediately', 'verifiable', 'quick', 'scan', 'original', 'scientific', 'article', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

38 --> Context  Symptom severity scores were quantified using the  following five measures: (i) individual symptom score for  20 symptoms, (ii) the upper respiratory symptom score,  calculated as the sum of severity scores for earache, runny  nose, sore throat, and sneezing, (iii) the lower respiratory  symptom score, calculated as the sum of severity scores  for cough, difficulty breathing, hoarseness, and chest  discomfort, (iv) the gastrointestinal symptom score,  calculated as the sum of severity scores for diarrhea,  vomiting, anorexia, nausea, and (Table 1) . 


 ---- TOKENS ----

 ['Context', 'Symptom', 'severity', 'scores', 'were', 'quantified', 'using', 'the', 'following', 'five', 'measures', ':', '(', 'i', ')', 'individual', 'symptom', 'score', 'for', '20', 'symptoms', ',', '(', 'ii', ')', 'the', 'upper', 'respiratory', 'symptom', 'score', ',', 'calculated', 'as', 'the', 'sum', 'of', 'severity', 'scores', 'for', 'earache', ',', 'runny', 'nose', ',', 'sore', 'throat', ',', 'and', 'sneezing', ',', '(', 'iii', ')', 'the', 'lower', 'respiratory', 'symptom', 'score', ',', 'calculated', 'as', 'the', 'sum', 'of', 'severity', 'scores', 'for', 'cough', ',', 'difficulty', 'breathing', ',', 'hoarseness', ',', 'and', 'chest', 'discomfort', ',', '(', 'iv', ')', 'the', 'gastrointestinal', 'symptom', 'score', ',', 'calculated', 'as', 'the', 'sum', 'of', 'severity', 'scores', 'for', 'diarrhea', ',', 'vomiting', ',', 'anorexia', ',', 'nausea', ',', 'and', '(', 'Table', '1', ')', '.'] 

 TOTAL TOKENS ==> 108

 ---- POST ----

 [('Context', 'NNP'), ('Symptom', 'NNP'), ('severity', 'NN'), ('scores', 'NNS'), ('were', 'VBD'), ('quantified', 'VBN'), ('using', 'VBG'), ('the', 'DT'), ('following', 'JJ'), ('five', 'CD'), ('measures', 'NNS'), (':', ':'), ('(', '('), ('i', 'NN'), (')', ')'), ('individual', 'JJ'), ('symptom', 'NN'), ('score', 'NN'), ('for', 'IN'), ('20', 'CD'), ('symptoms', 'NNS'), (',', ','), ('(', '('), ('ii', 'NN'), (')', ')'), ('the', 'DT'), ('upper', 'JJ'), ('respiratory', 'NN'), ('symptom', 'NN'), ('score', 'NN'), (',', ','), ('calculated', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('sum', 'NN'), ('of', 'IN'), ('severity', 'NN'), ('scores', 'NNS'), ('for', 'IN'), ('earache', 'NN'), (',', ','), ('runny', 'NN'), ('nose', 'RB'), (',', ','), ('sore', 'JJR'), ('throat', 'NN'), (',', ','), ('and', 'CC'), ('sneezing', 'NN'), (',', ','), ('(', '('), ('iii', 'NN'), (')', ')'), ('the', 'DT'), ('lower', 'JJR'), ('respiratory', 'NN'), ('symptom', 'NN'), ('score', 'NN'), (',', ','), ('calculated', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('sum', 'NN'), ('of', 'IN'), ('severity', 'NN'), ('scores', 'NNS'), ('for', 'IN'), ('cough', 'NN'), (',', ','), ('difficulty', 'NN'), ('breathing', 'NN'), (',', ','), ('hoarseness', 'NN'), (',', ','), ('and', 'CC'), ('chest', 'JJS'), ('discomfort', 'NN'), (',', ','), ('(', '('), ('iv', 'NN'), (')', ')'), ('the', 'DT'), ('gastrointestinal', 'JJ'), ('symptom', 'NN'), ('score', 'NN'), (',', ','), ('calculated', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('sum', 'NN'), ('of', 'IN'), ('severity', 'NN'), ('scores', 'NNS'), ('for', 'IN'), ('diarrhea', 'NN'), (',', ','), ('vomiting', 'VBG'), (',', ','), ('anorexia', 'NN'), (',', ','), ('nausea', 'NN'), (',', ','), ('and', 'CC'), ('(', '('), ('Table', 'NNP'), ('1', 'CD'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Context', 'Symptom', 'severity', 'scores', 'quantified', 'using', 'following', 'five', 'measures', ':', '(', ')', 'individual', 'symptom', 'score', '20', 'symptoms', ',', '(', 'ii', ')', 'upper', 'respiratory', 'symptom', 'score', ',', 'calculated', 'sum', 'severity', 'scores', 'earache', ',', 'runny', 'nose', ',', 'sore', 'throat', ',', 'sneezing', ',', '(', 'iii', ')', 'lower', 'respiratory', 'symptom', 'score', ',', 'calculated', 'sum', 'severity', 'scores', 'cough', ',', 'difficulty', 'breathing', ',', 'hoarseness', ',', 'chest', 'discomfort', ',', '(', 'iv', ')', 'gastrointestinal', 'symptom', 'score', ',', 'calculated', 'sum', 'severity', 'scores', 'diarrhea', ',', 'vomiting', ',', 'anorexia', ',', 'nausea', ',', '(', 'Table', '1', ')', '.']

 TOTAL FILTERED TOKENS ==>  86

 ---- POST FOR FILTERED TOKENS ----

 [('Context', 'NNP'), ('Symptom', 'NNP'), ('severity', 'NN'), ('scores', 'NNS'), ('quantified', 'VBD'), ('using', 'VBG'), ('following', 'VBG'), ('five', 'CD'), ('measures', 'NNS'), (':', ':'), ('(', '('), (')', ')'), ('individual', 'NN'), ('symptom', 'VBD'), ('score', 'RB'), ('20', 'CD'), ('symptoms', 'NNS'), (',', ','), ('(', '('), ('ii', 'NN'), (')', ')'), ('upper', 'IN'), ('respiratory', 'NN'), ('symptom', 'NN'), ('score', 'NN'), (',', ','), ('calculated', 'VBD'), ('sum', 'JJ'), ('severity', 'NN'), ('scores', 'NNS'), ('earache', 'VBP'), (',', ','), ('runny', 'VBP'), ('nose', 'RB'), (',', ','), ('sore', 'JJR'), ('throat', 'NN'), (',', ','), ('sneezing', 'NN'), (',', ','), ('(', '('), ('iii', 'NN'), (')', ')'), ('lower', 'JJR'), ('respiratory', 'NN'), ('symptom', 'NN'), ('score', 'NN'), (',', ','), ('calculated', 'VBD'), ('sum', 'JJ'), ('severity', 'NN'), ('scores', 'NNS'), ('cough', 'VBP'), (',', ','), ('difficulty', 'NN'), ('breathing', 'NN'), (',', ','), ('hoarseness', 'NN'), (',', ','), ('chest', 'NN'), ('discomfort', 'NN'), (',', ','), ('(', '('), ('iv', 'NN'), (')', ')'), ('gastrointestinal', 'JJ'), ('symptom', 'NN'), ('score', 'NN'), (',', ','), ('calculated', 'VBD'), ('sum', 'JJ'), ('severity', 'NN'), ('scores', 'NNS'), ('diarrhea', 'VBP'), (',', ','), ('vomiting', 'VBG'), (',', ','), ('anorexia', 'NN'), (',', ','), ('nausea', 'NN'), (',', ','), ('(', '('), ('Table', 'JJ'), ('1', 'CD'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Context Symptom', 'Symptom severity', 'severity scores', 'scores quantified', 'quantified using', 'using following', 'following five', 'five measures', 'measures :', ': (', '( )', ') individual', 'individual symptom', 'symptom score', 'score 20', '20 symptoms', 'symptoms ,', ', (', '( ii', 'ii )', ') upper', 'upper respiratory', 'respiratory symptom', 'symptom score', 'score ,', ', calculated', 'calculated sum', 'sum severity', 'severity scores', 'scores earache', 'earache ,', ', runny', 'runny nose', 'nose ,', ', sore', 'sore throat', 'throat ,', ', sneezing', 'sneezing ,', ', (', '( iii', 'iii )', ') lower', 'lower respiratory', 'respiratory symptom', 'symptom score', 'score ,', ', calculated', 'calculated sum', 'sum severity', 'severity scores', 'scores cough', 'cough ,', ', difficulty', 'difficulty breathing', 'breathing ,', ', hoarseness', 'hoarseness ,', ', chest', 'chest discomfort', 'discomfort ,', ', (', '( iv', 'iv )', ') gastrointestinal', 'gastrointestinal symptom', 'symptom score', 'score ,', ', calculated', 'calculated sum', 'sum severity', 'severity scores', 'scores diarrhea', 'diarrhea ,', ', vomiting', 'vomiting ,', ', anorexia', 'anorexia ,', ', nausea', 'nausea ,', ', (', '( Table', 'Table 1', '1 )', ') .'] 

 TOTAL BIGRAMS --> 85 



 ---- TRI-GRAMS ---- 

 ['Context Symptom severity', 'Symptom severity scores', 'severity scores quantified', 'scores quantified using', 'quantified using following', 'using following five', 'following five measures', 'five measures :', 'measures : (', ': ( )', '( ) individual', ') individual symptom', 'individual symptom score', 'symptom score 20', 'score 20 symptoms', '20 symptoms ,', 'symptoms , (', ', ( ii', '( ii )', 'ii ) upper', ') upper respiratory', 'upper respiratory symptom', 'respiratory symptom score', 'symptom score ,', 'score , calculated', ', calculated sum', 'calculated sum severity', 'sum severity scores', 'severity scores earache', 'scores earache ,', 'earache , runny', ', runny nose', 'runny nose ,', 'nose , sore', ', sore throat', 'sore throat ,', 'throat , sneezing', ', sneezing ,', 'sneezing , (', ', ( iii', '( iii )', 'iii ) lower', ') lower respiratory', 'lower respiratory symptom', 'respiratory symptom score', 'symptom score ,', 'score , calculated', ', calculated sum', 'calculated sum severity', 'sum severity scores', 'severity scores cough', 'scores cough ,', 'cough , difficulty', ', difficulty breathing', 'difficulty breathing ,', 'breathing , hoarseness', ', hoarseness ,', 'hoarseness , chest', ', chest discomfort', 'chest discomfort ,', 'discomfort , (', ', ( iv', '( iv )', 'iv ) gastrointestinal', ') gastrointestinal symptom', 'gastrointestinal symptom score', 'symptom score ,', 'score , calculated', ', calculated sum', 'calculated sum severity', 'sum severity scores', 'severity scores diarrhea', 'scores diarrhea ,', 'diarrhea , vomiting', ', vomiting ,', 'vomiting , anorexia', ', anorexia ,', 'anorexia , nausea', ', nausea ,', 'nausea , (', ', ( Table', '( Table 1', 'Table 1 )', '1 ) .'] 

 TOTAL TRIGRAMS --> 84 



 ---- NOUN PHRASES ---- 

 ['severity', 'individual', 'respiratory', 'symptom', 'score', 'sum severity', 'throat', 'sneezing', 'respiratory', 'symptom', 'score', 'sum severity', 'difficulty', 'breathing', 'hoarseness', 'chest', 'discomfort', 'gastrointestinal symptom', 'score', 'sum severity', 'anorexia', 'nausea'] 

 TOTAL NOUN PHRASES --> 22 



 ---- NER ----

 
 ORGANIZATION ---> ['Symptom']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Context']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['context', 'symptom', 'sever', 'score', 'quantifi', 'use', 'follow', 'five', 'measur', ':', '(', ')', 'individu', 'symptom', 'score', '20', 'symptom', ',', '(', 'ii', ')', 'upper', 'respiratori', 'symptom', 'score', ',', 'calcul', 'sum', 'sever', 'score', 'earach', ',', 'runni', 'nose', ',', 'sore', 'throat', ',', 'sneez', ',', '(', 'iii', ')', 'lower', 'respiratori', 'symptom', 'score', ',', 'calcul', 'sum', 'sever', 'score', 'cough', ',', 'difficulti', 'breath', ',', 'hoars', ',', 'chest', 'discomfort', ',', '(', 'iv', ')', 'gastrointestin', 'symptom', 'score', ',', 'calcul', 'sum', 'sever', 'score', 'diarrhea', ',', 'vomit', ',', 'anorexia', ',', 'nausea', ',', '(', 'tabl', '1', ')', '.']

 TOTAL PORTER STEM WORDS ==> 86



 ---- SNOWBALL STEMMING ----

['context', 'symptom', 'sever', 'score', 'quantifi', 'use', 'follow', 'five', 'measur', ':', '(', ')', 'individu', 'symptom', 'score', '20', 'symptom', ',', '(', 'ii', ')', 'upper', 'respiratori', 'symptom', 'score', ',', 'calcul', 'sum', 'sever', 'score', 'earach', ',', 'runni', 'nose', ',', 'sore', 'throat', ',', 'sneez', ',', '(', 'iii', ')', 'lower', 'respiratori', 'symptom', 'score', ',', 'calcul', 'sum', 'sever', 'score', 'cough', ',', 'difficulti', 'breath', ',', 'hoars', ',', 'chest', 'discomfort', ',', '(', 'iv', ')', 'gastrointestin', 'symptom', 'score', ',', 'calcul', 'sum', 'sever', 'score', 'diarrhea', ',', 'vomit', ',', 'anorexia', ',', 'nausea', ',', '(', 'tabl', '1', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 86



 ---- LEMMATIZATION ----

['Context', 'Symptom', 'severity', 'score', 'quantified', 'using', 'following', 'five', 'measure', ':', '(', ')', 'individual', 'symptom', 'score', '20', 'symptom', ',', '(', 'ii', ')', 'upper', 'respiratory', 'symptom', 'score', ',', 'calculated', 'sum', 'severity', 'score', 'earache', ',', 'runny', 'nose', ',', 'sore', 'throat', ',', 'sneezing', ',', '(', 'iii', ')', 'lower', 'respiratory', 'symptom', 'score', ',', 'calculated', 'sum', 'severity', 'score', 'cough', ',', 'difficulty', 'breathing', ',', 'hoarseness', ',', 'chest', 'discomfort', ',', '(', 'iv', ')', 'gastrointestinal', 'symptom', 'score', ',', 'calculated', 'sum', 'severity', 'score', 'diarrhea', ',', 'vomiting', ',', 'anorexia', ',', 'nausea', ',', '(', 'Table', '1', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 86

************************************************************************************************************************

39 --> There was  season-to-season variability in the leading causes of …  The findings of our study, conducted over a five-year  period at five geographically dispersed sites in the  USA, demonstrate that human coronavirus (HCoV) is an  important cause of influenza-like illness (ILI) ranged from  4% to 22%. 


 ---- TOKENS ----

 ['There', 'was', 'season-to-season', 'variability', 'in', 'the', 'leading', 'causes', 'of', '…', 'The', 'findings', 'of', 'our', 'study', ',', 'conducted', 'over', 'a', 'five-year', 'period', 'at', 'five', 'geographically', 'dispersed', 'sites', 'in', 'the', 'USA', ',', 'demonstrate', 'that', 'human', 'coronavirus', '(', 'HCoV', ')', 'is', 'an', 'important', 'cause', 'of', 'influenza-like', 'illness', '(', 'ILI', ')', 'ranged', 'from', '4', '%', 'to', '22', '%', '.'] 

 TOTAL TOKENS ==> 55

 ---- POST ----

 [('There', 'EX'), ('was', 'VBD'), ('season-to-season', 'JJ'), ('variability', 'NN'), ('in', 'IN'), ('the', 'DT'), ('leading', 'JJ'), ('causes', 'NNS'), ('of', 'IN'), ('…', 'NNP'), ('The', 'DT'), ('findings', 'NNS'), ('of', 'IN'), ('our', 'PRP$'), ('study', 'NN'), (',', ','), ('conducted', 'VBN'), ('over', 'IN'), ('a', 'DT'), ('five-year', 'JJ'), ('period', 'NN'), ('at', 'IN'), ('five', 'CD'), ('geographically', 'RB'), ('dispersed', 'VBN'), ('sites', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('USA', 'NNP'), (',', ','), ('demonstrate', 'NN'), ('that', 'IN'), ('human', 'JJ'), ('coronavirus', 'NN'), ('(', '('), ('HCoV', 'NNP'), (')', ')'), ('is', 'VBZ'), ('an', 'DT'), ('important', 'JJ'), ('cause', 'NN'), ('of', 'IN'), ('influenza-like', 'JJ'), ('illness', 'NN'), ('(', '('), ('ILI', 'NNP'), (')', ')'), ('ranged', 'VBD'), ('from', 'IN'), ('4', 'CD'), ('%', 'NN'), ('to', 'TO'), ('22', 'CD'), ('%', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['season-to-season', 'variability', 'leading', 'causes', '…', 'findings', 'study', ',', 'conducted', 'five-year', 'period', 'five', 'geographically', 'dispersed', 'sites', 'USA', ',', 'demonstrate', 'human', 'coronavirus', '(', 'HCoV', ')', 'important', 'cause', 'influenza-like', 'illness', '(', 'ILI', ')', 'ranged', '4', '%', '22', '%', '.']

 TOTAL FILTERED TOKENS ==>  36

 ---- POST FOR FILTERED TOKENS ----

 [('season-to-season', 'JJ'), ('variability', 'NN'), ('leading', 'VBG'), ('causes', 'NNS'), ('…', 'JJ'), ('findings', 'NNS'), ('study', 'NN'), (',', ','), ('conducted', 'VBN'), ('five-year', 'JJ'), ('period', 'NN'), ('five', 'CD'), ('geographically', 'RB'), ('dispersed', 'VBN'), ('sites', 'NNS'), ('USA', 'NNP'), (',', ','), ('demonstrate', 'NN'), ('human', 'JJ'), ('coronavirus', 'NN'), ('(', '('), ('HCoV', 'NNP'), (')', ')'), ('important', 'JJ'), ('cause', 'NN'), ('influenza-like', 'JJ'), ('illness', 'NN'), ('(', '('), ('ILI', 'NNP'), (')', ')'), ('ranged', 'VBD'), ('4', 'CD'), ('%', 'NN'), ('22', 'CD'), ('%', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['season-to-season variability', 'variability leading', 'leading causes', 'causes …', '… findings', 'findings study', 'study ,', ', conducted', 'conducted five-year', 'five-year period', 'period five', 'five geographically', 'geographically dispersed', 'dispersed sites', 'sites USA', 'USA ,', ', demonstrate', 'demonstrate human', 'human coronavirus', 'coronavirus (', '( HCoV', 'HCoV )', ') important', 'important cause', 'cause influenza-like', 'influenza-like illness', 'illness (', '( ILI', 'ILI )', ') ranged', 'ranged 4', '4 %', '% 22', '22 %', '% .'] 

 TOTAL BIGRAMS --> 35 



 ---- TRI-GRAMS ---- 

 ['season-to-season variability leading', 'variability leading causes', 'leading causes …', 'causes … findings', '… findings study', 'findings study ,', 'study , conducted', ', conducted five-year', 'conducted five-year period', 'five-year period five', 'period five geographically', 'five geographically dispersed', 'geographically dispersed sites', 'dispersed sites USA', 'sites USA ,', 'USA , demonstrate', ', demonstrate human', 'demonstrate human coronavirus', 'human coronavirus (', 'coronavirus ( HCoV', '( HCoV )', 'HCoV ) important', ') important cause', 'important cause influenza-like', 'cause influenza-like illness', 'influenza-like illness (', 'illness ( ILI', '( ILI )', 'ILI ) ranged', ') ranged 4', 'ranged 4 %', '4 % 22', '% 22 %', '22 % .'] 

 TOTAL TRIGRAMS --> 34 



 ---- NOUN PHRASES ---- 

 ['season-to-season variability', 'study', 'five-year period', 'demonstrate', 'human coronavirus', 'important cause', 'influenza-like illness', '%', '%'] 

 TOTAL NOUN PHRASES --> 9 



 ---- NER ----

 
 ORGANIZATION ---> ['USA']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['season-to-season', 'variabl', 'lead', 'caus', '…', 'find', 'studi', ',', 'conduct', 'five-year', 'period', 'five', 'geograph', 'dispers', 'site', 'usa', ',', 'demonstr', 'human', 'coronaviru', '(', 'hcov', ')', 'import', 'caus', 'influenza-lik', 'ill', '(', 'ili', ')', 'rang', '4', '%', '22', '%', '.']

 TOTAL PORTER STEM WORDS ==> 36



 ---- SNOWBALL STEMMING ----

['season-to-season', 'variabl', 'lead', 'caus', '…', 'find', 'studi', ',', 'conduct', 'five-year', 'period', 'five', 'geograph', 'dispers', 'site', 'usa', ',', 'demonstr', 'human', 'coronavirus', '(', 'hcov', ')', 'import', 'caus', 'influenza-lik', 'ill', '(', 'ili', ')', 'rang', '4', '%', '22', '%', '.']

 TOTAL SNOWBALL STEM WORDS ==> 36



 ---- LEMMATIZATION ----

['season-to-season', 'variability', 'leading', 'cause', '…', 'finding', 'study', ',', 'conducted', 'five-year', 'period', 'five', 'geographically', 'dispersed', 'site', 'USA', ',', 'demonstrate', 'human', 'coronavirus', '(', 'HCoV', ')', 'important', 'cause', 'influenza-like', 'illness', '(', 'ILI', ')', 'ranged', '4', '%', '22', '%', '.']

 TOTAL LEMMATIZE WORDS ==> 36

************************************************************************************************************************

40 --> [8] [9] [10] [11] [14] Additionally, we found  HCoV-OC43 to be the most common species among  adults, as has been reported elsewhere. 


 ---- TOKENS ----

 ['[', '8', ']', '[', '9', ']', '[', '10', ']', '[', '11', ']', '[', '14', ']', 'Additionally', ',', 'we', 'found', 'HCoV-OC43', 'to', 'be', 'the', 'most', 'common', 'species', 'among', 'adults', ',', 'as', 'has', 'been', 'reported', 'elsewhere', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('[', 'RB'), ('8', 'CD'), (']', 'JJ'), ('[', '$'), ('9', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('10', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('11', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('14', 'CD'), (']', 'NNP'), ('Additionally', 'RB'), (',', ','), ('we', 'PRP'), ('found', 'VBD'), ('HCoV-OC43', 'NNP'), ('to', 'TO'), ('be', 'VB'), ('the', 'DT'), ('most', 'RBS'), ('common', 'JJ'), ('species', 'NNS'), ('among', 'IN'), ('adults', 'NNS'), (',', ','), ('as', 'IN'), ('has', 'VBZ'), ('been', 'VBN'), ('reported', 'VBN'), ('elsewhere', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['[', '8', ']', '[', '9', ']', '[', '10', ']', '[', '11', ']', '[', '14', ']', 'Additionally', ',', 'found', 'HCoV-OC43', 'common', 'species', 'among', 'adults', ',', 'reported', 'elsewhere', '.']

 TOTAL FILTERED TOKENS ==>  27

 ---- POST FOR FILTERED TOKENS ----

 [('[', 'RB'), ('8', 'CD'), (']', 'JJ'), ('[', '$'), ('9', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('10', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('11', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('14', 'CD'), (']', 'NNP'), ('Additionally', 'NNP'), (',', ','), ('found', 'VBD'), ('HCoV-OC43', 'NNP'), ('common', 'JJ'), ('species', 'NNS'), ('among', 'IN'), ('adults', 'NNS'), (',', ','), ('reported', 'VBD'), ('elsewhere', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['[ 8', '8 ]', '] [', '[ 9', '9 ]', '] [', '[ 10', '10 ]', '] [', '[ 11', '11 ]', '] [', '[ 14', '14 ]', '] Additionally', 'Additionally ,', ', found', 'found HCoV-OC43', 'HCoV-OC43 common', 'common species', 'species among', 'among adults', 'adults ,', ', reported', 'reported elsewhere', 'elsewhere .'] 

 TOTAL BIGRAMS --> 26 



 ---- TRI-GRAMS ---- 

 ['[ 8 ]', '8 ] [', '] [ 9', '[ 9 ]', '9 ] [', '] [ 10', '[ 10 ]', '10 ] [', '] [ 11', '[ 11 ]', '11 ] [', '] [ 14', '[ 14 ]', '14 ] Additionally', '] Additionally ,', 'Additionally , found', ', found HCoV-OC43', 'found HCoV-OC43 common', 'HCoV-OC43 common species', 'common species among', 'species among adults', 'among adults ,', 'adults , reported', ', reported elsewhere', 'reported elsewhere .'] 

 TOTAL TRIGRAMS --> 25 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['[', '8', ']', '[', '9', ']', '[', '10', ']', '[', '11', ']', '[', '14', ']', 'addit', ',', 'found', 'hcov-oc43', 'common', 'speci', 'among', 'adult', ',', 'report', 'elsewher', '.']

 TOTAL PORTER STEM WORDS ==> 27



 ---- SNOWBALL STEMMING ----

['[', '8', ']', '[', '9', ']', '[', '10', ']', '[', '11', ']', '[', '14', ']', 'addit', ',', 'found', 'hcov-oc43', 'common', 'speci', 'among', 'adult', ',', 'report', 'elsewher', '.']

 TOTAL SNOWBALL STEM WORDS ==> 27



 ---- LEMMATIZATION ----

['[', '8', ']', '[', '9', ']', '[', '10', ']', '[', '11', ']', '[', '14', ']', 'Additionally', ',', 'found', 'HCoV-OC43', 'common', 'specie', 'among', 'adult', ',', 'reported', 'elsewhere', '.']

 TOTAL LEMMATIZE WORDS ==> 27

************************************************************************************************************************

41 --> [8], [9], [11], [12],  [14] HCoV-OC43 and HCoV-229E were the most common  strains in alternate seasons, reflecting a season-to- season variability of HCoV strain circulation that has been  reported in other multiyear studies. 


 ---- TOKENS ----

 ['[', '8', ']', ',', '[', '9', ']', ',', '[', '11', ']', ',', '[', '12', ']', ',', '[', '14', ']', 'HCoV-OC43', 'and', 'HCoV-229E', 'were', 'the', 'most', 'common', 'strains', 'in', 'alternate', 'seasons', ',', 'reflecting', 'a', 'season-to-', 'season', 'variability', 'of', 'HCoV', 'strain', 'circulation', 'that', 'has', 'been', 'reported', 'in', 'other', 'multiyear', 'studies', '.'] 

 TOTAL TOKENS ==> 49

 ---- POST ----

 [('[', 'RB'), ('8', 'CD'), (']', 'NNS'), (',', ','), ('[', 'VBP'), ('9', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('11', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('12', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('14', 'CD'), (']', 'JJ'), ('HCoV-OC43', 'NNP'), ('and', 'CC'), ('HCoV-229E', 'NNP'), ('were', 'VBD'), ('the', 'DT'), ('most', 'RBS'), ('common', 'JJ'), ('strains', 'NNS'), ('in', 'IN'), ('alternate', 'JJ'), ('seasons', 'NNS'), (',', ','), ('reflecting', 'VBG'), ('a', 'DT'), ('season-to-', 'JJ'), ('season', 'NN'), ('variability', 'NN'), ('of', 'IN'), ('HCoV', 'NNP'), ('strain', 'NN'), ('circulation', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('been', 'VBN'), ('reported', 'VBN'), ('in', 'IN'), ('other', 'JJ'), ('multiyear', 'JJ'), ('studies', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['[', '8', ']', ',', '[', '9', ']', ',', '[', '11', ']', ',', '[', '12', ']', ',', '[', '14', ']', 'HCoV-OC43', 'HCoV-229E', 'common', 'strains', 'alternate', 'seasons', ',', 'reflecting', 'season-to-', 'season', 'variability', 'HCoV', 'strain', 'circulation', 'reported', 'multiyear', 'studies', '.']

 TOTAL FILTERED TOKENS ==>  37

 ---- POST FOR FILTERED TOKENS ----

 [('[', 'RB'), ('8', 'CD'), (']', 'NNS'), (',', ','), ('[', 'VBP'), ('9', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('11', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('12', 'CD'), (']', 'NN'), (',', ','), ('[', 'VBZ'), ('14', 'CD'), (']', 'JJ'), ('HCoV-OC43', 'JJ'), ('HCoV-229E', 'JJ'), ('common', 'JJ'), ('strains', 'NNS'), ('alternate', 'JJ'), ('seasons', 'NNS'), (',', ','), ('reflecting', 'VBG'), ('season-to-', 'NN'), ('season', 'NN'), ('variability', 'NN'), ('HCoV', 'NNP'), ('strain', 'NN'), ('circulation', 'NN'), ('reported', 'VBD'), ('multiyear', 'JJ'), ('studies', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['[ 8', '8 ]', '] ,', ', [', '[ 9', '9 ]', '] ,', ', [', '[ 11', '11 ]', '] ,', ', [', '[ 12', '12 ]', '] ,', ', [', '[ 14', '14 ]', '] HCoV-OC43', 'HCoV-OC43 HCoV-229E', 'HCoV-229E common', 'common strains', 'strains alternate', 'alternate seasons', 'seasons ,', ', reflecting', 'reflecting season-to-', 'season-to- season', 'season variability', 'variability HCoV', 'HCoV strain', 'strain circulation', 'circulation reported', 'reported multiyear', 'multiyear studies', 'studies .'] 

 TOTAL BIGRAMS --> 36 



 ---- TRI-GRAMS ---- 

 ['[ 8 ]', '8 ] ,', '] , [', ', [ 9', '[ 9 ]', '9 ] ,', '] , [', ', [ 11', '[ 11 ]', '11 ] ,', '] , [', ', [ 12', '[ 12 ]', '12 ] ,', '] , [', ', [ 14', '[ 14 ]', '14 ] HCoV-OC43', '] HCoV-OC43 HCoV-229E', 'HCoV-OC43 HCoV-229E common', 'HCoV-229E common strains', 'common strains alternate', 'strains alternate seasons', 'alternate seasons ,', 'seasons , reflecting', ', reflecting season-to-', 'reflecting season-to- season', 'season-to- season variability', 'season variability HCoV', 'variability HCoV strain', 'HCoV strain circulation', 'strain circulation reported', 'circulation reported multiyear', 'reported multiyear studies', 'multiyear studies .'] 

 TOTAL TRIGRAMS --> 35 



 ---- NOUN PHRASES ---- 

 [']', ']', ']', 'season-to-', 'season', 'variability', 'strain', 'circulation'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['HCoV']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['[', '8', ']', ',', '[', '9', ']', ',', '[', '11', ']', ',', '[', '12', ']', ',', '[', '14', ']', 'hcov-oc43', 'hcov-229', 'common', 'strain', 'altern', 'season', ',', 'reflect', 'season-to-', 'season', 'variabl', 'hcov', 'strain', 'circul', 'report', 'multiyear', 'studi', '.']

 TOTAL PORTER STEM WORDS ==> 37



 ---- SNOWBALL STEMMING ----

['[', '8', ']', ',', '[', '9', ']', ',', '[', '11', ']', ',', '[', '12', ']', ',', '[', '14', ']', 'hcov-oc43', 'hcov-229', 'common', 'strain', 'altern', 'season', ',', 'reflect', 'season-to-', 'season', 'variabl', 'hcov', 'strain', 'circul', 'report', 'multiyear', 'studi', '.']

 TOTAL SNOWBALL STEM WORDS ==> 37



 ---- LEMMATIZATION ----

['[', '8', ']', ',', '[', '9', ']', ',', '[', '11', ']', ',', '[', '12', ']', ',', '[', '14', ']', 'HCoV-OC43', 'HCoV-229E', 'common', 'strain', 'alternate', 'season', ',', 'reflecting', 'season-to-', 'season', 'variability', 'HCoV', 'strain', 'circulation', 'reported', 'multiyear', 'study', '.']

 TOTAL LEMMATIZE WORDS ==> 37

************************************************************************************************************************

42 --> Figure 1. 


 ---- TOKENS ----

 ['Figure', '1', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('Figure', 'NN'), ('1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Figure', '1', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Figure', 'NN'), ('1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Figure 1', '1 .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Figure 1 .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['Figure'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['figur', '1', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['figur', '1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Figure', '1', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

43 --> AbbVie Search. 


 ---- TOKENS ----

 ['AbbVie', 'Search', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'Search', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie Search', 'Search .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['AbbVie Search .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie Search']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'search', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['abbvi', 'search', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['AbbVie', 'Search', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

44 --> A transformer-based NLP question/ answer model (based on BioBERT) that was trained on a biomedical  corpus. 


 ---- TOKENS ----

 ['A', 'transformer-based', 'NLP', 'question/', 'answer', 'model', '(', 'based', 'on', 'BioBERT', ')', 'that', 'was', 'trained', 'on', 'a', 'biomedical', 'corpus', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('A', 'DT'), ('transformer-based', 'JJ'), ('NLP', 'NNP'), ('question/', 'NN'), ('answer', 'NN'), ('model', 'NN'), ('(', '('), ('based', 'VBN'), ('on', 'IN'), ('BioBERT', 'NNP'), (')', ')'), ('that', 'WDT'), ('was', 'VBD'), ('trained', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('biomedical', 'JJ'), ('corpus', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['transformer-based', 'NLP', 'question/', 'answer', 'model', '(', 'based', 'BioBERT', ')', 'trained', 'biomedical', 'corpus', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('transformer-based', 'JJ'), ('NLP', 'NNP'), ('question/', 'NN'), ('answer', 'NN'), ('model', 'NN'), ('(', '('), ('based', 'VBN'), ('BioBERT', 'NNP'), (')', ')'), ('trained', 'VBD'), ('biomedical', 'JJ'), ('corpus', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['transformer-based NLP', 'NLP question/', 'question/ answer', 'answer model', 'model (', '( based', 'based BioBERT', 'BioBERT )', ') trained', 'trained biomedical', 'biomedical corpus', 'corpus .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['transformer-based NLP question/', 'NLP question/ answer', 'question/ answer model', 'answer model (', 'model ( based', '( based BioBERT', 'based BioBERT )', 'BioBERT ) trained', ') trained biomedical', 'trained biomedical corpus', 'biomedical corpus .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['question', 'answer', 'model', 'biomedical corpus'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['transformer-bas', 'nlp', 'question/', 'answer', 'model', '(', 'base', 'biobert', ')', 'train', 'biomed', 'corpu', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['transformer-bas', 'nlp', 'question/', 'answer', 'model', '(', 'base', 'biobert', ')', 'train', 'biomed', 'corpus', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['transformer-based', 'NLP', 'question/', 'answer', 'model', '(', 'based', 'BioBERT', ')', 'trained', 'biomedical', 'corpus', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

45 --> This allows AbbVie to develop models that are specific to  biopharmaceutical research. 


 ---- TOKENS ----

 ['This', 'allows', 'AbbVie', 'to', 'develop', 'models', 'that', 'are', 'specific', 'to', 'biopharmaceutical', 'research', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('This', 'DT'), ('allows', 'VBZ'), ('AbbVie', 'NNP'), ('to', 'TO'), ('develop', 'VB'), ('models', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('specific', 'JJ'), ('to', 'TO'), ('biopharmaceutical', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['allows', 'AbbVie', 'develop', 'models', 'specific', 'biopharmaceutical', 'research', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('allows', 'NNS'), ('AbbVie', 'NNP'), ('develop', 'NN'), ('models', 'NNS'), ('specific', 'JJ'), ('biopharmaceutical', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['allows AbbVie', 'AbbVie develop', 'develop models', 'models specific', 'specific biopharmaceutical', 'biopharmaceutical research', 'research .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['allows AbbVie develop', 'AbbVie develop models', 'develop models specific', 'models specific biopharmaceutical', 'specific biopharmaceutical research', 'biopharmaceutical research .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['develop', 'specific biopharmaceutical research'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['allow', 'abbvi', 'develop', 'model', 'specif', 'biopharmaceut', 'research', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['allow', 'abbvi', 'develop', 'model', 'specif', 'biopharmaceut', 'research', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['allows', 'AbbVie', 'develop', 'model', 'specific', 'biopharmaceutical', 'research', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

46 --> The question and context sentences  (for example, scientific article) are transformed into an embedding  space and fed into the AbbVie Search model. 


 ---- TOKENS ----

 ['The', 'question', 'and', 'context', 'sentences', '(', 'for', 'example', ',', 'scientific', 'article', ')', 'are', 'transformed', 'into', 'an', 'embedding', 'space', 'and', 'fed', 'into', 'the', 'AbbVie', 'Search', 'model', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('The', 'DT'), ('question', 'NN'), ('and', 'CC'), ('context', 'NN'), ('sentences', 'NNS'), ('(', '('), ('for', 'IN'), ('example', 'NN'), (',', ','), ('scientific', 'JJ'), ('article', 'NN'), (')', ')'), ('are', 'VBP'), ('transformed', 'VBN'), ('into', 'IN'), ('an', 'DT'), ('embedding', 'JJ'), ('space', 'NN'), ('and', 'CC'), ('fed', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('model', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['question', 'context', 'sentences', '(', 'example', ',', 'scientific', 'article', ')', 'transformed', 'embedding', 'space', 'fed', 'AbbVie', 'Search', 'model', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('question', 'NN'), ('context', 'NN'), ('sentences', 'NNS'), ('(', '('), ('example', 'NN'), (',', ','), ('scientific', 'JJ'), ('article', 'NN'), (')', ')'), ('transformed', 'VBD'), ('embedding', 'VBG'), ('space', 'NN'), ('fed', 'VBN'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('model', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['question context', 'context sentences', 'sentences (', '( example', 'example ,', ', scientific', 'scientific article', 'article )', ') transformed', 'transformed embedding', 'embedding space', 'space fed', 'fed AbbVie', 'AbbVie Search', 'Search model', 'model .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['question context sentences', 'context sentences (', 'sentences ( example', '( example ,', 'example , scientific', ', scientific article', 'scientific article )', 'article ) transformed', ') transformed embedding', 'transformed embedding space', 'embedding space fed', 'space fed AbbVie', 'fed AbbVie Search', 'AbbVie Search model', 'Search model .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['question', 'context', 'space', 'model'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie Search']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['question', 'context', 'sentenc', '(', 'exampl', ',', 'scientif', 'articl', ')', 'transform', 'embed', 'space', 'fed', 'abbvi', 'search', 'model', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['question', 'context', 'sentenc', '(', 'exampl', ',', 'scientif', 'articl', ')', 'transform', 'embed', 'space', 'fed', 'abbvi', 'search', 'model', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['question', 'context', 'sentence', '(', 'example', ',', 'scientific', 'article', ')', 'transformed', 'embedding', 'space', 'fed', 'AbbVie', 'Search', 'model', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

47 --> The model outputs the  position in the context where the answer can be found. 


 ---- TOKENS ----

 ['The', 'model', 'outputs', 'the', 'position', 'in', 'the', 'context', 'where', 'the', 'answer', 'can', 'be', 'found', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('The', 'DT'), ('model', 'NN'), ('outputs', 'VBZ'), ('the', 'DT'), ('position', 'NN'), ('in', 'IN'), ('the', 'DT'), ('context', 'NN'), ('where', 'WRB'), ('the', 'DT'), ('answer', 'NN'), ('can', 'MD'), ('be', 'VB'), ('found', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['model', 'outputs', 'position', 'context', 'answer', 'found', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('model', 'NN'), ('outputs', 'VBZ'), ('position', 'NN'), ('context', 'NN'), ('answer', 'NN'), ('found', 'VBD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['model outputs', 'outputs position', 'position context', 'context answer', 'answer found', 'found .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['model outputs position', 'outputs position context', 'position context answer', 'context answer found', 'answer found .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['model', 'position', 'context', 'answer'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['model', 'output', 'posit', 'context', 'answer', 'found', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['model', 'output', 'posit', 'context', 'answer', 'found', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['model', 'output', 'position', 'context', 'answer', 'found', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

48 --> Question What is the most common species of Human Coronavirus  among adults? 


 ---- TOKENS ----

 ['Question', 'What', 'is', 'the', 'most', 'common', 'species', 'of', 'Human', 'Coronavirus', 'among', 'adults', '?'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Question', 'NN'), ('What', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('common', 'JJ'), ('species', 'NNS'), ('of', 'IN'), ('Human', 'NNP'), ('Coronavirus', 'NNP'), ('among', 'IN'), ('adults', 'NNS'), ('?', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Question', 'common', 'species', 'Human', 'Coronavirus', 'among', 'adults', '?']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Question', 'NN'), ('common', 'JJ'), ('species', 'NNS'), ('Human', 'NNP'), ('Coronavirus', 'NNP'), ('among', 'IN'), ('adults', 'NNS'), ('?', '.')] 



 ---- BI-GRAMS ---- 

 ['Question common', 'common species', 'species Human', 'Human Coronavirus', 'Coronavirus among', 'among adults', 'adults ?'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Question common species', 'common species Human', 'species Human Coronavirus', 'Human Coronavirus among', 'Coronavirus among adults', 'among adults ?'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['Question'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Human Coronavirus']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Question']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['question', 'common', 'speci', 'human', 'coronaviru', 'among', 'adult', '?']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['question', 'common', 'speci', 'human', 'coronavirus', 'among', 'adult', '?']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Question', 'common', 'specie', 'Human', 'Coronavirus', 'among', 'adult', '?']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

49 --> Answer HCoV-OC43 Figure 2. 


 ---- TOKENS ----

 ['Answer', 'HCoV-OC43', 'Figure', '2', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('Answer', 'JJR'), ('HCoV-OC43', 'NNP'), ('Figure', 'NNP'), ('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Answer', 'HCoV-OC43', 'Figure', '2', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('Answer', 'JJR'), ('HCoV-OC43', 'NNP'), ('Figure', 'NNP'), ('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Answer HCoV-OC43', 'HCoV-OC43 Figure', 'Figure 2', '2 .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['Answer HCoV-OC43 Figure', 'HCoV-OC43 Figure 2', 'Figure 2 .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['answer', 'hcov-oc43', 'figur', '2', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['answer', 'hcov-oc43', 'figur', '2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['Answer', 'HCoV-OC43', 'Figure', '2', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

50 --> AbbVie Search Question and Answer Example. 


 ---- TOKENS ----

 ['AbbVie', 'Search', 'Question', 'and', 'Answer', 'Example', '.'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('Question', 'NNP'), ('and', 'CC'), ('Answer', 'NNP'), ('Example', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'Search', 'Question', 'Answer', 'Example', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('Question', 'NNP'), ('Answer', 'NNP'), ('Example', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie Search', 'Search Question', 'Question Answer', 'Answer Example', 'Example .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['AbbVie Search Question', 'Search Question Answer', 'Question Answer Example', 'Answer Example .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Search Question Answer Example']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'search', 'question', 'answer', 'exampl', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['abbvi', 'search', 'question', 'answer', 'exampl', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['AbbVie', 'Search', 'Question', 'Answer', 'Example', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

51 --> The user  inputs a question along with a collection of contexts of scientific  articles/clinical notes. 


 ---- TOKENS ----

 ['The', 'user', 'inputs', 'a', 'question', 'along', 'with', 'a', 'collection', 'of', 'contexts', 'of', 'scientific', 'articles/clinical', 'notes', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('The', 'DT'), ('user', 'NN'), ('inputs', 'VBZ'), ('a', 'DT'), ('question', 'NN'), ('along', 'IN'), ('with', 'IN'), ('a', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('contexts', 'NN'), ('of', 'IN'), ('scientific', 'JJ'), ('articles/clinical', 'JJ'), ('notes', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['user', 'inputs', 'question', 'along', 'collection', 'contexts', 'scientific', 'articles/clinical', 'notes', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('user', 'NN'), ('inputs', 'NNS'), ('question', 'NN'), ('along', 'IN'), ('collection', 'NN'), ('contexts', 'NN'), ('scientific', 'JJ'), ('articles/clinical', 'JJ'), ('notes', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['user inputs', 'inputs question', 'question along', 'along collection', 'collection contexts', 'contexts scientific', 'scientific articles/clinical', 'articles/clinical notes', 'notes .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['user inputs question', 'inputs question along', 'question along collection', 'along collection contexts', 'collection contexts scientific', 'contexts scientific articles/clinical', 'scientific articles/clinical notes', 'articles/clinical notes .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['user', 'question', 'collection', 'contexts'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['user', 'input', 'question', 'along', 'collect', 'context', 'scientif', 'articles/clin', 'note', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['user', 'input', 'question', 'along', 'collect', 'context', 'scientif', 'articles/clin', 'note', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['user', 'input', 'question', 'along', 'collection', 'context', 'scientific', 'articles/clinical', 'note', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

52 --> The model highlights where in the context the  answer can be found. 


 ---- TOKENS ----

 ['The', 'model', 'highlights', 'where', 'in', 'the', 'context', 'the', 'answer', 'can', 'be', 'found', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('The', 'DT'), ('model', 'NN'), ('highlights', 'NNS'), ('where', 'WRB'), ('in', 'IN'), ('the', 'DT'), ('context', 'NN'), ('the', 'DT'), ('answer', 'NN'), ('can', 'MD'), ('be', 'VB'), ('found', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['model', 'highlights', 'context', 'answer', 'found', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('model', 'NN'), ('highlights', 'NNS'), ('context', 'VBP'), ('answer', 'NN'), ('found', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['model highlights', 'highlights context', 'context answer', 'answer found', 'found .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['model highlights context', 'highlights context answer', 'context answer found', 'answer found .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 ['model', 'answer'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['model', 'highlight', 'context', 'answer', 'found', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['model', 'highlight', 'context', 'answer', 'found', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['model', 'highlight', 'context', 'answer', 'found', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

53 --> 1See backup for configuration details. 


 ---- TOKENS ----

 ['1See', 'backup', 'for', 'configuration', 'details', '.'] 

 TOTAL TOKENS ==> 6

 ---- POST ----

 [('1See', 'CD'), ('backup', 'NN'), ('for', 'IN'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1See', 'backup', 'configuration', 'details', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('1See', 'CD'), ('backup', 'NN'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1See backup', 'backup configuration', 'configuration details', 'details .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['1See backup configuration', 'backup configuration details', 'configuration details .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 ['backup', 'configuration'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1see', 'backup', 'configur', 'detail', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['1see', 'backup', 'configur', 'detail', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['1See', 'backup', 'configuration', 'detail', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

54 --> For more complete information about performance and benchmark results, visit www.intel.com/benchmarks. 


 ---- TOKENS ----

 ['For', 'more', 'complete', 'information', 'about', 'performance', 'and', 'benchmark', 'results', ',', 'visit', 'www.intel.com/benchmarks', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('For', 'IN'), ('more', 'JJR'), ('complete', 'JJ'), ('information', 'NN'), ('about', 'IN'), ('performance', 'NN'), ('and', 'CC'), ('benchmark', 'NN'), ('results', 'NNS'), (',', ','), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['complete', 'information', 'performance', 'benchmark', 'results', ',', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('complete', 'JJ'), ('information', 'NN'), ('performance', 'NN'), ('benchmark', 'NN'), ('results', 'NNS'), (',', ','), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['complete information', 'information performance', 'performance benchmark', 'benchmark results', 'results ,', ', visit', 'visit www.intel.com/benchmarks', 'www.intel.com/benchmarks .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['complete information performance', 'information performance benchmark', 'performance benchmark results', 'benchmark results ,', 'results , visit', ', visit www.intel.com/benchmarks', 'visit www.intel.com/benchmarks .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['complete information', 'performance', 'benchmark', 'visit'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['complet', 'inform', 'perform', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['complet', 'inform', 'perform', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['complete', 'information', 'performance', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

55 --> https://github.com/dmis-lab/biobert https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/ http://bioasq.org  White Paper | Accelerating Natural Language Processing Inference Models using Processor Optimized Capabilities Results  Abbelfish Machine Translation The 2020 version of the Abbelfish model is an 8-language  translation Transformer model with 24 layers and 500 million  parameters. 


 ---- TOKENS ----

 ['https', ':', '//github.com/dmis-lab/biobert', 'https', ':', '//rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/', 'http', ':', '//bioasq.org', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Results', 'Abbelfish', 'Machine', 'Translation', 'The', '2020', 'version', 'of', 'the', 'Abbelfish', 'model', 'is', 'an', '8-language', 'translation', 'Transformer', 'model', 'with', '24', 'layers', 'and', '500', 'million', 'parameters', '.'] 

 TOTAL TOKENS ==> 47

 ---- POST ----

 [('https', 'NN'), (':', ':'), ('//github.com/dmis-lab/biobert', 'JJ'), ('https', 'NN'), (':', ':'), ('//rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/', 'JJ'), ('http', 'NN'), (':', ':'), ('//bioasq.org', 'JJ'), ('White', 'NNP'), ('Paper', 'NNP'), ('|', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNP'), ('Results', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('The', 'DT'), ('2020', 'CD'), ('version', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Abbelfish', 'NNP'), ('model', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('8-language', 'JJ'), ('translation', 'NN'), ('Transformer', 'NNP'), ('model', 'NN'), ('with', 'IN'), ('24', 'CD'), ('layers', 'NNS'), ('and', 'CC'), ('500', 'CD'), ('million', 'CD'), ('parameters', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['https', ':', '//github.com/dmis-lab/biobert', 'https', ':', '//rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/', 'http', ':', '//bioasq.org', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Results', 'Abbelfish', 'Machine', 'Translation', '2020', 'version', 'Abbelfish', 'model', '8-language', 'translation', 'Transformer', 'model', '24', 'layers', '500', 'million', 'parameters', '.']

 TOTAL FILTERED TOKENS ==>  40

 ---- POST FOR FILTERED TOKENS ----

 [('https', 'NN'), (':', ':'), ('//github.com/dmis-lab/biobert', 'JJ'), ('https', 'NN'), (':', ':'), ('//rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/', 'JJ'), ('http', 'NN'), (':', ':'), ('//bioasq.org', 'JJ'), ('White', 'NNP'), ('Paper', 'NNP'), ('|', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNP'), ('Results', 'NNP'), ('Abbelfish', 'NNP'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('2020', 'CD'), ('version', 'NN'), ('Abbelfish', 'NNP'), ('model', 'NN'), ('8-language', 'JJ'), ('translation', 'NN'), ('Transformer', 'NNP'), ('model', 'NN'), ('24', 'CD'), ('layers', 'NNS'), ('500', 'CD'), ('million', 'CD'), ('parameters', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['https :', ': //github.com/dmis-lab/biobert', '//github.com/dmis-lab/biobert https', 'https :', ': //rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/', '//rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/ http', 'http :', ': //bioasq.org', '//bioasq.org White', 'White Paper', 'Paper |', '| Accelerating', 'Accelerating Natural', 'Natural Language', 'Language Processing', 'Processing Inference', 'Inference Models', 'Models using', 'using Processor', 'Processor Optimized', 'Optimized Capabilities', 'Capabilities Results', 'Results Abbelfish', 'Abbelfish Machine', 'Machine Translation', 'Translation 2020', '2020 version', 'version Abbelfish', 'Abbelfish model', 'model 8-language', '8-language translation', 'translation Transformer', 'Transformer model', 'model 24', '24 layers', 'layers 500', '500 million', 'million parameters', 'parameters .'] 

 TOTAL BIGRAMS --> 39 



 ---- TRI-GRAMS ---- 

 ['https : //github.com/dmis-lab/biobert', ': //github.com/dmis-lab/biobert https', '//github.com/dmis-lab/biobert https :', 'https : //rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/', ': //rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/ http', '//rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/ http :', 'http : //bioasq.org', ': //bioasq.org White', '//bioasq.org White Paper', 'White Paper |', 'Paper | Accelerating', '| Accelerating Natural', 'Accelerating Natural Language', 'Natural Language Processing', 'Language Processing Inference', 'Processing Inference Models', 'Inference Models using', 'Models using Processor', 'using Processor Optimized', 'Processor Optimized Capabilities', 'Optimized Capabilities Results', 'Capabilities Results Abbelfish', 'Results Abbelfish Machine', 'Abbelfish Machine Translation', 'Machine Translation 2020', 'Translation 2020 version', '2020 version Abbelfish', 'version Abbelfish model', 'Abbelfish model 8-language', 'model 8-language translation', '8-language translation Transformer', 'translation Transformer model', 'Transformer model 24', 'model 24 layers', '24 layers 500', 'layers 500 million', '500 million parameters', 'million parameters .'] 

 TOTAL TRIGRAMS --> 38 



 ---- NOUN PHRASES ---- 

 ['https', ' https', ' http', 'version', 'model', '8-language translation', 'model'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Processor Optimized Capabilities Results Abbelfish Machine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Abbelfish']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['http', ':', '//github.com/dmis-lab/biobert', 'http', ':', '//rajpurkar.github.io/squad-explorer/explore/1.1/dev/', 'http', ':', '//bioasq.org', 'white', 'paper', '|', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'result', 'abbelfish', 'machin', 'translat', '2020', 'version', 'abbelfish', 'model', '8-languag', 'translat', 'transform', 'model', '24', 'layer', '500', 'million', 'paramet', '.']

 TOTAL PORTER STEM WORDS ==> 40



 ---- SNOWBALL STEMMING ----

['https', ':', '//github.com/dmis-lab/biobert', 'https', ':', '//rajpurkar.github.io/squad-explorer/explore/1.1/dev/', 'http', ':', '//bioasq.org', 'white', 'paper', '|', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'result', 'abbelfish', 'machin', 'translat', '2020', 'version', 'abbelfish', 'model', '8-languag', 'translat', 'transform', 'model', '24', 'layer', '500', 'million', 'paramet', '.']

 TOTAL SNOWBALL STEM WORDS ==> 40



 ---- LEMMATIZATION ----

['http', ':', '//github.com/dmis-lab/biobert', 'http', ':', '//rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/', 'http', ':', '//bioasq.org', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Results', 'Abbelfish', 'Machine', 'Translation', '2020', 'version', 'Abbelfish', 'model', '8-language', 'translation', 'Transformer', 'model', '24', 'layer', '500', 'million', 'parameter', '.']

 TOTAL LEMMATIZE WORDS ==> 40

************************************************************************************************************************

56 --> A large portion of the Abbelfish workload is done  as a batch process. 


 ---- TOKENS ----

 ['A', 'large', 'portion', 'of', 'the', 'Abbelfish', 'workload', 'is', 'done', 'as', 'a', 'batch', 'process', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('A', 'DT'), ('large', 'JJ'), ('portion', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Abbelfish', 'NNP'), ('workload', 'NN'), ('is', 'VBZ'), ('done', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('batch', 'NN'), ('process', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['large', 'portion', 'Abbelfish', 'workload', 'done', 'batch', 'process', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('large', 'JJ'), ('portion', 'NN'), ('Abbelfish', 'NNP'), ('workload', 'NN'), ('done', 'VBN'), ('batch', 'NN'), ('process', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['large portion', 'portion Abbelfish', 'Abbelfish workload', 'workload done', 'done batch', 'batch process', 'process .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['large portion Abbelfish', 'portion Abbelfish workload', 'Abbelfish workload done', 'workload done batch', 'done batch process', 'batch process .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['large portion', 'workload', 'batch', 'process'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Abbelfish']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['larg', 'portion', 'abbelfish', 'workload', 'done', 'batch', 'process', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['larg', 'portion', 'abbelfish', 'workload', 'done', 'batch', 'process', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['large', 'portion', 'Abbelfish', 'workload', 'done', 'batch', 'process', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

57 --> To meet the needs of its researchers,  AbbVie set a target of translating one sentence every two  seconds. 


 ---- TOKENS ----

 ['To', 'meet', 'the', 'needs', 'of', 'its', 'researchers', ',', 'AbbVie', 'set', 'a', 'target', 'of', 'translating', 'one', 'sentence', 'every', 'two', 'seconds', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('To', 'TO'), ('meet', 'VB'), ('the', 'DT'), ('needs', 'NNS'), ('of', 'IN'), ('its', 'PRP$'), ('researchers', 'NNS'), (',', ','), ('AbbVie', 'NNP'), ('set', 'VBD'), ('a', 'DT'), ('target', 'NN'), ('of', 'IN'), ('translating', 'VBG'), ('one', 'CD'), ('sentence', 'NN'), ('every', 'DT'), ('two', 'CD'), ('seconds', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['meet', 'needs', 'researchers', ',', 'AbbVie', 'set', 'target', 'translating', 'one', 'sentence', 'every', 'two', 'seconds', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('meet', 'NN'), ('needs', 'VBZ'), ('researchers', 'NNS'), (',', ','), ('AbbVie', 'NNP'), ('set', 'VBD'), ('target', 'NN'), ('translating', 'VBG'), ('one', 'CD'), ('sentence', 'NN'), ('every', 'DT'), ('two', 'CD'), ('seconds', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['meet needs', 'needs researchers', 'researchers ,', ', AbbVie', 'AbbVie set', 'set target', 'target translating', 'translating one', 'one sentence', 'sentence every', 'every two', 'two seconds', 'seconds .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['meet needs researchers', 'needs researchers ,', 'researchers , AbbVie', ', AbbVie set', 'AbbVie set target', 'set target translating', 'target translating one', 'translating one sentence', 'one sentence every', 'sentence every two', 'every two seconds', 'two seconds .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['meet', 'target', 'sentence'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['meet', 'need', 'research', ',', 'abbvi', 'set', 'target', 'translat', 'one', 'sentenc', 'everi', 'two', 'second', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['meet', 'need', 'research', ',', 'abbvi', 'set', 'target', 'translat', 'one', 'sentenc', 'everi', 'two', 'second', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['meet', 'need', 'researcher', ',', 'AbbVie', 'set', 'target', 'translating', 'one', 'sentence', 'every', 'two', 'second', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

58 --> It is important to note that although faster inference  times are always desirable, AbbVie recognized that they don’t  add significant value to the product given the added expense  of dedicated hardware accelerators, such as GPUs. 


 ---- TOKENS ----

 ['It', 'is', 'important', 'to', 'note', 'that', 'although', 'faster', 'inference', 'times', 'are', 'always', 'desirable', ',', 'AbbVie', 'recognized', 'that', 'they', 'don', '’', 't', 'add', 'significant', 'value', 'to', 'the', 'product', 'given', 'the', 'added', 'expense', 'of', 'dedicated', 'hardware', 'accelerators', ',', 'such', 'as', 'GPUs', '.'] 

 TOTAL TOKENS ==> 40

 ---- POST ----

 [('It', 'PRP'), ('is', 'VBZ'), ('important', 'JJ'), ('to', 'TO'), ('note', 'VB'), ('that', 'IN'), ('although', 'IN'), ('faster', 'JJR'), ('inference', 'NN'), ('times', 'NNS'), ('are', 'VBP'), ('always', 'RB'), ('desirable', 'JJ'), (',', ','), ('AbbVie', 'NNP'), ('recognized', 'VBD'), ('that', 'IN'), ('they', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('add', 'NN'), ('significant', 'JJ'), ('value', 'NN'), ('to', 'TO'), ('the', 'DT'), ('product', 'NN'), ('given', 'VBN'), ('the', 'DT'), ('added', 'JJ'), ('expense', 'NN'), ('of', 'IN'), ('dedicated', 'VBN'), ('hardware', 'NN'), ('accelerators', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('GPUs', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['important', 'note', 'although', 'faster', 'inference', 'times', 'always', 'desirable', ',', 'AbbVie', 'recognized', '’', 'add', 'significant', 'value', 'product', 'given', 'added', 'expense', 'dedicated', 'hardware', 'accelerators', ',', 'GPUs', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('important', 'JJ'), ('note', 'NN'), ('although', 'IN'), ('faster', 'JJR'), ('inference', 'NN'), ('times', 'NNS'), ('always', 'RB'), ('desirable', 'JJ'), (',', ','), ('AbbVie', 'NNP'), ('recognized', 'VBD'), ('’', 'NNP'), ('add', 'VB'), ('significant', 'JJ'), ('value', 'NN'), ('product', 'NN'), ('given', 'VBN'), ('added', 'VBD'), ('expense', 'NN'), ('dedicated', 'VBN'), ('hardware', 'NN'), ('accelerators', 'NNS'), (',', ','), ('GPUs', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['important note', 'note although', 'although faster', 'faster inference', 'inference times', 'times always', 'always desirable', 'desirable ,', ', AbbVie', 'AbbVie recognized', 'recognized ’', '’ add', 'add significant', 'significant value', 'value product', 'product given', 'given added', 'added expense', 'expense dedicated', 'dedicated hardware', 'hardware accelerators', 'accelerators ,', ', GPUs', 'GPUs .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['important note although', 'note although faster', 'although faster inference', 'faster inference times', 'inference times always', 'times always desirable', 'always desirable ,', 'desirable , AbbVie', ', AbbVie recognized', 'AbbVie recognized ’', 'recognized ’ add', '’ add significant', 'add significant value', 'significant value product', 'value product given', 'product given added', 'given added expense', 'added expense dedicated', 'expense dedicated hardware', 'dedicated hardware accelerators', 'hardware accelerators ,', 'accelerators , GPUs', ', GPUs .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['important note', 'inference', 'significant value', 'product', 'expense', 'hardware'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'GPUs']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['import', 'note', 'although', 'faster', 'infer', 'time', 'alway', 'desir', ',', 'abbvi', 'recogn', '’', 'add', 'signific', 'valu', 'product', 'given', 'ad', 'expens', 'dedic', 'hardwar', 'acceler', ',', 'gpu', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['import', 'note', 'although', 'faster', 'infer', 'time', 'alway', 'desir', ',', 'abbvi', 'recogn', '’', 'add', 'signific', 'valu', 'product', 'given', 'ad', 'expens', 'dedic', 'hardwar', 'acceler', ',', 'gpus', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['important', 'note', 'although', 'faster', 'inference', 'time', 'always', 'desirable', ',', 'AbbVie', 'recognized', '’', 'add', 'significant', 'value', 'product', 'given', 'added', 'expense', 'dedicated', 'hardware', 'accelerator', ',', 'GPUs', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

59 --> Their  strategy allows AbbVie to offload its translation workloads  onto the Intel Xeon processor-based servers to free up other  hardware resources. 


 ---- TOKENS ----

 ['Their', 'strategy', 'allows', 'AbbVie', 'to', 'offload', 'its', 'translation', 'workloads', 'onto', 'the', 'Intel', 'Xeon', 'processor-based', 'servers', 'to', 'free', 'up', 'other', 'hardware', 'resources', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Their', 'PRP$'), ('strategy', 'NN'), ('allows', 'VBZ'), ('AbbVie', 'NNP'), ('to', 'TO'), ('offload', 'VB'), ('its', 'PRP$'), ('translation', 'NN'), ('workloads', 'NNS'), ('onto', 'IN'), ('the', 'DT'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-based', 'JJ'), ('servers', 'NNS'), ('to', 'TO'), ('free', 'VB'), ('up', 'RP'), ('other', 'JJ'), ('hardware', 'NN'), ('resources', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['strategy', 'allows', 'AbbVie', 'offload', 'translation', 'workloads', 'onto', 'Intel', 'Xeon', 'processor-based', 'servers', 'free', 'hardware', 'resources', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('strategy', 'NN'), ('allows', 'VBZ'), ('AbbVie', 'NNP'), ('offload', 'NN'), ('translation', 'NN'), ('workloads', 'NNS'), ('onto', 'IN'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-based', 'JJ'), ('servers', 'NNS'), ('free', 'JJ'), ('hardware', 'NN'), ('resources', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['strategy allows', 'allows AbbVie', 'AbbVie offload', 'offload translation', 'translation workloads', 'workloads onto', 'onto Intel', 'Intel Xeon', 'Xeon processor-based', 'processor-based servers', 'servers free', 'free hardware', 'hardware resources', 'resources .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['strategy allows AbbVie', 'allows AbbVie offload', 'AbbVie offload translation', 'offload translation workloads', 'translation workloads onto', 'workloads onto Intel', 'onto Intel Xeon', 'Intel Xeon processor-based', 'Xeon processor-based servers', 'processor-based servers free', 'servers free hardware', 'free hardware resources', 'hardware resources .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['strategy', 'offload', 'translation', 'free hardware'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'Intel Xeon']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['strategi', 'allow', 'abbvi', 'offload', 'translat', 'workload', 'onto', 'intel', 'xeon', 'processor-bas', 'server', 'free', 'hardwar', 'resourc', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['strategi', 'allow', 'abbvi', 'offload', 'translat', 'workload', 'onto', 'intel', 'xeon', 'processor-bas', 'server', 'free', 'hardwar', 'resourc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['strategy', 'allows', 'AbbVie', 'offload', 'translation', 'workload', 'onto', 'Intel', 'Xeon', 'processor-based', 'server', 'free', 'hardware', 'resource', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

60 --> AbbVie Search The Abbelfish translation model was benchmarked on a  2nd gen Intel Xeon Scalable processor-based server (Intel  Xeon Gold 6252N Processor, 2.30 GHz, 2 sockets, 24 cores  per socket). 


 ---- TOKENS ----

 ['AbbVie', 'Search', 'The', 'Abbelfish', 'translation', 'model', 'was', 'benchmarked', 'on', 'a', '2nd', 'gen', 'Intel', 'Xeon', 'Scalable', 'processor-based', 'server', '(', 'Intel', 'Xeon', 'Gold', '6252N', 'Processor', ',', '2.30', 'GHz', ',', '2', 'sockets', ',', '24', 'cores', 'per', 'socket', ')', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('The', 'DT'), ('Abbelfish', 'NNP'), ('translation', 'NN'), ('model', 'NN'), ('was', 'VBD'), ('benchmarked', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('2nd', 'CD'), ('gen', 'NN'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('Scalable', 'NNP'), ('processor-based', 'JJ'), ('server', 'NN'), ('(', '('), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), (',', ','), ('2.30', 'CD'), ('GHz', 'NNP'), (',', ','), ('2', 'CD'), ('sockets', 'NNS'), (',', ','), ('24', 'CD'), ('cores', 'NNS'), ('per', 'IN'), ('socket', 'NN'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', 'Search', 'Abbelfish', 'translation', 'model', 'benchmarked', '2nd', 'gen', 'Intel', 'Xeon', 'Scalable', 'processor-based', 'server', '(', 'Intel', 'Xeon', 'Gold', '6252N', 'Processor', ',', '2.30', 'GHz', ',', '2', 'sockets', ',', '24', 'cores', 'per', 'socket', ')', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ('Search', 'NNP'), ('Abbelfish', 'NNP'), ('translation', 'NN'), ('model', 'NN'), ('benchmarked', 'VBD'), ('2nd', 'CD'), ('gen', 'NN'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('Scalable', 'NNP'), ('processor-based', 'JJ'), ('server', 'NN'), ('(', '('), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), (',', ','), ('2.30', 'CD'), ('GHz', 'NNP'), (',', ','), ('2', 'CD'), ('sockets', 'NNS'), (',', ','), ('24', 'CD'), ('cores', 'NNS'), ('per', 'IN'), ('socket', 'NN'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['AbbVie Search', 'Search Abbelfish', 'Abbelfish translation', 'translation model', 'model benchmarked', 'benchmarked 2nd', '2nd gen', 'gen Intel', 'Intel Xeon', 'Xeon Scalable', 'Scalable processor-based', 'processor-based server', 'server (', '( Intel', 'Intel Xeon', 'Xeon Gold', 'Gold 6252N', '6252N Processor', 'Processor ,', ', 2.30', '2.30 GHz', 'GHz ,', ', 2', '2 sockets', 'sockets ,', ', 24', '24 cores', 'cores per', 'per socket', 'socket )', ') .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['AbbVie Search Abbelfish', 'Search Abbelfish translation', 'Abbelfish translation model', 'translation model benchmarked', 'model benchmarked 2nd', 'benchmarked 2nd gen', '2nd gen Intel', 'gen Intel Xeon', 'Intel Xeon Scalable', 'Xeon Scalable processor-based', 'Scalable processor-based server', 'processor-based server (', 'server ( Intel', '( Intel Xeon', 'Intel Xeon Gold', 'Xeon Gold 6252N', 'Gold 6252N Processor', '6252N Processor ,', 'Processor , 2.30', ', 2.30 GHz', '2.30 GHz ,', 'GHz , 2', ', 2 sockets', '2 sockets ,', 'sockets , 24', ', 24 cores', '24 cores per', 'cores per socket', 'per socket )', 'socket ) .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['translation', 'model', 'gen', 'processor-based server'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'Intel Xeon']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> ['Search Abbelfish']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', 'search', 'abbelfish', 'translat', 'model', 'benchmark', '2nd', 'gen', 'intel', 'xeon', 'scalabl', 'processor-bas', 'server', '(', 'intel', 'xeon', 'gold', '6252n', 'processor', ',', '2.30', 'ghz', ',', '2', 'socket', ',', '24', 'core', 'per', 'socket', ')', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['abbvi', 'search', 'abbelfish', 'translat', 'model', 'benchmark', '2nd', 'gen', 'intel', 'xeon', 'scalabl', 'processor-bas', 'server', '(', 'intel', 'xeon', 'gold', '6252n', 'processor', ',', '2.30', 'ghz', ',', '2', 'socket', ',', '24', 'core', 'per', 'socket', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['AbbVie', 'Search', 'Abbelfish', 'translation', 'model', 'benchmarked', '2nd', 'gen', 'Intel', 'Xeon', 'Scalable', 'processor-based', 'server', '(', 'Intel', 'Xeon', 'Gold', '6252N', 'Processor', ',', '2.30', 'GHz', ',', '2', 'socket', ',', '24', 'core', 'per', 'socket', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

61 --> The model and data pipeline included the  Tensor2Tensor library, which only works with version 1 of  TensorFlow. 


 ---- TOKENS ----

 ['The', 'model', 'and', 'data', 'pipeline', 'included', 'the', 'Tensor2Tensor', 'library', ',', 'which', 'only', 'works', 'with', 'version', '1', 'of', 'TensorFlow', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('The', 'DT'), ('model', 'NN'), ('and', 'CC'), ('data', 'NNS'), ('pipeline', 'NN'), ('included', 'VBD'), ('the', 'DT'), ('Tensor2Tensor', 'NNP'), ('library', 'NN'), (',', ','), ('which', 'WDT'), ('only', 'RB'), ('works', 'VBZ'), ('with', 'IN'), ('version', 'NN'), ('1', 'CD'), ('of', 'IN'), ('TensorFlow', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['model', 'data', 'pipeline', 'included', 'Tensor2Tensor', 'library', ',', 'works', 'version', '1', 'TensorFlow', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('model', 'NN'), ('data', 'NNS'), ('pipeline', 'NN'), ('included', 'VBD'), ('Tensor2Tensor', 'NNP'), ('library', 'NN'), (',', ','), ('works', 'VBZ'), ('version', 'NN'), ('1', 'CD'), ('TensorFlow', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['model data', 'data pipeline', 'pipeline included', 'included Tensor2Tensor', 'Tensor2Tensor library', 'library ,', ', works', 'works version', 'version 1', '1 TensorFlow', 'TensorFlow .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['model data pipeline', 'data pipeline included', 'pipeline included Tensor2Tensor', 'included Tensor2Tensor library', 'Tensor2Tensor library ,', 'library , works', ', works version', 'works version 1', 'version 1 TensorFlow', '1 TensorFlow .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['model', 'pipeline', 'library', 'version'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['TensorFlow']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Tensor2Tensor']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['model', 'data', 'pipelin', 'includ', 'tensor2tensor', 'librari', ',', 'work', 'version', '1', 'tensorflow', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['model', 'data', 'pipelin', 'includ', 'tensor2tensor', 'librari', ',', 'work', 'version', '1', 'tensorflow', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['model', 'data', 'pipeline', 'included', 'Tensor2Tensor', 'library', ',', 'work', 'version', '1', 'TensorFlow', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

62 --> In addition to using multiple CPU threads during  inference, AbbVie was also able to create parallel inference  streams by pinning each stream to half of the CPU socket using  the numactl command. 


 ---- TOKENS ----

 ['In', 'addition', 'to', 'using', 'multiple', 'CPU', 'threads', 'during', 'inference', ',', 'AbbVie', 'was', 'also', 'able', 'to', 'create', 'parallel', 'inference', 'streams', 'by', 'pinning', 'each', 'stream', 'to', 'half', 'of', 'the', 'CPU', 'socket', 'using', 'the', 'numactl', 'command', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('In', 'IN'), ('addition', 'NN'), ('to', 'TO'), ('using', 'VBG'), ('multiple', 'JJ'), ('CPU', 'NNP'), ('threads', 'NNS'), ('during', 'IN'), ('inference', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('was', 'VBD'), ('also', 'RB'), ('able', 'JJ'), ('to', 'TO'), ('create', 'VB'), ('parallel', 'JJ'), ('inference', 'NN'), ('streams', 'NNS'), ('by', 'IN'), ('pinning', 'VBG'), ('each', 'DT'), ('stream', 'NN'), ('to', 'TO'), ('half', 'NN'), ('of', 'IN'), ('the', 'DT'), ('CPU', 'NNP'), ('socket', 'NN'), ('using', 'VBG'), ('the', 'DT'), ('numactl', 'JJ'), ('command', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['addition', 'using', 'multiple', 'CPU', 'threads', 'inference', ',', 'AbbVie', 'also', 'able', 'create', 'parallel', 'inference', 'streams', 'pinning', 'stream', 'half', 'CPU', 'socket', 'using', 'numactl', 'command', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('addition', 'NN'), ('using', 'VBG'), ('multiple', 'JJ'), ('CPU', 'NNP'), ('threads', 'NNS'), ('inference', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('also', 'RB'), ('able', 'JJ'), ('create', 'NN'), ('parallel', 'JJ'), ('inference', 'NN'), ('streams', 'NNS'), ('pinning', 'VBG'), ('stream', 'NN'), ('half', 'NN'), ('CPU', 'NNP'), ('socket', 'NN'), ('using', 'VBG'), ('numactl', 'JJ'), ('command', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['addition using', 'using multiple', 'multiple CPU', 'CPU threads', 'threads inference', 'inference ,', ', AbbVie', 'AbbVie also', 'also able', 'able create', 'create parallel', 'parallel inference', 'inference streams', 'streams pinning', 'pinning stream', 'stream half', 'half CPU', 'CPU socket', 'socket using', 'using numactl', 'numactl command', 'command .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['addition using multiple', 'using multiple CPU', 'multiple CPU threads', 'CPU threads inference', 'threads inference ,', 'inference , AbbVie', ', AbbVie also', 'AbbVie also able', 'also able create', 'able create parallel', 'create parallel inference', 'parallel inference streams', 'inference streams pinning', 'streams pinning stream', 'pinning stream half', 'stream half CPU', 'half CPU socket', 'CPU socket using', 'socket using numactl', 'using numactl command', 'numactl command .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['addition', 'inference', 'able create', 'parallel inference', 'stream', 'half', 'socket', 'numactl command'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['CPU', 'AbbVie', 'CPU']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['addit', 'use', 'multipl', 'cpu', 'thread', 'infer', ',', 'abbvi', 'also', 'abl', 'creat', 'parallel', 'infer', 'stream', 'pin', 'stream', 'half', 'cpu', 'socket', 'use', 'numactl', 'command', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['addit', 'use', 'multipl', 'cpu', 'thread', 'infer', ',', 'abbvi', 'also', 'abl', 'creat', 'parallel', 'infer', 'stream', 'pin', 'stream', 'half', 'cpu', 'socket', 'use', 'numactl', 'command', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['addition', 'using', 'multiple', 'CPU', 'thread', 'inference', ',', 'AbbVie', 'also', 'able', 'create', 'parallel', 'inference', 'stream', 'pinning', 'stream', 'half', 'CPU', 'socket', 'using', 'numactl', 'command', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

63 --> Figure 3 compares the model’s performance between un- optimized TensorFlow 1.15 (without) and the Intel Optimization  for TensorFlow (with). 


 ---- TOKENS ----

 ['Figure', '3', 'compares', 'the', 'model', '’', 's', 'performance', 'between', 'un-', 'optimized', 'TensorFlow', '1.15', '(', 'without', ')', 'and', 'the', 'Intel', 'Optimization', 'for', 'TensorFlow', '(', 'with', ')', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Figure', 'NN'), ('3', 'CD'), ('compares', 'VBZ'), ('the', 'DT'), ('model', 'NN'), ('’', 'NNP'), ('s', 'VBZ'), ('performance', 'NN'), ('between', 'IN'), ('un-', 'JJ'), ('optimized', 'VBN'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('without', 'IN'), (')', ')'), ('and', 'CC'), ('the', 'DT'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('for', 'IN'), ('TensorFlow', 'NNP'), ('(', '('), ('with', 'IN'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Figure', '3', 'compares', 'model', '’', 'performance', 'un-', 'optimized', 'TensorFlow', '1.15', '(', 'without', ')', 'Intel', 'Optimization', 'TensorFlow', '(', ')', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Figure', 'NN'), ('3', 'CD'), ('compares', 'VBZ'), ('model', 'NN'), ('’', 'JJ'), ('performance', 'NN'), ('un-', 'JJ'), ('optimized', 'VBN'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('without', 'IN'), (')', ')'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('TensorFlow', 'NNP'), ('(', '('), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Figure 3', '3 compares', 'compares model', 'model ’', '’ performance', 'performance un-', 'un- optimized', 'optimized TensorFlow', 'TensorFlow 1.15', '1.15 (', '( without', 'without )', ') Intel', 'Intel Optimization', 'Optimization TensorFlow', 'TensorFlow (', '( )', ') .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Figure 3 compares', '3 compares model', 'compares model ’', 'model ’ performance', '’ performance un-', 'performance un- optimized', 'un- optimized TensorFlow', 'optimized TensorFlow 1.15', 'TensorFlow 1.15 (', '1.15 ( without', '( without )', 'without ) Intel', ') Intel Optimization', 'Intel Optimization TensorFlow', 'Optimization TensorFlow (', 'TensorFlow ( )', '( ) .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['Figure', 'model', '’ performance'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['TensorFlow', 'Intel Optimization']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['figur', '3', 'compar', 'model', '’', 'perform', 'un-', 'optim', 'tensorflow', '1.15', '(', 'without', ')', 'intel', 'optim', 'tensorflow', '(', ')', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['figur', '3', 'compar', 'model', '’', 'perform', 'un-', 'optim', 'tensorflow', '1.15', '(', 'without', ')', 'intel', 'optim', 'tensorflow', '(', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Figure', '3', 'compare', 'model', '’', 'performance', 'un-', 'optimized', 'TensorFlow', '1.15', '(', 'without', ')', 'Intel', 'Optimization', 'TensorFlow', '(', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

64 --> In both cases, there were four parallel  inference streams with a batch size of 256 sentences. 


 ---- TOKENS ----

 ['In', 'both', 'cases', ',', 'there', 'were', 'four', 'parallel', 'inference', 'streams', 'with', 'a', 'batch', 'size', 'of', '256', 'sentences', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('In', 'IN'), ('both', 'DT'), ('cases', 'NNS'), (',', ','), ('there', 'EX'), ('were', 'VBD'), ('four', 'CD'), ('parallel', 'JJ'), ('inference', 'NN'), ('streams', 'NNS'), ('with', 'IN'), ('a', 'DT'), ('batch', 'NN'), ('size', 'NN'), ('of', 'IN'), ('256', 'CD'), ('sentences', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['cases', ',', 'four', 'parallel', 'inference', 'streams', 'batch', 'size', '256', 'sentences', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('cases', 'NNS'), (',', ','), ('four', 'CD'), ('parallel', 'JJ'), ('inference', 'NN'), ('streams', 'NNS'), ('batch', 'VBP'), ('size', 'NN'), ('256', 'CD'), ('sentences', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['cases ,', ', four', 'four parallel', 'parallel inference', 'inference streams', 'streams batch', 'batch size', 'size 256', '256 sentences', 'sentences .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['cases , four', ', four parallel', 'four parallel inference', 'parallel inference streams', 'inference streams batch', 'streams batch size', 'batch size 256', 'size 256 sentences', '256 sentences .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['parallel inference', 'size'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['case', ',', 'four', 'parallel', 'infer', 'stream', 'batch', 'size', '256', 'sentenc', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['case', ',', 'four', 'parallel', 'infer', 'stream', 'batch', 'size', '256', 'sentenc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['case', ',', 'four', 'parallel', 'inference', 'stream', 'batch', 'size', '256', 'sentence', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

65 --> The  effective throughput of all four parallel inference streams was  2.6 sentences per second without DNNL and 5.0 sentences  per second with. 


 ---- TOKENS ----

 ['The', 'effective', 'throughput', 'of', 'all', 'four', 'parallel', 'inference', 'streams', 'was', '2.6', 'sentences', 'per', 'second', 'without', 'DNNL', 'and', '5.0', 'sentences', 'per', 'second', 'with', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('The', 'DT'), ('effective', 'JJ'), ('throughput', 'NN'), ('of', 'IN'), ('all', 'DT'), ('four', 'CD'), ('parallel', 'JJ'), ('inference', 'NN'), ('streams', 'NNS'), ('was', 'VBD'), ('2.6', 'CD'), ('sentences', 'NNS'), ('per', 'IN'), ('second', 'NN'), ('without', 'IN'), ('DNNL', 'NNP'), ('and', 'CC'), ('5.0', 'CD'), ('sentences', 'NNS'), ('per', 'IN'), ('second', 'NN'), ('with', 'IN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['effective', 'throughput', 'four', 'parallel', 'inference', 'streams', '2.6', 'sentences', 'per', 'second', 'without', 'DNNL', '5.0', 'sentences', 'per', 'second', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('effective', 'JJ'), ('throughput', 'NN'), ('four', 'CD'), ('parallel', 'JJ'), ('inference', 'NN'), ('streams', 'VBD'), ('2.6', 'CD'), ('sentences', 'NNS'), ('per', 'IN'), ('second', 'NN'), ('without', 'IN'), ('DNNL', 'NNP'), ('5.0', 'CD'), ('sentences', 'NNS'), ('per', 'IN'), ('second', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['effective throughput', 'throughput four', 'four parallel', 'parallel inference', 'inference streams', 'streams 2.6', '2.6 sentences', 'sentences per', 'per second', 'second without', 'without DNNL', 'DNNL 5.0', '5.0 sentences', 'sentences per', 'per second', 'second .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['effective throughput four', 'throughput four parallel', 'four parallel inference', 'parallel inference streams', 'inference streams 2.6', 'streams 2.6 sentences', '2.6 sentences per', 'sentences per second', 'per second without', 'second without DNNL', 'without DNNL 5.0', 'DNNL 5.0 sentences', '5.0 sentences per', 'sentences per second', 'per second .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['effective throughput', 'parallel inference', 'second', 'second'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['DNNL']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['effect', 'throughput', 'four', 'parallel', 'infer', 'stream', '2.6', 'sentenc', 'per', 'second', 'without', 'dnnl', '5.0', 'sentenc', 'per', 'second', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['effect', 'throughput', 'four', 'parallel', 'infer', 'stream', '2.6', 'sentenc', 'per', 'second', 'without', 'dnnl', '5.0', 'sentenc', 'per', 'second', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['effective', 'throughput', 'four', 'parallel', 'inference', 'stream', '2.6', 'sentence', 'per', 'second', 'without', 'DNNL', '5.0', 'sentence', 'per', 'second', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

66 --> This is a 1.9x speedup over the unoptimized  TensorFlow 1.15 (without DNNL) and 10x the performance  requirements needed by AbbVie.1 Note that even without  optimizations, the raw CPU performance was sufficient  to meet the AbbVie requirement. 


 ---- TOKENS ----

 ['This', 'is', 'a', '1.9x', 'speedup', 'over', 'the', 'unoptimized', 'TensorFlow', '1.15', '(', 'without', 'DNNL', ')', 'and', '10x', 'the', 'performance', 'requirements', 'needed', 'by', 'AbbVie.1', 'Note', 'that', 'even', 'without', 'optimizations', ',', 'the', 'raw', 'CPU', 'performance', 'was', 'sufficient', 'to', 'meet', 'the', 'AbbVie', 'requirement', '.'] 

 TOTAL TOKENS ==> 40

 ---- POST ----

 [('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('1.9x', 'CD'), ('speedup', 'NN'), ('over', 'IN'), ('the', 'DT'), ('unoptimized', 'JJ'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('without', 'IN'), ('DNNL', 'NNP'), (')', ')'), ('and', 'CC'), ('10x', 'CD'), ('the', 'DT'), ('performance', 'NN'), ('requirements', 'NNS'), ('needed', 'VBN'), ('by', 'IN'), ('AbbVie.1', 'NNP'), ('Note', 'NNP'), ('that', 'IN'), ('even', 'RB'), ('without', 'IN'), ('optimizations', 'NNS'), (',', ','), ('the', 'DT'), ('raw', 'JJ'), ('CPU', 'NNP'), ('performance', 'NN'), ('was', 'VBD'), ('sufficient', 'JJ'), ('to', 'TO'), ('meet', 'VB'), ('the', 'DT'), ('AbbVie', 'NNP'), ('requirement', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.9x', 'speedup', 'unoptimized', 'TensorFlow', '1.15', '(', 'without', 'DNNL', ')', '10x', 'performance', 'requirements', 'needed', 'AbbVie.1', 'Note', 'even', 'without', 'optimizations', ',', 'raw', 'CPU', 'performance', 'sufficient', 'meet', 'AbbVie', 'requirement', '.']

 TOTAL FILTERED TOKENS ==>  27

 ---- POST FOR FILTERED TOKENS ----

 [('1.9x', 'CD'), ('speedup', 'JJ'), ('unoptimized', 'JJ'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('without', 'IN'), ('DNNL', 'NNP'), (')', ')'), ('10x', 'CD'), ('performance', 'NN'), ('requirements', 'NNS'), ('needed', 'VBN'), ('AbbVie.1', 'NNP'), ('Note', 'NNP'), ('even', 'RB'), ('without', 'IN'), ('optimizations', 'NNS'), (',', ','), ('raw', 'JJ'), ('CPU', 'NNP'), ('performance', 'NN'), ('sufficient', 'JJ'), ('meet', 'NN'), ('AbbVie', 'NNP'), ('requirement', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.9x speedup', 'speedup unoptimized', 'unoptimized TensorFlow', 'TensorFlow 1.15', '1.15 (', '( without', 'without DNNL', 'DNNL )', ') 10x', '10x performance', 'performance requirements', 'requirements needed', 'needed AbbVie.1', 'AbbVie.1 Note', 'Note even', 'even without', 'without optimizations', 'optimizations ,', ', raw', 'raw CPU', 'CPU performance', 'performance sufficient', 'sufficient meet', 'meet AbbVie', 'AbbVie requirement', 'requirement .'] 

 TOTAL BIGRAMS --> 26 



 ---- TRI-GRAMS ---- 

 ['1.9x speedup unoptimized', 'speedup unoptimized TensorFlow', 'unoptimized TensorFlow 1.15', 'TensorFlow 1.15 (', '1.15 ( without', '( without DNNL', 'without DNNL )', 'DNNL ) 10x', ') 10x performance', '10x performance requirements', 'performance requirements needed', 'requirements needed AbbVie.1', 'needed AbbVie.1 Note', 'AbbVie.1 Note even', 'Note even without', 'even without optimizations', 'without optimizations ,', 'optimizations , raw', ', raw CPU', 'raw CPU performance', 'CPU performance sufficient', 'performance sufficient meet', 'sufficient meet AbbVie', 'meet AbbVie requirement', 'AbbVie requirement .'] 

 TOTAL TRIGRAMS --> 25 



 ---- NOUN PHRASES ---- 

 ['performance', 'performance', 'sufficient meet', 'requirement'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['TensorFlow', 'CPU', 'AbbVie']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.9x', 'speedup', 'unoptim', 'tensorflow', '1.15', '(', 'without', 'dnnl', ')', '10x', 'perform', 'requir', 'need', 'abbvie.1', 'note', 'even', 'without', 'optim', ',', 'raw', 'cpu', 'perform', 'suffici', 'meet', 'abbvi', 'requir', '.']

 TOTAL PORTER STEM WORDS ==> 27



 ---- SNOWBALL STEMMING ----

['1.9x', 'speedup', 'unoptim', 'tensorflow', '1.15', '(', 'without', 'dnnl', ')', '10x', 'perform', 'requir', 'need', 'abbvie.1', 'note', 'even', 'without', 'optim', ',', 'raw', 'cpu', 'perform', 'suffici', 'meet', 'abbvi', 'requir', '.']

 TOTAL SNOWBALL STEM WORDS ==> 27



 ---- LEMMATIZATION ----

['1.9x', 'speedup', 'unoptimized', 'TensorFlow', '1.15', '(', 'without', 'DNNL', ')', '10x', 'performance', 'requirement', 'needed', 'AbbVie.1', 'Note', 'even', 'without', 'optimization', ',', 'raw', 'CPU', 'performance', 'sufficient', 'meet', 'AbbVie', 'requirement', '.']

 TOTAL LEMMATIZE WORDS ==> 27

************************************************************************************************************************

67 --> More importantly, the  performance of just a single stream using was over 2x the  AbbVie requirement, and only used 12 of the 48 cores on the  server. 


 ---- TOKENS ----

 ['More', 'importantly', ',', 'the', 'performance', 'of', 'just', 'a', 'single', 'stream', 'using', 'was', 'over', '2x', 'the', 'AbbVie', 'requirement', ',', 'and', 'only', 'used', '12', 'of', 'the', '48', 'cores', 'on', 'the', 'server', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('More', 'RBR'), ('importantly', 'RB'), (',', ','), ('the', 'DT'), ('performance', 'NN'), ('of', 'IN'), ('just', 'RB'), ('a', 'DT'), ('single', 'JJ'), ('stream', 'NN'), ('using', 'VBG'), ('was', 'VBD'), ('over', 'IN'), ('2x', 'CD'), ('the', 'DT'), ('AbbVie', 'NNP'), ('requirement', 'NN'), (',', ','), ('and', 'CC'), ('only', 'RB'), ('used', 'VBD'), ('12', 'CD'), ('of', 'IN'), ('the', 'DT'), ('48', 'CD'), ('cores', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('server', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['importantly', ',', 'performance', 'single', 'stream', 'using', '2x', 'AbbVie', 'requirement', ',', 'used', '12', '48', 'cores', 'server', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('importantly', 'RB'), (',', ','), ('performance', 'NN'), ('single', 'JJ'), ('stream', 'NN'), ('using', 'VBG'), ('2x', 'CD'), ('AbbVie', 'NNP'), ('requirement', 'NN'), (',', ','), ('used', 'VBD'), ('12', 'CD'), ('48', 'CD'), ('cores', 'NNS'), ('server', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['importantly ,', ', performance', 'performance single', 'single stream', 'stream using', 'using 2x', '2x AbbVie', 'AbbVie requirement', 'requirement ,', ', used', 'used 12', '12 48', '48 cores', 'cores server', 'server .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['importantly , performance', ', performance single', 'performance single stream', 'single stream using', 'stream using 2x', 'using 2x AbbVie', '2x AbbVie requirement', 'AbbVie requirement ,', 'requirement , used', ', used 12', 'used 12 48', '12 48 cores', '48 cores server', 'cores server .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['performance', 'single stream', 'requirement'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['importantli', ',', 'perform', 'singl', 'stream', 'use', '2x', 'abbvi', 'requir', ',', 'use', '12', '48', 'core', 'server', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['import', ',', 'perform', 'singl', 'stream', 'use', '2x', 'abbvi', 'requir', ',', 'use', '12', '48', 'core', 'server', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['importantly', ',', 'performance', 'single', 'stream', 'using', '2x', 'AbbVie', 'requirement', ',', 'used', '12', '48', 'core', 'server', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

68 --> This means that AbbVie could easily process Abbelfish  translation workloads and still have 36 CPU cores (75 percent  Figure 3. 


 ---- TOKENS ----

 ['This', 'means', 'that', 'AbbVie', 'could', 'easily', 'process', 'Abbelfish', 'translation', 'workloads', 'and', 'still', 'have', '36', 'CPU', 'cores', '(', '75', 'percent', 'Figure', '3', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('This', 'DT'), ('means', 'VBZ'), ('that', 'IN'), ('AbbVie', 'NNP'), ('could', 'MD'), ('easily', 'RB'), ('process', 'VB'), ('Abbelfish', 'JJ'), ('translation', 'NN'), ('workloads', 'NNS'), ('and', 'CC'), ('still', 'RB'), ('have', 'VB'), ('36', 'CD'), ('CPU', 'NNP'), ('cores', 'NNS'), ('(', '('), ('75', 'CD'), ('percent', 'NN'), ('Figure', 'NN'), ('3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['means', 'AbbVie', 'could', 'easily', 'process', 'Abbelfish', 'translation', 'workloads', 'still', '36', 'CPU', 'cores', '(', '75', 'percent', 'Figure', '3', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('means', 'NNS'), ('AbbVie', 'NNP'), ('could', 'MD'), ('easily', 'RB'), ('process', 'VB'), ('Abbelfish', 'JJ'), ('translation', 'NN'), ('workloads', 'NNS'), ('still', 'RB'), ('36', 'CD'), ('CPU', 'NNP'), ('cores', 'NNS'), ('(', '('), ('75', 'CD'), ('percent', 'NN'), ('Figure', 'NN'), ('3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['means AbbVie', 'AbbVie could', 'could easily', 'easily process', 'process Abbelfish', 'Abbelfish translation', 'translation workloads', 'workloads still', 'still 36', '36 CPU', 'CPU cores', 'cores (', '( 75', '75 percent', 'percent Figure', 'Figure 3', '3 .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['means AbbVie could', 'AbbVie could easily', 'could easily process', 'easily process Abbelfish', 'process Abbelfish translation', 'Abbelfish translation workloads', 'translation workloads still', 'workloads still 36', 'still 36 CPU', '36 CPU cores', 'CPU cores (', 'cores ( 75', '( 75 percent', '75 percent Figure', 'percent Figure 3', 'Figure 3 .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['mean', 'abbvi', 'could', 'easili', 'process', 'abbelfish', 'translat', 'workload', 'still', '36', 'cpu', 'core', '(', '75', 'percent', 'figur', '3', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['mean', 'abbvi', 'could', 'easili', 'process', 'abbelfish', 'translat', 'workload', 'still', '36', 'cpu', 'core', '(', '75', 'percent', 'figur', '3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['mean', 'AbbVie', 'could', 'easily', 'process', 'Abbelfish', 'translation', 'workload', 'still', '36', 'CPU', 'core', '(', '75', 'percent', 'Figure', '3', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

69 --> AbbVie's Abbelfish translated over five sentences per  second using Intel Optimization for TensorFlow with oneAPI Deep  Neural Network Library (oneDNN).1  Figure 4. 


 ---- TOKENS ----

 ['AbbVie', "'s", 'Abbelfish', 'translated', 'over', 'five', 'sentences', 'per', 'second', 'using', 'Intel', 'Optimization', 'for', 'TensorFlow', 'with', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', '.1', 'Figure', '4', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('AbbVie', 'NNP'), ("'s", 'POS'), ('Abbelfish', 'NNP'), ('translated', 'VBD'), ('over', 'RP'), ('five', 'CD'), ('sentences', 'NNS'), ('per', 'IN'), ('second', 'JJ'), ('using', 'VBG'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('for', 'IN'), ('TensorFlow', 'NNP'), ('with', 'IN'), ('oneAPI', 'JJ'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('(', '('), ('oneDNN', 'NN'), (')', ')'), ('.1', 'VBZ'), ('Figure', '$'), ('4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['AbbVie', "'s", 'Abbelfish', 'translated', 'five', 'sentences', 'per', 'second', 'using', 'Intel', 'Optimization', 'TensorFlow', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', '.1', 'Figure', '4', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('AbbVie', 'NNP'), ("'s", 'POS'), ('Abbelfish', 'NNP'), ('translated', 'VBD'), ('five', 'CD'), ('sentences', 'NNS'), ('per', 'IN'), ('second', 'JJ'), ('using', 'VBG'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('TensorFlow', 'NNP'), ('oneAPI', 'MD'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('(', '('), ('oneDNN', 'NN'), (')', ')'), ('.1', 'VBZ'), ('Figure', '$'), ('4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ["AbbVie 's", "'s Abbelfish", 'Abbelfish translated', 'translated five', 'five sentences', 'sentences per', 'per second', 'second using', 'using Intel', 'Intel Optimization', 'Optimization TensorFlow', 'TensorFlow oneAPI', 'oneAPI Deep', 'Deep Neural', 'Neural Network', 'Network Library', 'Library (', '( oneDNN', 'oneDNN )', ') .1', '.1 Figure', 'Figure 4', '4 .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ["AbbVie 's Abbelfish", "'s Abbelfish translated", 'Abbelfish translated five', 'translated five sentences', 'five sentences per', 'sentences per second', 'per second using', 'second using Intel', 'using Intel Optimization', 'Intel Optimization TensorFlow', 'Optimization TensorFlow oneAPI', 'TensorFlow oneAPI Deep', 'oneAPI Deep Neural', 'Deep Neural Network', 'Neural Network Library', 'Network Library (', 'Library ( oneDNN', '( oneDNN )', 'oneDNN ) .1', ') .1 Figure', '.1 Figure 4', 'Figure 4 .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Optimization']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Abbelfish', 'Deep Neural Network Library']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> ['AbbVie']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbvi', "'s", 'abbelfish', 'translat', 'five', 'sentenc', 'per', 'second', 'use', 'intel', 'optim', 'tensorflow', 'oneapi', 'deep', 'neural', 'network', 'librari', '(', 'onednn', ')', '.1', 'figur', '4', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['abbvi', "'s", 'abbelfish', 'translat', 'five', 'sentenc', 'per', 'second', 'use', 'intel', 'optim', 'tensorflow', 'oneapi', 'deep', 'neural', 'network', 'librari', '(', 'onednn', ')', '.1', 'figur', '4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['AbbVie', "'s", 'Abbelfish', 'translated', 'five', 'sentence', 'per', 'second', 'using', 'Intel', 'Optimization', 'TensorFlow', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', '.1', 'Figure', '4', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

70 --> Abbelfish performance using Intel Optimization for  TensorFlow 1.15 with oneDNN.1 of the remaining compute) for other simultaneous workloads  (Figure 4). 


 ---- TOKENS ----

 ['Abbelfish', 'performance', 'using', 'Intel', 'Optimization', 'for', 'TensorFlow', '1.15', 'with', 'oneDNN.1', 'of', 'the', 'remaining', 'compute', ')', 'for', 'other', 'simultaneous', 'workloads', '(', 'Figure', '4', ')', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Abbelfish', 'JJ'), ('performance', 'NN'), ('using', 'VBG'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('for', 'IN'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('with', 'IN'), ('oneDNN.1', 'NN'), ('of', 'IN'), ('the', 'DT'), ('remaining', 'VBG'), ('compute', 'NN'), (')', ')'), ('for', 'IN'), ('other', 'JJ'), ('simultaneous', 'JJ'), ('workloads', 'NNS'), ('(', '('), ('Figure', 'NNP'), ('4', 'CD'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Abbelfish', 'performance', 'using', 'Intel', 'Optimization', 'TensorFlow', '1.15', 'oneDNN.1', 'remaining', 'compute', ')', 'simultaneous', 'workloads', '(', 'Figure', '4', ')', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Abbelfish', 'JJ'), ('performance', 'NN'), ('using', 'VBG'), ('Intel', 'NNP'), ('Optimization', 'NNP'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('oneDNN.1', 'NN'), ('remaining', 'VBG'), ('compute', 'NN'), (')', ')'), ('simultaneous', 'JJ'), ('workloads', 'NNS'), ('(', '('), ('Figure', 'NNP'), ('4', 'CD'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Abbelfish performance', 'performance using', 'using Intel', 'Intel Optimization', 'Optimization TensorFlow', 'TensorFlow 1.15', '1.15 oneDNN.1', 'oneDNN.1 remaining', 'remaining compute', 'compute )', ') simultaneous', 'simultaneous workloads', 'workloads (', '( Figure', 'Figure 4', '4 )', ') .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Abbelfish performance using', 'performance using Intel', 'using Intel Optimization', 'Intel Optimization TensorFlow', 'Optimization TensorFlow 1.15', 'TensorFlow 1.15 oneDNN.1', '1.15 oneDNN.1 remaining', 'oneDNN.1 remaining compute', 'remaining compute )', 'compute ) simultaneous', ') simultaneous workloads', 'simultaneous workloads (', 'workloads ( Figure', '( Figure 4', 'Figure 4 )', '4 ) .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['abbelfish', 'perform', 'use', 'intel', 'optim', 'tensorflow', '1.15', 'onednn.1', 'remain', 'comput', ')', 'simultan', 'workload', '(', 'figur', '4', ')', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['abbelfish', 'perform', 'use', 'intel', 'optim', 'tensorflow', '1.15', 'onednn.1', 'remain', 'comput', ')', 'simultan', 'workload', '(', 'figur', '4', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Abbelfish', 'performance', 'using', 'Intel', 'Optimization', 'TensorFlow', '1.15', 'oneDNN.1', 'remaining', 'compute', ')', 'simultaneous', 'workload', '(', 'Figure', '4', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

71 --> This greatly simplifies AbbVie’s deployment because  they can seamlessly adjust the Intel Xeon processor-based  server to their desired balance of AI versus non-AI workload  performance. 


 ---- TOKENS ----

 ['This', 'greatly', 'simplifies', 'AbbVie', '’', 's', 'deployment', 'because', 'they', 'can', 'seamlessly', 'adjust', 'the', 'Intel', 'Xeon', 'processor-based', 'server', 'to', 'their', 'desired', 'balance', 'of', 'AI', 'versus', 'non-AI', 'workload', 'performance', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('This', 'DT'), ('greatly', 'JJ'), ('simplifies', 'VBZ'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('deployment', 'NN'), ('because', 'IN'), ('they', 'PRP'), ('can', 'MD'), ('seamlessly', 'RB'), ('adjust', 'VB'), ('the', 'DT'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-based', 'JJ'), ('server', 'NN'), ('to', 'TO'), ('their', 'PRP$'), ('desired', 'JJ'), ('balance', 'NN'), ('of', 'IN'), ('AI', 'NNP'), ('versus', 'IN'), ('non-AI', 'JJ'), ('workload', 'NN'), ('performance', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['greatly', 'simplifies', 'AbbVie', '’', 'deployment', 'seamlessly', 'adjust', 'Intel', 'Xeon', 'processor-based', 'server', 'desired', 'balance', 'AI', 'versus', 'non-AI', 'workload', 'performance', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('greatly', 'RB'), ('simplifies', 'NNS'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('deployment', 'NN'), ('seamlessly', 'RB'), ('adjust', 'JJ'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-based', 'JJ'), ('server', 'NN'), ('desired', 'VBD'), ('balance', 'NN'), ('AI', 'NNP'), ('versus', 'IN'), ('non-AI', 'JJ'), ('workload', 'NN'), ('performance', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['greatly simplifies', 'simplifies AbbVie', 'AbbVie ’', '’ deployment', 'deployment seamlessly', 'seamlessly adjust', 'adjust Intel', 'Intel Xeon', 'Xeon processor-based', 'processor-based server', 'server desired', 'desired balance', 'balance AI', 'AI versus', 'versus non-AI', 'non-AI workload', 'workload performance', 'performance .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['greatly simplifies AbbVie', 'simplifies AbbVie ’', 'AbbVie ’ deployment', '’ deployment seamlessly', 'deployment seamlessly adjust', 'seamlessly adjust Intel', 'adjust Intel Xeon', 'Intel Xeon processor-based', 'Xeon processor-based server', 'processor-based server desired', 'server desired balance', 'desired balance AI', 'balance AI versus', 'AI versus non-AI', 'versus non-AI workload', 'non-AI workload performance', 'workload performance .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['deployment', 'processor-based server', 'balance', 'non-AI workload', 'performance'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie', 'Intel Xeon']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['greatli', 'simplifi', 'abbvi', '’', 'deploy', 'seamlessli', 'adjust', 'intel', 'xeon', 'processor-bas', 'server', 'desir', 'balanc', 'ai', 'versu', 'non-ai', 'workload', 'perform', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['great', 'simplifi', 'abbvi', '’', 'deploy', 'seamless', 'adjust', 'intel', 'xeon', 'processor-bas', 'server', 'desir', 'balanc', 'ai', 'versus', 'non-ai', 'workload', 'perform', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['greatly', 'simplifies', 'AbbVie', '’', 'deployment', 'seamlessly', 'adjust', 'Intel', 'Xeon', 'processor-based', 'server', 'desired', 'balance', 'AI', 'versus', 'non-AI', 'workload', 'performance', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

72 --> Intel® Xeon® Gold 6252N  Processor 1.9x speedup. 


 ---- TOKENS ----

 ['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '1.9x', 'speedup', '.'] 

 TOTAL TOKENS ==> 8

 ---- POST ----

 [('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('1.9x', 'CD'), ('speedup', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '1.9x', 'speedup', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('1.9x', 'CD'), ('speedup', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel® Xeon®', 'Xeon® Gold', 'Gold 6252N', '6252N Processor', 'Processor 1.9x', '1.9x speedup', 'speedup .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Intel® Xeon® Gold', 'Xeon® Gold 6252N', 'Gold 6252N Processor', '6252N Processor 1.9x', 'Processor 1.9x speedup', '1.9x speedup .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['speedup'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel®', 'xeon®', 'gold', '6252n', 'processor', '1.9x', 'speedup', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['intel®', 'xeon®', 'gold', '6252n', 'processor', '1.9x', 'speedup', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '1.9x', 'speedup', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

73 --> Higher is better. 


 ---- TOKENS ----

 ['Higher', 'is', 'better', '.'] 

 TOTAL TOKENS ==> 4

 ---- POST ----

 [('Higher', 'JJR'), ('is', 'VBZ'), ('better', 'RBR'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Higher', 'better', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Higher', 'JJR'), ('better', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Higher better', 'better .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Higher better .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['better'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['higher', 'better', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['higher', 'better', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Higher', 'better', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

74 --> Abbelfish Model Performance Se nt en ce s  p er  s ec on d DNNL Disabled 5 4 3 2 1 0 DNNL Enabled Desired performance 5.0 2.6 Intel® Xeon® Gold 6252N  Processor Se nt en ce s  p er  s ec on d 1 stream (12 cores) 4 stream (48 cores) 5 4 3 2 1 0 Desired performance 5.0 1.7 Abbelfish Single Versus Multiple Streams Figure 5. 


 ---- TOKENS ----

 ['Abbelfish', 'Model', 'Performance', 'Se', 'nt', 'en', 'ce', 's', 'p', 'er', 's', 'ec', 'on', 'd', 'DNNL', 'Disabled', '5', '4', '3', '2', '1', '0', 'DNNL', 'Enabled', 'Desired', 'performance', '5.0', '2.6', 'Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', 'Se', 'nt', 'en', 'ce', 's', 'p', 'er', 's', 'ec', 'on', 'd', '1', 'stream', '(', '12', 'cores', ')', '4', 'stream', '(', '48', 'cores', ')', '5', '4', '3', '2', '1', '0', 'Desired', 'performance', '5.0', '1.7', 'Abbelfish', 'Single', 'Versus', 'Multiple', 'Streams', 'Figure', '5', '.'] 

 TOTAL TOKENS ==> 74

 ---- POST ----

 [('Abbelfish', 'JJ'), ('Model', 'NNP'), ('Performance', 'NNP'), ('Se', 'NNP'), ('nt', 'MD'), ('en', 'VB'), ('ce', 'NN'), ('s', 'NN'), ('p', 'NN'), ('er', 'NN'), ('s', 'VBP'), ('ec', 'NN'), ('on', 'IN'), ('d', 'NN'), ('DNNL', 'NNP'), ('Disabled', 'VBD'), ('5', 'CD'), ('4', 'CD'), ('3', 'CD'), ('2', 'CD'), ('1', 'CD'), ('0', 'CD'), ('DNNL', 'NNP'), ('Enabled', 'VBD'), ('Desired', 'NNP'), ('performance', 'NN'), ('5.0', 'CD'), ('2.6', 'CD'), ('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('Se', 'NNP'), ('nt', 'MD'), ('en', 'VB'), ('ce', 'NN'), ('s', 'NN'), ('p', 'NN'), ('er', 'NN'), ('s', 'VBP'), ('ec', 'NN'), ('on', 'IN'), ('d', 'NN'), ('1', 'CD'), ('stream', 'NN'), ('(', '('), ('12', 'CD'), ('cores', 'NNS'), (')', ')'), ('4', 'CD'), ('stream', 'NN'), ('(', '('), ('48', 'CD'), ('cores', 'NNS'), (')', ')'), ('5', 'CD'), ('4', 'CD'), ('3', 'CD'), ('2', 'CD'), ('1', 'CD'), ('0', 'CD'), ('Desired', 'NNP'), ('performance', 'NN'), ('5.0', 'CD'), ('1.7', 'CD'), ('Abbelfish', 'JJ'), ('Single', 'NNP'), ('Versus', 'NNP'), ('Multiple', 'NNP'), ('Streams', 'NNP'), ('Figure', 'NNP'), ('5', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Abbelfish', 'Model', 'Performance', 'Se', 'nt', 'en', 'ce', 'p', 'er', 'ec', 'DNNL', 'Disabled', '5', '4', '3', '2', '1', '0', 'DNNL', 'Enabled', 'Desired', 'performance', '5.0', '2.6', 'Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', 'Se', 'nt', 'en', 'ce', 'p', 'er', 'ec', '1', 'stream', '(', '12', 'cores', ')', '4', 'stream', '(', '48', 'cores', ')', '5', '4', '3', '2', '1', '0', 'Desired', 'performance', '5.0', '1.7', 'Abbelfish', 'Single', 'Versus', 'Multiple', 'Streams', 'Figure', '5', '.']

 TOTAL FILTERED TOKENS ==>  66

 ---- POST FOR FILTERED TOKENS ----

 [('Abbelfish', 'JJ'), ('Model', 'NNP'), ('Performance', 'NNP'), ('Se', 'NNP'), ('nt', 'MD'), ('en', 'VB'), ('ce', 'NN'), ('p', 'NN'), ('er', 'VBP'), ('ec', 'JJ'), ('DNNL', 'NNP'), ('Disabled', 'VBD'), ('5', 'CD'), ('4', 'CD'), ('3', 'CD'), ('2', 'CD'), ('1', 'CD'), ('0', 'CD'), ('DNNL', 'NNP'), ('Enabled', 'VBD'), ('Desired', 'NNP'), ('performance', 'NN'), ('5.0', 'CD'), ('2.6', 'CD'), ('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('Se', 'NNP'), ('nt', 'MD'), ('en', 'VB'), ('ce', 'NN'), ('p', 'NN'), ('er', 'VBP'), ('ec', '$'), ('1', 'CD'), ('stream', 'NN'), ('(', '('), ('12', 'CD'), ('cores', 'NNS'), (')', ')'), ('4', 'CD'), ('stream', 'NN'), ('(', '('), ('48', 'CD'), ('cores', 'NNS'), (')', ')'), ('5', 'CD'), ('4', 'CD'), ('3', 'CD'), ('2', 'CD'), ('1', 'CD'), ('0', 'CD'), ('Desired', 'NNP'), ('performance', 'NN'), ('5.0', 'CD'), ('1.7', 'CD'), ('Abbelfish', 'JJ'), ('Single', 'NNP'), ('Versus', 'NNP'), ('Multiple', 'NNP'), ('Streams', 'NNP'), ('Figure', 'NNP'), ('5', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Abbelfish Model', 'Model Performance', 'Performance Se', 'Se nt', 'nt en', 'en ce', 'ce p', 'p er', 'er ec', 'ec DNNL', 'DNNL Disabled', 'Disabled 5', '5 4', '4 3', '3 2', '2 1', '1 0', '0 DNNL', 'DNNL Enabled', 'Enabled Desired', 'Desired performance', 'performance 5.0', '5.0 2.6', '2.6 Intel®', 'Intel® Xeon®', 'Xeon® Gold', 'Gold 6252N', '6252N Processor', 'Processor Se', 'Se nt', 'nt en', 'en ce', 'ce p', 'p er', 'er ec', 'ec 1', '1 stream', 'stream (', '( 12', '12 cores', 'cores )', ') 4', '4 stream', 'stream (', '( 48', '48 cores', 'cores )', ') 5', '5 4', '4 3', '3 2', '2 1', '1 0', '0 Desired', 'Desired performance', 'performance 5.0', '5.0 1.7', '1.7 Abbelfish', 'Abbelfish Single', 'Single Versus', 'Versus Multiple', 'Multiple Streams', 'Streams Figure', 'Figure 5', '5 .'] 

 TOTAL BIGRAMS --> 65 



 ---- TRI-GRAMS ---- 

 ['Abbelfish Model Performance', 'Model Performance Se', 'Performance Se nt', 'Se nt en', 'nt en ce', 'en ce p', 'ce p er', 'p er ec', 'er ec DNNL', 'ec DNNL Disabled', 'DNNL Disabled 5', 'Disabled 5 4', '5 4 3', '4 3 2', '3 2 1', '2 1 0', '1 0 DNNL', '0 DNNL Enabled', 'DNNL Enabled Desired', 'Enabled Desired performance', 'Desired performance 5.0', 'performance 5.0 2.6', '5.0 2.6 Intel®', '2.6 Intel® Xeon®', 'Intel® Xeon® Gold', 'Xeon® Gold 6252N', 'Gold 6252N Processor', '6252N Processor Se', 'Processor Se nt', 'Se nt en', 'nt en ce', 'en ce p', 'ce p er', 'p er ec', 'er ec 1', 'ec 1 stream', '1 stream (', 'stream ( 12', '( 12 cores', '12 cores )', 'cores ) 4', ') 4 stream', '4 stream (', 'stream ( 48', '( 48 cores', '48 cores )', 'cores ) 5', ') 5 4', '5 4 3', '4 3 2', '3 2 1', '2 1 0', '1 0 Desired', '0 Desired performance', 'Desired performance 5.0', 'performance 5.0 1.7', '5.0 1.7 Abbelfish', '1.7 Abbelfish Single', 'Abbelfish Single Versus', 'Single Versus Multiple', 'Versus Multiple Streams', 'Multiple Streams Figure', 'Streams Figure 5', 'Figure 5 .'] 

 TOTAL TRIGRAMS --> 64 



 ---- NOUN PHRASES ---- 

 ['ce', 'p', 'performance', 'ce', 'p', 'stream', 'stream', 'performance'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['DNNL', 'DNNL', 'Single Versus Multiple Streams']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> ['Model Performance Se']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Abbelfish']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbelfish', 'model', 'perform', 'se', 'nt', 'en', 'ce', 'p', 'er', 'ec', 'dnnl', 'disabl', '5', '4', '3', '2', '1', '0', 'dnnl', 'enabl', 'desir', 'perform', '5.0', '2.6', 'intel®', 'xeon®', 'gold', '6252n', 'processor', 'se', 'nt', 'en', 'ce', 'p', 'er', 'ec', '1', 'stream', '(', '12', 'core', ')', '4', 'stream', '(', '48', 'core', ')', '5', '4', '3', '2', '1', '0', 'desir', 'perform', '5.0', '1.7', 'abbelfish', 'singl', 'versu', 'multipl', 'stream', 'figur', '5', '.']

 TOTAL PORTER STEM WORDS ==> 66



 ---- SNOWBALL STEMMING ----

['abbelfish', 'model', 'perform', 'se', 'nt', 'en', 'ce', 'p', 'er', 'ec', 'dnnl', 'disabl', '5', '4', '3', '2', '1', '0', 'dnnl', 'enabl', 'desir', 'perform', '5.0', '2.6', 'intel®', 'xeon®', 'gold', '6252n', 'processor', 'se', 'nt', 'en', 'ce', 'p', 'er', 'ec', '1', 'stream', '(', '12', 'core', ')', '4', 'stream', '(', '48', 'core', ')', '5', '4', '3', '2', '1', '0', 'desir', 'perform', '5.0', '1.7', 'abbelfish', 'singl', 'versus', 'multipl', 'stream', 'figur', '5', '.']

 TOTAL SNOWBALL STEM WORDS ==> 66



 ---- LEMMATIZATION ----

['Abbelfish', 'Model', 'Performance', 'Se', 'nt', 'en', 'ce', 'p', 'er', 'ec', 'DNNL', 'Disabled', '5', '4', '3', '2', '1', '0', 'DNNL', 'Enabled', 'Desired', 'performance', '5.0', '2.6', 'Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', 'Se', 'nt', 'en', 'ce', 'p', 'er', 'ec', '1', 'stream', '(', '12', 'core', ')', '4', 'stream', '(', '48', 'core', ')', '5', '4', '3', '2', '1', '0', 'Desired', 'performance', '5.0', '1.7', 'Abbelfish', 'Single', 'Versus', 'Multiple', 'Streams', 'Figure', '5', '.']

 TOTAL LEMMATIZE WORDS ==> 66

************************************************************************************************************************

75 --> Comparison of AbbVie Search inference between  unoptimized TensorFlow 1.15 (oneDNN disabled) and OpenVINO  toolkit 2020.3.1 1See backup for configuration details. 


 ---- TOKENS ----

 ['Comparison', 'of', 'AbbVie', 'Search', 'inference', 'between', 'unoptimized', 'TensorFlow', '1.15', '(', 'oneDNN', 'disabled', ')', 'and', 'OpenVINO', 'toolkit', '2020.3.1', '1See', 'backup', 'for', 'configuration', 'details', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Comparison', 'NNP'), ('of', 'IN'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('inference', 'NN'), ('between', 'IN'), ('unoptimized', 'JJ'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('oneDNN', 'PRP'), ('disabled', 'VBN'), (')', ')'), ('and', 'CC'), ('OpenVINO', 'NNP'), ('toolkit', 'VBD'), ('2020.3.1', 'CD'), ('1See', 'CD'), ('backup', 'NN'), ('for', 'IN'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Comparison', 'AbbVie', 'Search', 'inference', 'unoptimized', 'TensorFlow', '1.15', '(', 'oneDNN', 'disabled', ')', 'OpenVINO', 'toolkit', '2020.3.1', '1See', 'backup', 'configuration', 'details', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Comparison', 'NNP'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('inference', 'NN'), ('unoptimized', 'VBD'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('oneDNN', 'PRP'), ('disabled', 'VBD'), (')', ')'), ('OpenVINO', 'NNP'), ('toolkit', '$'), ('2020.3.1', 'CD'), ('1See', 'CD'), ('backup', 'NN'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Comparison AbbVie', 'AbbVie Search', 'Search inference', 'inference unoptimized', 'unoptimized TensorFlow', 'TensorFlow 1.15', '1.15 (', '( oneDNN', 'oneDNN disabled', 'disabled )', ') OpenVINO', 'OpenVINO toolkit', 'toolkit 2020.3.1', '2020.3.1 1See', '1See backup', 'backup configuration', 'configuration details', 'details .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Comparison AbbVie Search', 'AbbVie Search inference', 'Search inference unoptimized', 'inference unoptimized TensorFlow', 'unoptimized TensorFlow 1.15', 'TensorFlow 1.15 (', '1.15 ( oneDNN', '( oneDNN disabled', 'oneDNN disabled )', 'disabled ) OpenVINO', ') OpenVINO toolkit', 'OpenVINO toolkit 2020.3.1', 'toolkit 2020.3.1 1See', '2020.3.1 1See backup', '1See backup configuration', 'backup configuration details', 'configuration details .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['inference', 'backup', 'configuration'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['Comparison', 'AbbVie Search', 'TensorFlow']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['comparison', 'abbvi', 'search', 'infer', 'unoptim', 'tensorflow', '1.15', '(', 'onednn', 'disabl', ')', 'openvino', 'toolkit', '2020.3.1', '1see', 'backup', 'configur', 'detail', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['comparison', 'abbvi', 'search', 'infer', 'unoptim', 'tensorflow', '1.15', '(', 'onednn', 'disabl', ')', 'openvino', 'toolkit', '2020.3.1', '1see', 'backup', 'configur', 'detail', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Comparison', 'AbbVie', 'Search', 'inference', 'unoptimized', 'TensorFlow', '1.15', '(', 'oneDNN', 'disabled', ')', 'OpenVINO', 'toolkit', '2020.3.1', '1See', 'backup', 'configuration', 'detail', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

76 --> For more complete information about performance and benchmark results, visit www.intel.com/benchmarks. 


 ---- TOKENS ----

 ['For', 'more', 'complete', 'information', 'about', 'performance', 'and', 'benchmark', 'results', ',', 'visit', 'www.intel.com/benchmarks', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('For', 'IN'), ('more', 'JJR'), ('complete', 'JJ'), ('information', 'NN'), ('about', 'IN'), ('performance', 'NN'), ('and', 'CC'), ('benchmark', 'NN'), ('results', 'NNS'), (',', ','), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['complete', 'information', 'performance', 'benchmark', 'results', ',', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('complete', 'JJ'), ('information', 'NN'), ('performance', 'NN'), ('benchmark', 'NN'), ('results', 'NNS'), (',', ','), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['complete information', 'information performance', 'performance benchmark', 'benchmark results', 'results ,', ', visit', 'visit www.intel.com/benchmarks', 'www.intel.com/benchmarks .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['complete information performance', 'information performance benchmark', 'performance benchmark results', 'benchmark results ,', 'results , visit', ', visit www.intel.com/benchmarks', 'visit www.intel.com/benchmarks .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['complete information', 'performance', 'benchmark', 'visit'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['complet', 'inform', 'perform', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['complet', 'inform', 'perform', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['complete', 'information', 'performance', 'benchmark', 'result', ',', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

77 --> Intel® Xeon® Gold 6252N  Processor 5.3x speedup. 


 ---- TOKENS ----

 ['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '5.3x', 'speedup', '.'] 

 TOTAL TOKENS ==> 8

 ---- POST ----

 [('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('5.3x', 'CD'), ('speedup', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '5.3x', 'speedup', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('5.3x', 'CD'), ('speedup', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel® Xeon®', 'Xeon® Gold', 'Gold 6252N', '6252N Processor', 'Processor 5.3x', '5.3x speedup', 'speedup .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Intel® Xeon® Gold', 'Xeon® Gold 6252N', 'Gold 6252N Processor', '6252N Processor 5.3x', 'Processor 5.3x speedup', '5.3x speedup .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['speedup'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel®', 'xeon®', 'gold', '6252n', 'processor', '5.3x', 'speedup', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['intel®', 'xeon®', 'gold', '6252n', 'processor', '5.3x', 'speedup', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '5.3x', 'speedup', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

78 --> Higher is better. 


 ---- TOKENS ----

 ['Higher', 'is', 'better', '.'] 

 TOTAL TOKENS ==> 4

 ---- POST ----

 [('Higher', 'JJR'), ('is', 'VBZ'), ('better', 'RBR'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Higher', 'better', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Higher', 'JJR'), ('better', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Higher better', 'better .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Higher better .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['better'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['higher', 'better', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['higher', 'better', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Higher', 'better', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

79 --> Q ue st io ns  p er  s ec on d Standard TensorFlow 1.15 OpenVINO toolkit 2020.3 16 12 8 4 0 17.9 3.4 AbbVie Search Model Performance Figure 5 shows the performance of the AbbVie Search  question/answer model. 


 ---- TOKENS ----

 ['Q', 'ue', 'st', 'io', 'ns', 'p', 'er', 's', 'ec', 'on', 'd', 'Standard', 'TensorFlow', '1.15', 'OpenVINO', 'toolkit', '2020.3', '16', '12', '8', '4', '0', '17.9', '3.4', 'AbbVie', 'Search', 'Model', 'Performance', 'Figure', '5', 'shows', 'the', 'performance', 'of', 'the', 'AbbVie', 'Search', 'question/answer', 'model', '.'] 

 TOTAL TOKENS ==> 40

 ---- POST ----

 [('Q', 'NNP'), ('ue', 'JJ'), ('st', 'NN'), ('io', 'NN'), ('ns', 'JJ'), ('p', 'NN'), ('er', 'NN'), ('s', 'VBP'), ('ec', 'NN'), ('on', 'IN'), ('d', 'JJ'), ('Standard', 'NNP'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('OpenVINO', 'NNP'), ('toolkit', 'VBD'), ('2020.3', 'CD'), ('16', 'CD'), ('12', 'CD'), ('8', 'CD'), ('4', 'CD'), ('0', 'CD'), ('17.9', 'CD'), ('3.4', 'CD'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('Model', 'NNP'), ('Performance', 'NNP'), ('Figure', 'NNP'), ('5', 'CD'), ('shows', 'VBZ'), ('the', 'DT'), ('performance', 'NN'), ('of', 'IN'), ('the', 'DT'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('question/answer', 'JJR'), ('model', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Q', 'ue', 'st', 'io', 'ns', 'p', 'er', 'ec', 'Standard', 'TensorFlow', '1.15', 'OpenVINO', 'toolkit', '2020.3', '16', '12', '8', '4', '0', '17.9', '3.4', 'AbbVie', 'Search', 'Model', 'Performance', 'Figure', '5', 'shows', 'performance', 'AbbVie', 'Search', 'question/answer', 'model', '.']

 TOTAL FILTERED TOKENS ==>  34

 ---- POST FOR FILTERED TOKENS ----

 [('Q', 'NNP'), ('ue', 'JJ'), ('st', 'NN'), ('io', 'NN'), ('ns', 'JJ'), ('p', 'NN'), ('er', 'NN'), ('ec', 'JJ'), ('Standard', 'NNP'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('OpenVINO', 'NNP'), ('toolkit', 'VBD'), ('2020.3', 'CD'), ('16', 'CD'), ('12', 'CD'), ('8', 'CD'), ('4', 'CD'), ('0', 'CD'), ('17.9', 'CD'), ('3.4', 'CD'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('Model', 'NNP'), ('Performance', 'NNP'), ('Figure', 'NNP'), ('5', 'CD'), ('shows', 'NNS'), ('performance', 'NN'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('question/answer', 'JJR'), ('model', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Q ue', 'ue st', 'st io', 'io ns', 'ns p', 'p er', 'er ec', 'ec Standard', 'Standard TensorFlow', 'TensorFlow 1.15', '1.15 OpenVINO', 'OpenVINO toolkit', 'toolkit 2020.3', '2020.3 16', '16 12', '12 8', '8 4', '4 0', '0 17.9', '17.9 3.4', '3.4 AbbVie', 'AbbVie Search', 'Search Model', 'Model Performance', 'Performance Figure', 'Figure 5', '5 shows', 'shows performance', 'performance AbbVie', 'AbbVie Search', 'Search question/answer', 'question/answer model', 'model .'] 

 TOTAL BIGRAMS --> 33 



 ---- TRI-GRAMS ---- 

 ['Q ue st', 'ue st io', 'st io ns', 'io ns p', 'ns p er', 'p er ec', 'er ec Standard', 'ec Standard TensorFlow', 'Standard TensorFlow 1.15', 'TensorFlow 1.15 OpenVINO', '1.15 OpenVINO toolkit', 'OpenVINO toolkit 2020.3', 'toolkit 2020.3 16', '2020.3 16 12', '16 12 8', '12 8 4', '8 4 0', '4 0 17.9', '0 17.9 3.4', '17.9 3.4 AbbVie', '3.4 AbbVie Search', 'AbbVie Search Model', 'Search Model Performance', 'Model Performance Figure', 'Performance Figure 5', 'Figure 5 shows', '5 shows performance', 'shows performance AbbVie', 'performance AbbVie Search', 'AbbVie Search question/answer', 'Search question/answer model', 'question/answer model .'] 

 TOTAL TRIGRAMS --> 32 



 ---- NOUN PHRASES ---- 

 ['ue st', 'io', 'ns p', 'er', 'performance', 'model'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['OpenVINO', 'AbbVie Search Model Performance', 'AbbVie']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> ['Standard']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['q', 'ue', 'st', 'io', 'ns', 'p', 'er', 'ec', 'standard', 'tensorflow', '1.15', 'openvino', 'toolkit', '2020.3', '16', '12', '8', '4', '0', '17.9', '3.4', 'abbvi', 'search', 'model', 'perform', 'figur', '5', 'show', 'perform', 'abbvi', 'search', 'question/answ', 'model', '.']

 TOTAL PORTER STEM WORDS ==> 34



 ---- SNOWBALL STEMMING ----

['q', 'ue', 'st', 'io', 'ns', 'p', 'er', 'ec', 'standard', 'tensorflow', '1.15', 'openvino', 'toolkit', '2020.3', '16', '12', '8', '4', '0', '17.9', '3.4', 'abbvi', 'search', 'model', 'perform', 'figur', '5', 'show', 'perform', 'abbvi', 'search', 'question/answ', 'model', '.']

 TOTAL SNOWBALL STEM WORDS ==> 34



 ---- LEMMATIZATION ----

['Q', 'ue', 'st', 'io', 'n', 'p', 'er', 'ec', 'Standard', 'TensorFlow', '1.15', 'OpenVINO', 'toolkit', '2020.3', '16', '12', '8', '4', '0', '17.9', '3.4', 'AbbVie', 'Search', 'Model', 'Performance', 'Figure', '5', 'show', 'performance', 'AbbVie', 'Search', 'question/answer', 'model', '.']

 TOTAL LEMMATIZE WORDS ==> 34

************************************************************************************************************************

80 --> The same Intel Xeon processor -based  server was used for this benchmark. 


 ---- TOKENS ----

 ['The', 'same', 'Intel', 'Xeon', 'processor', '-based', 'server', 'was', 'used', 'for', 'this', 'benchmark', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('The', 'DT'), ('same', 'JJ'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor', 'NN'), ('-based', 'VBD'), ('server', 'NN'), ('was', 'VBD'), ('used', 'VBN'), ('for', 'IN'), ('this', 'DT'), ('benchmark', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel', 'Xeon', 'processor', '-based', 'server', 'used', 'benchmark', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor', 'NN'), ('-based', 'VBD'), ('server', 'NN'), ('used', 'VBN'), ('benchmark', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel Xeon', 'Xeon processor', 'processor -based', '-based server', 'server used', 'used benchmark', 'benchmark .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Intel Xeon processor', 'Xeon processor -based', 'processor -based server', '-based server used', 'server used benchmark', 'used benchmark .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['processor', 'server', 'benchmark'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Xeon']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel', 'xeon', 'processor', '-base', 'server', 'use', 'benchmark', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['intel', 'xeon', 'processor', '-base', 'server', 'use', 'benchmark', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Intel', 'Xeon', 'processor', '-based', 'server', 'used', 'benchmark', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

81 --> The Intel Distribution of  OpenVINO toolkit provided a 5.3x speedup in the number of  questions answered per second compared with the unoptimized  version of TensorFlow 1.15 (without oneDNN).1 This allows  AbbVie researchers to answer more than 17 questions per  second from a given scientific article or clinical report. 


 ---- TOKENS ----

 ['The', 'Intel', 'Distribution', 'of', 'OpenVINO', 'toolkit', 'provided', 'a', '5.3x', 'speedup', 'in', 'the', 'number', 'of', 'questions', 'answered', 'per', 'second', 'compared', 'with', 'the', 'unoptimized', 'version', 'of', 'TensorFlow', '1.15', '(', 'without', 'oneDNN', ')', '.1', 'This', 'allows', 'AbbVie', 'researchers', 'to', 'answer', 'more', 'than', '17', 'questions', 'per', 'second', 'from', 'a', 'given', 'scientific', 'article', 'or', 'clinical', 'report', '.'] 

 TOTAL TOKENS ==> 52

 ---- POST ----

 [('The', 'DT'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('of', 'IN'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), ('provided', 'VBD'), ('a', 'DT'), ('5.3x', 'CD'), ('speedup', 'NN'), ('in', 'IN'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('questions', 'NNS'), ('answered', 'VBN'), ('per', 'IN'), ('second', 'JJ'), ('compared', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('unoptimized', 'JJ'), ('version', 'NN'), ('of', 'IN'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('without', 'IN'), ('oneDNN', 'NN'), (')', ')'), ('.1', 'VBZ'), ('This', 'DT'), ('allows', 'VBZ'), ('AbbVie', 'NNP'), ('researchers', 'NNS'), ('to', 'TO'), ('answer', 'VB'), ('more', 'JJR'), ('than', 'IN'), ('17', 'CD'), ('questions', 'NNS'), ('per', 'IN'), ('second', 'NN'), ('from', 'IN'), ('a', 'DT'), ('given', 'VBN'), ('scientific', 'JJ'), ('article', 'NN'), ('or', 'CC'), ('clinical', 'JJ'), ('report', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel', 'Distribution', 'OpenVINO', 'toolkit', 'provided', '5.3x', 'speedup', 'number', 'questions', 'answered', 'per', 'second', 'compared', 'unoptimized', 'version', 'TensorFlow', '1.15', '(', 'without', 'oneDNN', ')', '.1', 'allows', 'AbbVie', 'researchers', 'answer', '17', 'questions', 'per', 'second', 'given', 'scientific', 'article', 'clinical', 'report', '.']

 TOTAL FILTERED TOKENS ==>  36

 ---- POST FOR FILTERED TOKENS ----

 [('Intel', 'NNP'), ('Distribution', 'NNP'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), ('provided', 'VBD'), ('5.3x', 'CD'), ('speedup', 'JJ'), ('number', 'NN'), ('questions', 'NNS'), ('answered', 'VBD'), ('per', 'IN'), ('second', 'JJ'), ('compared', 'VBN'), ('unoptimized', 'JJ'), ('version', 'NN'), ('TensorFlow', 'NNP'), ('1.15', 'CD'), ('(', '('), ('without', 'IN'), ('oneDNN', 'NN'), (')', ')'), ('.1', 'NN'), ('allows', 'VBZ'), ('AbbVie', 'NNP'), ('researchers', 'NNS'), ('answer', 'VBP'), ('17', 'CD'), ('questions', 'NNS'), ('per', 'IN'), ('second', 'JJ'), ('given', 'VBN'), ('scientific', 'JJ'), ('article', 'NN'), ('clinical', 'JJ'), ('report', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel Distribution', 'Distribution OpenVINO', 'OpenVINO toolkit', 'toolkit provided', 'provided 5.3x', '5.3x speedup', 'speedup number', 'number questions', 'questions answered', 'answered per', 'per second', 'second compared', 'compared unoptimized', 'unoptimized version', 'version TensorFlow', 'TensorFlow 1.15', '1.15 (', '( without', 'without oneDNN', 'oneDNN )', ') .1', '.1 allows', 'allows AbbVie', 'AbbVie researchers', 'researchers answer', 'answer 17', '17 questions', 'questions per', 'per second', 'second given', 'given scientific', 'scientific article', 'article clinical', 'clinical report', 'report .'] 

 TOTAL BIGRAMS --> 35 



 ---- TRI-GRAMS ---- 

 ['Intel Distribution OpenVINO', 'Distribution OpenVINO toolkit', 'OpenVINO toolkit provided', 'toolkit provided 5.3x', 'provided 5.3x speedup', '5.3x speedup number', 'speedup number questions', 'number questions answered', 'questions answered per', 'answered per second', 'per second compared', 'second compared unoptimized', 'compared unoptimized version', 'unoptimized version TensorFlow', 'version TensorFlow 1.15', 'TensorFlow 1.15 (', '1.15 ( without', '( without oneDNN', 'without oneDNN )', 'oneDNN ) .1', ') .1 allows', '.1 allows AbbVie', 'allows AbbVie researchers', 'AbbVie researchers answer', 'researchers answer 17', 'answer 17 questions', '17 questions per', 'questions per second', 'per second given', 'second given scientific', 'given scientific article', 'scientific article clinical', 'article clinical report', 'clinical report .'] 

 TOTAL TRIGRAMS --> 34 



 ---- NOUN PHRASES ---- 

 ['toolkit', 'speedup number', 'unoptimized version', '.1', 'scientific article', 'clinical report'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Distribution', 'TensorFlow', 'AbbVie']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel', 'distribut', 'openvino', 'toolkit', 'provid', '5.3x', 'speedup', 'number', 'question', 'answer', 'per', 'second', 'compar', 'unoptim', 'version', 'tensorflow', '1.15', '(', 'without', 'onednn', ')', '.1', 'allow', 'abbvi', 'research', 'answer', '17', 'question', 'per', 'second', 'given', 'scientif', 'articl', 'clinic', 'report', '.']

 TOTAL PORTER STEM WORDS ==> 36



 ---- SNOWBALL STEMMING ----

['intel', 'distribut', 'openvino', 'toolkit', 'provid', '5.3x', 'speedup', 'number', 'question', 'answer', 'per', 'second', 'compar', 'unoptim', 'version', 'tensorflow', '1.15', '(', 'without', 'onednn', ')', '.1', 'allow', 'abbvi', 'research', 'answer', '17', 'question', 'per', 'second', 'given', 'scientif', 'articl', 'clinic', 'report', '.']

 TOTAL SNOWBALL STEM WORDS ==> 36



 ---- LEMMATIZATION ----

['Intel', 'Distribution', 'OpenVINO', 'toolkit', 'provided', '5.3x', 'speedup', 'number', 'question', 'answered', 'per', 'second', 'compared', 'unoptimized', 'version', 'TensorFlow', '1.15', '(', 'without', 'oneDNN', ')', '.1', 'allows', 'AbbVie', 'researcher', 'answer', '17', 'question', 'per', 'second', 'given', 'scientific', 'article', 'clinical', 'report', '.']

 TOTAL LEMMATIZE WORDS ==> 36

************************************************************************************************************************

82 --> In the  future, AbbVie Search can be scaled across the company  by leveraging the OpenVINO Model Server, a gRPC-based  microservice that is compatible with existing TensorFlow  Serving applications. 


 ---- TOKENS ----

 ['In', 'the', 'future', ',', 'AbbVie', 'Search', 'can', 'be', 'scaled', 'across', 'the', 'company', 'by', 'leveraging', 'the', 'OpenVINO', 'Model', 'Server', ',', 'a', 'gRPC-based', 'microservice', 'that', 'is', 'compatible', 'with', 'existing', 'TensorFlow', 'Serving', 'applications', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('In', 'IN'), ('the', 'DT'), ('future', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('can', 'MD'), ('be', 'VB'), ('scaled', 'VBN'), ('across', 'IN'), ('the', 'DT'), ('company', 'NN'), ('by', 'IN'), ('leveraging', 'VBG'), ('the', 'DT'), ('OpenVINO', 'NNP'), ('Model', 'NNP'), ('Server', 'NNP'), (',', ','), ('a', 'DT'), ('gRPC-based', 'JJ'), ('microservice', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('compatible', 'JJ'), ('with', 'IN'), ('existing', 'VBG'), ('TensorFlow', 'NNP'), ('Serving', 'NNP'), ('applications', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['future', ',', 'AbbVie', 'Search', 'scaled', 'across', 'company', 'leveraging', 'OpenVINO', 'Model', 'Server', ',', 'gRPC-based', 'microservice', 'compatible', 'existing', 'TensorFlow', 'Serving', 'applications', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('future', 'NN'), (',', ','), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('scaled', 'VBD'), ('across', 'RP'), ('company', 'NN'), ('leveraging', 'VBG'), ('OpenVINO', 'NNP'), ('Model', 'NNP'), ('Server', 'NNP'), (',', ','), ('gRPC-based', 'JJ'), ('microservice', 'NN'), ('compatible', 'JJ'), ('existing', 'VBG'), ('TensorFlow', 'NNP'), ('Serving', 'NNP'), ('applications', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['future ,', ', AbbVie', 'AbbVie Search', 'Search scaled', 'scaled across', 'across company', 'company leveraging', 'leveraging OpenVINO', 'OpenVINO Model', 'Model Server', 'Server ,', ', gRPC-based', 'gRPC-based microservice', 'microservice compatible', 'compatible existing', 'existing TensorFlow', 'TensorFlow Serving', 'Serving applications', 'applications .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['future , AbbVie', ', AbbVie Search', 'AbbVie Search scaled', 'Search scaled across', 'scaled across company', 'across company leveraging', 'company leveraging OpenVINO', 'leveraging OpenVINO Model', 'OpenVINO Model Server', 'Model Server ,', 'Server , gRPC-based', ', gRPC-based microservice', 'gRPC-based microservice compatible', 'microservice compatible existing', 'compatible existing TensorFlow', 'existing TensorFlow Serving', 'TensorFlow Serving applications', 'Serving applications .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['future', 'company', 'gRPC-based microservice'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie Search', 'OpenVINO Model Server', 'TensorFlow']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['futur', ',', 'abbvi', 'search', 'scale', 'across', 'compani', 'leverag', 'openvino', 'model', 'server', ',', 'grpc-base', 'microservic', 'compat', 'exist', 'tensorflow', 'serv', 'applic', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['futur', ',', 'abbvi', 'search', 'scale', 'across', 'compani', 'leverag', 'openvino', 'model', 'server', ',', 'grpc-base', 'microservic', 'compat', 'exist', 'tensorflow', 'serv', 'applic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['future', ',', 'AbbVie', 'Search', 'scaled', 'across', 'company', 'leveraging', 'OpenVINO', 'Model', 'Server', ',', 'gRPC-based', 'microservice', 'compatible', 'existing', 'TensorFlow', 'Serving', 'application', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

83 --> https://github.com/tensorflow/tensor2tensor https://linux.die.net/man/8/numactl https://ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html https://github.com/openvinotoolkit/model_server  White Paper | Accelerating Natural Language Processing Inference Models using Processor Optimized Capabilities Conclusion References AbbVie’s use of the oneAPI Deep Neural  Network Library (oneDNN) and the Intel  Distribution of OpenVINO toolkit have allowed  them to speed up their NLP services while  leaving CPU resources for their additional  non-AI workloads. 


 ---- TOKENS ----

 ['https', ':', '//github.com/tensorflow/tensor2tensor', 'https', ':', '//linux.die.net/man/8/numactl', 'https', ':', '//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', 'https', ':', '//github.com/openvinotoolkit/model_server', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Conclusion', 'References', 'AbbVie', '’', 's', 'use', 'of', 'the', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', 'and', 'the', 'Intel', 'Distribution', 'of', 'OpenVINO', 'toolkit', 'have', 'allowed', 'them', 'to', 'speed', 'up', 'their', 'NLP', 'services', 'while', 'leaving', 'CPU', 'resources', 'for', 'their', 'additional', 'non-AI', 'workloads', '.'] 

 TOTAL TOKENS ==> 67

 ---- POST ----

 [('https', 'NN'), (':', ':'), ('//github.com/tensorflow/tensor2tensor', 'NN'), ('https', 'NN'), (':', ':'), ('//linux.die.net/man/8/numactl', 'JJ'), ('https', 'NN'), (':', ':'), ('//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', 'JJ'), ('https', 'NN'), (':', ':'), ('//github.com/openvinotoolkit/model_server', 'JJ'), ('White', 'NNP'), ('Paper', 'NNP'), ('|', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNP'), ('Conclusion', 'NNP'), ('References', 'NNP'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'NN'), ('use', 'NN'), ('of', 'IN'), ('the', 'DT'), ('oneAPI', 'JJ'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('(', '('), ('oneDNN', 'NN'), (')', ')'), ('and', 'CC'), ('the', 'DT'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('of', 'IN'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), ('have', 'VBP'), ('allowed', 'VBN'), ('them', 'PRP'), ('to', 'TO'), ('speed', 'VB'), ('up', 'RP'), ('their', 'PRP$'), ('NLP', 'NNP'), ('services', 'NNS'), ('while', 'IN'), ('leaving', 'VBG'), ('CPU', 'NNP'), ('resources', 'NNS'), ('for', 'IN'), ('their', 'PRP$'), ('additional', 'JJ'), ('non-AI', 'JJ'), ('workloads', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['https', ':', '//github.com/tensorflow/tensor2tensor', 'https', ':', '//linux.die.net/man/8/numactl', 'https', ':', '//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', 'https', ':', '//github.com/openvinotoolkit/model_server', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Conclusion', 'References', 'AbbVie', '’', 'use', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', 'Intel', 'Distribution', 'OpenVINO', 'toolkit', 'allowed', 'speed', 'NLP', 'services', 'leaving', 'CPU', 'resources', 'additional', 'non-AI', 'workloads', '.']

 TOTAL FILTERED TOKENS ==>  53

 ---- POST FOR FILTERED TOKENS ----

 [('https', 'NN'), (':', ':'), ('//github.com/tensorflow/tensor2tensor', 'NN'), ('https', 'NN'), (':', ':'), ('//linux.die.net/man/8/numactl', 'JJ'), ('https', 'NN'), (':', ':'), ('//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', 'JJ'), ('https', 'NN'), (':', ':'), ('//github.com/openvinotoolkit/model_server', 'JJ'), ('White', 'NNP'), ('Paper', 'NNP'), ('|', 'NNP'), ('Accelerating', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Inference', 'NNP'), ('Models', 'NNP'), ('using', 'VBG'), ('Processor', 'NNP'), ('Optimized', 'NNP'), ('Capabilities', 'NNP'), ('Conclusion', 'NNP'), ('References', 'NNP'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('use', 'NN'), ('oneAPI', 'JJ'), ('Deep', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('Library', 'NNP'), ('(', '('), ('oneDNN', 'NN'), (')', ')'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), ('allowed', 'VBD'), ('speed', 'NN'), ('NLP', 'NNP'), ('services', 'NNS'), ('leaving', 'VBG'), ('CPU', 'NNP'), ('resources', 'NNS'), ('additional', 'JJ'), ('non-AI', 'JJ'), ('workloads', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['https :', ': //github.com/tensorflow/tensor2tensor', '//github.com/tensorflow/tensor2tensor https', 'https :', ': //linux.die.net/man/8/numactl', '//linux.die.net/man/8/numactl https', 'https :', ': //ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', '//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html https', 'https :', ': //github.com/openvinotoolkit/model_server', '//github.com/openvinotoolkit/model_server White', 'White Paper', 'Paper |', '| Accelerating', 'Accelerating Natural', 'Natural Language', 'Language Processing', 'Processing Inference', 'Inference Models', 'Models using', 'using Processor', 'Processor Optimized', 'Optimized Capabilities', 'Capabilities Conclusion', 'Conclusion References', 'References AbbVie', 'AbbVie ’', '’ use', 'use oneAPI', 'oneAPI Deep', 'Deep Neural', 'Neural Network', 'Network Library', 'Library (', '( oneDNN', 'oneDNN )', ') Intel', 'Intel Distribution', 'Distribution OpenVINO', 'OpenVINO toolkit', 'toolkit allowed', 'allowed speed', 'speed NLP', 'NLP services', 'services leaving', 'leaving CPU', 'CPU resources', 'resources additional', 'additional non-AI', 'non-AI workloads', 'workloads .'] 

 TOTAL BIGRAMS --> 52 



 ---- TRI-GRAMS ---- 

 ['https : //github.com/tensorflow/tensor2tensor', ': //github.com/tensorflow/tensor2tensor https', '//github.com/tensorflow/tensor2tensor https :', 'https : //linux.die.net/man/8/numactl', ': //linux.die.net/man/8/numactl https', '//linux.die.net/man/8/numactl https :', 'https : //ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', ': //ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html https', '//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html https :', 'https : //github.com/openvinotoolkit/model_server', ': //github.com/openvinotoolkit/model_server White', '//github.com/openvinotoolkit/model_server White Paper', 'White Paper |', 'Paper | Accelerating', '| Accelerating Natural', 'Accelerating Natural Language', 'Natural Language Processing', 'Language Processing Inference', 'Processing Inference Models', 'Inference Models using', 'Models using Processor', 'using Processor Optimized', 'Processor Optimized Capabilities', 'Optimized Capabilities Conclusion', 'Capabilities Conclusion References', 'Conclusion References AbbVie', 'References AbbVie ’', 'AbbVie ’ use', '’ use oneAPI', 'use oneAPI Deep', 'oneAPI Deep Neural', 'Deep Neural Network', 'Neural Network Library', 'Network Library (', 'Library ( oneDNN', '( oneDNN )', 'oneDNN ) Intel', ') Intel Distribution', 'Intel Distribution OpenVINO', 'Distribution OpenVINO toolkit', 'OpenVINO toolkit allowed', 'toolkit allowed speed', 'allowed speed NLP', 'speed NLP services', 'NLP services leaving', 'services leaving CPU', 'leaving CPU resources', 'CPU resources additional', 'resources additional non-AI', 'additional non-AI workloads', 'non-AI workloads .'] 

 TOTAL TRIGRAMS --> 51 



 ---- NOUN PHRASES ---- 

 ['https', '', 'https', ' https', ' https', 'use', 'toolkit', 'speed'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['oneAPI Deep', 'Intel Distribution', 'NLP', 'CPU']
 TOTAL ORGANIZATION ENTITY --> 4 


 PERSON ---> ['Processor Optimized Capabilities', 'Network Library']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['http', ':', '//github.com/tensorflow/tensor2tensor', 'http', ':', '//linux.die.net/man/8/numactl', 'http', ':', '//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', 'http', ':', '//github.com/openvinotoolkit/model_serv', 'white', 'paper', '|', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'conclus', 'refer', 'abbvi', '’', 'use', 'oneapi', 'deep', 'neural', 'network', 'librari', '(', 'onednn', ')', 'intel', 'distribut', 'openvino', 'toolkit', 'allow', 'speed', 'nlp', 'servic', 'leav', 'cpu', 'resourc', 'addit', 'non-ai', 'workload', '.']

 TOTAL PORTER STEM WORDS ==> 53



 ---- SNOWBALL STEMMING ----

['https', ':', '//github.com/tensorflow/tensor2tensor', 'https', ':', '//linux.die.net/man/8/numactl', 'https', ':', '//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', 'https', ':', '//github.com/openvinotoolkit/model_serv', 'white', 'paper', '|', 'acceler', 'natur', 'languag', 'process', 'infer', 'model', 'use', 'processor', 'optim', 'capabl', 'conclus', 'refer', 'abbvi', '’', 'use', 'oneapi', 'deep', 'neural', 'network', 'librari', '(', 'onednn', ')', 'intel', 'distribut', 'openvino', 'toolkit', 'allow', 'speed', 'nlp', 'servic', 'leav', 'cpu', 'resourc', 'addit', 'non-ai', 'workload', '.']

 TOTAL SNOWBALL STEM WORDS ==> 53



 ---- LEMMATIZATION ----

['http', ':', '//github.com/tensorflow/tensor2tensor', 'http', ':', '//linux.die.net/man/8/numactl', 'http', ':', '//ark.intel.com/content/www/us/en/ark/products/193951/intel-xeon-gold-6252n-processor-35-75m-cache-2-30-ghz.html', 'http', ':', '//github.com/openvinotoolkit/model_server', 'White', 'Paper', '|', 'Accelerating', 'Natural', 'Language', 'Processing', 'Inference', 'Models', 'using', 'Processor', 'Optimized', 'Capabilities', 'Conclusion', 'References', 'AbbVie', '’', 'use', 'oneAPI', 'Deep', 'Neural', 'Network', 'Library', '(', 'oneDNN', ')', 'Intel', 'Distribution', 'OpenVINO', 'toolkit', 'allowed', 'speed', 'NLP', 'service', 'leaving', 'CPU', 'resource', 'additional', 'non-AI', 'workload', '.']

 TOTAL LEMMATIZE WORDS ==> 53

************************************************************************************************************************

84 --> This greatly simplifies  AbbVie’s deployment and reduces the need  for additional hardware accelerators. 


 ---- TOKENS ----

 ['This', 'greatly', 'simplifies', 'AbbVie', '’', 's', 'deployment', 'and', 'reduces', 'the', 'need', 'for', 'additional', 'hardware', 'accelerators', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('This', 'DT'), ('greatly', 'JJ'), ('simplifies', 'VBZ'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('s', 'POS'), ('deployment', 'NN'), ('and', 'CC'), ('reduces', 'VBZ'), ('the', 'DT'), ('need', 'NN'), ('for', 'IN'), ('additional', 'JJ'), ('hardware', 'NN'), ('accelerators', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['greatly', 'simplifies', 'AbbVie', '’', 'deployment', 'reduces', 'need', 'additional', 'hardware', 'accelerators', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('greatly', 'RB'), ('simplifies', 'NNS'), ('AbbVie', 'NNP'), ('’', 'NNP'), ('deployment', 'NN'), ('reduces', 'NNS'), ('need', 'VBP'), ('additional', 'JJ'), ('hardware', 'NN'), ('accelerators', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['greatly simplifies', 'simplifies AbbVie', 'AbbVie ’', '’ deployment', 'deployment reduces', 'reduces need', 'need additional', 'additional hardware', 'hardware accelerators', 'accelerators .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['greatly simplifies AbbVie', 'simplifies AbbVie ’', 'AbbVie ’ deployment', '’ deployment reduces', 'deployment reduces need', 'reduces need additional', 'need additional hardware', 'additional hardware accelerators', 'hardware accelerators .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['deployment', 'additional hardware'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['greatli', 'simplifi', 'abbvi', '’', 'deploy', 'reduc', 'need', 'addit', 'hardwar', 'acceler', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['great', 'simplifi', 'abbvi', '’', 'deploy', 'reduc', 'need', 'addit', 'hardwar', 'acceler', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['greatly', 'simplifies', 'AbbVie', '’', 'deployment', 'reduces', 'need', 'additional', 'hardware', 'accelerator', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

85 --> Abbelfish  and AbbVie Search leverage these AI-optimized  libraries to scale NLP inference across their  worldwide research using Intel Xeon processor- based servers. 


 ---- TOKENS ----

 ['Abbelfish', 'and', 'AbbVie', 'Search', 'leverage', 'these', 'AI-optimized', 'libraries', 'to', 'scale', 'NLP', 'inference', 'across', 'their', 'worldwide', 'research', 'using', 'Intel', 'Xeon', 'processor-', 'based', 'servers', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Abbelfish', 'JJ'), ('and', 'CC'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('leverage', 'NN'), ('these', 'DT'), ('AI-optimized', 'JJ'), ('libraries', 'NNS'), ('to', 'TO'), ('scale', 'VB'), ('NLP', 'NNP'), ('inference', 'NN'), ('across', 'IN'), ('their', 'PRP$'), ('worldwide', 'NN'), ('research', 'NN'), ('using', 'VBG'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-', 'NN'), ('based', 'VBN'), ('servers', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Abbelfish', 'AbbVie', 'Search', 'leverage', 'AI-optimized', 'libraries', 'scale', 'NLP', 'inference', 'across', 'worldwide', 'research', 'using', 'Intel', 'Xeon', 'processor-', 'based', 'servers', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Abbelfish', 'JJ'), ('AbbVie', 'NNP'), ('Search', 'NNP'), ('leverage', 'NN'), ('AI-optimized', 'JJ'), ('libraries', 'NNS'), ('scale', 'VBP'), ('NLP', 'NNP'), ('inference', 'NN'), ('across', 'IN'), ('worldwide', 'JJ'), ('research', 'NN'), ('using', 'VBG'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('processor-', 'NN'), ('based', 'VBN'), ('servers', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Abbelfish AbbVie', 'AbbVie Search', 'Search leverage', 'leverage AI-optimized', 'AI-optimized libraries', 'libraries scale', 'scale NLP', 'NLP inference', 'inference across', 'across worldwide', 'worldwide research', 'research using', 'using Intel', 'Intel Xeon', 'Xeon processor-', 'processor- based', 'based servers', 'servers .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Abbelfish AbbVie Search', 'AbbVie Search leverage', 'Search leverage AI-optimized', 'leverage AI-optimized libraries', 'AI-optimized libraries scale', 'libraries scale NLP', 'scale NLP inference', 'NLP inference across', 'inference across worldwide', 'across worldwide research', 'worldwide research using', 'research using Intel', 'using Intel Xeon', 'Intel Xeon processor-', 'Xeon processor- based', 'processor- based servers', 'based servers .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['leverage', 'inference', 'worldwide research', 'processor-'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie Search', 'NLP', 'Intel Xeon']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Abbelfish']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['abbelfish', 'abbvi', 'search', 'leverag', 'ai-optim', 'librari', 'scale', 'nlp', 'infer', 'across', 'worldwid', 'research', 'use', 'intel', 'xeon', 'processor-', 'base', 'server', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['abbelfish', 'abbvi', 'search', 'leverag', 'ai-optim', 'librari', 'scale', 'nlp', 'infer', 'across', 'worldwid', 'research', 'use', 'intel', 'xeon', 'processor-', 'base', 'server', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Abbelfish', 'AbbVie', 'Search', 'leverage', 'AI-optimized', 'library', 'scale', 'NLP', 'inference', 'across', 'worldwide', 'research', 'using', 'Intel', 'Xeon', 'processor-', 'based', 'server', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

86 --> For more information about Intel Xeon Scalable  Processors, visit: intel.com/xeonscalable For more information about the Intel  Distribution of OpenVINO toolkit,   visit: intel.com/openvino. 


 ---- TOKENS ----

 ['For', 'more', 'information', 'about', 'Intel', 'Xeon', 'Scalable', 'Processors', ',', 'visit', ':', 'intel.com/xeonscalable', 'For', 'more', 'information', 'about', 'the', 'Intel', 'Distribution', 'of', 'OpenVINO', 'toolkit', ',', 'visit', ':', 'intel.com/openvino', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('For', 'IN'), ('more', 'JJR'), ('information', 'NN'), ('about', 'IN'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('Scalable', 'NNP'), ('Processors', 'NNPS'), (',', ','), ('visit', 'NN'), (':', ':'), ('intel.com/xeonscalable', 'JJ'), ('For', 'IN'), ('more', 'JJR'), ('information', 'NN'), ('about', 'IN'), ('the', 'DT'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('of', 'IN'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), (',', ','), ('visit', 'NN'), (':', ':'), ('intel.com/openvino', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['information', 'Intel', 'Xeon', 'Scalable', 'Processors', ',', 'visit', ':', 'intel.com/xeonscalable', 'information', 'Intel', 'Distribution', 'OpenVINO', 'toolkit', ',', 'visit', ':', 'intel.com/openvino', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('information', 'NN'), ('Intel', 'NNP'), ('Xeon', 'NNP'), ('Scalable', 'NNP'), ('Processors', 'NNPS'), (',', ','), ('visit', 'NN'), (':', ':'), ('intel.com/xeonscalable', 'JJ'), ('information', 'NN'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('OpenVINO', 'NNP'), ('toolkit', 'NN'), (',', ','), ('visit', 'NN'), (':', ':'), ('intel.com/openvino', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['information Intel', 'Intel Xeon', 'Xeon Scalable', 'Scalable Processors', 'Processors ,', ', visit', 'visit :', ': intel.com/xeonscalable', 'intel.com/xeonscalable information', 'information Intel', 'Intel Distribution', 'Distribution OpenVINO', 'OpenVINO toolkit', 'toolkit ,', ', visit', 'visit :', ': intel.com/openvino', 'intel.com/openvino .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['information Intel Xeon', 'Intel Xeon Scalable', 'Xeon Scalable Processors', 'Scalable Processors ,', 'Processors , visit', ', visit :', 'visit : intel.com/xeonscalable', ': intel.com/xeonscalable information', 'intel.com/xeonscalable information Intel', 'information Intel Distribution', 'Intel Distribution OpenVINO', 'Distribution OpenVINO toolkit', 'OpenVINO toolkit ,', 'toolkit , visit', ', visit :', 'visit : intel.com/openvino', ': intel.com/openvino .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['information', 'visit', 'intel.com information', 'toolkit', 'visit', 'intel.com'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Xeon Scalable Processors', 'Intel Distribution']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['inform', 'intel', 'xeon', 'scalabl', 'processor', ',', 'visit', ':', 'intel.com/xeonscal', 'inform', 'intel', 'distribut', 'openvino', 'toolkit', ',', 'visit', ':', 'intel.com/openvino', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['inform', 'intel', 'xeon', 'scalabl', 'processor', ',', 'visit', ':', 'intel.com/xeonscal', 'inform', 'intel', 'distribut', 'openvino', 'toolkit', ',', 'visit', ':', 'intel.com/openvino', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['information', 'Intel', 'Xeon', 'Scalable', 'Processors', ',', 'visit', ':', 'intel.com/xeonscalable', 'information', 'Intel', 'Distribution', 'OpenVINO', 'toolkit', ',', 'visit', ':', 'intel.com/openvino', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

87 --> Download the Intel Distribution of OpenVINO Toolkit Notices & Disclaimers     Software and workloads used in performance tests may have been optimized for performance only on Intel microprocessors. 


 ---- TOKENS ----

 ['Download', 'the', 'Intel', 'Distribution', 'of', 'OpenVINO', 'Toolkit', 'Notices', '&', 'Disclaimers', 'Software', 'and', 'workloads', 'used', 'in', 'performance', 'tests', 'may', 'have', 'been', 'optimized', 'for', 'performance', 'only', 'on', 'Intel', 'microprocessors', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('Download', 'NNP'), ('the', 'DT'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('of', 'IN'), ('OpenVINO', 'NNP'), ('Toolkit', 'NNP'), ('Notices', 'NNP'), ('&', 'CC'), ('Disclaimers', 'NNP'), ('Software', 'NNP'), ('and', 'CC'), ('workloads', 'NNS'), ('used', 'VBN'), ('in', 'IN'), ('performance', 'NN'), ('tests', 'NNS'), ('may', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('optimized', 'VBN'), ('for', 'IN'), ('performance', 'NN'), ('only', 'RB'), ('on', 'IN'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Download', 'Intel', 'Distribution', 'OpenVINO', 'Toolkit', 'Notices', '&', 'Disclaimers', 'Software', 'workloads', 'used', 'performance', 'tests', 'may', 'optimized', 'performance', 'Intel', 'microprocessors', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Download', 'NNP'), ('Intel', 'NNP'), ('Distribution', 'NNP'), ('OpenVINO', 'NNP'), ('Toolkit', 'NNP'), ('Notices', 'NNP'), ('&', 'CC'), ('Disclaimers', 'NNP'), ('Software', 'NNP'), ('workloads', 'NNS'), ('used', 'VBD'), ('performance', 'NN'), ('tests', 'NNS'), ('may', 'MD'), ('optimized', 'VB'), ('performance', 'NN'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Download Intel', 'Intel Distribution', 'Distribution OpenVINO', 'OpenVINO Toolkit', 'Toolkit Notices', 'Notices &', '& Disclaimers', 'Disclaimers Software', 'Software workloads', 'workloads used', 'used performance', 'performance tests', 'tests may', 'may optimized', 'optimized performance', 'performance Intel', 'Intel microprocessors', 'microprocessors .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Download Intel Distribution', 'Intel Distribution OpenVINO', 'Distribution OpenVINO Toolkit', 'OpenVINO Toolkit Notices', 'Toolkit Notices &', 'Notices & Disclaimers', '& Disclaimers Software', 'Disclaimers Software workloads', 'Software workloads used', 'workloads used performance', 'used performance tests', 'performance tests may', 'tests may optimized', 'may optimized performance', 'optimized performance Intel', 'performance Intel microprocessors', 'Intel microprocessors .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['performance', 'performance'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Distribution', 'Disclaimers Software', 'Intel']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> ['Download']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['download', 'intel', 'distribut', 'openvino', 'toolkit', 'notic', '&', 'disclaim', 'softwar', 'workload', 'use', 'perform', 'test', 'may', 'optim', 'perform', 'intel', 'microprocessor', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['download', 'intel', 'distribut', 'openvino', 'toolkit', 'notic', '&', 'disclaim', 'softwar', 'workload', 'use', 'perform', 'test', 'may', 'optim', 'perform', 'intel', 'microprocessor', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Download', 'Intel', 'Distribution', 'OpenVINO', 'Toolkit', 'Notices', '&', 'Disclaimers', 'Software', 'workload', 'used', 'performance', 'test', 'may', 'optimized', 'performance', 'Intel', 'microprocessor', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

88 --> Performance tests, such as SYSmark and MobileMark, are measured using specific computer systems, components, software, operations and functions. 


 ---- TOKENS ----

 ['Performance', 'tests', ',', 'such', 'as', 'SYSmark', 'and', 'MobileMark', ',', 'are', 'measured', 'using', 'specific', 'computer', 'systems', ',', 'components', ',', 'software', ',', 'operations', 'and', 'functions', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Performance', 'NN'), ('tests', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('SYSmark', 'NNP'), ('and', 'CC'), ('MobileMark', 'NNP'), (',', ','), ('are', 'VBP'), ('measured', 'VBN'), ('using', 'VBG'), ('specific', 'JJ'), ('computer', 'NN'), ('systems', 'NNS'), (',', ','), ('components', 'NNS'), (',', ','), ('software', 'NN'), (',', ','), ('operations', 'NNS'), ('and', 'CC'), ('functions', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Performance', 'tests', ',', 'SYSmark', 'MobileMark', ',', 'measured', 'using', 'specific', 'computer', 'systems', ',', 'components', ',', 'software', ',', 'operations', 'functions', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Performance', 'NN'), ('tests', 'NNS'), (',', ','), ('SYSmark', 'NNP'), ('MobileMark', 'NNP'), (',', ','), ('measured', 'VBD'), ('using', 'VBG'), ('specific', 'JJ'), ('computer', 'NN'), ('systems', 'NNS'), (',', ','), ('components', 'NNS'), (',', ','), ('software', 'NN'), (',', ','), ('operations', 'NNS'), ('functions', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Performance tests', 'tests ,', ', SYSmark', 'SYSmark MobileMark', 'MobileMark ,', ', measured', 'measured using', 'using specific', 'specific computer', 'computer systems', 'systems ,', ', components', 'components ,', ', software', 'software ,', ', operations', 'operations functions', 'functions .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Performance tests ,', 'tests , SYSmark', ', SYSmark MobileMark', 'SYSmark MobileMark ,', 'MobileMark , measured', ', measured using', 'measured using specific', 'using specific computer', 'specific computer systems', 'computer systems ,', 'systems , components', ', components ,', 'components , software', ', software ,', 'software , operations', ', operations functions', 'operations functions .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['Performance', 'specific computer', 'software'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['SYSmark MobileMark']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Performance']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['perform', 'test', ',', 'sysmark', 'mobilemark', ',', 'measur', 'use', 'specif', 'comput', 'system', ',', 'compon', ',', 'softwar', ',', 'oper', 'function', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['perform', 'test', ',', 'sysmark', 'mobilemark', ',', 'measur', 'use', 'specif', 'comput', 'system', ',', 'compon', ',', 'softwar', ',', 'oper', 'function', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Performance', 'test', ',', 'SYSmark', 'MobileMark', ',', 'measured', 'using', 'specific', 'computer', 'system', ',', 'component', ',', 'software', ',', 'operation', 'function', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

89 --> Any change to any of those  factors may cause the results to vary. 


 ---- TOKENS ----

 ['Any', 'change', 'to', 'any', 'of', 'those', 'factors', 'may', 'cause', 'the', 'results', 'to', 'vary', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Any', 'DT'), ('change', 'NN'), ('to', 'TO'), ('any', 'DT'), ('of', 'IN'), ('those', 'DT'), ('factors', 'NNS'), ('may', 'MD'), ('cause', 'VB'), ('the', 'DT'), ('results', 'NNS'), ('to', 'TO'), ('vary', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['change', 'factors', 'may', 'cause', 'results', 'vary', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('change', 'NN'), ('factors', 'NNS'), ('may', 'MD'), ('cause', 'VB'), ('results', 'NNS'), ('vary', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['change factors', 'factors may', 'may cause', 'cause results', 'results vary', 'vary .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['change factors may', 'factors may cause', 'may cause results', 'cause results vary', 'results vary .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['change'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['chang', 'factor', 'may', 'caus', 'result', 'vari', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['chang', 'factor', 'may', 'caus', 'result', 'vari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['change', 'factor', 'may', 'cause', 'result', 'vary', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

90 --> You should consult other information and performance tests to assist you in fully evaluating your contemplated purchases, including the  performance of that product when combined with other products. 


 ---- TOKENS ----

 ['You', 'should', 'consult', 'other', 'information', 'and', 'performance', 'tests', 'to', 'assist', 'you', 'in', 'fully', 'evaluating', 'your', 'contemplated', 'purchases', ',', 'including', 'the', 'performance', 'of', 'that', 'product', 'when', 'combined', 'with', 'other', 'products', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('You', 'PRP'), ('should', 'MD'), ('consult', 'VB'), ('other', 'JJ'), ('information', 'NN'), ('and', 'CC'), ('performance', 'NN'), ('tests', 'NNS'), ('to', 'TO'), ('assist', 'VB'), ('you', 'PRP'), ('in', 'IN'), ('fully', 'RB'), ('evaluating', 'VBG'), ('your', 'PRP$'), ('contemplated', 'JJ'), ('purchases', 'NNS'), (',', ','), ('including', 'VBG'), ('the', 'DT'), ('performance', 'NN'), ('of', 'IN'), ('that', 'DT'), ('product', 'NN'), ('when', 'WRB'), ('combined', 'VBN'), ('with', 'IN'), ('other', 'JJ'), ('products', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['consult', 'information', 'performance', 'tests', 'assist', 'fully', 'evaluating', 'contemplated', 'purchases', ',', 'including', 'performance', 'product', 'combined', 'products', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('consult', 'NN'), ('information', 'NN'), ('performance', 'NN'), ('tests', 'NNS'), ('assist', 'VBP'), ('fully', 'RB'), ('evaluating', 'VBG'), ('contemplated', 'VBN'), ('purchases', 'NNS'), (',', ','), ('including', 'VBG'), ('performance', 'NN'), ('product', 'NN'), ('combined', 'VBN'), ('products', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['consult information', 'information performance', 'performance tests', 'tests assist', 'assist fully', 'fully evaluating', 'evaluating contemplated', 'contemplated purchases', 'purchases ,', ', including', 'including performance', 'performance product', 'product combined', 'combined products', 'products .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['consult information performance', 'information performance tests', 'performance tests assist', 'tests assist fully', 'assist fully evaluating', 'fully evaluating contemplated', 'evaluating contemplated purchases', 'contemplated purchases ,', 'purchases , including', ', including performance', 'including performance product', 'performance product combined', 'product combined products', 'combined products .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['consult', 'information', 'performance', 'performance', 'product'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['consult', 'inform', 'perform', 'test', 'assist', 'fulli', 'evalu', 'contempl', 'purchas', ',', 'includ', 'perform', 'product', 'combin', 'product', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['consult', 'inform', 'perform', 'test', 'assist', 'fulli', 'evalu', 'contempl', 'purchas', ',', 'includ', 'perform', 'product', 'combin', 'product', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['consult', 'information', 'performance', 'test', 'assist', 'fully', 'evaluating', 'contemplated', 'purchase', ',', 'including', 'performance', 'product', 'combined', 'product', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

91 --> For more complete information visit www.intel.com/benchmarks. 


 ---- TOKENS ----

 ['For', 'more', 'complete', 'information', 'visit', 'www.intel.com/benchmarks', '.'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('For', 'IN'), ('more', 'JJR'), ('complete', 'JJ'), ('information', 'NN'), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['complete', 'information', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('complete', 'JJ'), ('information', 'NN'), ('visit', 'NN'), ('www.intel.com/benchmarks', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['complete information', 'information visit', 'visit www.intel.com/benchmarks', 'www.intel.com/benchmarks .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['complete information visit', 'information visit www.intel.com/benchmarks', 'visit www.intel.com/benchmarks .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 ['complete information', 'visit', 'www.intel.com'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['complet', 'inform', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['complet', 'inform', 'visit', 'www.intel.com/benchmark', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['complete', 'information', 'visit', 'www.intel.com/benchmarks', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

92 --> Intel's compilers may or may not optimize to the same degree for non-Intel microprocessors for optimizations that are not unique to Intel microprocessors. 


 ---- TOKENS ----

 ['Intel', "'s", 'compilers', 'may', 'or', 'may', 'not', 'optimize', 'to', 'the', 'same', 'degree', 'for', 'non-Intel', 'microprocessors', 'for', 'optimizations', 'that', 'are', 'not', 'unique', 'to', 'Intel', 'microprocessors', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Intel', 'NNP'), ("'s", 'POS'), ('compilers', 'NNS'), ('may', 'MD'), ('or', 'CC'), ('may', 'MD'), ('not', 'RB'), ('optimize', 'VB'), ('to', 'TO'), ('the', 'DT'), ('same', 'JJ'), ('degree', 'NN'), ('for', 'IN'), ('non-Intel', 'JJ'), ('microprocessors', 'NNS'), ('for', 'IN'), ('optimizations', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('not', 'RB'), ('unique', 'JJ'), ('to', 'TO'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel', "'s", 'compilers', 'may', 'may', 'optimize', 'degree', 'non-Intel', 'microprocessors', 'optimizations', 'unique', 'Intel', 'microprocessors', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('Intel', 'NNP'), ("'s", 'POS'), ('compilers', 'NNS'), ('may', 'MD'), ('may', 'MD'), ('optimize', 'VB'), ('degree', 'JJ'), ('non-Intel', 'JJ'), ('microprocessors', 'NNS'), ('optimizations', 'NNS'), ('unique', 'JJ'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ["Intel 's", "'s compilers", 'compilers may', 'may may', 'may optimize', 'optimize degree', 'degree non-Intel', 'non-Intel microprocessors', 'microprocessors optimizations', 'optimizations unique', 'unique Intel', 'Intel microprocessors', 'microprocessors .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ["Intel 's compilers", "'s compilers may", 'compilers may may', 'may may optimize', 'may optimize degree', 'optimize degree non-Intel', 'degree non-Intel microprocessors', 'non-Intel microprocessors optimizations', 'microprocessors optimizations unique', 'optimizations unique Intel', 'unique Intel microprocessors', 'Intel microprocessors .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Intel']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel', "'s", 'compil', 'may', 'may', 'optim', 'degre', 'non-intel', 'microprocessor', 'optim', 'uniqu', 'intel', 'microprocessor', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['intel', "'s", 'compil', 'may', 'may', 'optim', 'degre', 'non-intel', 'microprocessor', 'optim', 'uniqu', 'intel', 'microprocessor', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['Intel', "'s", 'compiler', 'may', 'may', 'optimize', 'degree', 'non-Intel', 'microprocessor', 'optimization', 'unique', 'Intel', 'microprocessor', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

93 --> These optimizations include  SSE2, SSE3, and SSSE3 instruction sets and other optimizations. 


 ---- TOKENS ----

 ['These', 'optimizations', 'include', 'SSE2', ',', 'SSE3', ',', 'and', 'SSSE3', 'instruction', 'sets', 'and', 'other', 'optimizations', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('These', 'DT'), ('optimizations', 'NNS'), ('include', 'VBP'), ('SSE2', 'NNP'), (',', ','), ('SSE3', 'NNP'), (',', ','), ('and', 'CC'), ('SSSE3', 'NNP'), ('instruction', 'NN'), ('sets', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('optimizations', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['optimizations', 'include', 'SSE2', ',', 'SSE3', ',', 'SSSE3', 'instruction', 'sets', 'optimizations', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('optimizations', 'NNS'), ('include', 'VBP'), ('SSE2', 'NNP'), (',', ','), ('SSE3', 'NNP'), (',', ','), ('SSSE3', 'NNP'), ('instruction', 'NN'), ('sets', 'NNS'), ('optimizations', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['optimizations include', 'include SSE2', 'SSE2 ,', ', SSE3', 'SSE3 ,', ', SSSE3', 'SSSE3 instruction', 'instruction sets', 'sets optimizations', 'optimizations .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['optimizations include SSE2', 'include SSE2 ,', 'SSE2 , SSE3', ', SSE3 ,', 'SSE3 , SSSE3', ', SSSE3 instruction', 'SSSE3 instruction sets', 'instruction sets optimizations', 'sets optimizations .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['instruction'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['SSE2', 'SSE3', 'SSSE3']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['optim', 'includ', 'sse2', ',', 'sse3', ',', 'ssse3', 'instruct', 'set', 'optim', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['optim', 'includ', 'sse2', ',', 'sse3', ',', 'ssse3', 'instruct', 'set', 'optim', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['optimization', 'include', 'SSE2', ',', 'SSE3', ',', 'SSSE3', 'instruction', 'set', 'optimization', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

94 --> Intel does not guarantee the availability, functionality, or effectiveness of any optimization on microprocessors  not manufactured by Intel. 


 ---- TOKENS ----

 ['Intel', 'does', 'not', 'guarantee', 'the', 'availability', ',', 'functionality', ',', 'or', 'effectiveness', 'of', 'any', 'optimization', 'on', 'microprocessors', 'not', 'manufactured', 'by', 'Intel', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Intel', 'NNP'), ('does', 'VBZ'), ('not', 'RB'), ('guarantee', 'VB'), ('the', 'DT'), ('availability', 'NN'), (',', ','), ('functionality', 'NN'), (',', ','), ('or', 'CC'), ('effectiveness', 'NN'), ('of', 'IN'), ('any', 'DT'), ('optimization', 'NN'), ('on', 'IN'), ('microprocessors', 'NNS'), ('not', 'RB'), ('manufactured', 'VBN'), ('by', 'IN'), ('Intel', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel', 'guarantee', 'availability', ',', 'functionality', ',', 'effectiveness', 'optimization', 'microprocessors', 'manufactured', 'Intel', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Intel', 'NNP'), ('guarantee', 'NN'), ('availability', 'NN'), (',', ','), ('functionality', 'NN'), (',', ','), ('effectiveness', 'JJ'), ('optimization', 'NN'), ('microprocessors', 'NNS'), ('manufactured', 'VBD'), ('Intel', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel guarantee', 'guarantee availability', 'availability ,', ', functionality', 'functionality ,', ', effectiveness', 'effectiveness optimization', 'optimization microprocessors', 'microprocessors manufactured', 'manufactured Intel', 'Intel .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Intel guarantee availability', 'guarantee availability ,', 'availability , functionality', ', functionality ,', 'functionality , effectiveness', ', effectiveness optimization', 'effectiveness optimization microprocessors', 'optimization microprocessors manufactured', 'microprocessors manufactured Intel', 'manufactured Intel .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['guarantee', 'availability', 'functionality', 'effectiveness optimization'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Intel']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel', 'guarante', 'avail', ',', 'function', ',', 'effect', 'optim', 'microprocessor', 'manufactur', 'intel', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['intel', 'guarante', 'avail', ',', 'function', ',', 'effect', 'optim', 'microprocessor', 'manufactur', 'intel', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Intel', 'guarantee', 'availability', ',', 'functionality', ',', 'effectiveness', 'optimization', 'microprocessor', 'manufactured', 'Intel', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

95 --> Microprocessor-dependent optimizations in this product are intended for use with Intel microprocessors. 


 ---- TOKENS ----

 ['Microprocessor-dependent', 'optimizations', 'in', 'this', 'product', 'are', 'intended', 'for', 'use', 'with', 'Intel', 'microprocessors', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Microprocessor-dependent', 'JJ'), ('optimizations', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('product', 'NN'), ('are', 'VBP'), ('intended', 'VBN'), ('for', 'IN'), ('use', 'NN'), ('with', 'IN'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Microprocessor-dependent', 'optimizations', 'product', 'intended', 'use', 'Intel', 'microprocessors', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Microprocessor-dependent', 'JJ'), ('optimizations', 'NNS'), ('product', 'NN'), ('intended', 'VBN'), ('use', 'JJ'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Microprocessor-dependent optimizations', 'optimizations product', 'product intended', 'intended use', 'use Intel', 'Intel microprocessors', 'microprocessors .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Microprocessor-dependent optimizations product', 'optimizations product intended', 'product intended use', 'intended use Intel', 'use Intel microprocessors', 'Intel microprocessors .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['product'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['microprocessor-depend', 'optim', 'product', 'intend', 'use', 'intel', 'microprocessor', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['microprocessor-depend', 'optim', 'product', 'intend', 'use', 'intel', 'microprocessor', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Microprocessor-dependent', 'optimization', 'product', 'intended', 'use', 'Intel', 'microprocessor', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

96 --> Certain optimizations not specific to Intel  microarchitecture are reserved for Intel microprocessors. 


 ---- TOKENS ----

 ['Certain', 'optimizations', 'not', 'specific', 'to', 'Intel', 'microarchitecture', 'are', 'reserved', 'for', 'Intel', 'microprocessors', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Certain', 'NNP'), ('optimizations', 'NNS'), ('not', 'RB'), ('specific', 'JJ'), ('to', 'TO'), ('Intel', 'NNP'), ('microarchitecture', 'NN'), ('are', 'VBP'), ('reserved', 'VBN'), ('for', 'IN'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Certain', 'optimizations', 'specific', 'Intel', 'microarchitecture', 'reserved', 'Intel', 'microprocessors', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Certain', 'NNP'), ('optimizations', 'NNS'), ('specific', 'JJ'), ('Intel', 'NNP'), ('microarchitecture', 'NN'), ('reserved', 'VBD'), ('Intel', 'NNP'), ('microprocessors', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Certain optimizations', 'optimizations specific', 'specific Intel', 'Intel microarchitecture', 'microarchitecture reserved', 'reserved Intel', 'Intel microprocessors', 'microprocessors .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Certain optimizations specific', 'optimizations specific Intel', 'specific Intel microarchitecture', 'Intel microarchitecture reserved', 'microarchitecture reserved Intel', 'reserved Intel microprocessors', 'Intel microprocessors .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['microarchitecture'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel', 'Intel']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Certain']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['certain', 'optim', 'specif', 'intel', 'microarchitectur', 'reserv', 'intel', 'microprocessor', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['certain', 'optim', 'specif', 'intel', 'microarchitectur', 'reserv', 'intel', 'microprocessor', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Certain', 'optimization', 'specific', 'Intel', 'microarchitecture', 'reserved', 'Intel', 'microprocessor', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

97 --> Please refer to the applicable product User and Reference Guides for more information regarding the specific instruction sets  covered by this notice. 


 ---- TOKENS ----

 ['Please', 'refer', 'to', 'the', 'applicable', 'product', 'User', 'and', 'Reference', 'Guides', 'for', 'more', 'information', 'regarding', 'the', 'specific', 'instruction', 'sets', 'covered', 'by', 'this', 'notice', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Please', 'NNP'), ('refer', 'NN'), ('to', 'TO'), ('the', 'DT'), ('applicable', 'JJ'), ('product', 'NN'), ('User', 'NNP'), ('and', 'CC'), ('Reference', 'NNP'), ('Guides', 'NNP'), ('for', 'IN'), ('more', 'JJR'), ('information', 'NN'), ('regarding', 'VBG'), ('the', 'DT'), ('specific', 'JJ'), ('instruction', 'NN'), ('sets', 'NNS'), ('covered', 'VBN'), ('by', 'IN'), ('this', 'DT'), ('notice', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Please', 'refer', 'applicable', 'product', 'User', 'Reference', 'Guides', 'information', 'regarding', 'specific', 'instruction', 'sets', 'covered', 'notice', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Please', 'NNP'), ('refer', 'VBP'), ('applicable', 'JJ'), ('product', 'NN'), ('User', 'NNP'), ('Reference', 'NNP'), ('Guides', 'NNP'), ('information', 'NN'), ('regarding', 'VBG'), ('specific', 'JJ'), ('instruction', 'NN'), ('sets', 'NNS'), ('covered', 'VBD'), ('notice', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Please refer', 'refer applicable', 'applicable product', 'product User', 'User Reference', 'Reference Guides', 'Guides information', 'information regarding', 'regarding specific', 'specific instruction', 'instruction sets', 'sets covered', 'covered notice', 'notice .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Please refer applicable', 'refer applicable product', 'applicable product User', 'product User Reference', 'User Reference Guides', 'Reference Guides information', 'Guides information regarding', 'information regarding specific', 'regarding specific instruction', 'specific instruction sets', 'instruction sets covered', 'sets covered notice', 'covered notice .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['applicable product', 'information', 'specific instruction', 'notice'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['User Reference Guides']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Please']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['pleas', 'refer', 'applic', 'product', 'user', 'refer', 'guid', 'inform', 'regard', 'specif', 'instruct', 'set', 'cover', 'notic', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['pleas', 'refer', 'applic', 'product', 'user', 'refer', 'guid', 'inform', 'regard', 'specif', 'instruct', 'set', 'cover', 'notic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Please', 'refer', 'applicable', 'product', 'User', 'Reference', 'Guides', 'information', 'regarding', 'specific', 'instruction', 'set', 'covered', 'notice', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

98 --> Notice Revision #20110804 Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates. 


 ---- TOKENS ----

 ['Notice', 'Revision', '#', '20110804', 'Performance', 'results', 'are', 'based', 'on', 'testing', 'as', 'of', 'dates', 'shown', 'in', 'configurations', 'and', 'may', 'not', 'reflect', 'all', 'publicly', 'available', 'updates', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Notice', 'NNP'), ('Revision', 'NNP'), ('#', '#'), ('20110804', 'CD'), ('Performance', 'NN'), ('results', 'NNS'), ('are', 'VBP'), ('based', 'VBN'), ('on', 'IN'), ('testing', 'VBG'), ('as', 'IN'), ('of', 'IN'), ('dates', 'NNS'), ('shown', 'VBN'), ('in', 'IN'), ('configurations', 'NNS'), ('and', 'CC'), ('may', 'MD'), ('not', 'RB'), ('reflect', 'VB'), ('all', 'DT'), ('publicly', 'RB'), ('available', 'JJ'), ('updates', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Notice', 'Revision', '#', '20110804', 'Performance', 'results', 'based', 'testing', 'dates', 'shown', 'configurations', 'may', 'reflect', 'publicly', 'available', 'updates', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Notice', 'NNP'), ('Revision', 'NNP'), ('#', '#'), ('20110804', 'CD'), ('Performance', 'NNP'), ('results', 'NNS'), ('based', 'VBN'), ('testing', 'VBG'), ('dates', 'NNS'), ('shown', 'VBN'), ('configurations', 'NNS'), ('may', 'MD'), ('reflect', 'VB'), ('publicly', 'RB'), ('available', 'JJ'), ('updates', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Notice Revision', 'Revision #', '# 20110804', '20110804 Performance', 'Performance results', 'results based', 'based testing', 'testing dates', 'dates shown', 'shown configurations', 'configurations may', 'may reflect', 'reflect publicly', 'publicly available', 'available updates', 'updates .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Notice Revision #', 'Revision # 20110804', '# 20110804 Performance', '20110804 Performance results', 'Performance results based', 'results based testing', 'based testing dates', 'testing dates shown', 'dates shown configurations', 'shown configurations may', 'configurations may reflect', 'may reflect publicly', 'reflect publicly available', 'publicly available updates', 'available updates .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['notic', 'revis', '#', '20110804', 'perform', 'result', 'base', 'test', 'date', 'shown', 'configur', 'may', 'reflect', 'publicli', 'avail', 'updat', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['notic', 'revis', '#', '20110804', 'perform', 'result', 'base', 'test', 'date', 'shown', 'configur', 'may', 'reflect', 'public', 'avail', 'updat', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Notice', 'Revision', '#', '20110804', 'Performance', 'result', 'based', 'testing', 'date', 'shown', 'configuration', 'may', 'reflect', 'publicly', 'available', 'update', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

99 --> See backup for configuration details. 


 ---- TOKENS ----

 ['See', 'backup', 'for', 'configuration', 'details', '.'] 

 TOTAL TOKENS ==> 6

 ---- POST ----

 [('See', 'VB'), ('backup', 'NN'), ('for', 'IN'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['See', 'backup', 'configuration', 'details', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('See', 'VB'), ('backup', 'JJ'), ('configuration', 'NN'), ('details', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['See backup', 'backup configuration', 'configuration details', 'details .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['See backup configuration', 'backup configuration details', 'configuration details .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 ['backup configuration'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['see', 'backup', 'configur', 'detail', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['see', 'backup', 'configur', 'detail', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['See', 'backup', 'configuration', 'detail', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

100 --> No product or  component can be absolutely secure. 


 ---- TOKENS ----

 ['No', 'product', 'or', 'component', 'can', 'be', 'absolutely', 'secure', '.'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('No', 'DT'), ('product', 'NN'), ('or', 'CC'), ('component', 'NN'), ('can', 'MD'), ('be', 'VB'), ('absolutely', 'RB'), ('secure', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['product', 'component', 'absolutely', 'secure', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('product', 'NN'), ('component', 'NN'), ('absolutely', 'RB'), ('secure', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['product component', 'component absolutely', 'absolutely secure', 'secure .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['product component absolutely', 'component absolutely secure', 'absolutely secure .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 ['product', 'component', 'secure'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['product', 'compon', 'absolut', 'secur', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['product', 'compon', 'absolut', 'secur', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['product', 'component', 'absolutely', 'secure', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

101 --> Your costs and results may vary. 


 ---- TOKENS ----

 ['Your', 'costs', 'and', 'results', 'may', 'vary', '.'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('Your', 'PRP$'), ('costs', 'NNS'), ('and', 'CC'), ('results', 'NNS'), ('may', 'MD'), ('vary', 'VB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['costs', 'results', 'may', 'vary', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('costs', 'NNS'), ('results', 'NNS'), ('may', 'MD'), ('vary', 'VB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['costs results', 'results may', 'may vary', 'vary .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['costs results may', 'results may vary', 'may vary .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['cost', 'result', 'may', 'vari', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['cost', 'result', 'may', 'vari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['cost', 'result', 'may', 'vary', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

102 --> Intel technologies may require enabled hardware, software or service activation. 


 ---- TOKENS ----

 ['Intel', 'technologies', 'may', 'require', 'enabled', 'hardware', ',', 'software', 'or', 'service', 'activation', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('Intel', 'NNP'), ('technologies', 'NNS'), ('may', 'MD'), ('require', 'VB'), ('enabled', 'JJ'), ('hardware', 'NN'), (',', ','), ('software', 'NN'), ('or', 'CC'), ('service', 'NN'), ('activation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel', 'technologies', 'may', 'require', 'enabled', 'hardware', ',', 'software', 'service', 'activation', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Intel', 'NNP'), ('technologies', 'NNS'), ('may', 'MD'), ('require', 'VB'), ('enabled', 'JJ'), ('hardware', 'NN'), (',', ','), ('software', 'NN'), ('service', 'NN'), ('activation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel technologies', 'technologies may', 'may require', 'require enabled', 'enabled hardware', 'hardware ,', ', software', 'software service', 'service activation', 'activation .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Intel technologies may', 'technologies may require', 'may require enabled', 'require enabled hardware', 'enabled hardware ,', 'hardware , software', ', software service', 'software service activation', 'service activation .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['enabled hardware', 'software', 'service', 'activation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Intel']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel', 'technolog', 'may', 'requir', 'enabl', 'hardwar', ',', 'softwar', 'servic', 'activ', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['intel', 'technolog', 'may', 'requir', 'enabl', 'hardwar', ',', 'softwar', 'servic', 'activ', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Intel', 'technology', 'may', 'require', 'enabled', 'hardware', ',', 'software', 'service', 'activation', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

103 --> © Intel Corporation. 


 ---- TOKENS ----

 ['©', 'Intel', 'Corporation', '.'] 

 TOTAL TOKENS ==> 4

 ---- POST ----

 [('©', 'JJ'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['©', 'Intel', 'Corporation', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('©', 'JJ'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['© Intel', 'Intel Corporation', 'Corporation .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['© Intel Corporation', 'Intel Corporation .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel Corporation']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['©', 'intel', 'corpor', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['©', 'intel', 'corpor', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['©', 'Intel', 'Corporation', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

104 --> Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. 


 ---- TOKENS ----

 ['Intel', ',', 'the', 'Intel', 'logo', ',', 'and', 'other', 'Intel', 'marks', 'are', 'trademarks', 'of', 'Intel', 'Corporation', 'or', 'its', 'subsidiaries', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Intel', 'NNP'), (',', ','), ('the', 'DT'), ('Intel', 'NNP'), ('logo', 'NN'), (',', ','), ('and', 'CC'), ('other', 'JJ'), ('Intel', 'NNP'), ('marks', 'NNS'), ('are', 'VBP'), ('trademarks', 'NNS'), ('of', 'IN'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('or', 'CC'), ('its', 'PRP$'), ('subsidiaries', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel', ',', 'Intel', 'logo', ',', 'Intel', 'marks', 'trademarks', 'Intel', 'Corporation', 'subsidiaries', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Intel', 'NNP'), (',', ','), ('Intel', 'NNP'), ('logo', 'NN'), (',', ','), ('Intel', 'NNP'), ('marks', 'VBZ'), ('trademarks', 'NNS'), ('Intel', 'NNP'), ('Corporation', 'NNP'), ('subsidiaries', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel ,', ', Intel', 'Intel logo', 'logo ,', ', Intel', 'Intel marks', 'marks trademarks', 'trademarks Intel', 'Intel Corporation', 'Corporation subsidiaries', 'subsidiaries .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Intel , Intel', ', Intel logo', 'Intel logo ,', 'logo , Intel', ', Intel marks', 'Intel marks trademarks', 'marks trademarks Intel', 'trademarks Intel Corporation', 'Intel Corporation subsidiaries', 'Corporation subsidiaries .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['logo'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel', 'Intel', 'Intel Corporation']
 TOTAL ORGANIZATION ENTITY --> 3 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Intel']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel', ',', 'intel', 'logo', ',', 'intel', 'mark', 'trademark', 'intel', 'corpor', 'subsidiari', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['intel', ',', 'intel', 'logo', ',', 'intel', 'mark', 'trademark', 'intel', 'corpor', 'subsidiari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Intel', ',', 'Intel', 'logo', ',', 'Intel', 'mark', 'trademark', 'Intel', 'Corporation', 'subsidiary', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

105 --> Other names and brands may be claimed as the property of others. 


 ---- TOKENS ----

 ['Other', 'names', 'and', 'brands', 'may', 'be', 'claimed', 'as', 'the', 'property', 'of', 'others', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Other', 'JJ'), ('names', 'NNS'), ('and', 'CC'), ('brands', 'NNS'), ('may', 'MD'), ('be', 'VB'), ('claimed', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('property', 'NN'), ('of', 'IN'), ('others', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['names', 'brands', 'may', 'claimed', 'property', 'others', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('names', 'NNS'), ('brands', 'NNS'), ('may', 'MD'), ('claimed', 'VB'), ('property', 'NN'), ('others', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['names brands', 'brands may', 'may claimed', 'claimed property', 'property others', 'others .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['names brands may', 'brands may claimed', 'may claimed property', 'claimed property others', 'property others .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['property'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['name', 'brand', 'may', 'claim', 'properti', 'other', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['name', 'brand', 'may', 'claim', 'properti', 'other', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['name', 'brand', 'may', 'claimed', 'property', 'others', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

106 --> • AbbVie, “A Closer Look”, https://www.abbvie.com/ content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_ Corporate_Presentation.pdf, accessed online 20 April 2020 • Devlin J, Change MW, Lee K, Toutanova K. “BERT: Pre- training of Deep Bidirectional Transformers for Language  Understanding”, https://arxiv.org/pdf/1810.04805.pdf • Lee J, Yoon W, Kim S, Kim D, Kim S, So, Jaewoo  Kang. 


 ---- TOKENS ----

 ['•', 'AbbVie', ',', '“', 'A', 'Closer', 'Look', '”', ',', 'https', ':', '//www.abbvie.com/', 'content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_', 'Corporate_Presentation.pdf', ',', 'accessed', 'online', '20', 'April', '2020', '•', 'Devlin', 'J', ',', 'Change', 'MW', ',', 'Lee', 'K', ',', 'Toutanova', 'K.', '“', 'BERT', ':', 'Pre-', 'training', 'of', 'Deep', 'Bidirectional', 'Transformers', 'for', 'Language', 'Understanding', '”', ',', 'https', ':', '//arxiv.org/pdf/1810.04805.pdf', '•', 'Lee', 'J', ',', 'Yoon', 'W', ',', 'Kim', 'S', ',', 'Kim', 'D', ',', 'Kim', 'S', ',', 'So', ',', 'Jaewoo', 'Kang', '.'] 

 TOTAL TOKENS ==> 70

 ---- POST ----

 [('•', 'JJ'), ('AbbVie', 'NNP'), (',', ','), ('“', 'VBZ'), ('A', 'NNP'), ('Closer', 'NNP'), ('Look', 'NNP'), ('”', 'NNP'), (',', ','), ('https', 'NN'), (':', ':'), ('//www.abbvie.com/', 'JJ'), ('content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_', 'JJ'), ('Corporate_Presentation.pdf', 'NNP'), (',', ','), ('accessed', 'VBD'), ('online', 'JJ'), ('20', 'CD'), ('April', 'NNP'), ('2020', 'CD'), ('•', 'NNP'), ('Devlin', 'NNP'), ('J', 'NNP'), (',', ','), ('Change', 'NNP'), ('MW', 'NNP'), (',', ','), ('Lee', 'NNP'), ('K', 'NNP'), (',', ','), ('Toutanova', 'NNP'), ('K.', 'NNP'), ('“', 'NNP'), ('BERT', 'NNP'), (':', ':'), ('Pre-', 'JJ'), ('training', 'NN'), ('of', 'IN'), ('Deep', 'NNP'), ('Bidirectional', 'NNP'), ('Transformers', 'NNP'), ('for', 'IN'), ('Language', 'NNP'), ('Understanding', 'NNP'), ('”', 'NNP'), (',', ','), ('https', 'NN'), (':', ':'), ('//arxiv.org/pdf/1810.04805.pdf', 'NN'), ('•', 'VBZ'), ('Lee', 'NNP'), ('J', 'NNP'), (',', ','), ('Yoon', 'NNP'), ('W', 'NNP'), (',', ','), ('Kim', 'NNP'), ('S', 'NNP'), (',', ','), ('Kim', 'NNP'), ('D', 'NNP'), (',', ','), ('Kim', 'NNP'), ('S', 'NNP'), (',', ','), ('So', 'NNP'), (',', ','), ('Jaewoo', 'NNP'), ('Kang', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'AbbVie', ',', '“', 'Closer', 'Look', '”', ',', 'https', ':', '//www.abbvie.com/', 'content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_', 'Corporate_Presentation.pdf', ',', 'accessed', 'online', '20', 'April', '2020', '•', 'Devlin', 'J', ',', 'Change', 'MW', ',', 'Lee', 'K', ',', 'Toutanova', 'K.', '“', 'BERT', ':', 'Pre-', 'training', 'Deep', 'Bidirectional', 'Transformers', 'Language', 'Understanding', '”', ',', 'https', ':', '//arxiv.org/pdf/1810.04805.pdf', '•', 'Lee', 'J', ',', 'Yoon', 'W', ',', 'Kim', ',', 'Kim', ',', 'Kim', ',', ',', 'Jaewoo', 'Kang', '.']

 TOTAL FILTERED TOKENS ==>  63

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('AbbVie', 'NNP'), (',', ','), ('“', 'NNP'), ('Closer', 'NNP'), ('Look', 'NNP'), ('”', 'NNP'), (',', ','), ('https', 'NN'), (':', ':'), ('//www.abbvie.com/', 'JJ'), ('content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_', 'JJ'), ('Corporate_Presentation.pdf', 'NNP'), (',', ','), ('accessed', 'VBD'), ('online', 'JJ'), ('20', 'CD'), ('April', 'NNP'), ('2020', 'CD'), ('•', 'NNP'), ('Devlin', 'NNP'), ('J', 'NNP'), (',', ','), ('Change', 'NNP'), ('MW', 'NNP'), (',', ','), ('Lee', 'NNP'), ('K', 'NNP'), (',', ','), ('Toutanova', 'NNP'), ('K.', 'NNP'), ('“', 'NNP'), ('BERT', 'NNP'), (':', ':'), ('Pre-', 'JJ'), ('training', 'NN'), ('Deep', 'NNP'), ('Bidirectional', 'NNP'), ('Transformers', 'NNP'), ('Language', 'NNP'), ('Understanding', 'NNP'), ('”', 'NNP'), (',', ','), ('https', 'NN'), (':', ':'), ('//arxiv.org/pdf/1810.04805.pdf', 'NN'), ('•', 'VBZ'), ('Lee', 'NNP'), ('J', 'NNP'), (',', ','), ('Yoon', 'NNP'), ('W', 'NNP'), (',', ','), ('Kim', 'NNP'), (',', ','), ('Kim', 'NNP'), (',', ','), ('Kim', 'NNP'), (',', ','), (',', ','), ('Jaewoo', 'NNP'), ('Kang', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• AbbVie', 'AbbVie ,', ', “', '“ Closer', 'Closer Look', 'Look ”', '” ,', ', https', 'https :', ': //www.abbvie.com/', '//www.abbvie.com/ content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_', 'content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_ Corporate_Presentation.pdf', 'Corporate_Presentation.pdf ,', ', accessed', 'accessed online', 'online 20', '20 April', 'April 2020', '2020 •', '• Devlin', 'Devlin J', 'J ,', ', Change', 'Change MW', 'MW ,', ', Lee', 'Lee K', 'K ,', ', Toutanova', 'Toutanova K.', 'K. “', '“ BERT', 'BERT :', ': Pre-', 'Pre- training', 'training Deep', 'Deep Bidirectional', 'Bidirectional Transformers', 'Transformers Language', 'Language Understanding', 'Understanding ”', '” ,', ', https', 'https :', ': //arxiv.org/pdf/1810.04805.pdf', '//arxiv.org/pdf/1810.04805.pdf •', '• Lee', 'Lee J', 'J ,', ', Yoon', 'Yoon W', 'W ,', ', Kim', 'Kim ,', ', Kim', 'Kim ,', ', Kim', 'Kim ,', ', ,', ', Jaewoo', 'Jaewoo Kang', 'Kang .'] 

 TOTAL BIGRAMS --> 62 



 ---- TRI-GRAMS ---- 

 ['• AbbVie ,', 'AbbVie , “', ', “ Closer', '“ Closer Look', 'Closer Look ”', 'Look ” ,', '” , https', ', https :', 'https : //www.abbvie.com/', ': //www.abbvie.com/ content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_', '//www.abbvie.com/ content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_ Corporate_Presentation.pdf', 'content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_ Corporate_Presentation.pdf ,', 'Corporate_Presentation.pdf , accessed', ', accessed online', 'accessed online 20', 'online 20 April', '20 April 2020', 'April 2020 •', '2020 • Devlin', '• Devlin J', 'Devlin J ,', 'J , Change', ', Change MW', 'Change MW ,', 'MW , Lee', ', Lee K', 'Lee K ,', 'K , Toutanova', ', Toutanova K.', 'Toutanova K. “', 'K. “ BERT', '“ BERT :', 'BERT : Pre-', ': Pre- training', 'Pre- training Deep', 'training Deep Bidirectional', 'Deep Bidirectional Transformers', 'Bidirectional Transformers Language', 'Transformers Language Understanding', 'Language Understanding ”', 'Understanding ” ,', '” , https', ', https :', 'https : //arxiv.org/pdf/1810.04805.pdf', ': //arxiv.org/pdf/1810.04805.pdf •', '//arxiv.org/pdf/1810.04805.pdf • Lee', '• Lee J', 'Lee J ,', 'J , Yoon', ', Yoon W', 'Yoon W ,', 'W , Kim', ', Kim ,', 'Kim , Kim', ', Kim ,', 'Kim , Kim', ', Kim ,', 'Kim , ,', ', , Jaewoo', ', Jaewoo Kang', 'Jaewoo Kang .'] 

 TOTAL TRIGRAMS --> 61 



 ---- NOUN PHRASES ---- 

 ['https', 'Pre- training', 'https', ''] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['AbbVie']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Devlin J', 'Change MW', 'Lee K', 'Toutanova K.', 'Deep Bidirectional Transformers Language', 'Lee J', 'Yoon W', 'Kim', 'Kim', 'Kim', 'Jaewoo Kang']
 TOTAL PERSON ENTITY --> 11 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'abbvi', ',', '“', 'closer', 'look', '”', ',', 'http', ':', '//www.abbvie.com/', 'content/dam/abbvie-dotcom/uploads/pdfs/abbvie_', 'corporate_presentation.pdf', ',', 'access', 'onlin', '20', 'april', '2020', '•', 'devlin', 'j', ',', 'chang', 'mw', ',', 'lee', 'k', ',', 'toutanova', 'k.', '“', 'bert', ':', 'pre-', 'train', 'deep', 'bidirect', 'transform', 'languag', 'understand', '”', ',', 'http', ':', '//arxiv.org/pdf/1810.04805.pdf', '•', 'lee', 'j', ',', 'yoon', 'w', ',', 'kim', ',', 'kim', ',', 'kim', ',', ',', 'jaewoo', 'kang', '.']

 TOTAL PORTER STEM WORDS ==> 63



 ---- SNOWBALL STEMMING ----

['•', 'abbvi', ',', '“', 'closer', 'look', '”', ',', 'https', ':', '//www.abbvie.com/', 'content/dam/abbvie-dotcom/uploads/pdfs/abbvie_', 'corporate_presentation.pdf', ',', 'access', 'onlin', '20', 'april', '2020', '•', 'devlin', 'j', ',', 'chang', 'mw', ',', 'lee', 'k', ',', 'toutanova', 'k.', '“', 'bert', ':', 'pre-', 'train', 'deep', 'bidirect', 'transform', 'languag', 'understand', '”', ',', 'https', ':', '//arxiv.org/pdf/1810.04805.pdf', '•', 'lee', 'j', ',', 'yoon', 'w', ',', 'kim', ',', 'kim', ',', 'kim', ',', ',', 'jaewoo', 'kang', '.']

 TOTAL SNOWBALL STEM WORDS ==> 63



 ---- LEMMATIZATION ----

['•', 'AbbVie', ',', '“', 'Closer', 'Look', '”', ',', 'http', ':', '//www.abbvie.com/', 'content/dam/abbvie-dotcom/uploads/PDFs/AbbVie_', 'Corporate_Presentation.pdf', ',', 'accessed', 'online', '20', 'April', '2020', '•', 'Devlin', 'J', ',', 'Change', 'MW', ',', 'Lee', 'K', ',', 'Toutanova', 'K.', '“', 'BERT', ':', 'Pre-', 'training', 'Deep', 'Bidirectional', 'Transformers', 'Language', 'Understanding', '”', ',', 'http', ':', '//arxiv.org/pdf/1810.04805.pdf', '•', 'Lee', 'J', ',', 'Yoon', 'W', ',', 'Kim', ',', 'Kim', ',', 'Kim', ',', ',', 'Jaewoo', 'Kang', '.']

 TOTAL LEMMATIZE WORDS ==> 63

************************************************************************************************************************

107 --> “BioBERT: a pre-trained biomedical language  representation model for biomedical text mining”,  Bioinformatics, Volume 36, Issue 4, 15 February 2020,  pages 1234–1240 • Tsatsaronis G, Balikas G, Malakasiotis P, Partalas I,  Zschunke M, Alvers M, Weissenborn D, Krithara A,  Petridis S, Polychronopoulos D, Almirantis Y, Pavlopoulos  J, Baskiotis N, Gallinari P, Artieres T, Nogonga Ngomo  AC, Heino N, Gaussier E, Barrio-Alvers L, Schroeder M,  Androutsoploulos I, Paliouras G. “An overview of the  BIOASQ large-scale biomedical semantic indexing and  question answering competition”. 


 ---- TOKENS ----

 ['“', 'BioBERT', ':', 'a', 'pre-trained', 'biomedical', 'language', 'representation', 'model', 'for', 'biomedical', 'text', 'mining', '”', ',', 'Bioinformatics', ',', 'Volume', '36', ',', 'Issue', '4', ',', '15', 'February', '2020', ',', 'pages', '1234–1240', '•', 'Tsatsaronis', 'G', ',', 'Balikas', 'G', ',', 'Malakasiotis', 'P', ',', 'Partalas', 'I', ',', 'Zschunke', 'M', ',', 'Alvers', 'M', ',', 'Weissenborn', 'D', ',', 'Krithara', 'A', ',', 'Petridis', 'S', ',', 'Polychronopoulos', 'D', ',', 'Almirantis', 'Y', ',', 'Pavlopoulos', 'J', ',', 'Baskiotis', 'N', ',', 'Gallinari', 'P', ',', 'Artieres', 'T', ',', 'Nogonga', 'Ngomo', 'AC', ',', 'Heino', 'N', ',', 'Gaussier', 'E', ',', 'Barrio-Alvers', 'L', ',', 'Schroeder', 'M', ',', 'Androutsoploulos', 'I', ',', 'Paliouras', 'G.', '“', 'An', 'overview', 'of', 'the', 'BIOASQ', 'large-scale', 'biomedical', 'semantic', 'indexing', 'and', 'question', 'answering', 'competition', '”', '.'] 

 TOTAL TOKENS ==> 112

 ---- POST ----

 [('“', 'JJ'), ('BioBERT', 'NNP'), (':', ':'), ('a', 'DT'), ('pre-trained', 'JJ'), ('biomedical', 'JJ'), ('language', 'NN'), ('representation', 'NN'), ('model', 'NN'), ('for', 'IN'), ('biomedical', 'JJ'), ('text', 'NN'), ('mining', 'NN'), ('”', 'NN'), (',', ','), ('Bioinformatics', 'NNP'), (',', ','), ('Volume', 'NN'), ('36', 'CD'), (',', ','), ('Issue', 'NNP'), ('4', 'CD'), (',', ','), ('15', 'CD'), ('February', 'NNP'), ('2020', 'CD'), (',', ','), ('pages', 'VBZ'), ('1234–1240', 'CD'), ('•', 'NN'), ('Tsatsaronis', 'NNP'), ('G', 'NNP'), (',', ','), ('Balikas', 'NNP'), ('G', 'NNP'), (',', ','), ('Malakasiotis', 'NNP'), ('P', 'NNP'), (',', ','), ('Partalas', 'NNP'), ('I', 'PRP'), (',', ','), ('Zschunke', 'NNP'), ('M', 'NNP'), (',', ','), ('Alvers', 'NNP'), ('M', 'NNP'), (',', ','), ('Weissenborn', 'NNP'), ('D', 'NNP'), (',', ','), ('Krithara', 'NNP'), ('A', 'NNP'), (',', ','), ('Petridis', 'NNP'), ('S', 'NNP'), (',', ','), ('Polychronopoulos', 'NNP'), ('D', 'NNP'), (',', ','), ('Almirantis', 'NNP'), ('Y', 'NNP'), (',', ','), ('Pavlopoulos', 'NNP'), ('J', 'NNP'), (',', ','), ('Baskiotis', 'NNP'), ('N', 'NNP'), (',', ','), ('Gallinari', 'NNP'), ('P', 'NNP'), (',', ','), ('Artieres', 'NNP'), ('T', 'NNP'), (',', ','), ('Nogonga', 'NNP'), ('Ngomo', 'NNP'), ('AC', 'NNP'), (',', ','), ('Heino', 'NNP'), ('N', 'NNP'), (',', ','), ('Gaussier', 'NNP'), ('E', 'NNP'), (',', ','), ('Barrio-Alvers', 'NNP'), ('L', 'NNP'), (',', ','), ('Schroeder', 'NNP'), ('M', 'NNP'), (',', ','), ('Androutsoploulos', 'NNP'), ('I', 'PRP'), (',', ','), ('Paliouras', 'NNP'), ('G.', 'NNP'), ('“', 'NNP'), ('An', 'DT'), ('overview', 'NN'), ('of', 'IN'), ('the', 'DT'), ('BIOASQ', 'NNP'), ('large-scale', 'JJ'), ('biomedical', 'JJ'), ('semantic', 'JJ'), ('indexing', 'NN'), ('and', 'CC'), ('question', 'NN'), ('answering', 'VBG'), ('competition', 'NN'), ('”', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['“', 'BioBERT', ':', 'pre-trained', 'biomedical', 'language', 'representation', 'model', 'biomedical', 'text', 'mining', '”', ',', 'Bioinformatics', ',', 'Volume', '36', ',', 'Issue', '4', ',', '15', 'February', '2020', ',', 'pages', '1234–1240', '•', 'Tsatsaronis', 'G', ',', 'Balikas', 'G', ',', 'Malakasiotis', 'P', ',', 'Partalas', ',', 'Zschunke', ',', 'Alvers', ',', 'Weissenborn', ',', 'Krithara', ',', 'Petridis', ',', 'Polychronopoulos', ',', 'Almirantis', ',', 'Pavlopoulos', 'J', ',', 'Baskiotis', 'N', ',', 'Gallinari', 'P', ',', 'Artieres', ',', 'Nogonga', 'Ngomo', 'AC', ',', 'Heino', 'N', ',', 'Gaussier', 'E', ',', 'Barrio-Alvers', 'L', ',', 'Schroeder', ',', 'Androutsoploulos', ',', 'Paliouras', 'G.', '“', 'overview', 'BIOASQ', 'large-scale', 'biomedical', 'semantic', 'indexing', 'question', 'answering', 'competition', '”', '.']

 TOTAL FILTERED TOKENS ==>  95

 ---- POST FOR FILTERED TOKENS ----

 [('“', 'JJ'), ('BioBERT', 'NNP'), (':', ':'), ('pre-trained', 'JJ'), ('biomedical', 'JJ'), ('language', 'NN'), ('representation', 'NN'), ('model', 'FW'), ('biomedical', 'JJ'), ('text', 'NN'), ('mining', 'NN'), ('”', 'NN'), (',', ','), ('Bioinformatics', 'NNP'), (',', ','), ('Volume', 'NN'), ('36', 'CD'), (',', ','), ('Issue', 'NNP'), ('4', 'CD'), (',', ','), ('15', 'CD'), ('February', 'NNP'), ('2020', 'CD'), (',', ','), ('pages', 'VBZ'), ('1234–1240', 'CD'), ('•', 'NN'), ('Tsatsaronis', 'NNP'), ('G', 'NNP'), (',', ','), ('Balikas', 'NNP'), ('G', 'NNP'), (',', ','), ('Malakasiotis', 'NNP'), ('P', 'NNP'), (',', ','), ('Partalas', 'NNP'), (',', ','), ('Zschunke', 'NNP'), (',', ','), ('Alvers', 'NNP'), (',', ','), ('Weissenborn', 'NNP'), (',', ','), ('Krithara', 'NNP'), (',', ','), ('Petridis', 'NNP'), (',', ','), ('Polychronopoulos', 'NNP'), (',', ','), ('Almirantis', 'NNP'), (',', ','), ('Pavlopoulos', 'NNP'), ('J', 'NNP'), (',', ','), ('Baskiotis', 'NNP'), ('N', 'NNP'), (',', ','), ('Gallinari', 'NNP'), ('P', 'NNP'), (',', ','), ('Artieres', 'NNP'), (',', ','), ('Nogonga', 'NNP'), ('Ngomo', 'NNP'), ('AC', 'NNP'), (',', ','), ('Heino', 'NNP'), ('N', 'NNP'), (',', ','), ('Gaussier', 'NNP'), ('E', 'NNP'), (',', ','), ('Barrio-Alvers', 'NNP'), ('L', 'NNP'), (',', ','), ('Schroeder', 'NNP'), (',', ','), ('Androutsoploulos', 'NNP'), (',', ','), ('Paliouras', 'NNP'), ('G.', 'NNP'), ('“', 'NNP'), ('overview', 'MD'), ('BIOASQ', 'NNP'), ('large-scale', 'JJ'), ('biomedical', 'JJ'), ('semantic', 'JJ'), ('indexing', 'VBG'), ('question', 'NN'), ('answering', 'VBG'), ('competition', 'NN'), ('”', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['“ BioBERT', 'BioBERT :', ': pre-trained', 'pre-trained biomedical', 'biomedical language', 'language representation', 'representation model', 'model biomedical', 'biomedical text', 'text mining', 'mining ”', '” ,', ', Bioinformatics', 'Bioinformatics ,', ', Volume', 'Volume 36', '36 ,', ', Issue', 'Issue 4', '4 ,', ', 15', '15 February', 'February 2020', '2020 ,', ', pages', 'pages 1234–1240', '1234–1240 •', '• Tsatsaronis', 'Tsatsaronis G', 'G ,', ', Balikas', 'Balikas G', 'G ,', ', Malakasiotis', 'Malakasiotis P', 'P ,', ', Partalas', 'Partalas ,', ', Zschunke', 'Zschunke ,', ', Alvers', 'Alvers ,', ', Weissenborn', 'Weissenborn ,', ', Krithara', 'Krithara ,', ', Petridis', 'Petridis ,', ', Polychronopoulos', 'Polychronopoulos ,', ', Almirantis', 'Almirantis ,', ', Pavlopoulos', 'Pavlopoulos J', 'J ,', ', Baskiotis', 'Baskiotis N', 'N ,', ', Gallinari', 'Gallinari P', 'P ,', ', Artieres', 'Artieres ,', ', Nogonga', 'Nogonga Ngomo', 'Ngomo AC', 'AC ,', ', Heino', 'Heino N', 'N ,', ', Gaussier', 'Gaussier E', 'E ,', ', Barrio-Alvers', 'Barrio-Alvers L', 'L ,', ', Schroeder', 'Schroeder ,', ', Androutsoploulos', 'Androutsoploulos ,', ', Paliouras', 'Paliouras G.', 'G. “', '“ overview', 'overview BIOASQ', 'BIOASQ large-scale', 'large-scale biomedical', 'biomedical semantic', 'semantic indexing', 'indexing question', 'question answering', 'answering competition', 'competition ”', '” .'] 

 TOTAL BIGRAMS --> 94 



 ---- TRI-GRAMS ---- 

 ['“ BioBERT :', 'BioBERT : pre-trained', ': pre-trained biomedical', 'pre-trained biomedical language', 'biomedical language representation', 'language representation model', 'representation model biomedical', 'model biomedical text', 'biomedical text mining', 'text mining ”', 'mining ” ,', '” , Bioinformatics', ', Bioinformatics ,', 'Bioinformatics , Volume', ', Volume 36', 'Volume 36 ,', '36 , Issue', ', Issue 4', 'Issue 4 ,', '4 , 15', ', 15 February', '15 February 2020', 'February 2020 ,', '2020 , pages', ', pages 1234–1240', 'pages 1234–1240 •', '1234–1240 • Tsatsaronis', '• Tsatsaronis G', 'Tsatsaronis G ,', 'G , Balikas', ', Balikas G', 'Balikas G ,', 'G , Malakasiotis', ', Malakasiotis P', 'Malakasiotis P ,', 'P , Partalas', ', Partalas ,', 'Partalas , Zschunke', ', Zschunke ,', 'Zschunke , Alvers', ', Alvers ,', 'Alvers , Weissenborn', ', Weissenborn ,', 'Weissenborn , Krithara', ', Krithara ,', 'Krithara , Petridis', ', Petridis ,', 'Petridis , Polychronopoulos', ', Polychronopoulos ,', 'Polychronopoulos , Almirantis', ', Almirantis ,', 'Almirantis , Pavlopoulos', ', Pavlopoulos J', 'Pavlopoulos J ,', 'J , Baskiotis', ', Baskiotis N', 'Baskiotis N ,', 'N , Gallinari', ', Gallinari P', 'Gallinari P ,', 'P , Artieres', ', Artieres ,', 'Artieres , Nogonga', ', Nogonga Ngomo', 'Nogonga Ngomo AC', 'Ngomo AC ,', 'AC , Heino', ', Heino N', 'Heino N ,', 'N , Gaussier', ', Gaussier E', 'Gaussier E ,', 'E , Barrio-Alvers', ', Barrio-Alvers L', 'Barrio-Alvers L ,', 'L , Schroeder', ', Schroeder ,', 'Schroeder , Androutsoploulos', ', Androutsoploulos ,', 'Androutsoploulos , Paliouras', ', Paliouras G.', 'Paliouras G. “', 'G. “ overview', '“ overview BIOASQ', 'overview BIOASQ large-scale', 'BIOASQ large-scale biomedical', 'large-scale biomedical semantic', 'biomedical semantic indexing', 'semantic indexing question', 'indexing question answering', 'question answering competition', 'answering competition ”', 'competition ” .'] 

 TOTAL TRIGRAMS --> 93 



 ---- NOUN PHRASES ---- 

 ['pre-trained biomedical language', 'representation', 'biomedical text', 'mining', '”', 'Volume', '•', 'question', 'competition', '”'] 

 TOTAL NOUN PHRASES --> 10 



 ---- NER ----

 
 ORGANIZATION ---> ['Volume 36', 'BIOASQ']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> ['Bioinformatics', 'Tsatsaronis G', 'Balikas G', 'Malakasiotis P', 'Almirantis', 'Pavlopoulos J', 'Baskiotis N', 'Gallinari P', 'Artieres', 'Nogonga Ngomo AC', 'Heino N', 'Gaussier E', 'Schroeder', 'Androutsoploulos', 'Paliouras G.']
 TOTAL PERSON ENTITY --> 15 


 GPE ---> ['Partalas', 'Zschunke', 'Alvers', 'Weissenborn', 'Krithara', 'Petridis', 'Polychronopoulos']
 TOTAL GPE ENTITY --> 7 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['“', 'biobert', ':', 'pre-train', 'biomed', 'languag', 'represent', 'model', 'biomed', 'text', 'mine', '”', ',', 'bioinformat', ',', 'volum', '36', ',', 'issu', '4', ',', '15', 'februari', '2020', ',', 'page', '1234–1240', '•', 'tsatsaroni', 'g', ',', 'balika', 'g', ',', 'malakasioti', 'p', ',', 'partala', ',', 'zschunk', ',', 'alver', ',', 'weissenborn', ',', 'krithara', ',', 'petridi', ',', 'polychronopoulo', ',', 'almiranti', ',', 'pavlopoulo', 'j', ',', 'baskioti', 'n', ',', 'gallinari', 'p', ',', 'artier', ',', 'nogonga', 'ngomo', 'ac', ',', 'heino', 'n', ',', 'gaussier', 'e', ',', 'barrio-alv', 'l', ',', 'schroeder', ',', 'androutsoploulo', ',', 'palioura', 'g.', '“', 'overview', 'bioasq', 'large-scal', 'biomed', 'semant', 'index', 'question', 'answer', 'competit', '”', '.']

 TOTAL PORTER STEM WORDS ==> 95



 ---- SNOWBALL STEMMING ----

['“', 'biobert', ':', 'pre-train', 'biomed', 'languag', 'represent', 'model', 'biomed', 'text', 'mine', '”', ',', 'bioinformat', ',', 'volum', '36', ',', 'issu', '4', ',', '15', 'februari', '2020', ',', 'page', '1234–1240', '•', 'tsatsaroni', 'g', ',', 'balika', 'g', ',', 'malakasioti', 'p', ',', 'partala', ',', 'zschunk', ',', 'alver', ',', 'weissenborn', ',', 'krithara', ',', 'petridi', ',', 'polychronopoulo', ',', 'almiranti', ',', 'pavlopoulo', 'j', ',', 'baskioti', 'n', ',', 'gallinari', 'p', ',', 'artier', ',', 'nogonga', 'ngomo', 'ac', ',', 'heino', 'n', ',', 'gaussier', 'e', ',', 'barrio-alv', 'l', ',', 'schroeder', ',', 'androutsoploulo', ',', 'palioura', 'g.', '“', 'overview', 'bioasq', 'large-scal', 'biomed', 'semant', 'index', 'question', 'answer', 'competit', '”', '.']

 TOTAL SNOWBALL STEM WORDS ==> 95



 ---- LEMMATIZATION ----

['“', 'BioBERT', ':', 'pre-trained', 'biomedical', 'language', 'representation', 'model', 'biomedical', 'text', 'mining', '”', ',', 'Bioinformatics', ',', 'Volume', '36', ',', 'Issue', '4', ',', '15', 'February', '2020', ',', 'page', '1234–1240', '•', 'Tsatsaronis', 'G', ',', 'Balikas', 'G', ',', 'Malakasiotis', 'P', ',', 'Partalas', ',', 'Zschunke', ',', 'Alvers', ',', 'Weissenborn', ',', 'Krithara', ',', 'Petridis', ',', 'Polychronopoulos', ',', 'Almirantis', ',', 'Pavlopoulos', 'J', ',', 'Baskiotis', 'N', ',', 'Gallinari', 'P', ',', 'Artieres', ',', 'Nogonga', 'Ngomo', 'AC', ',', 'Heino', 'N', ',', 'Gaussier', 'E', ',', 'Barrio-Alvers', 'L', ',', 'Schroeder', ',', 'Androutsoploulos', ',', 'Paliouras', 'G.', '“', 'overview', 'BIOASQ', 'large-scale', 'biomedical', 'semantic', 'indexing', 'question', 'answering', 'competition', '”', '.']

 TOTAL LEMMATIZE WORDS ==> 95

************************************************************************************************************************

108 --> BMC Bioinformatics, 16,  138 (2015). 


 ---- TOKENS ----

 ['BMC', 'Bioinformatics', ',', '16', ',', '138', '(', '2015', ')', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('BMC', 'NNP'), ('Bioinformatics', 'NNP'), (',', ','), ('16', 'CD'), (',', ','), ('138', 'CD'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['BMC', 'Bioinformatics', ',', '16', ',', '138', '(', '2015', ')', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('BMC', 'NNP'), ('Bioinformatics', 'NNP'), (',', ','), ('16', 'CD'), (',', ','), ('138', 'CD'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['BMC Bioinformatics', 'Bioinformatics ,', ', 16', '16 ,', ', 138', '138 (', '( 2015', '2015 )', ') .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['BMC Bioinformatics ,', 'Bioinformatics , 16', ', 16 ,', '16 , 138', ', 138 (', '138 ( 2015', '( 2015 )', '2015 ) .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['BMC Bioinformatics']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['bmc', 'bioinformat', ',', '16', ',', '138', '(', '2015', ')', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['bmc', 'bioinformat', ',', '16', ',', '138', '(', '2015', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['BMC', 'Bioinformatics', ',', '16', ',', '138', '(', '2015', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

109 --> https://doi.org/10.1186/s12859-015-0564-6 Backup: System Configuration Details    All tests were performed by Intel in June 2020. 


 ---- TOKENS ----

 ['https', ':', '//doi.org/10.1186/s12859-015-0564-6', 'Backup', ':', 'System', 'Configuration', 'Details', 'All', 'tests', 'were', 'performed', 'by', 'Intel', 'in', 'June', '2020', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('https', 'NN'), (':', ':'), ('//doi.org/10.1186/s12859-015-0564-6', 'JJ'), ('Backup', 'NNP'), (':', ':'), ('System', 'NN'), ('Configuration', 'NNP'), ('Details', 'NNP'), ('All', 'NNP'), ('tests', 'NNS'), ('were', 'VBD'), ('performed', 'VBN'), ('by', 'IN'), ('Intel', 'NNP'), ('in', 'IN'), ('June', 'NNP'), ('2020', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['https', ':', '//doi.org/10.1186/s12859-015-0564-6', 'Backup', ':', 'System', 'Configuration', 'Details', 'tests', 'performed', 'Intel', 'June', '2020', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('https', 'NN'), (':', ':'), ('//doi.org/10.1186/s12859-015-0564-6', 'JJ'), ('Backup', 'NNP'), (':', ':'), ('System', 'NN'), ('Configuration', 'NNP'), ('Details', 'NNP'), ('tests', 'NNS'), ('performed', 'VBD'), ('Intel', 'NNP'), ('June', 'NNP'), ('2020', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['https :', ': //doi.org/10.1186/s12859-015-0564-6', '//doi.org/10.1186/s12859-015-0564-6 Backup', 'Backup :', ': System', 'System Configuration', 'Configuration Details', 'Details tests', 'tests performed', 'performed Intel', 'Intel June', 'June 2020', '2020 .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['https : //doi.org/10.1186/s12859-015-0564-6', ': //doi.org/10.1186/s12859-015-0564-6 Backup', '//doi.org/10.1186/s12859-015-0564-6 Backup :', 'Backup : System', ': System Configuration', 'System Configuration Details', 'Configuration Details tests', 'Details tests performed', 'tests performed Intel', 'performed Intel June', 'Intel June 2020', 'June 2020 .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['https', 'System'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['System Configuration Details']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['http', ':', '//doi.org/10.1186/s12859-015-0564-6', 'backup', ':', 'system', 'configur', 'detail', 'test', 'perform', 'intel', 'june', '2020', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['https', ':', '//doi.org/10.1186/s12859-015-0564-6', 'backup', ':', 'system', 'configur', 'detail', 'test', 'perform', 'intel', 'june', '2020', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['http', ':', '//doi.org/10.1186/s12859-015-0564-6', 'Backup', ':', 'System', 'Configuration', 'Details', 'test', 'performed', 'Intel', 'June', '2020', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

110 --> Intel® Xeon® Gold 6252N Processor @ 2.30 GHz, two sockets, 24 cores per socket, 394 GB DDR4 RAM, Intel Hyper-Threading Technology enabled, Intel® Turbo Boost enabled,  NUMA enabled, BIOS version 4.1.12, Microcode 0x500002c, Ubuntu 18.04.4 LTS, Linux Kernel 4.15.0-101-generic, Spectre/Meltdown mitigated, Software: Intel® Optimization for  TensorFlow* version 1.15 with DNNL and Intel® Distribution of OpenVINO™ toolkit. 


 ---- TOKENS ----

 ['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '@', '2.30', 'GHz', ',', 'two', 'sockets', ',', '24', 'cores', 'per', 'socket', ',', '394', 'GB', 'DDR4', 'RAM', ',', 'Intel', 'Hyper-Threading', 'Technology', 'enabled', ',', 'Intel®', 'Turbo', 'Boost', 'enabled', ',', 'NUMA', 'enabled', ',', 'BIOS', 'version', '4.1.12', ',', 'Microcode', '0x500002c', ',', 'Ubuntu', '18.04.4', 'LTS', ',', 'Linux', 'Kernel', '4.15.0-101-generic', ',', 'Spectre/Meltdown', 'mitigated', ',', 'Software', ':', 'Intel®', 'Optimization', 'for', 'TensorFlow', '*', 'version', '1.15', 'with', 'DNNL', 'and', 'Intel®', 'Distribution', 'of', 'OpenVINO™', 'toolkit', '.'] 

 TOTAL TOKENS ==> 71

 ---- POST ----

 [('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('@', 'VBD'), ('2.30', 'CD'), ('GHz', 'NNP'), (',', ','), ('two', 'CD'), ('sockets', 'NNS'), (',', ','), ('24', 'CD'), ('cores', 'NNS'), ('per', 'IN'), ('socket', 'NN'), (',', ','), ('394', 'CD'), ('GB', 'NNP'), ('DDR4', 'NNP'), ('RAM', 'NNP'), (',', ','), ('Intel', 'NNP'), ('Hyper-Threading', 'NNP'), ('Technology', 'NNP'), ('enabled', 'VBD'), (',', ','), ('Intel®', 'NNP'), ('Turbo', 'NNP'), ('Boost', 'NNP'), ('enabled', 'VBD'), (',', ','), ('NUMA', 'NNP'), ('enabled', 'VBD'), (',', ','), ('BIOS', 'NNP'), ('version', 'NN'), ('4.1.12', 'CD'), (',', ','), ('Microcode', 'NNP'), ('0x500002c', 'CD'), (',', ','), ('Ubuntu', 'NNP'), ('18.04.4', 'CD'), ('LTS', 'NNP'), (',', ','), ('Linux', 'NNP'), ('Kernel', 'NNP'), ('4.15.0-101-generic', 'JJ'), (',', ','), ('Spectre/Meltdown', 'NNP'), ('mitigated', 'VBD'), (',', ','), ('Software', 'NNP'), (':', ':'), ('Intel®', 'NNP'), ('Optimization', 'NNP'), ('for', 'IN'), ('TensorFlow', 'NNP'), ('*', 'NNP'), ('version', 'NN'), ('1.15', 'CD'), ('with', 'IN'), ('DNNL', 'NNP'), ('and', 'CC'), ('Intel®', 'NNP'), ('Distribution', 'NNP'), ('of', 'IN'), ('OpenVINO™', 'NNP'), ('toolkit', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '@', '2.30', 'GHz', ',', 'two', 'sockets', ',', '24', 'cores', 'per', 'socket', ',', '394', 'GB', 'DDR4', 'RAM', ',', 'Intel', 'Hyper-Threading', 'Technology', 'enabled', ',', 'Intel®', 'Turbo', 'Boost', 'enabled', ',', 'NUMA', 'enabled', ',', 'BIOS', 'version', '4.1.12', ',', 'Microcode', '0x500002c', ',', 'Ubuntu', '18.04.4', 'LTS', ',', 'Linux', 'Kernel', '4.15.0-101-generic', ',', 'Spectre/Meltdown', 'mitigated', ',', 'Software', ':', 'Intel®', 'Optimization', 'TensorFlow', '*', 'version', '1.15', 'DNNL', 'Intel®', 'Distribution', 'OpenVINO™', 'toolkit', '.']

 TOTAL FILTERED TOKENS ==>  67

 ---- POST FOR FILTERED TOKENS ----

 [('Intel®', 'NNP'), ('Xeon®', 'NNP'), ('Gold', 'NNP'), ('6252N', 'CD'), ('Processor', 'NNP'), ('@', 'VBD'), ('2.30', 'CD'), ('GHz', 'NNP'), (',', ','), ('two', 'CD'), ('sockets', 'NNS'), (',', ','), ('24', 'CD'), ('cores', 'NNS'), ('per', 'IN'), ('socket', 'NN'), (',', ','), ('394', 'CD'), ('GB', 'NNP'), ('DDR4', 'NNP'), ('RAM', 'NNP'), (',', ','), ('Intel', 'NNP'), ('Hyper-Threading', 'NNP'), ('Technology', 'NNP'), ('enabled', 'VBD'), (',', ','), ('Intel®', 'NNP'), ('Turbo', 'NNP'), ('Boost', 'NNP'), ('enabled', 'VBD'), (',', ','), ('NUMA', 'NNP'), ('enabled', 'VBD'), (',', ','), ('BIOS', 'NNP'), ('version', 'NN'), ('4.1.12', 'CD'), (',', ','), ('Microcode', 'NNP'), ('0x500002c', 'CD'), (',', ','), ('Ubuntu', 'NNP'), ('18.04.4', 'CD'), ('LTS', 'NNP'), (',', ','), ('Linux', 'NNP'), ('Kernel', 'NNP'), ('4.15.0-101-generic', 'JJ'), (',', ','), ('Spectre/Meltdown', 'NNP'), ('mitigated', 'VBD'), (',', ','), ('Software', 'NNP'), (':', ':'), ('Intel®', 'NNP'), ('Optimization', 'NNP'), ('TensorFlow', 'NNP'), ('*', 'NNP'), ('version', 'NN'), ('1.15', 'CD'), ('DNNL', 'NNP'), ('Intel®', 'NNP'), ('Distribution', 'NNP'), ('OpenVINO™', 'NNP'), ('toolkit', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Intel® Xeon®', 'Xeon® Gold', 'Gold 6252N', '6252N Processor', 'Processor @', '@ 2.30', '2.30 GHz', 'GHz ,', ', two', 'two sockets', 'sockets ,', ', 24', '24 cores', 'cores per', 'per socket', 'socket ,', ', 394', '394 GB', 'GB DDR4', 'DDR4 RAM', 'RAM ,', ', Intel', 'Intel Hyper-Threading', 'Hyper-Threading Technology', 'Technology enabled', 'enabled ,', ', Intel®', 'Intel® Turbo', 'Turbo Boost', 'Boost enabled', 'enabled ,', ', NUMA', 'NUMA enabled', 'enabled ,', ', BIOS', 'BIOS version', 'version 4.1.12', '4.1.12 ,', ', Microcode', 'Microcode 0x500002c', '0x500002c ,', ', Ubuntu', 'Ubuntu 18.04.4', '18.04.4 LTS', 'LTS ,', ', Linux', 'Linux Kernel', 'Kernel 4.15.0-101-generic', '4.15.0-101-generic ,', ', Spectre/Meltdown', 'Spectre/Meltdown mitigated', 'mitigated ,', ', Software', 'Software :', ': Intel®', 'Intel® Optimization', 'Optimization TensorFlow', 'TensorFlow *', '* version', 'version 1.15', '1.15 DNNL', 'DNNL Intel®', 'Intel® Distribution', 'Distribution OpenVINO™', 'OpenVINO™ toolkit', 'toolkit .'] 

 TOTAL BIGRAMS --> 66 



 ---- TRI-GRAMS ---- 

 ['Intel® Xeon® Gold', 'Xeon® Gold 6252N', 'Gold 6252N Processor', '6252N Processor @', 'Processor @ 2.30', '@ 2.30 GHz', '2.30 GHz ,', 'GHz , two', ', two sockets', 'two sockets ,', 'sockets , 24', ', 24 cores', '24 cores per', 'cores per socket', 'per socket ,', 'socket , 394', ', 394 GB', '394 GB DDR4', 'GB DDR4 RAM', 'DDR4 RAM ,', 'RAM , Intel', ', Intel Hyper-Threading', 'Intel Hyper-Threading Technology', 'Hyper-Threading Technology enabled', 'Technology enabled ,', 'enabled , Intel®', ', Intel® Turbo', 'Intel® Turbo Boost', 'Turbo Boost enabled', 'Boost enabled ,', 'enabled , NUMA', ', NUMA enabled', 'NUMA enabled ,', 'enabled , BIOS', ', BIOS version', 'BIOS version 4.1.12', 'version 4.1.12 ,', '4.1.12 , Microcode', ', Microcode 0x500002c', 'Microcode 0x500002c ,', '0x500002c , Ubuntu', ', Ubuntu 18.04.4', 'Ubuntu 18.04.4 LTS', '18.04.4 LTS ,', 'LTS , Linux', ', Linux Kernel', 'Linux Kernel 4.15.0-101-generic', 'Kernel 4.15.0-101-generic ,', '4.15.0-101-generic , Spectre/Meltdown', ', Spectre/Meltdown mitigated', 'Spectre/Meltdown mitigated ,', 'mitigated , Software', ', Software :', 'Software : Intel®', ': Intel® Optimization', 'Intel® Optimization TensorFlow', 'Optimization TensorFlow *', 'TensorFlow * version', '* version 1.15', 'version 1.15 DNNL', '1.15 DNNL Intel®', 'DNNL Intel® Distribution', 'Intel® Distribution OpenVINO™', 'Distribution OpenVINO™ toolkit', 'OpenVINO™ toolkit .'] 

 TOTAL TRIGRAMS --> 65 



 ---- NOUN PHRASES ---- 

 ['socket', 'version', 'version', 'toolkit'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['Intel', 'NUMA', 'BIOS', 'Microcode', 'Ubuntu', 'TensorFlow', 'DNNL']
 TOTAL ORGANIZATION ENTITY --> 7 


 PERSON ---> ['Turbo Boost', 'Linux Kernel', 'Software']
 TOTAL PERSON ENTITY --> 3 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['intel®', 'xeon®', 'gold', '6252n', 'processor', '@', '2.30', 'ghz', ',', 'two', 'socket', ',', '24', 'core', 'per', 'socket', ',', '394', 'gb', 'ddr4', 'ram', ',', 'intel', 'hyper-thread', 'technolog', 'enabl', ',', 'intel®', 'turbo', 'boost', 'enabl', ',', 'numa', 'enabl', ',', 'bio', 'version', '4.1.12', ',', 'microcod', '0x500002c', ',', 'ubuntu', '18.04.4', 'lt', ',', 'linux', 'kernel', '4.15.0-101-gener', ',', 'spectre/meltdown', 'mitig', ',', 'softwar', ':', 'intel®', 'optim', 'tensorflow', '*', 'version', '1.15', 'dnnl', 'intel®', 'distribut', 'openvino™', 'toolkit', '.']

 TOTAL PORTER STEM WORDS ==> 67



 ---- SNOWBALL STEMMING ----

['intel®', 'xeon®', 'gold', '6252n', 'processor', '@', '2.30', 'ghz', ',', 'two', 'socket', ',', '24', 'core', 'per', 'socket', ',', '394', 'gb', 'ddr4', 'ram', ',', 'intel', 'hyper-thread', 'technolog', 'enabl', ',', 'intel®', 'turbo', 'boost', 'enabl', ',', 'numa', 'enabl', ',', 'bio', 'version', '4.1.12', ',', 'microcod', '0x500002c', ',', 'ubuntu', '18.04.4', 'lts', ',', 'linux', 'kernel', '4.15.0-101-gener', ',', 'spectre/meltdown', 'mitig', ',', 'softwar', ':', 'intel®', 'optim', 'tensorflow', '*', 'version', '1.15', 'dnnl', 'intel®', 'distribut', 'openvino™', 'toolkit', '.']

 TOTAL SNOWBALL STEM WORDS ==> 67



 ---- LEMMATIZATION ----

['Intel®', 'Xeon®', 'Gold', '6252N', 'Processor', '@', '2.30', 'GHz', ',', 'two', 'socket', ',', '24', 'core', 'per', 'socket', ',', '394', 'GB', 'DDR4', 'RAM', ',', 'Intel', 'Hyper-Threading', 'Technology', 'enabled', ',', 'Intel®', 'Turbo', 'Boost', 'enabled', ',', 'NUMA', 'enabled', ',', 'BIOS', 'version', '4.1.12', ',', 'Microcode', '0x500002c', ',', 'Ubuntu', '18.04.4', 'LTS', ',', 'Linux', 'Kernel', '4.15.0-101-generic', ',', 'Spectre/Meltdown', 'mitigated', ',', 'Software', ':', 'Intel®', 'Optimization', 'TensorFlow', '*', 'version', '1.15', 'DNNL', 'Intel®', 'Distribution', 'OpenVINO™', 'toolkit', '.']

 TOTAL LEMMATIZE WORDS ==> 67

************************************************************************************************************************

111 --> http://intel.com/xeonscalable http://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html 


 ---- TOKENS ----

 ['http', ':', '//intel.com/xeonscalable', 'http', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', 'https', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('http', 'NN'), (':', ':'), ('//intel.com/xeonscalable', 'JJ'), ('http', 'NN'), (':', ':'), ('//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', 'JJ'), ('https', 'NN'), (':', ':'), ('//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html', 'JJ')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['http', ':', '//intel.com/xeonscalable', 'http', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', 'https', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('http', 'NN'), (':', ':'), ('//intel.com/xeonscalable', 'JJ'), ('http', 'NN'), (':', ':'), ('//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', 'JJ'), ('https', 'NN'), (':', ':'), ('//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html', 'JJ')] 



 ---- BI-GRAMS ---- 

 ['http :', ': //intel.com/xeonscalable', '//intel.com/xeonscalable http', 'http :', ': //software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html https', 'https :', ': //software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['http : //intel.com/xeonscalable', ': //intel.com/xeonscalable http', '//intel.com/xeonscalable http :', 'http : //software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', ': //software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html https', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html https :', 'https : //software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['http', ' http', ' https'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['http', ':', '//intel.com/xeonscal', 'http', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', 'http', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['http', ':', '//intel.com/xeonscal', 'http', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', 'https', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['http', ':', '//intel.com/xeonscalable', 'http', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html', 'http', ':', '//software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

