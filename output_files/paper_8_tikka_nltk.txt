1 --> White Paper on Natural Language Processing  White Paper on  Natural Language Processing  Ralph Weiscbedel, Chairperson  BBN Systems and Technologies Corporation  Jaime Carbonell  Carnegie-Mellon University  Barbara Grosz  Harvard University  • Wendy Lehnert  University of Massachusetts, Amherst  Mitchell Marcus  University of Pennsylvania  Raymond Perrault  SRI International  Robert Wilensky  University of California, Berkeley  I. 


 ---- TOKENS ----

 ['White', 'Paper', 'on', 'Natural', 'Language', 'Processing', 'White', 'Paper', 'on', 'Natural', 'Language', 'Processing', 'Ralph', 'Weiscbedel', ',', 'Chairperson', 'BBN', 'Systems', 'and', 'Technologies', 'Corporation', 'Jaime', 'Carbonell', 'Carnegie-Mellon', 'University', 'Barbara', 'Grosz', 'Harvard', 'University', '•', 'Wendy', 'Lehnert', 'University', 'of', 'Massachusetts', ',', 'Amherst', 'Mitchell', 'Marcus', 'University', 'of', 'Pennsylvania', 'Raymond', 'Perrault', 'SRI', 'International', 'Robert', 'Wilensky', 'University', 'of', 'California', ',', 'Berkeley', 'I', '.'] 

 TOTAL TOKENS ==> 55

 ---- POST ----

 [('White', 'NNP'), ('Paper', 'NNP'), ('on', 'IN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('White', 'NNP'), ('Paper', 'NNP'), ('on', 'IN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Ralph', 'NNP'), ('Weiscbedel', 'NNP'), (',', ','), ('Chairperson', 'NNP'), ('BBN', 'NNP'), ('Systems', 'NNPS'), ('and', 'CC'), ('Technologies', 'NNPS'), ('Corporation', 'NNP'), ('Jaime', 'NNP'), ('Carbonell', 'NNP'), ('Carnegie-Mellon', 'NNP'), ('University', 'NNP'), ('Barbara', 'NNP'), ('Grosz', 'NNP'), ('Harvard', 'NNP'), ('University', 'NNP'), ('•', 'NNP'), ('Wendy', 'NNP'), ('Lehnert', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Massachusetts', 'NNP'), (',', ','), ('Amherst', 'NNP'), ('Mitchell', 'NNP'), ('Marcus', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Pennsylvania', 'NNP'), ('Raymond', 'NNP'), ('Perrault', 'NNP'), ('SRI', 'NNP'), ('International', 'NNP'), ('Robert', 'NNP'), ('Wilensky', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('California', 'NNP'), (',', ','), ('Berkeley', 'NNP'), ('I', 'PRP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['White', 'Paper', 'Natural', 'Language', 'Processing', 'White', 'Paper', 'Natural', 'Language', 'Processing', 'Ralph', 'Weiscbedel', ',', 'Chairperson', 'BBN', 'Systems', 'Technologies', 'Corporation', 'Jaime', 'Carbonell', 'Carnegie-Mellon', 'University', 'Barbara', 'Grosz', 'Harvard', 'University', '•', 'Wendy', 'Lehnert', 'University', 'Massachusetts', ',', 'Amherst', 'Mitchell', 'Marcus', 'University', 'Pennsylvania', 'Raymond', 'Perrault', 'SRI', 'International', 'Robert', 'Wilensky', 'University', 'California', ',', 'Berkeley', '.']

 TOTAL FILTERED TOKENS ==>  48

 ---- POST FOR FILTERED TOKENS ----

 [('White', 'NNP'), ('Paper', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('White', 'NNP'), ('Paper', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Ralph', 'NNP'), ('Weiscbedel', 'NNP'), (',', ','), ('Chairperson', 'NNP'), ('BBN', 'NNP'), ('Systems', 'NNP'), ('Technologies', 'NNPS'), ('Corporation', 'NNP'), ('Jaime', 'NNP'), ('Carbonell', 'NNP'), ('Carnegie-Mellon', 'NNP'), ('University', 'NNP'), ('Barbara', 'NNP'), ('Grosz', 'NNP'), ('Harvard', 'NNP'), ('University', 'NNP'), ('•', 'NNP'), ('Wendy', 'NNP'), ('Lehnert', 'NNP'), ('University', 'NNP'), ('Massachusetts', 'NNP'), (',', ','), ('Amherst', 'NNP'), ('Mitchell', 'NNP'), ('Marcus', 'NNP'), ('University', 'NNP'), ('Pennsylvania', 'NNP'), ('Raymond', 'NNP'), ('Perrault', 'NNP'), ('SRI', 'NNP'), ('International', 'NNP'), ('Robert', 'NNP'), ('Wilensky', 'NNP'), ('University', 'NNP'), ('California', 'NNP'), (',', ','), ('Berkeley', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['White Paper', 'Paper Natural', 'Natural Language', 'Language Processing', 'Processing White', 'White Paper', 'Paper Natural', 'Natural Language', 'Language Processing', 'Processing Ralph', 'Ralph Weiscbedel', 'Weiscbedel ,', ', Chairperson', 'Chairperson BBN', 'BBN Systems', 'Systems Technologies', 'Technologies Corporation', 'Corporation Jaime', 'Jaime Carbonell', 'Carbonell Carnegie-Mellon', 'Carnegie-Mellon University', 'University Barbara', 'Barbara Grosz', 'Grosz Harvard', 'Harvard University', 'University •', '• Wendy', 'Wendy Lehnert', 'Lehnert University', 'University Massachusetts', 'Massachusetts ,', ', Amherst', 'Amherst Mitchell', 'Mitchell Marcus', 'Marcus University', 'University Pennsylvania', 'Pennsylvania Raymond', 'Raymond Perrault', 'Perrault SRI', 'SRI International', 'International Robert', 'Robert Wilensky', 'Wilensky University', 'University California', 'California ,', ', Berkeley', 'Berkeley .'] 

 TOTAL BIGRAMS --> 47 



 ---- TRI-GRAMS ---- 

 ['White Paper Natural', 'Paper Natural Language', 'Natural Language Processing', 'Language Processing White', 'Processing White Paper', 'White Paper Natural', 'Paper Natural Language', 'Natural Language Processing', 'Language Processing Ralph', 'Processing Ralph Weiscbedel', 'Ralph Weiscbedel ,', 'Weiscbedel , Chairperson', ', Chairperson BBN', 'Chairperson BBN Systems', 'BBN Systems Technologies', 'Systems Technologies Corporation', 'Technologies Corporation Jaime', 'Corporation Jaime Carbonell', 'Jaime Carbonell Carnegie-Mellon', 'Carbonell Carnegie-Mellon University', 'Carnegie-Mellon University Barbara', 'University Barbara Grosz', 'Barbara Grosz Harvard', 'Grosz Harvard University', 'Harvard University •', 'University • Wendy', '• Wendy Lehnert', 'Wendy Lehnert University', 'Lehnert University Massachusetts', 'University Massachusetts ,', 'Massachusetts , Amherst', ', Amherst Mitchell', 'Amherst Mitchell Marcus', 'Mitchell Marcus University', 'Marcus University Pennsylvania', 'University Pennsylvania Raymond', 'Pennsylvania Raymond Perrault', 'Raymond Perrault SRI', 'Perrault SRI International', 'SRI International Robert', 'International Robert Wilensky', 'Robert Wilensky University', 'Wilensky University California', 'University California ,', 'California , Berkeley', ', Berkeley .'] 

 TOTAL TRIGRAMS --> 46 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['SRI International']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Paper Natural Language', 'Ralph Weiscbedel', 'Chairperson BBN Systems', 'Carbonell', 'Barbara Grosz Harvard University', 'Wendy Lehnert University Massachusetts', 'Amherst Mitchell Marcus University Pennsylvania Raymond Perrault', 'Robert Wilensky University California', 'Berkeley']
 TOTAL PERSON ENTITY --> 9 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['white', 'paper', 'natur', 'languag', 'process', 'white', 'paper', 'natur', 'languag', 'process', 'ralph', 'weiscbedel', ',', 'chairperson', 'bbn', 'system', 'technolog', 'corpor', 'jaim', 'carbonel', 'carnegie-mellon', 'univers', 'barbara', 'grosz', 'harvard', 'univers', '•', 'wendi', 'lehnert', 'univers', 'massachusett', ',', 'amherst', 'mitchel', 'marcu', 'univers', 'pennsylvania', 'raymond', 'perrault', 'sri', 'intern', 'robert', 'wilenski', 'univers', 'california', ',', 'berkeley', '.']

 TOTAL PORTER STEM WORDS ==> 48



 ---- SNOWBALL STEMMING ----

['white', 'paper', 'natur', 'languag', 'process', 'white', 'paper', 'natur', 'languag', 'process', 'ralph', 'weiscbedel', ',', 'chairperson', 'bbn', 'system', 'technolog', 'corpor', 'jaim', 'carbonel', 'carnegie-mellon', 'univers', 'barbara', 'grosz', 'harvard', 'univers', '•', 'wendi', 'lehnert', 'univers', 'massachusett', ',', 'amherst', 'mitchel', 'marcus', 'univers', 'pennsylvania', 'raymond', 'perrault', 'sri', 'intern', 'robert', 'wilenski', 'univers', 'california', ',', 'berkeley', '.']

 TOTAL SNOWBALL STEM WORDS ==> 48



 ---- LEMMATIZATION ----

['White', 'Paper', 'Natural', 'Language', 'Processing', 'White', 'Paper', 'Natural', 'Language', 'Processing', 'Ralph', 'Weiscbedel', ',', 'Chairperson', 'BBN', 'Systems', 'Technologies', 'Corporation', 'Jaime', 'Carbonell', 'Carnegie-Mellon', 'University', 'Barbara', 'Grosz', 'Harvard', 'University', '•', 'Wendy', 'Lehnert', 'University', 'Massachusetts', ',', 'Amherst', 'Mitchell', 'Marcus', 'University', 'Pennsylvania', 'Raymond', 'Perrault', 'SRI', 'International', 'Robert', 'Wilensky', 'University', 'California', ',', 'Berkeley', '.']

 TOTAL LEMMATIZE WORDS ==> 48

************************************************************************************************************************

2 --> Scope  1.1. 


 ---- TOKENS ----

 ['Scope', '1.1', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('Scope', 'NN'), ('1.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Scope', '1.1', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Scope', 'NN'), ('1.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Scope 1.1', '1.1 .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Scope 1.1 .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['Scope'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['scope', '1.1', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['scope', '1.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Scope', '1.1', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

3 --> M a j o r  Cha l l enges   We take the ultimate goal of natural language processing (NLP) to be the ability to use natural languages  as effectively as humans do. 


 ---- TOKENS ----

 ['M', 'a', 'j', 'o', 'r', 'Cha', 'l', 'l', 'enges', 'We', 'take', 'the', 'ultimate', 'goal', 'of', 'natural', 'language', 'processing', '(', 'NLP', ')', 'to', 'be', 'the', 'ability', 'to', 'use', 'natural', 'languages', 'as', 'effectively', 'as', 'humans', 'do', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('M', 'NNP'), ('a', 'DT'), ('j', 'NN'), ('o', 'NN'), ('r', 'NN'), ('Cha', 'NNP'), ('l', 'NN'), ('l', 'NN'), ('enges', 'VBZ'), ('We', 'PRP'), ('take', 'VBP'), ('the', 'DT'), ('ultimate', 'JJ'), ('goal', 'NN'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('to', 'TO'), ('be', 'VB'), ('the', 'DT'), ('ability', 'NN'), ('to', 'TO'), ('use', 'VB'), ('natural', 'JJ'), ('languages', 'NNS'), ('as', 'RB'), ('effectively', 'RB'), ('as', 'IN'), ('humans', 'NNS'), ('do', 'VBP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['j', 'r', 'Cha', 'l', 'l', 'enges', 'take', 'ultimate', 'goal', 'natural', 'language', 'processing', '(', 'NLP', ')', 'ability', 'use', 'natural', 'languages', 'effectively', 'humans', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('j', 'NN'), ('r', 'NN'), ('Cha', 'NNP'), ('l', 'NN'), ('l', 'NN'), ('enges', 'NNS'), ('take', 'VBP'), ('ultimate', 'JJ'), ('goal', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('ability', 'NN'), ('use', 'VBP'), ('natural', 'JJ'), ('languages', 'NNS'), ('effectively', 'RB'), ('humans', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['j r', 'r Cha', 'Cha l', 'l l', 'l enges', 'enges take', 'take ultimate', 'ultimate goal', 'goal natural', 'natural language', 'language processing', 'processing (', '( NLP', 'NLP )', ') ability', 'ability use', 'use natural', 'natural languages', 'languages effectively', 'effectively humans', 'humans .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['j r Cha', 'r Cha l', 'Cha l l', 'l l enges', 'l enges take', 'enges take ultimate', 'take ultimate goal', 'ultimate goal natural', 'goal natural language', 'natural language processing', 'language processing (', 'processing ( NLP', '( NLP )', 'NLP ) ability', ') ability use', 'ability use natural', 'use natural languages', 'natural languages effectively', 'languages effectively humans', 'effectively humans .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['j', 'r', 'l', 'l', 'ultimate goal', 'natural language', 'processing', 'ability'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['j', 'r', 'cha', 'l', 'l', 'eng', 'take', 'ultim', 'goal', 'natur', 'languag', 'process', '(', 'nlp', ')', 'abil', 'use', 'natur', 'languag', 'effect', 'human', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['j', 'r', 'cha', 'l', 'l', 'eng', 'take', 'ultim', 'goal', 'natur', 'languag', 'process', '(', 'nlp', ')', 'abil', 'use', 'natur', 'languag', 'effect', 'human', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['j', 'r', 'Cha', 'l', 'l', 'enges', 'take', 'ultimate', 'goal', 'natural', 'language', 'processing', '(', 'NLP', ')', 'ability', 'use', 'natural', 'language', 'effectively', 'human', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

4 --> Natural language, whether spoken, written, or typed, is the most natural means of  communication between humans, and the mode of expression of choice for most of the documents they produce. 


 ---- TOKENS ----

 ['Natural', 'language', ',', 'whether', 'spoken', ',', 'written', ',', 'or', 'typed', ',', 'is', 'the', 'most', 'natural', 'means', 'of', 'communication', 'between', 'humans', ',', 'and', 'the', 'mode', 'of', 'expression', 'of', 'choice', 'for', 'most', 'of', 'the', 'documents', 'they', 'produce', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('Natural', 'JJ'), ('language', 'NN'), (',', ','), ('whether', 'IN'), ('spoken', 'VBN'), (',', ','), ('written', 'VBN'), (',', ','), ('or', 'CC'), ('typed', 'VBN'), (',', ','), ('is', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('natural', 'JJ'), ('means', 'NNS'), ('of', 'IN'), ('communication', 'NN'), ('between', 'IN'), ('humans', 'NNS'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('mode', 'NN'), ('of', 'IN'), ('expression', 'NN'), ('of', 'IN'), ('choice', 'NN'), ('for', 'IN'), ('most', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('documents', 'NNS'), ('they', 'PRP'), ('produce', 'VBP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Natural', 'language', ',', 'whether', 'spoken', ',', 'written', ',', 'typed', ',', 'natural', 'means', 'communication', 'humans', ',', 'mode', 'expression', 'choice', 'documents', 'produce', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('Natural', 'JJ'), ('language', 'NN'), (',', ','), ('whether', 'IN'), ('spoken', 'VBN'), (',', ','), ('written', 'VBN'), (',', ','), ('typed', 'VBD'), (',', ','), ('natural', 'JJ'), ('means', 'VBZ'), ('communication', 'NN'), ('humans', 'NNS'), (',', ','), ('mode', 'JJ'), ('expression', 'NN'), ('choice', 'NN'), ('documents', 'NNS'), ('produce', 'VBP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Natural language', 'language ,', ', whether', 'whether spoken', 'spoken ,', ', written', 'written ,', ', typed', 'typed ,', ', natural', 'natural means', 'means communication', 'communication humans', 'humans ,', ', mode', 'mode expression', 'expression choice', 'choice documents', 'documents produce', 'produce .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['Natural language ,', 'language , whether', ', whether spoken', 'whether spoken ,', 'spoken , written', ', written ,', 'written , typed', ', typed ,', 'typed , natural', ', natural means', 'natural means communication', 'means communication humans', 'communication humans ,', 'humans , mode', ', mode expression', 'mode expression choice', 'expression choice documents', 'choice documents produce', 'documents produce .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['Natural language', 'communication', 'mode expression', 'choice'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['natur', 'languag', ',', 'whether', 'spoken', ',', 'written', ',', 'type', ',', 'natur', 'mean', 'commun', 'human', ',', 'mode', 'express', 'choic', 'document', 'produc', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['natur', 'languag', ',', 'whether', 'spoken', ',', 'written', ',', 'type', ',', 'natur', 'mean', 'communic', 'human', ',', 'mode', 'express', 'choic', 'document', 'produc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['Natural', 'language', ',', 'whether', 'spoken', ',', 'written', ',', 'typed', ',', 'natural', 'mean', 'communication', 'human', ',', 'mode', 'expression', 'choice', 'document', 'produce', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

5 --> As  computers play a larger role in the preparation, acquisition, transmission, monitoring, storage, analysis, and  transformation of information, endowing them with the ability to understand and generate information expressed in  natural languages becomes more and more necessary. 


 ---- TOKENS ----

 ['As', 'computers', 'play', 'a', 'larger', 'role', 'in', 'the', 'preparation', ',', 'acquisition', ',', 'transmission', ',', 'monitoring', ',', 'storage', ',', 'analysis', ',', 'and', 'transformation', 'of', 'information', ',', 'endowing', 'them', 'with', 'the', 'ability', 'to', 'understand', 'and', 'generate', 'information', 'expressed', 'in', 'natural', 'languages', 'becomes', 'more', 'and', 'more', 'necessary', '.'] 

 TOTAL TOKENS ==> 45

 ---- POST ----

 [('As', 'IN'), ('computers', 'NNS'), ('play', 'VBP'), ('a', 'DT'), ('larger', 'JJR'), ('role', 'NN'), ('in', 'IN'), ('the', 'DT'), ('preparation', 'NN'), (',', ','), ('acquisition', 'NN'), (',', ','), ('transmission', 'NN'), (',', ','), ('monitoring', 'NN'), (',', ','), ('storage', 'NN'), (',', ','), ('analysis', 'NN'), (',', ','), ('and', 'CC'), ('transformation', 'NN'), ('of', 'IN'), ('information', 'NN'), (',', ','), ('endowing', 'VBG'), ('them', 'PRP'), ('with', 'IN'), ('the', 'DT'), ('ability', 'NN'), ('to', 'TO'), ('understand', 'VB'), ('and', 'CC'), ('generate', 'VB'), ('information', 'NN'), ('expressed', 'VBN'), ('in', 'IN'), ('natural', 'JJ'), ('languages', 'NNS'), ('becomes', 'VBZ'), ('more', 'JJR'), ('and', 'CC'), ('more', 'JJR'), ('necessary', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['computers', 'play', 'larger', 'role', 'preparation', ',', 'acquisition', ',', 'transmission', ',', 'monitoring', ',', 'storage', ',', 'analysis', ',', 'transformation', 'information', ',', 'endowing', 'ability', 'understand', 'generate', 'information', 'expressed', 'natural', 'languages', 'becomes', 'necessary', '.']

 TOTAL FILTERED TOKENS ==>  30

 ---- POST FOR FILTERED TOKENS ----

 [('computers', 'NNS'), ('play', 'VBP'), ('larger', 'JJR'), ('role', 'NN'), ('preparation', 'NN'), (',', ','), ('acquisition', 'NN'), (',', ','), ('transmission', 'NN'), (',', ','), ('monitoring', 'NN'), (',', ','), ('storage', 'NN'), (',', ','), ('analysis', 'NN'), (',', ','), ('transformation', 'NN'), ('information', 'NN'), (',', ','), ('endowing', 'VBG'), ('ability', 'NN'), ('understand', 'VBP'), ('generate', 'NN'), ('information', 'NN'), ('expressed', 'VBD'), ('natural', 'JJ'), ('languages', 'NNS'), ('becomes', 'RB'), ('necessary', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['computers play', 'play larger', 'larger role', 'role preparation', 'preparation ,', ', acquisition', 'acquisition ,', ', transmission', 'transmission ,', ', monitoring', 'monitoring ,', ', storage', 'storage ,', ', analysis', 'analysis ,', ', transformation', 'transformation information', 'information ,', ', endowing', 'endowing ability', 'ability understand', 'understand generate', 'generate information', 'information expressed', 'expressed natural', 'natural languages', 'languages becomes', 'becomes necessary', 'necessary .'] 

 TOTAL BIGRAMS --> 29 



 ---- TRI-GRAMS ---- 

 ['computers play larger', 'play larger role', 'larger role preparation', 'role preparation ,', 'preparation , acquisition', ', acquisition ,', 'acquisition , transmission', ', transmission ,', 'transmission , monitoring', ', monitoring ,', 'monitoring , storage', ', storage ,', 'storage , analysis', ', analysis ,', 'analysis , transformation', ', transformation information', 'transformation information ,', 'information , endowing', ', endowing ability', 'endowing ability understand', 'ability understand generate', 'understand generate information', 'generate information expressed', 'information expressed natural', 'expressed natural languages', 'natural languages becomes', 'languages becomes necessary', 'becomes necessary .'] 

 TOTAL TRIGRAMS --> 28 



 ---- NOUN PHRASES ---- 

 ['role', 'preparation', 'acquisition', 'transmission', 'monitoring', 'storage', 'analysis', 'transformation', 'information', 'ability', 'generate', 'information'] 

 TOTAL NOUN PHRASES --> 12 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['comput', 'play', 'larger', 'role', 'prepar', ',', 'acquisit', ',', 'transmiss', ',', 'monitor', ',', 'storag', ',', 'analysi', ',', 'transform', 'inform', ',', 'endow', 'abil', 'understand', 'gener', 'inform', 'express', 'natur', 'languag', 'becom', 'necessari', '.']

 TOTAL PORTER STEM WORDS ==> 30



 ---- SNOWBALL STEMMING ----

['comput', 'play', 'larger', 'role', 'prepar', ',', 'acquisit', ',', 'transmiss', ',', 'monitor', ',', 'storag', ',', 'analysi', ',', 'transform', 'inform', ',', 'endow', 'abil', 'understand', 'generat', 'inform', 'express', 'natur', 'languag', 'becom', 'necessari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 30



 ---- LEMMATIZATION ----

['computer', 'play', 'larger', 'role', 'preparation', ',', 'acquisition', ',', 'transmission', ',', 'monitoring', ',', 'storage', ',', 'analysis', ',', 'transformation', 'information', ',', 'endowing', 'ability', 'understand', 'generate', 'information', 'expressed', 'natural', 'language', 'becomes', 'necessary', '.']

 TOTAL LEMMATIZE WORDS ==> 30

************************************************************************************************************************

6 --> Some tasks currently performed by humans cannot be  automated without endowing computers with natural language processing capabilities, and these provide two major  challenges to NLP systems:  1. 


 ---- TOKENS ----

 ['Some', 'tasks', 'currently', 'performed', 'by', 'humans', 'can', 'not', 'be', 'automated', 'without', 'endowing', 'computers', 'with', 'natural', 'language', 'processing', 'capabilities', ',', 'and', 'these', 'provide', 'two', 'major', 'challenges', 'to', 'NLP', 'systems', ':', '1', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('Some', 'DT'), ('tasks', 'NNS'), ('currently', 'RB'), ('performed', 'VBN'), ('by', 'IN'), ('humans', 'NNS'), ('can', 'MD'), ('not', 'RB'), ('be', 'VB'), ('automated', 'VBN'), ('without', 'IN'), ('endowing', 'VBG'), ('computers', 'NNS'), ('with', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('capabilities', 'NNS'), (',', ','), ('and', 'CC'), ('these', 'DT'), ('provide', 'VBP'), ('two', 'CD'), ('major', 'JJ'), ('challenges', 'NNS'), ('to', 'TO'), ('NLP', 'NNP'), ('systems', 'NNS'), (':', ':'), ('1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['tasks', 'currently', 'performed', 'humans', 'automated', 'without', 'endowing', 'computers', 'natural', 'language', 'processing', 'capabilities', ',', 'provide', 'two', 'major', 'challenges', 'NLP', 'systems', ':', '1', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('tasks', 'NNS'), ('currently', 'RB'), ('performed', 'VBN'), ('humans', 'NNS'), ('automated', 'VBD'), ('without', 'IN'), ('endowing', 'VBG'), ('computers', 'NNS'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('capabilities', 'NNS'), (',', ','), ('provide', 'VBP'), ('two', 'CD'), ('major', 'JJ'), ('challenges', 'NNS'), ('NLP', 'NNP'), ('systems', 'NNS'), (':', ':'), ('1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['tasks currently', 'currently performed', 'performed humans', 'humans automated', 'automated without', 'without endowing', 'endowing computers', 'computers natural', 'natural language', 'language processing', 'processing capabilities', 'capabilities ,', ', provide', 'provide two', 'two major', 'major challenges', 'challenges NLP', 'NLP systems', 'systems :', ': 1', '1 .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['tasks currently performed', 'currently performed humans', 'performed humans automated', 'humans automated without', 'automated without endowing', 'without endowing computers', 'endowing computers natural', 'computers natural language', 'natural language processing', 'language processing capabilities', 'processing capabilities ,', 'capabilities , provide', ', provide two', 'provide two major', 'two major challenges', 'major challenges NLP', 'challenges NLP systems', 'NLP systems :', 'systems : 1', ': 1 .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['natural language', 'processing'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['task', 'current', 'perform', 'human', 'autom', 'without', 'endow', 'comput', 'natur', 'languag', 'process', 'capabl', ',', 'provid', 'two', 'major', 'challeng', 'nlp', 'system', ':', '1', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['task', 'current', 'perform', 'human', 'autom', 'without', 'endow', 'comput', 'natur', 'languag', 'process', 'capabl', ',', 'provid', 'two', 'major', 'challeng', 'nlp', 'system', ':', '1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['task', 'currently', 'performed', 'human', 'automated', 'without', 'endowing', 'computer', 'natural', 'language', 'processing', 'capability', ',', 'provide', 'two', 'major', 'challenge', 'NLP', 'system', ':', '1', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

7 --> Reading and writing text, applied to tasks such as message routing, abstracting, monitoring, summarizing, and  entering information in databases, with applications, in such areas as intelligence, logistics, office automation, and  libraries. 


 ---- TOKENS ----

 ['Reading', 'and', 'writing', 'text', ',', 'applied', 'to', 'tasks', 'such', 'as', 'message', 'routing', ',', 'abstracting', ',', 'monitoring', ',', 'summarizing', ',', 'and', 'entering', 'information', 'in', 'databases', ',', 'with', 'applications', ',', 'in', 'such', 'areas', 'as', 'intelligence', ',', 'logistics', ',', 'office', 'automation', ',', 'and', 'libraries', '.'] 

 TOTAL TOKENS ==> 42

 ---- POST ----

 [('Reading', 'VBG'), ('and', 'CC'), ('writing', 'VBG'), ('text', 'NN'), (',', ','), ('applied', 'VBN'), ('to', 'TO'), ('tasks', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('message', 'NN'), ('routing', 'NN'), (',', ','), ('abstracting', 'VBG'), (',', ','), ('monitoring', 'NN'), (',', ','), ('summarizing', 'NN'), (',', ','), ('and', 'CC'), ('entering', 'VBG'), ('information', 'NN'), ('in', 'IN'), ('databases', 'NNS'), (',', ','), ('with', 'IN'), ('applications', 'NNS'), (',', ','), ('in', 'IN'), ('such', 'JJ'), ('areas', 'NNS'), ('as', 'IN'), ('intelligence', 'NN'), (',', ','), ('logistics', 'NNS'), (',', ','), ('office', 'NN'), ('automation', 'NN'), (',', ','), ('and', 'CC'), ('libraries', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Reading', 'writing', 'text', ',', 'applied', 'tasks', 'message', 'routing', ',', 'abstracting', ',', 'monitoring', ',', 'summarizing', ',', 'entering', 'information', 'databases', ',', 'applications', ',', 'areas', 'intelligence', ',', 'logistics', ',', 'office', 'automation', ',', 'libraries', '.']

 TOTAL FILTERED TOKENS ==>  31

 ---- POST FOR FILTERED TOKENS ----

 [('Reading', 'VBG'), ('writing', 'VBG'), ('text', 'NN'), (',', ','), ('applied', 'VBN'), ('tasks', 'NNS'), ('message', 'RBR'), ('routing', 'VBG'), (',', ','), ('abstracting', 'VBG'), (',', ','), ('monitoring', 'NN'), (',', ','), ('summarizing', 'VBG'), (',', ','), ('entering', 'VBG'), ('information', 'NN'), ('databases', 'NNS'), (',', ','), ('applications', 'NNS'), (',', ','), ('areas', 'NNS'), ('intelligence', 'NN'), (',', ','), ('logistics', 'NNS'), (',', ','), ('office', 'NN'), ('automation', 'NN'), (',', ','), ('libraries', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Reading writing', 'writing text', 'text ,', ', applied', 'applied tasks', 'tasks message', 'message routing', 'routing ,', ', abstracting', 'abstracting ,', ', monitoring', 'monitoring ,', ', summarizing', 'summarizing ,', ', entering', 'entering information', 'information databases', 'databases ,', ', applications', 'applications ,', ', areas', 'areas intelligence', 'intelligence ,', ', logistics', 'logistics ,', ', office', 'office automation', 'automation ,', ', libraries', 'libraries .'] 

 TOTAL BIGRAMS --> 30 



 ---- TRI-GRAMS ---- 

 ['Reading writing text', 'writing text ,', 'text , applied', ', applied tasks', 'applied tasks message', 'tasks message routing', 'message routing ,', 'routing , abstracting', ', abstracting ,', 'abstracting , monitoring', ', monitoring ,', 'monitoring , summarizing', ', summarizing ,', 'summarizing , entering', ', entering information', 'entering information databases', 'information databases ,', 'databases , applications', ', applications ,', 'applications , areas', ', areas intelligence', 'areas intelligence ,', 'intelligence , logistics', ', logistics ,', 'logistics , office', ', office automation', 'office automation ,', 'automation , libraries', ', libraries .'] 

 TOTAL TRIGRAMS --> 29 



 ---- NOUN PHRASES ---- 

 ['text', 'monitoring', 'information', 'intelligence', 'office', 'automation'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['read', 'write', 'text', ',', 'appli', 'task', 'messag', 'rout', ',', 'abstract', ',', 'monitor', ',', 'summar', ',', 'enter', 'inform', 'databas', ',', 'applic', ',', 'area', 'intellig', ',', 'logist', ',', 'offic', 'autom', ',', 'librari', '.']

 TOTAL PORTER STEM WORDS ==> 31



 ---- SNOWBALL STEMMING ----

['read', 'write', 'text', ',', 'appli', 'task', 'messag', 'rout', ',', 'abstract', ',', 'monitor', ',', 'summar', ',', 'enter', 'inform', 'databas', ',', 'applic', ',', 'area', 'intellig', ',', 'logist', ',', 'offic', 'autom', ',', 'librari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 31



 ---- LEMMATIZATION ----

['Reading', 'writing', 'text', ',', 'applied', 'task', 'message', 'routing', ',', 'abstracting', ',', 'monitoring', ',', 'summarizing', ',', 'entering', 'information', 'database', ',', 'application', ',', 'area', 'intelligence', ',', 'logistics', ',', 'office', 'automation', ',', 'library', '.']

 TOTAL LEMMATIZE WORDS ==> 31

************************************************************************************************************************

8 --> Computers should be able to assimilate and compose extended communications. 


 ---- TOKENS ----

 ['Computers', 'should', 'be', 'able', 'to', 'assimilate', 'and', 'compose', 'extended', 'communications', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Computers', 'NNS'), ('should', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('assimilate', 'VB'), ('and', 'CC'), ('compose', 'VB'), ('extended', 'JJ'), ('communications', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Computers', 'able', 'assimilate', 'compose', 'extended', 'communications', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('Computers', 'NNS'), ('able', 'JJ'), ('assimilate', 'JJ'), ('compose', 'NN'), ('extended', 'VBD'), ('communications', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Computers able', 'able assimilate', 'assimilate compose', 'compose extended', 'extended communications', 'communications .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['Computers able assimilate', 'able assimilate compose', 'assimilate compose extended', 'compose extended communications', 'extended communications .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['able assimilate compose'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['comput', 'abl', 'assimil', 'compos', 'extend', 'commun', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['comput', 'abl', 'assimil', 'compos', 'extend', 'communic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['Computers', 'able', 'assimilate', 'compose', 'extended', 'communication', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

9 --> 2. 


 ---- TOKENS ----

 ['2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

10 --> Translation, of documents or spoken language, with applications, in such areas as in science, diplomacy,  multinational commerce, and intelligence. 


 ---- TOKENS ----

 ['Translation', ',', 'of', 'documents', 'or', 'spoken', 'language', ',', 'with', 'applications', ',', 'in', 'such', 'areas', 'as', 'in', 'science', ',', 'diplomacy', ',', 'multinational', 'commerce', ',', 'and', 'intelligence', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Translation', 'NN'), (',', ','), ('of', 'IN'), ('documents', 'NNS'), ('or', 'CC'), ('spoken', 'JJ'), ('language', 'NN'), (',', ','), ('with', 'IN'), ('applications', 'NNS'), (',', ','), ('in', 'IN'), ('such', 'JJ'), ('areas', 'NNS'), ('as', 'IN'), ('in', 'IN'), ('science', 'NN'), (',', ','), ('diplomacy', 'NN'), (',', ','), ('multinational', 'JJ'), ('commerce', 'NN'), (',', ','), ('and', 'CC'), ('intelligence', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Translation', ',', 'documents', 'spoken', 'language', ',', 'applications', ',', 'areas', 'science', ',', 'diplomacy', ',', 'multinational', 'commerce', ',', 'intelligence', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Translation', 'NN'), (',', ','), ('documents', 'NNS'), ('spoken', 'JJ'), ('language', 'NN'), (',', ','), ('applications', 'NNS'), (',', ','), ('areas', 'NNS'), ('science', 'NN'), (',', ','), ('diplomacy', 'NN'), (',', ','), ('multinational', 'JJ'), ('commerce', 'NN'), (',', ','), ('intelligence', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Translation ,', ', documents', 'documents spoken', 'spoken language', 'language ,', ', applications', 'applications ,', ', areas', 'areas science', 'science ,', ', diplomacy', 'diplomacy ,', ', multinational', 'multinational commerce', 'commerce ,', ', intelligence', 'intelligence .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Translation , documents', ', documents spoken', 'documents spoken language', 'spoken language ,', 'language , applications', ', applications ,', 'applications , areas', ', areas science', 'areas science ,', 'science , diplomacy', ', diplomacy ,', 'diplomacy , multinational', ', multinational commerce', 'multinational commerce ,', 'commerce , intelligence', ', intelligence .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['Translation', 'spoken language', 'science', 'diplomacy', 'multinational commerce', 'intelligence'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Translation']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['translat', ',', 'document', 'spoken', 'languag', ',', 'applic', ',', 'area', 'scienc', ',', 'diplomaci', ',', 'multin', 'commerc', ',', 'intellig', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['translat', ',', 'document', 'spoken', 'languag', ',', 'applic', ',', 'area', 'scienc', ',', 'diplomaci', ',', 'multin', 'commerc', ',', 'intellig', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Translation', ',', 'document', 'spoken', 'language', ',', 'application', ',', 'area', 'science', ',', 'diplomacy', ',', 'multinational', 'commerce', ',', 'intelligence', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

11 --> Computers should be able to understand input in more than one  language, provide output in more than one language, and translate between languages. 


 ---- TOKENS ----

 ['Computers', 'should', 'be', 'able', 'to', 'understand', 'input', 'in', 'more', 'than', 'one', 'language', ',', 'provide', 'output', 'in', 'more', 'than', 'one', 'language', ',', 'and', 'translate', 'between', 'languages', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Computers', 'NNS'), ('should', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('understand', 'VB'), ('input', 'NN'), ('in', 'IN'), ('more', 'JJR'), ('than', 'IN'), ('one', 'CD'), ('language', 'NN'), (',', ','), ('provide', 'VBP'), ('output', 'NN'), ('in', 'IN'), ('more', 'JJR'), ('than', 'IN'), ('one', 'CD'), ('language', 'NN'), (',', ','), ('and', 'CC'), ('translate', 'NN'), ('between', 'IN'), ('languages', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Computers', 'able', 'understand', 'input', 'one', 'language', ',', 'provide', 'output', 'one', 'language', ',', 'translate', 'languages', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Computers', 'NNS'), ('able', 'JJ'), ('understand', 'JJ'), ('input', 'NN'), ('one', 'CD'), ('language', 'NN'), (',', ','), ('provide', 'VB'), ('output', 'NN'), ('one', 'CD'), ('language', 'NN'), (',', ','), ('translate', 'NN'), ('languages', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Computers able', 'able understand', 'understand input', 'input one', 'one language', 'language ,', ', provide', 'provide output', 'output one', 'one language', 'language ,', ', translate', 'translate languages', 'languages .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Computers able understand', 'able understand input', 'understand input one', 'input one language', 'one language ,', 'language , provide', ', provide output', 'provide output one', 'output one language', 'one language ,', 'language , translate', ', translate languages', 'translate languages .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['able understand input', 'language', 'output', 'language', 'translate'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['comput', 'abl', 'understand', 'input', 'one', 'languag', ',', 'provid', 'output', 'one', 'languag', ',', 'translat', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['comput', 'abl', 'understand', 'input', 'one', 'languag', ',', 'provid', 'output', 'one', 'languag', ',', 'translat', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Computers', 'able', 'understand', 'input', 'one', 'language', ',', 'provide', 'output', 'one', 'language', ',', 'translate', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

12 --> The dominance of natural language as a means of communication in a broad range of interactions among  humans suggests that it would be an attractive medium in human-computer interaction as well. 


 ---- TOKENS ----

 ['The', 'dominance', 'of', 'natural', 'language', 'as', 'a', 'means', 'of', 'communication', 'in', 'a', 'broad', 'range', 'of', 'interactions', 'among', 'humans', 'suggests', 'that', 'it', 'would', 'be', 'an', 'attractive', 'medium', 'in', 'human-computer', 'interaction', 'as', 'well', '.'] 

 TOTAL TOKENS ==> 32

 ---- POST ----

 [('The', 'DT'), ('dominance', 'NN'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('as', 'IN'), ('a', 'DT'), ('means', 'NN'), ('of', 'IN'), ('communication', 'NN'), ('in', 'IN'), ('a', 'DT'), ('broad', 'JJ'), ('range', 'NN'), ('of', 'IN'), ('interactions', 'NNS'), ('among', 'IN'), ('humans', 'NNS'), ('suggests', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('would', 'MD'), ('be', 'VB'), ('an', 'DT'), ('attractive', 'JJ'), ('medium', 'NN'), ('in', 'IN'), ('human-computer', 'JJ'), ('interaction', 'NN'), ('as', 'IN'), ('well', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['dominance', 'natural', 'language', 'means', 'communication', 'broad', 'range', 'interactions', 'among', 'humans', 'suggests', 'would', 'attractive', 'medium', 'human-computer', 'interaction', 'well', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('dominance', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('means', 'VBZ'), ('communication', 'NN'), ('broad', 'JJ'), ('range', 'NN'), ('interactions', 'NNS'), ('among', 'IN'), ('humans', 'NNS'), ('suggests', 'NNS'), ('would', 'MD'), ('attractive', 'VB'), ('medium', 'NN'), ('human-computer', 'JJ'), ('interaction', 'NN'), ('well', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['dominance natural', 'natural language', 'language means', 'means communication', 'communication broad', 'broad range', 'range interactions', 'interactions among', 'among humans', 'humans suggests', 'suggests would', 'would attractive', 'attractive medium', 'medium human-computer', 'human-computer interaction', 'interaction well', 'well .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['dominance natural language', 'natural language means', 'language means communication', 'means communication broad', 'communication broad range', 'broad range interactions', 'range interactions among', 'interactions among humans', 'among humans suggests', 'humans suggests would', 'suggests would attractive', 'would attractive medium', 'attractive medium human-computer', 'medium human-computer interaction', 'human-computer interaction well', 'interaction well .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['dominance', 'natural language', 'communication', 'broad range', 'medium', 'human-computer interaction'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['domin', 'natur', 'languag', 'mean', 'commun', 'broad', 'rang', 'interact', 'among', 'human', 'suggest', 'would', 'attract', 'medium', 'human-comput', 'interact', 'well', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['domin', 'natur', 'languag', 'mean', 'communic', 'broad', 'rang', 'interact', 'among', 'human', 'suggest', 'would', 'attract', 'medium', 'human-comput', 'interact', 'well', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['dominance', 'natural', 'language', 'mean', 'communication', 'broad', 'range', 'interaction', 'among', 'human', 'suggests', 'would', 'attractive', 'medium', 'human-computer', 'interaction', 'well', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

13 --> The case is  particularly strong where the environment precludes the use of keyboard, display, and mouse, so that spoken natural  language is almost the only alternative. 


 ---- TOKENS ----

 ['The', 'case', 'is', 'particularly', 'strong', 'where', 'the', 'environment', 'precludes', 'the', 'use', 'of', 'keyboard', ',', 'display', ',', 'and', 'mouse', ',', 'so', 'that', 'spoken', 'natural', 'language', 'is', 'almost', 'the', 'only', 'alternative', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('The', 'DT'), ('case', 'NN'), ('is', 'VBZ'), ('particularly', 'RB'), ('strong', 'JJ'), ('where', 'WRB'), ('the', 'DT'), ('environment', 'NN'), ('precludes', 'VBZ'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('keyboard', 'NN'), (',', ','), ('display', 'NN'), (',', ','), ('and', 'CC'), ('mouse', 'NN'), (',', ','), ('so', 'IN'), ('that', 'DT'), ('spoken', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('is', 'VBZ'), ('almost', 'RB'), ('the', 'DT'), ('only', 'JJ'), ('alternative', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['case', 'particularly', 'strong', 'environment', 'precludes', 'use', 'keyboard', ',', 'display', ',', 'mouse', ',', 'spoken', 'natural', 'language', 'almost', 'alternative', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('case', 'NN'), ('particularly', 'RB'), ('strong', 'JJ'), ('environment', 'NN'), ('precludes', 'NNS'), ('use', 'VBP'), ('keyboard', 'NN'), (',', ','), ('display', 'NN'), (',', ','), ('mouse', 'NN'), (',', ','), ('spoken', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('almost', 'RB'), ('alternative', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['case particularly', 'particularly strong', 'strong environment', 'environment precludes', 'precludes use', 'use keyboard', 'keyboard ,', ', display', 'display ,', ', mouse', 'mouse ,', ', spoken', 'spoken natural', 'natural language', 'language almost', 'almost alternative', 'alternative .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['case particularly strong', 'particularly strong environment', 'strong environment precludes', 'environment precludes use', 'precludes use keyboard', 'use keyboard ,', 'keyboard , display', ', display ,', 'display , mouse', ', mouse ,', 'mouse , spoken', ', spoken natural', 'spoken natural language', 'natural language almost', 'language almost alternative', 'almost alternative .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['case', 'strong environment', 'keyboard', 'display', 'mouse', 'spoken natural language'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['case', 'particularli', 'strong', 'environ', 'preclud', 'use', 'keyboard', ',', 'display', ',', 'mous', ',', 'spoken', 'natur', 'languag', 'almost', 'altern', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['case', 'particular', 'strong', 'environ', 'preclud', 'use', 'keyboard', ',', 'display', ',', 'mous', ',', 'spoken', 'natur', 'languag', 'almost', 'altern', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['case', 'particularly', 'strong', 'environment', 'precludes', 'use', 'keyboard', ',', 'display', ',', 'mouse', ',', 'spoken', 'natural', 'language', 'almost', 'alternative', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

14 --> However, speech recognition alone will not suffice in these settings. 


 ---- TOKENS ----

 ['However', ',', 'speech', 'recognition', 'alone', 'will', 'not', 'suffice', 'in', 'these', 'settings', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('However', 'RB'), (',', ','), ('speech', 'JJ'), ('recognition', 'NN'), ('alone', 'RB'), ('will', 'MD'), ('not', 'RB'), ('suffice', 'VB'), ('in', 'IN'), ('these', 'DT'), ('settings', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['However', ',', 'speech', 'recognition', 'alone', 'suffice', 'settings', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('However', 'RB'), (',', ','), ('speech', 'JJ'), ('recognition', 'NN'), ('alone', 'RB'), ('suffice', 'JJ'), ('settings', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['However ,', ', speech', 'speech recognition', 'recognition alone', 'alone suffice', 'suffice settings', 'settings .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['However , speech', ', speech recognition', 'speech recognition alone', 'recognition alone suffice', 'alone suffice settings', 'suffice settings .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['speech recognition'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['howev', ',', 'speech', 'recognit', 'alon', 'suffic', 'set', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['howev', ',', 'speech', 'recognit', 'alon', 'suffic', 'set', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['However', ',', 'speech', 'recognition', 'alone', 'suffice', 'setting', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

15 --> Words  and phrases must be parsed and interpreted so that their intended meaning (as command, query, or assertion) may be  determined and an appropriate response formulated and expressed. 


 ---- TOKENS ----

 ['Words', 'and', 'phrases', 'must', 'be', 'parsed', 'and', 'interpreted', 'so', 'that', 'their', 'intended', 'meaning', '(', 'as', 'command', ',', 'query', ',', 'or', 'assertion', ')', 'may', 'be', 'determined', 'and', 'an', 'appropriate', 'response', 'formulated', 'and', 'expressed', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('Words', 'NNS'), ('and', 'CC'), ('phrases', 'NNS'), ('must', 'MD'), ('be', 'VB'), ('parsed', 'VBN'), ('and', 'CC'), ('interpreted', 'VBN'), ('so', 'RB'), ('that', 'IN'), ('their', 'PRP$'), ('intended', 'VBN'), ('meaning', 'NN'), ('(', '('), ('as', 'IN'), ('command', 'NN'), (',', ','), ('query', 'NN'), (',', ','), ('or', 'CC'), ('assertion', 'NN'), (')', ')'), ('may', 'MD'), ('be', 'VB'), ('determined', 'VBN'), ('and', 'CC'), ('an', 'DT'), ('appropriate', 'JJ'), ('response', 'NN'), ('formulated', 'VBN'), ('and', 'CC'), ('expressed', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Words', 'phrases', 'must', 'parsed', 'interpreted', 'intended', 'meaning', '(', 'command', ',', 'query', ',', 'assertion', ')', 'may', 'determined', 'appropriate', 'response', 'formulated', 'expressed', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('Words', 'NNS'), ('phrases', 'NNS'), ('must', 'MD'), ('parsed', 'VBN'), ('interpreted', 'VBN'), ('intended', 'JJ'), ('meaning', 'NN'), ('(', '('), ('command', 'NN'), (',', ','), ('query', 'NN'), (',', ','), ('assertion', 'NN'), (')', ')'), ('may', 'MD'), ('determined', 'VB'), ('appropriate', 'JJ'), ('response', 'NN'), ('formulated', 'VBD'), ('expressed', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Words phrases', 'phrases must', 'must parsed', 'parsed interpreted', 'interpreted intended', 'intended meaning', 'meaning (', '( command', 'command ,', ', query', 'query ,', ', assertion', 'assertion )', ') may', 'may determined', 'determined appropriate', 'appropriate response', 'response formulated', 'formulated expressed', 'expressed .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['Words phrases must', 'phrases must parsed', 'must parsed interpreted', 'parsed interpreted intended', 'interpreted intended meaning', 'intended meaning (', 'meaning ( command', '( command ,', 'command , query', ', query ,', 'query , assertion', ', assertion )', 'assertion ) may', ') may determined', 'may determined appropriate', 'determined appropriate response', 'appropriate response formulated', 'response formulated expressed', 'formulated expressed .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['intended meaning', 'appropriate response'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['word', 'phrase', 'must', 'pars', 'interpret', 'intend', 'mean', '(', 'command', ',', 'queri', ',', 'assert', ')', 'may', 'determin', 'appropri', 'respons', 'formul', 'express', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['word', 'phrase', 'must', 'pars', 'interpret', 'intend', 'mean', '(', 'command', ',', 'queri', ',', 'assert', ')', 'may', 'determin', 'appropri', 'respons', 'formul', 'express', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['Words', 'phrase', 'must', 'parsed', 'interpreted', 'intended', 'meaning', '(', 'command', ',', 'query', ',', 'assertion', ')', 'may', 'determined', 'appropriate', 'response', 'formulated', 'expressed', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

16 --> 481   Even where other devices are available, the artificial languages they give the user access to -- menu and  icon selection, and programming, command, and database query languages -- are limited. 


 ---- TOKENS ----

 ['481', 'Even', 'where', 'other', 'devices', 'are', 'available', ',', 'the', 'artificial', 'languages', 'they', 'give', 'the', 'user', 'access', 'to', '--', 'menu', 'and', 'icon', 'selection', ',', 'and', 'programming', ',', 'command', ',', 'and', 'database', 'query', 'languages', '--', 'are', 'limited', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('481', 'CD'), ('Even', 'RB'), ('where', 'WRB'), ('other', 'JJ'), ('devices', 'NNS'), ('are', 'VBP'), ('available', 'JJ'), (',', ','), ('the', 'DT'), ('artificial', 'JJ'), ('languages', 'NNS'), ('they', 'PRP'), ('give', 'VBP'), ('the', 'DT'), ('user', 'NN'), ('access', 'NN'), ('to', 'TO'), ('--', ':'), ('menu', 'NN'), ('and', 'CC'), ('icon', 'NN'), ('selection', 'NN'), (',', ','), ('and', 'CC'), ('programming', 'NN'), (',', ','), ('command', 'NN'), (',', ','), ('and', 'CC'), ('database', 'VB'), ('query', 'NN'), ('languages', 'NNS'), ('--', ':'), ('are', 'VBP'), ('limited', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['481', 'Even', 'devices', 'available', ',', 'artificial', 'languages', 'give', 'user', 'access', '--', 'menu', 'icon', 'selection', ',', 'programming', ',', 'command', ',', 'database', 'query', 'languages', '--', 'limited', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('481', 'CD'), ('Even', 'RB'), ('devices', 'NNS'), ('available', 'JJ'), (',', ','), ('artificial', 'JJ'), ('languages', 'NNS'), ('give', 'VBP'), ('user', 'JJ'), ('access', 'NN'), ('--', ':'), ('menu', 'JJ'), ('icon', 'JJ'), ('selection', 'NN'), (',', ','), ('programming', 'NN'), (',', ','), ('command', 'NN'), (',', ','), ('database', 'NN'), ('query', 'NN'), ('languages', 'NNS'), ('--', ':'), ('limited', 'VBD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['481 Even', 'Even devices', 'devices available', 'available ,', ', artificial', 'artificial languages', 'languages give', 'give user', 'user access', 'access --', '-- menu', 'menu icon', 'icon selection', 'selection ,', ', programming', 'programming ,', ', command', 'command ,', ', database', 'database query', 'query languages', 'languages --', '-- limited', 'limited .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['481 Even devices', 'Even devices available', 'devices available ,', 'available , artificial', ', artificial languages', 'artificial languages give', 'languages give user', 'give user access', 'user access --', 'access -- menu', '-- menu icon', 'menu icon selection', 'icon selection ,', 'selection , programming', ', programming ,', 'programming , command', ', command ,', 'command , database', ', database query', 'database query languages', 'query languages --', 'languages -- limited', '-- limited .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['user access', 'menu icon selection', 'programming', 'command', 'database', 'query'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['481', 'even', 'devic', 'avail', ',', 'artifici', 'languag', 'give', 'user', 'access', '--', 'menu', 'icon', 'select', ',', 'program', ',', 'command', ',', 'databas', 'queri', 'languag', '--', 'limit', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['481', 'even', 'devic', 'avail', ',', 'artifici', 'languag', 'give', 'user', 'access', '--', 'menu', 'icon', 'select', ',', 'program', ',', 'command', ',', 'databas', 'queri', 'languag', '--', 'limit', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['481', 'Even', 'device', 'available', ',', 'artificial', 'language', 'give', 'user', 'access', '--', 'menu', 'icon', 'selection', ',', 'programming', ',', 'command', ',', 'database', 'query', 'language', '--', 'limited', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

17 --> Menus and icons make it  easy to present the user with the available options at any time, but they constrain the user to operating on visible  objects only. 


 ---- TOKENS ----

 ['Menus', 'and', 'icons', 'make', 'it', 'easy', 'to', 'present', 'the', 'user', 'with', 'the', 'available', 'options', 'at', 'any', 'time', ',', 'but', 'they', 'constrain', 'the', 'user', 'to', 'operating', 'on', 'visible', 'objects', 'only', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('Menus', 'NNP'), ('and', 'CC'), ('icons', 'NNS'), ('make', 'VBP'), ('it', 'PRP'), ('easy', 'JJ'), ('to', 'TO'), ('present', 'VB'), ('the', 'DT'), ('user', 'NN'), ('with', 'IN'), ('the', 'DT'), ('available', 'JJ'), ('options', 'NNS'), ('at', 'IN'), ('any', 'DT'), ('time', 'NN'), (',', ','), ('but', 'CC'), ('they', 'PRP'), ('constrain', 'VBP'), ('the', 'DT'), ('user', 'NN'), ('to', 'TO'), ('operating', 'VBG'), ('on', 'IN'), ('visible', 'JJ'), ('objects', 'NNS'), ('only', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Menus', 'icons', 'make', 'easy', 'present', 'user', 'available', 'options', 'time', ',', 'constrain', 'user', 'operating', 'visible', 'objects', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Menus', 'NNP'), ('icons', 'NNS'), ('make', 'VBP'), ('easy', 'JJ'), ('present', 'JJ'), ('user', 'NN'), ('available', 'JJ'), ('options', 'NNS'), ('time', 'NN'), (',', ','), ('constrain', 'VBP'), ('user', 'JJ'), ('operating', 'NN'), ('visible', 'JJ'), ('objects', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Menus icons', 'icons make', 'make easy', 'easy present', 'present user', 'user available', 'available options', 'options time', 'time ,', ', constrain', 'constrain user', 'user operating', 'operating visible', 'visible objects', 'objects .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Menus icons make', 'icons make easy', 'make easy present', 'easy present user', 'present user available', 'user available options', 'available options time', 'options time ,', 'time , constrain', ', constrain user', 'constrain user operating', 'user operating visible', 'operating visible objects', 'visible objects .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['easy present user', 'time', 'user operating'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Menus']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['menu', 'icon', 'make', 'easi', 'present', 'user', 'avail', 'option', 'time', ',', 'constrain', 'user', 'oper', 'visibl', 'object', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['menus', 'icon', 'make', 'easi', 'present', 'user', 'avail', 'option', 'time', ',', 'constrain', 'user', 'oper', 'visibl', 'object', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Menus', 'icon', 'make', 'easy', 'present', 'user', 'available', 'option', 'time', ',', 'constrain', 'user', 'operating', 'visible', 'object', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

18 --> It is also awkward or impossible to operate on sets of objects selected by complex properties (e.g.,  "Send all the C3 ships with RRI radar to the nearest port"). 


 ---- TOKENS ----

 ['It', 'is', 'also', 'awkward', 'or', 'impossible', 'to', 'operate', 'on', 'sets', 'of', 'objects', 'selected', 'by', 'complex', 'properties', '(', 'e.g.', ',', '``', 'Send', 'all', 'the', 'C3', 'ships', 'with', 'RRI', 'radar', 'to', 'the', 'nearest', 'port', "''", ')', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('It', 'PRP'), ('is', 'VBZ'), ('also', 'RB'), ('awkward', 'RB'), ('or', 'CC'), ('impossible', 'JJ'), ('to', 'TO'), ('operate', 'VB'), ('on', 'IN'), ('sets', 'NNS'), ('of', 'IN'), ('objects', 'NNS'), ('selected', 'VBN'), ('by', 'IN'), ('complex', 'JJ'), ('properties', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('``', '``'), ('Send', 'VBP'), ('all', 'PDT'), ('the', 'DT'), ('C3', 'NNP'), ('ships', 'NNS'), ('with', 'IN'), ('RRI', 'NNP'), ('radar', 'NN'), ('to', 'TO'), ('the', 'DT'), ('nearest', 'JJS'), ('port', 'NN'), ("''", "''"), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['also', 'awkward', 'impossible', 'operate', 'sets', 'objects', 'selected', 'complex', 'properties', '(', 'e.g.', ',', '``', 'Send', 'C3', 'ships', 'RRI', 'radar', 'nearest', 'port', "''", ')', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('also', 'RB'), ('awkward', 'RB'), ('impossible', 'JJ'), ('operate', 'JJ'), ('sets', 'NNS'), ('objects', 'VBZ'), ('selected', 'VBN'), ('complex', 'JJ'), ('properties', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('``', '``'), ('Send', 'NNP'), ('C3', 'NNP'), ('ships', 'NNS'), ('RRI', 'NNP'), ('radar', 'NN'), ('nearest', 'JJS'), ('port', 'NN'), ("''", "''"), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['also awkward', 'awkward impossible', 'impossible operate', 'operate sets', 'sets objects', 'objects selected', 'selected complex', 'complex properties', 'properties (', '( e.g.', 'e.g. ,', ', ``', '`` Send', 'Send C3', 'C3 ships', 'ships RRI', 'RRI radar', 'radar nearest', 'nearest port', "port ''", "'' )", ') .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['also awkward impossible', 'awkward impossible operate', 'impossible operate sets', 'operate sets objects', 'sets objects selected', 'objects selected complex', 'selected complex properties', 'complex properties (', 'properties ( e.g.', '( e.g. ,', 'e.g. , ``', ', `` Send', '`` Send C3', 'Send C3 ships', 'C3 ships RRI', 'ships RRI radar', 'RRI radar nearest', 'radar nearest port', "nearest port ''", "port '' )", "'' ) ."] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['also', 'awkward', 'imposs', 'oper', 'set', 'object', 'select', 'complex', 'properti', '(', 'e.g.', ',', '``', 'send', 'c3', 'ship', 'rri', 'radar', 'nearest', 'port', "''", ')', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['also', 'awkward', 'imposs', 'oper', 'set', 'object', 'select', 'complex', 'properti', '(', 'e.g.', ',', '``', 'send', 'c3', 'ship', 'rri', 'radar', 'nearest', 'port', "''", ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['also', 'awkward', 'impossible', 'operate', 'set', 'object', 'selected', 'complex', 'property', '(', 'e.g.', ',', '``', 'Send', 'C3', 'ship', 'RRI', 'radar', 'nearest', 'port', "''", ')', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

19 --> Programming and other " l inear"  artificial languages  offer well-defined control structures but axe more difficult to learn, and do not take advantage of pointing to objects  on the screen. 


 ---- TOKENS ----

 ['Programming', 'and', 'other', '``', 'l', 'inear', "''", 'artificial', 'languages', 'offer', 'well-defined', 'control', 'structures', 'but', 'axe', 'more', 'difficult', 'to', 'learn', ',', 'and', 'do', 'not', 'take', 'advantage', 'of', 'pointing', 'to', 'objects', 'on', 'the', 'screen', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('Programming', 'VBG'), ('and', 'CC'), ('other', 'JJ'), ('``', '``'), ('l', 'JJ'), ('inear', 'NN'), ("''", "''"), ('artificial', 'JJ'), ('languages', 'NNS'), ('offer', 'VBP'), ('well-defined', 'JJ'), ('control', 'NN'), ('structures', 'NNS'), ('but', 'CC'), ('axe', 'VBZ'), ('more', 'RBR'), ('difficult', 'JJ'), ('to', 'TO'), ('learn', 'VB'), (',', ','), ('and', 'CC'), ('do', 'VBP'), ('not', 'RB'), ('take', 'VB'), ('advantage', 'NN'), ('of', 'IN'), ('pointing', 'VBG'), ('to', 'TO'), ('objects', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('screen', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Programming', '``', 'l', 'inear', "''", 'artificial', 'languages', 'offer', 'well-defined', 'control', 'structures', 'axe', 'difficult', 'learn', ',', 'take', 'advantage', 'pointing', 'objects', 'screen', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('Programming', 'VBG'), ('``', '``'), ('l', 'JJ'), ('inear', 'NN'), ("''", "''"), ('artificial', 'JJ'), ('languages', 'NNS'), ('offer', 'VBP'), ('well-defined', 'JJ'), ('control', 'NN'), ('structures', 'VBZ'), ('axe', 'JJ'), ('difficult', 'JJ'), ('learn', 'NN'), (',', ','), ('take', 'VBP'), ('advantage', 'NN'), ('pointing', 'VBG'), ('objects', 'NNS'), ('screen', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Programming ``', '`` l', 'l inear', "inear ''", "'' artificial", 'artificial languages', 'languages offer', 'offer well-defined', 'well-defined control', 'control structures', 'structures axe', 'axe difficult', 'difficult learn', 'learn ,', ', take', 'take advantage', 'advantage pointing', 'pointing objects', 'objects screen', 'screen .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['Programming `` l', '`` l inear', "l inear ''", "inear '' artificial", "'' artificial languages", 'artificial languages offer', 'languages offer well-defined', 'offer well-defined control', 'well-defined control structures', 'control structures axe', 'structures axe difficult', 'axe difficult learn', 'difficult learn ,', 'learn , take', ', take advantage', 'take advantage pointing', 'advantage pointing objects', 'pointing objects screen', 'objects screen .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['l inear', 'well-defined control', 'axe difficult learn', 'advantage', 'screen'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['program', '``', 'l', 'inear', "''", 'artifici', 'languag', 'offer', 'well-defin', 'control', 'structur', 'axe', 'difficult', 'learn', ',', 'take', 'advantag', 'point', 'object', 'screen', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['program', '``', 'l', 'inear', "''", 'artifici', 'languag', 'offer', 'well-defin', 'control', 'structur', 'axe', 'difficult', 'learn', ',', 'take', 'advantag', 'point', 'object', 'screen', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['Programming', '``', 'l', 'inear', "''", 'artificial', 'language', 'offer', 'well-defined', 'control', 'structure', 'axe', 'difficult', 'learn', ',', 'take', 'advantage', 'pointing', 'object', 'screen', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

20 --> Moreover, they typically require substantial knowledge of underlying representations, and they offer  the user little guidance as to what can be done next. 


 ---- TOKENS ----

 ['Moreover', ',', 'they', 'typically', 'require', 'substantial', 'knowledge', 'of', 'underlying', 'representations', ',', 'and', 'they', 'offer', 'the', 'user', 'little', 'guidance', 'as', 'to', 'what', 'can', 'be', 'done', 'next', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Moreover', 'RB'), (',', ','), ('they', 'PRP'), ('typically', 'RB'), ('require', 'VBP'), ('substantial', 'JJ'), ('knowledge', 'NN'), ('of', 'IN'), ('underlying', 'JJ'), ('representations', 'NNS'), (',', ','), ('and', 'CC'), ('they', 'PRP'), ('offer', 'VBP'), ('the', 'DT'), ('user', 'NN'), ('little', 'JJ'), ('guidance', 'NN'), ('as', 'IN'), ('to', 'TO'), ('what', 'WP'), ('can', 'MD'), ('be', 'VB'), ('done', 'VBN'), ('next', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Moreover', ',', 'typically', 'require', 'substantial', 'knowledge', 'underlying', 'representations', ',', 'offer', 'user', 'little', 'guidance', 'done', 'next', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Moreover', 'RB'), (',', ','), ('typically', 'RB'), ('require', 'VBP'), ('substantial', 'JJ'), ('knowledge', 'NN'), ('underlying', 'VBG'), ('representations', 'NNS'), (',', ','), ('offer', 'VBP'), ('user', 'JJ'), ('little', 'JJ'), ('guidance', 'NN'), ('done', 'VBN'), ('next', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Moreover ,', ', typically', 'typically require', 'require substantial', 'substantial knowledge', 'knowledge underlying', 'underlying representations', 'representations ,', ', offer', 'offer user', 'user little', 'little guidance', 'guidance done', 'done next', 'next .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Moreover , typically', ', typically require', 'typically require substantial', 'require substantial knowledge', 'substantial knowledge underlying', 'knowledge underlying representations', 'underlying representations ,', 'representations , offer', ', offer user', 'offer user little', 'user little guidance', 'little guidance done', 'guidance done next', 'done next .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['substantial knowledge', 'user little guidance'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['moreov', ',', 'typic', 'requir', 'substanti', 'knowledg', 'underli', 'represent', ',', 'offer', 'user', 'littl', 'guidanc', 'done', 'next', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['moreov', ',', 'typic', 'requir', 'substanti', 'knowledg', 'under', 'represent', ',', 'offer', 'user', 'littl', 'guidanc', 'done', 'next', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Moreover', ',', 'typically', 'require', 'substantial', 'knowledge', 'underlying', 'representation', ',', 'offer', 'user', 'little', 'guidance', 'done', 'next', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

21 --> In fact, interaction with computers in any artificial language  places on the user most of the burden of discovering how to express in the language the commands necessary to  achieve the desired objective. 


 ---- TOKENS ----

 ['In', 'fact', ',', 'interaction', 'with', 'computers', 'in', 'any', 'artificial', 'language', 'places', 'on', 'the', 'user', 'most', 'of', 'the', 'burden', 'of', 'discovering', 'how', 'to', 'express', 'in', 'the', 'language', 'the', 'commands', 'necessary', 'to', 'achieve', 'the', 'desired', 'objective', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('In', 'IN'), ('fact', 'NN'), (',', ','), ('interaction', 'NN'), ('with', 'IN'), ('computers', 'NNS'), ('in', 'IN'), ('any', 'DT'), ('artificial', 'JJ'), ('language', 'NN'), ('places', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('user', 'NN'), ('most', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('burden', 'NN'), ('of', 'IN'), ('discovering', 'VBG'), ('how', 'WRB'), ('to', 'TO'), ('express', 'VB'), ('in', 'IN'), ('the', 'DT'), ('language', 'NN'), ('the', 'DT'), ('commands', 'NNS'), ('necessary', 'JJ'), ('to', 'TO'), ('achieve', 'VB'), ('the', 'DT'), ('desired', 'JJ'), ('objective', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['fact', ',', 'interaction', 'computers', 'artificial', 'language', 'places', 'user', 'burden', 'discovering', 'express', 'language', 'commands', 'necessary', 'achieve', 'desired', 'objective', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('fact', 'NN'), (',', ','), ('interaction', 'NN'), ('computers', 'NNS'), ('artificial', 'JJ'), ('language', 'NN'), ('places', 'NNS'), ('user', 'RB'), ('burden', 'IN'), ('discovering', 'VBG'), ('express', 'JJ'), ('language', 'NN'), ('commands', 'NNS'), ('necessary', 'JJ'), ('achieve', 'VBP'), ('desired', 'VBN'), ('objective', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['fact ,', ', interaction', 'interaction computers', 'computers artificial', 'artificial language', 'language places', 'places user', 'user burden', 'burden discovering', 'discovering express', 'express language', 'language commands', 'commands necessary', 'necessary achieve', 'achieve desired', 'desired objective', 'objective .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['fact , interaction', ', interaction computers', 'interaction computers artificial', 'computers artificial language', 'artificial language places', 'language places user', 'places user burden', 'user burden discovering', 'burden discovering express', 'discovering express language', 'express language commands', 'language commands necessary', 'commands necessary achieve', 'necessary achieve desired', 'achieve desired objective', 'desired objective .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['fact', 'interaction', 'artificial language', 'express language'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['fact', ',', 'interact', 'comput', 'artifici', 'languag', 'place', 'user', 'burden', 'discov', 'express', 'languag', 'command', 'necessari', 'achiev', 'desir', 'object', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['fact', ',', 'interact', 'comput', 'artifici', 'languag', 'place', 'user', 'burden', 'discov', 'express', 'languag', 'command', 'necessari', 'achiev', 'desir', 'object', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['fact', ',', 'interaction', 'computer', 'artificial', 'language', 'place', 'user', 'burden', 'discovering', 'express', 'language', 'command', 'necessary', 'achieve', 'desired', 'objective', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

22 --> It is natural for humans using natural languages to state complex conditions, to  integrate these with pointing, and to negotiate how a task could and should be done. 


 ---- TOKENS ----

 ['It', 'is', 'natural', 'for', 'humans', 'using', 'natural', 'languages', 'to', 'state', 'complex', 'conditions', ',', 'to', 'integrate', 'these', 'with', 'pointing', ',', 'and', 'to', 'negotiate', 'how', 'a', 'task', 'could', 'and', 'should', 'be', 'done', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('It', 'PRP'), ('is', 'VBZ'), ('natural', 'JJ'), ('for', 'IN'), ('humans', 'NNS'), ('using', 'VBG'), ('natural', 'JJ'), ('languages', 'NNS'), ('to', 'TO'), ('state', 'NN'), ('complex', 'JJ'), ('conditions', 'NNS'), (',', ','), ('to', 'TO'), ('integrate', 'VB'), ('these', 'DT'), ('with', 'IN'), ('pointing', 'NN'), (',', ','), ('and', 'CC'), ('to', 'TO'), ('negotiate', 'VB'), ('how', 'WRB'), ('a', 'DT'), ('task', 'NN'), ('could', 'MD'), ('and', 'CC'), ('should', 'MD'), ('be', 'VB'), ('done', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['natural', 'humans', 'using', 'natural', 'languages', 'state', 'complex', 'conditions', ',', 'integrate', 'pointing', ',', 'negotiate', 'task', 'could', 'done', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('natural', 'JJ'), ('humans', 'NNS'), ('using', 'VBG'), ('natural', 'JJ'), ('languages', 'NNS'), ('state', 'NN'), ('complex', 'JJ'), ('conditions', 'NNS'), (',', ','), ('integrate', 'NN'), ('pointing', 'NN'), (',', ','), ('negotiate', 'JJ'), ('task', 'NN'), ('could', 'MD'), ('done', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['natural humans', 'humans using', 'using natural', 'natural languages', 'languages state', 'state complex', 'complex conditions', 'conditions ,', ', integrate', 'integrate pointing', 'pointing ,', ', negotiate', 'negotiate task', 'task could', 'could done', 'done .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['natural humans using', 'humans using natural', 'using natural languages', 'natural languages state', 'languages state complex', 'state complex conditions', 'complex conditions ,', 'conditions , integrate', ', integrate pointing', 'integrate pointing ,', 'pointing , negotiate', ', negotiate task', 'negotiate task could', 'task could done', 'could done .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['state', 'integrate', 'pointing', 'negotiate task'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['natur', 'human', 'use', 'natur', 'languag', 'state', 'complex', 'condit', ',', 'integr', 'point', ',', 'negoti', 'task', 'could', 'done', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['natur', 'human', 'use', 'natur', 'languag', 'state', 'complex', 'condit', ',', 'integr', 'point', ',', 'negoti', 'task', 'could', 'done', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['natural', 'human', 'using', 'natural', 'language', 'state', 'complex', 'condition', ',', 'integrate', 'pointing', ',', 'negotiate', 'task', 'could', 'done', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

23 --> Natural language should,  however, be seen as a powerful addition to the repertoire of methods for human-machine interaction, and not as a  replacement for those methods. 


 ---- TOKENS ----

 ['Natural', 'language', 'should', ',', 'however', ',', 'be', 'seen', 'as', 'a', 'powerful', 'addition', 'to', 'the', 'repertoire', 'of', 'methods', 'for', 'human-machine', 'interaction', ',', 'and', 'not', 'as', 'a', 'replacement', 'for', 'those', 'methods', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('Natural', 'JJ'), ('language', 'NN'), ('should', 'MD'), (',', ','), ('however', 'RB'), (',', ','), ('be', 'VB'), ('seen', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('powerful', 'JJ'), ('addition', 'NN'), ('to', 'TO'), ('the', 'DT'), ('repertoire', 'NN'), ('of', 'IN'), ('methods', 'NNS'), ('for', 'IN'), ('human-machine', 'JJ'), ('interaction', 'NN'), (',', ','), ('and', 'CC'), ('not', 'RB'), ('as', 'IN'), ('a', 'DT'), ('replacement', 'NN'), ('for', 'IN'), ('those', 'DT'), ('methods', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Natural', 'language', ',', 'however', ',', 'seen', 'powerful', 'addition', 'repertoire', 'methods', 'human-machine', 'interaction', ',', 'replacement', 'methods', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Natural', 'JJ'), ('language', 'NN'), (',', ','), ('however', 'RB'), (',', ','), ('seen', 'VBN'), ('powerful', 'JJ'), ('addition', 'NN'), ('repertoire', 'NN'), ('methods', 'NNS'), ('human-machine', 'JJ'), ('interaction', 'NN'), (',', ','), ('replacement', 'NN'), ('methods', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Natural language', 'language ,', ', however', 'however ,', ', seen', 'seen powerful', 'powerful addition', 'addition repertoire', 'repertoire methods', 'methods human-machine', 'human-machine interaction', 'interaction ,', ', replacement', 'replacement methods', 'methods .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Natural language ,', 'language , however', ', however ,', 'however , seen', ', seen powerful', 'seen powerful addition', 'powerful addition repertoire', 'addition repertoire methods', 'repertoire methods human-machine', 'methods human-machine interaction', 'human-machine interaction ,', 'interaction , replacement', ', replacement methods', 'replacement methods .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['Natural language', 'powerful addition', 'repertoire', 'human-machine interaction', 'replacement'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['natur', 'languag', ',', 'howev', ',', 'seen', 'power', 'addit', 'repertoir', 'method', 'human-machin', 'interact', ',', 'replac', 'method', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['natur', 'languag', ',', 'howev', ',', 'seen', 'power', 'addit', 'repertoir', 'method', 'human-machin', 'interact', ',', 'replac', 'method', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Natural', 'language', ',', 'however', ',', 'seen', 'powerful', 'addition', 'repertoire', 'method', 'human-machine', 'interaction', ',', 'replacement', 'method', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

24 --> Thus, the third major challenge of natural language processing is  3. 


 ---- TOKENS ----

 ['Thus', ',', 'the', 'third', 'major', 'challenge', 'of', 'natural', 'language', 'processing', 'is', '3', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Thus', 'RB'), (',', ','), ('the', 'DT'), ('third', 'JJ'), ('major', 'JJ'), ('challenge', 'NN'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Thus', ',', 'third', 'major', 'challenge', 'natural', 'language', 'processing', '3', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Thus', 'RB'), (',', ','), ('third', 'JJ'), ('major', 'JJ'), ('challenge', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Thus ,', ', third', 'third major', 'major challenge', 'challenge natural', 'natural language', 'language processing', 'processing 3', '3 .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Thus , third', ', third major', 'third major challenge', 'major challenge natural', 'challenge natural language', 'natural language processing', 'language processing 3', 'processing 3 .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['third major challenge', 'natural language', 'processing'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['thu', ',', 'third', 'major', 'challeng', 'natur', 'languag', 'process', '3', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['thus', ',', 'third', 'major', 'challeng', 'natur', 'languag', 'process', '3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Thus', ',', 'third', 'major', 'challenge', 'natural', 'language', 'processing', '3', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

25 --> Interactive dialogue, allowing humans simple, effective access to computer systems, using natural language and  other modalities, for problem-solving, decision-making, and control. 


 ---- TOKENS ----

 ['Interactive', 'dialogue', ',', 'allowing', 'humans', 'simple', ',', 'effective', 'access', 'to', 'computer', 'systems', ',', 'using', 'natural', 'language', 'and', 'other', 'modalities', ',', 'for', 'problem-solving', ',', 'decision-making', ',', 'and', 'control', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('Interactive', 'NNP'), ('dialogue', 'NN'), (',', ','), ('allowing', 'VBG'), ('humans', 'NNS'), ('simple', 'JJ'), (',', ','), ('effective', 'JJ'), ('access', 'NN'), ('to', 'TO'), ('computer', 'NN'), ('systems', 'NNS'), (',', ','), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('and', 'CC'), ('other', 'JJ'), ('modalities', 'NNS'), (',', ','), ('for', 'IN'), ('problem-solving', 'JJ'), (',', ','), ('decision-making', 'JJ'), (',', ','), ('and', 'CC'), ('control', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Interactive', 'dialogue', ',', 'allowing', 'humans', 'simple', ',', 'effective', 'access', 'computer', 'systems', ',', 'using', 'natural', 'language', 'modalities', ',', 'problem-solving', ',', 'decision-making', ',', 'control', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('Interactive', 'NNP'), ('dialogue', 'NN'), (',', ','), ('allowing', 'VBG'), ('humans', 'NNS'), ('simple', 'JJ'), (',', ','), ('effective', 'JJ'), ('access', 'NN'), ('computer', 'NN'), ('systems', 'NNS'), (',', ','), ('using', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('modalities', 'NNS'), (',', ','), ('problem-solving', 'JJ'), (',', ','), ('decision-making', 'JJ'), (',', ','), ('control', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Interactive dialogue', 'dialogue ,', ', allowing', 'allowing humans', 'humans simple', 'simple ,', ', effective', 'effective access', 'access computer', 'computer systems', 'systems ,', ', using', 'using natural', 'natural language', 'language modalities', 'modalities ,', ', problem-solving', 'problem-solving ,', ', decision-making', 'decision-making ,', ', control', 'control .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['Interactive dialogue ,', 'dialogue , allowing', ', allowing humans', 'allowing humans simple', 'humans simple ,', 'simple , effective', ', effective access', 'effective access computer', 'access computer systems', 'computer systems ,', 'systems , using', ', using natural', 'using natural language', 'natural language modalities', 'language modalities ,', 'modalities , problem-solving', ', problem-solving ,', 'problem-solving , decision-making', ', decision-making ,', 'decision-making , control', ', control .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['dialogue', 'effective access', 'computer', 'natural language', 'control'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Interactive']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['interact', 'dialogu', ',', 'allow', 'human', 'simpl', ',', 'effect', 'access', 'comput', 'system', ',', 'use', 'natur', 'languag', 'modal', ',', 'problem-solv', ',', 'decision-mak', ',', 'control', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['interact', 'dialogu', ',', 'allow', 'human', 'simpl', ',', 'effect', 'access', 'comput', 'system', ',', 'use', 'natur', 'languag', 'modal', ',', 'problem-solv', ',', 'decision-mak', ',', 'control', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['Interactive', 'dialogue', ',', 'allowing', 'human', 'simple', ',', 'effective', 'access', 'computer', 'system', ',', 'using', 'natural', 'language', 'modality', ',', 'problem-solving', ',', 'decision-making', ',', 'control', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

26 --> Application areas include database access,  command and control, factory control, office automation, logistics, and computer-assisted instruction. 


 ---- TOKENS ----

 ['Application', 'areas', 'include', 'database', 'access', ',', 'command', 'and', 'control', ',', 'factory', 'control', ',', 'office', 'automation', ',', 'logistics', ',', 'and', 'computer-assisted', 'instruction', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Application', 'NNP'), ('areas', 'NNS'), ('include', 'VBP'), ('database', 'JJ'), ('access', 'NN'), (',', ','), ('command', 'NN'), ('and', 'CC'), ('control', 'NN'), (',', ','), ('factory', 'NN'), ('control', 'NN'), (',', ','), ('office', 'NN'), ('automation', 'NN'), (',', ','), ('logistics', 'NNS'), (',', ','), ('and', 'CC'), ('computer-assisted', 'JJ'), ('instruction', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Application', 'areas', 'include', 'database', 'access', ',', 'command', 'control', ',', 'factory', 'control', ',', 'office', 'automation', ',', 'logistics', ',', 'computer-assisted', 'instruction', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('Application', 'NNP'), ('areas', 'NNS'), ('include', 'VBP'), ('database', 'JJ'), ('access', 'NN'), (',', ','), ('command', 'NN'), ('control', 'NN'), (',', ','), ('factory', 'NN'), ('control', 'NN'), (',', ','), ('office', 'NN'), ('automation', 'NN'), (',', ','), ('logistics', 'NNS'), (',', ','), ('computer-assisted', 'JJ'), ('instruction', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Application areas', 'areas include', 'include database', 'database access', 'access ,', ', command', 'command control', 'control ,', ', factory', 'factory control', 'control ,', ', office', 'office automation', 'automation ,', ', logistics', 'logistics ,', ', computer-assisted', 'computer-assisted instruction', 'instruction .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['Application areas include', 'areas include database', 'include database access', 'database access ,', 'access , command', ', command control', 'command control ,', 'control , factory', ', factory control', 'factory control ,', 'control , office', ', office automation', 'office automation ,', 'automation , logistics', ', logistics ,', 'logistics , computer-assisted', ', computer-assisted instruction', 'computer-assisted instruction .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['database access', 'command', 'control', 'factory', 'control', 'office', 'automation', 'computer-assisted instruction'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Application']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['applic', 'area', 'includ', 'databas', 'access', ',', 'command', 'control', ',', 'factori', 'control', ',', 'offic', 'autom', ',', 'logist', ',', 'computer-assist', 'instruct', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['applic', 'area', 'includ', 'databas', 'access', ',', 'command', 'control', ',', 'factori', 'control', ',', 'offic', 'autom', ',', 'logist', ',', 'computer-assist', 'instruct', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['Application', 'area', 'include', 'database', 'access', ',', 'command', 'control', ',', 'factory', 'control', ',', 'office', 'automation', ',', 'logistics', ',', 'computer-assisted', 'instruction', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

27 --> Human-  machine interaction should be as natural, facile, and multi-modal as interaction among humans. 


 ---- TOKENS ----

 ['Human-', 'machine', 'interaction', 'should', 'be', 'as', 'natural', ',', 'facile', ',', 'and', 'multi-modal', 'as', 'interaction', 'among', 'humans', '.'] 

 TOTAL TOKENS ==> 17

 ---- POST ----

 [('Human-', 'JJ'), ('machine', 'NN'), ('interaction', 'NN'), ('should', 'MD'), ('be', 'VB'), ('as', 'IN'), ('natural', 'JJ'), (',', ','), ('facile', 'JJ'), (',', ','), ('and', 'CC'), ('multi-modal', 'JJ'), ('as', 'IN'), ('interaction', 'NN'), ('among', 'IN'), ('humans', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Human-', 'machine', 'interaction', 'natural', ',', 'facile', ',', 'multi-modal', 'interaction', 'among', 'humans', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Human-', 'JJ'), ('machine', 'NN'), ('interaction', 'NN'), ('natural', 'JJ'), (',', ','), ('facile', 'JJ'), (',', ','), ('multi-modal', 'JJ'), ('interaction', 'NN'), ('among', 'IN'), ('humans', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Human- machine', 'machine interaction', 'interaction natural', 'natural ,', ', facile', 'facile ,', ', multi-modal', 'multi-modal interaction', 'interaction among', 'among humans', 'humans .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Human- machine interaction', 'machine interaction natural', 'interaction natural ,', 'natural , facile', ', facile ,', 'facile , multi-modal', ', multi-modal interaction', 'multi-modal interaction among', 'interaction among humans', 'among humans .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['Human- machine', 'interaction', 'multi-modal interaction'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['human-', 'machin', 'interact', 'natur', ',', 'facil', ',', 'multi-mod', 'interact', 'among', 'human', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['human-', 'machin', 'interact', 'natur', ',', 'facil', ',', 'multi-mod', 'interact', 'among', 'human', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Human-', 'machine', 'interaction', 'natural', ',', 'facile', ',', 'multi-modal', 'interaction', 'among', 'human', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

28 --> While it will be quite some time before systems meet these challenges with the depth and flexibility that  humans bring to them, useful shorter term goals of economic value have been and can continue to be met. 


 ---- TOKENS ----

 ['While', 'it', 'will', 'be', 'quite', 'some', 'time', 'before', 'systems', 'meet', 'these', 'challenges', 'with', 'the', 'depth', 'and', 'flexibility', 'that', 'humans', 'bring', 'to', 'them', ',', 'useful', 'shorter', 'term', 'goals', 'of', 'economic', 'value', 'have', 'been', 'and', 'can', 'continue', 'to', 'be', 'met', '.'] 

 TOTAL TOKENS ==> 39

 ---- POST ----

 [('While', 'IN'), ('it', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('quite', 'RB'), ('some', 'DT'), ('time', 'NN'), ('before', 'IN'), ('systems', 'NNS'), ('meet', 'IN'), ('these', 'DT'), ('challenges', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('depth', 'NN'), ('and', 'CC'), ('flexibility', 'NN'), ('that', 'IN'), ('humans', 'VBZ'), ('bring', 'VBG'), ('to', 'TO'), ('them', 'PRP'), (',', ','), ('useful', 'JJ'), ('shorter', 'JJR'), ('term', 'NN'), ('goals', 'NNS'), ('of', 'IN'), ('economic', 'JJ'), ('value', 'NN'), ('have', 'VBP'), ('been', 'VBN'), ('and', 'CC'), ('can', 'MD'), ('continue', 'VB'), ('to', 'TO'), ('be', 'VB'), ('met', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['quite', 'time', 'systems', 'meet', 'challenges', 'depth', 'flexibility', 'humans', 'bring', ',', 'useful', 'shorter', 'term', 'goals', 'economic', 'value', 'continue', 'met', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('quite', 'JJ'), ('time', 'NN'), ('systems', 'NNS'), ('meet', 'JJ'), ('challenges', 'NNS'), ('depth', 'VBP'), ('flexibility', 'NN'), ('humans', 'NNS'), ('bring', 'VBP'), (',', ','), ('useful', 'JJ'), ('shorter', 'JJR'), ('term', 'NN'), ('goals', 'NNS'), ('economic', 'JJ'), ('value', 'NN'), ('continue', 'VBP'), ('met', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['quite time', 'time systems', 'systems meet', 'meet challenges', 'challenges depth', 'depth flexibility', 'flexibility humans', 'humans bring', 'bring ,', ', useful', 'useful shorter', 'shorter term', 'term goals', 'goals economic', 'economic value', 'value continue', 'continue met', 'met .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['quite time systems', 'time systems meet', 'systems meet challenges', 'meet challenges depth', 'challenges depth flexibility', 'depth flexibility humans', 'flexibility humans bring', 'humans bring ,', 'bring , useful', ', useful shorter', 'useful shorter term', 'shorter term goals', 'term goals economic', 'goals economic value', 'economic value continue', 'value continue met', 'continue met .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['quite time', 'flexibility', 'term', 'economic value'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['quit', 'time', 'system', 'meet', 'challeng', 'depth', 'flexibl', 'human', 'bring', ',', 'use', 'shorter', 'term', 'goal', 'econom', 'valu', 'continu', 'met', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['quit', 'time', 'system', 'meet', 'challeng', 'depth', 'flexibl', 'human', 'bring', ',', 'use', 'shorter', 'term', 'goal', 'econom', 'valu', 'continu', 'met', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['quite', 'time', 'system', 'meet', 'challenge', 'depth', 'flexibility', 'human', 'bring', ',', 'useful', 'shorter', 'term', 'goal', 'economic', 'value', 'continue', 'met', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

29 --> These  include database access systems, multi-modal interfaces to expert systems and simulators, processing of text (e.g.,  for database update), and semi-automatic machine translation systems. 


 ---- TOKENS ----

 ['These', 'include', 'database', 'access', 'systems', ',', 'multi-modal', 'interfaces', 'to', 'expert', 'systems', 'and', 'simulators', ',', 'processing', 'of', 'text', '(', 'e.g.', ',', 'for', 'database', 'update', ')', ',', 'and', 'semi-automatic', 'machine', 'translation', 'systems', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('These', 'DT'), ('include', 'VBP'), ('database', 'NN'), ('access', 'NN'), ('systems', 'NNS'), (',', ','), ('multi-modal', 'JJ'), ('interfaces', 'NNS'), ('to', 'TO'), ('expert', 'VB'), ('systems', 'NNS'), ('and', 'CC'), ('simulators', 'NNS'), (',', ','), ('processing', 'NN'), ('of', 'IN'), ('text', 'NN'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('for', 'IN'), ('database', 'NN'), ('update', 'NN'), (')', ')'), (',', ','), ('and', 'CC'), ('semi-automatic', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['include', 'database', 'access', 'systems', ',', 'multi-modal', 'interfaces', 'expert', 'systems', 'simulators', ',', 'processing', 'text', '(', 'e.g.', ',', 'database', 'update', ')', ',', 'semi-automatic', 'machine', 'translation', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('include', 'JJ'), ('database', 'NN'), ('access', 'NN'), ('systems', 'NNS'), (',', ','), ('multi-modal', 'JJ'), ('interfaces', 'NNS'), ('expert', 'JJ'), ('systems', 'NNS'), ('simulators', 'NNS'), (',', ','), ('processing', 'VBG'), ('text', 'NN'), ('(', '('), ('e.g.', 'JJ'), (',', ','), ('database', 'VB'), ('update', 'NN'), (')', ')'), (',', ','), ('semi-automatic', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['include database', 'database access', 'access systems', 'systems ,', ', multi-modal', 'multi-modal interfaces', 'interfaces expert', 'expert systems', 'systems simulators', 'simulators ,', ', processing', 'processing text', 'text (', '( e.g.', 'e.g. ,', ', database', 'database update', 'update )', ') ,', ', semi-automatic', 'semi-automatic machine', 'machine translation', 'translation systems', 'systems .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['include database access', 'database access systems', 'access systems ,', 'systems , multi-modal', ', multi-modal interfaces', 'multi-modal interfaces expert', 'interfaces expert systems', 'expert systems simulators', 'systems simulators ,', 'simulators , processing', ', processing text', 'processing text (', 'text ( e.g.', '( e.g. ,', 'e.g. , database', ', database update', 'database update )', 'update ) ,', ') , semi-automatic', ', semi-automatic machine', 'semi-automatic machine translation', 'machine translation systems', 'translation systems .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['include database', 'access', 'text', 'semi-automatic machine', 'translation'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['includ', 'databas', 'access', 'system', ',', 'multi-mod', 'interfac', 'expert', 'system', 'simul', ',', 'process', 'text', '(', 'e.g.', ',', 'databas', 'updat', ')', ',', 'semi-automat', 'machin', 'translat', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['includ', 'databas', 'access', 'system', ',', 'multi-mod', 'interfac', 'expert', 'system', 'simul', ',', 'process', 'text', '(', 'e.g.', ',', 'databas', 'updat', ')', ',', 'semi-automat', 'machin', 'translat', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['include', 'database', 'access', 'system', ',', 'multi-modal', 'interface', 'expert', 'system', 'simulator', ',', 'processing', 'text', '(', 'e.g.', ',', 'database', 'update', ')', ',', 'semi-automatic', 'machine', 'translation', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

30 --> Virtually all developments necessary to long- and short-term progress toward these goals will be relevant  to the transition from speech recognition systems to spoken language systems (SLS), which is the subject of a  separate report to this committee. 


 ---- TOKENS ----

 ['Virtually', 'all', 'developments', 'necessary', 'to', 'long-', 'and', 'short-term', 'progress', 'toward', 'these', 'goals', 'will', 'be', 'relevant', 'to', 'the', 'transition', 'from', 'speech', 'recognition', 'systems', 'to', 'spoken', 'language', 'systems', '(', 'SLS', ')', ',', 'which', 'is', 'the', 'subject', 'of', 'a', 'separate', 'report', 'to', 'this', 'committee', '.'] 

 TOTAL TOKENS ==> 42

 ---- POST ----

 [('Virtually', 'RB'), ('all', 'DT'), ('developments', 'NNS'), ('necessary', 'JJ'), ('to', 'TO'), ('long-', 'JJ'), ('and', 'CC'), ('short-term', 'JJ'), ('progress', 'NN'), ('toward', 'IN'), ('these', 'DT'), ('goals', 'NNS'), ('will', 'MD'), ('be', 'VB'), ('relevant', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('transition', 'NN'), ('from', 'IN'), ('speech', 'JJ'), ('recognition', 'NN'), ('systems', 'NNS'), ('to', 'TO'), ('spoken', 'JJ'), ('language', 'NN'), ('systems', 'NNS'), ('(', '('), ('SLS', 'NNP'), (')', ')'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('subject', 'NN'), ('of', 'IN'), ('a', 'DT'), ('separate', 'JJ'), ('report', 'NN'), ('to', 'TO'), ('this', 'DT'), ('committee', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Virtually', 'developments', 'necessary', 'long-', 'short-term', 'progress', 'toward', 'goals', 'relevant', 'transition', 'speech', 'recognition', 'systems', 'spoken', 'language', 'systems', '(', 'SLS', ')', ',', 'subject', 'separate', 'report', 'committee', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('Virtually', 'RB'), ('developments', 'NNS'), ('necessary', 'JJ'), ('long-', 'JJ'), ('short-term', 'JJ'), ('progress', 'NN'), ('toward', 'IN'), ('goals', 'NNS'), ('relevant', 'JJ'), ('transition', 'NN'), ('speech', 'NN'), ('recognition', 'NN'), ('systems', 'NNS'), ('spoken', 'JJ'), ('language', 'NN'), ('systems', 'NNS'), ('(', '('), ('SLS', 'NNP'), (')', ')'), (',', ','), ('subject', 'JJ'), ('separate', 'JJ'), ('report', 'NN'), ('committee', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Virtually developments', 'developments necessary', 'necessary long-', 'long- short-term', 'short-term progress', 'progress toward', 'toward goals', 'goals relevant', 'relevant transition', 'transition speech', 'speech recognition', 'recognition systems', 'systems spoken', 'spoken language', 'language systems', 'systems (', '( SLS', 'SLS )', ') ,', ', subject', 'subject separate', 'separate report', 'report committee', 'committee .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['Virtually developments necessary', 'developments necessary long-', 'necessary long- short-term', 'long- short-term progress', 'short-term progress toward', 'progress toward goals', 'toward goals relevant', 'goals relevant transition', 'relevant transition speech', 'transition speech recognition', 'speech recognition systems', 'recognition systems spoken', 'systems spoken language', 'spoken language systems', 'language systems (', 'systems ( SLS', '( SLS )', 'SLS ) ,', ') , subject', ', subject separate', 'subject separate report', 'separate report committee', 'report committee .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['necessary long- short-term progress', 'relevant transition', 'speech', 'recognition', 'spoken language', 'subject separate report', 'committee'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['virtual', 'develop', 'necessari', 'long-', 'short-term', 'progress', 'toward', 'goal', 'relev', 'transit', 'speech', 'recognit', 'system', 'spoken', 'languag', 'system', '(', 'sl', ')', ',', 'subject', 'separ', 'report', 'committe', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['virtual', 'develop', 'necessari', 'long-', 'short-term', 'progress', 'toward', 'goal', 'relev', 'transit', 'speech', 'recognit', 'system', 'spoken', 'languag', 'system', '(', 'sls', ')', ',', 'subject', 'separ', 'report', 'committe', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['Virtually', 'development', 'necessary', 'long-', 'short-term', 'progress', 'toward', 'goal', 'relevant', 'transition', 'speech', 'recognition', 'system', 'spoken', 'language', 'system', '(', 'SLS', ')', ',', 'subject', 'separate', 'report', 'committee', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

31 --> However, in this report we will not have anything ~rther to say specifically about  SLSs or their attendant problems in speech signal processing,  1.2. 


 ---- TOKENS ----

 ['However', ',', 'in', 'this', 'report', 'we', 'will', 'not', 'have', 'anything', '~rther', 'to', 'say', 'specifically', 'about', 'SLSs', 'or', 'their', 'attendant', 'problems', 'in', 'speech', 'signal', 'processing', ',', '1.2', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('However', 'RB'), (',', ','), ('in', 'IN'), ('this', 'DT'), ('report', 'NN'), ('we', 'PRP'), ('will', 'MD'), ('not', 'RB'), ('have', 'VB'), ('anything', 'NN'), ('~rther', 'JJR'), ('to', 'TO'), ('say', 'VB'), ('specifically', 'RB'), ('about', 'RB'), ('SLSs', 'NNP'), ('or', 'CC'), ('their', 'PRP$'), ('attendant', 'JJ'), ('problems', 'NNS'), ('in', 'IN'), ('speech', 'JJ'), ('signal', 'NN'), ('processing', 'NN'), (',', ','), ('1.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['However', ',', 'report', 'anything', '~rther', 'say', 'specifically', 'SLSs', 'attendant', 'problems', 'speech', 'signal', 'processing', ',', '1.2', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('However', 'RB'), (',', ','), ('report', 'NN'), ('anything', 'NN'), ('~rther', 'JJ'), ('say', 'VBP'), ('specifically', 'RB'), ('SLSs', 'NNP'), ('attendant', 'NN'), ('problems', 'NNS'), ('speech', 'VBP'), ('signal', 'JJ'), ('processing', 'NN'), (',', ','), ('1.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['However ,', ', report', 'report anything', 'anything ~rther', '~rther say', 'say specifically', 'specifically SLSs', 'SLSs attendant', 'attendant problems', 'problems speech', 'speech signal', 'signal processing', 'processing ,', ', 1.2', '1.2 .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['However , report', ', report anything', 'report anything ~rther', 'anything ~rther say', '~rther say specifically', 'say specifically SLSs', 'specifically SLSs attendant', 'SLSs attendant problems', 'attendant problems speech', 'problems speech signal', 'speech signal processing', 'signal processing ,', 'processing , 1.2', ', 1.2 .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['report', 'anything', 'attendant', 'signal processing'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['SLSs']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['howev', ',', 'report', 'anyth', '~rther', 'say', 'specif', 'slss', 'attend', 'problem', 'speech', 'signal', 'process', ',', '1.2', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['howev', ',', 'report', 'anyth', '~rther', 'say', 'specif', 'slss', 'attend', 'problem', 'speech', 'signal', 'process', ',', '1.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['However', ',', 'report', 'anything', '~rther', 'say', 'specifically', 'SLSs', 'attendant', 'problem', 'speech', 'signal', 'processing', ',', '1.2', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

32 --> B a r r i e r s  to P r o g r e s s   1.2.1. 


 ---- TOKENS ----

 ['B', 'a', 'r', 'r', 'i', 'e', 'r', 's', 'to', 'P', 'r', 'o', 'g', 'r', 'e', 's', 's', '1.2.1', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('B', 'IN'), ('a', 'DT'), ('r', 'NN'), ('r', 'NN'), ('i', 'NN'), ('e', 'VBP'), ('r', 'NN'), ('s', 'NN'), ('to', 'TO'), ('P', 'NNP'), ('r', 'NN'), ('o', 'NN'), ('g', 'NN'), ('r', 'NN'), ('e', 'NN'), ('s', 'VBD'), ('s', 'JJ'), ('1.2.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['B', 'r', 'r', 'e', 'r', 'P', 'r', 'g', 'r', 'e', '1.2.1', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('B', 'NNP'), ('r', 'NN'), ('r', 'NN'), ('e', 'NN'), ('r', 'NN'), ('P', 'NNP'), ('r', 'NN'), ('g', 'NN'), ('r', 'NN'), ('e', 'VBD'), ('1.2.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['B r', 'r r', 'r e', 'e r', 'r P', 'P r', 'r g', 'g r', 'r e', 'e 1.2.1', '1.2.1 .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['B r r', 'r r e', 'r e r', 'e r P', 'r P r', 'P r g', 'r g r', 'g r e', 'r e 1.2.1', 'e 1.2.1 .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['r', 'r', 'e', 'r', 'r', 'g', 'r'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['b', 'r', 'r', 'e', 'r', 'p', 'r', 'g', 'r', 'e', '1.2.1', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['b', 'r', 'r', 'e', 'r', 'p', 'r', 'g', 'r', 'e', '1.2.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['B', 'r', 'r', 'e', 'r', 'P', 'r', 'g', 'r', 'e', '1.2.1', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

33 --> Success and Limitations Thus Far  NLP systems perform three related functions: analysis (or interpretation) of the input, mapping it into an  expression in some meaning representation language (MRL); reasoning about the interpretation to determine the  content of what should be produced in response to the user, perhaps accessing information in databases, expert  systems, etc: and finally, generation of a response, perhaps as a natural-language utterance or text. 


 ---- TOKENS ----

 ['Success', 'and', 'Limitations', 'Thus', 'Far', 'NLP', 'systems', 'perform', 'three', 'related', 'functions', ':', 'analysis', '(', 'or', 'interpretation', ')', 'of', 'the', 'input', ',', 'mapping', 'it', 'into', 'an', 'expression', 'in', 'some', 'meaning', 'representation', 'language', '(', 'MRL', ')', ';', 'reasoning', 'about', 'the', 'interpretation', 'to', 'determine', 'the', 'content', 'of', 'what', 'should', 'be', 'produced', 'in', 'response', 'to', 'the', 'user', ',', 'perhaps', 'accessing', 'information', 'in', 'databases', ',', 'expert', 'systems', ',', 'etc', ':', 'and', 'finally', ',', 'generation', 'of', 'a', 'response', ',', 'perhaps', 'as', 'a', 'natural-language', 'utterance', 'or', 'text', '.'] 

 TOTAL TOKENS ==> 81

 ---- POST ----

 [('Success', 'NN'), ('and', 'CC'), ('Limitations', 'NNP'), ('Thus', 'NNP'), ('Far', 'NNP'), ('NLP', 'NNP'), ('systems', 'NNS'), ('perform', 'VBP'), ('three', 'CD'), ('related', 'JJ'), ('functions', 'NNS'), (':', ':'), ('analysis', 'NN'), ('(', '('), ('or', 'CC'), ('interpretation', 'NN'), (')', ')'), ('of', 'IN'), ('the', 'DT'), ('input', 'NN'), (',', ','), ('mapping', 'VBG'), ('it', 'PRP'), ('into', 'IN'), ('an', 'DT'), ('expression', 'NN'), ('in', 'IN'), ('some', 'DT'), ('meaning', 'NN'), ('representation', 'NN'), ('language', 'NN'), ('(', '('), ('MRL', 'NNP'), (')', ')'), (';', ':'), ('reasoning', 'VBG'), ('about', 'IN'), ('the', 'DT'), ('interpretation', 'NN'), ('to', 'TO'), ('determine', 'VB'), ('the', 'DT'), ('content', 'NN'), ('of', 'IN'), ('what', 'WP'), ('should', 'MD'), ('be', 'VB'), ('produced', 'VBN'), ('in', 'IN'), ('response', 'NN'), ('to', 'TO'), ('the', 'DT'), ('user', 'NN'), (',', ','), ('perhaps', 'RB'), ('accessing', 'VBG'), ('information', 'NN'), ('in', 'IN'), ('databases', 'NNS'), (',', ','), ('expert', 'JJ'), ('systems', 'NNS'), (',', ','), ('etc', 'NN'), (':', ':'), ('and', 'CC'), ('finally', 'RB'), (',', ','), ('generation', 'NN'), ('of', 'IN'), ('a', 'DT'), ('response', 'NN'), (',', ','), ('perhaps', 'RB'), ('as', 'IN'), ('a', 'DT'), ('natural-language', 'JJ'), ('utterance', 'NN'), ('or', 'CC'), ('text', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Success', 'Limitations', 'Thus', 'Far', 'NLP', 'systems', 'perform', 'three', 'related', 'functions', ':', 'analysis', '(', 'interpretation', ')', 'input', ',', 'mapping', 'expression', 'meaning', 'representation', 'language', '(', 'MRL', ')', ';', 'reasoning', 'interpretation', 'determine', 'content', 'produced', 'response', 'user', ',', 'perhaps', 'accessing', 'information', 'databases', ',', 'expert', 'systems', ',', 'etc', ':', 'finally', ',', 'generation', 'response', ',', 'perhaps', 'natural-language', 'utterance', 'text', '.']

 TOTAL FILTERED TOKENS ==>  54

 ---- POST FOR FILTERED TOKENS ----

 [('Success', 'JJ'), ('Limitations', 'NNP'), ('Thus', 'NNP'), ('Far', 'NNP'), ('NLP', 'NNP'), ('systems', 'NNS'), ('perform', 'VBP'), ('three', 'CD'), ('related', 'JJ'), ('functions', 'NNS'), (':', ':'), ('analysis', 'NN'), ('(', '('), ('interpretation', 'NN'), (')', ')'), ('input', 'NN'), (',', ','), ('mapping', 'VBG'), ('expression', 'NN'), ('meaning', 'VBG'), ('representation', 'NN'), ('language', 'NN'), ('(', '('), ('MRL', 'NNP'), (')', ')'), (';', ':'), ('reasoning', 'VBG'), ('interpretation', 'NN'), ('determine', 'NN'), ('content', 'NN'), ('produced', 'VBN'), ('response', 'NN'), ('user', 'NN'), (',', ','), ('perhaps', 'RB'), ('accessing', 'VBG'), ('information', 'NN'), ('databases', 'NNS'), (',', ','), ('expert', 'JJ'), ('systems', 'NNS'), (',', ','), ('etc', 'NN'), (':', ':'), ('finally', 'RB'), (',', ','), ('generation', 'NN'), ('response', 'NN'), (',', ','), ('perhaps', 'RB'), ('natural-language', 'JJ'), ('utterance', 'NN'), ('text', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Success Limitations', 'Limitations Thus', 'Thus Far', 'Far NLP', 'NLP systems', 'systems perform', 'perform three', 'three related', 'related functions', 'functions :', ': analysis', 'analysis (', '( interpretation', 'interpretation )', ') input', 'input ,', ', mapping', 'mapping expression', 'expression meaning', 'meaning representation', 'representation language', 'language (', '( MRL', 'MRL )', ') ;', '; reasoning', 'reasoning interpretation', 'interpretation determine', 'determine content', 'content produced', 'produced response', 'response user', 'user ,', ', perhaps', 'perhaps accessing', 'accessing information', 'information databases', 'databases ,', ', expert', 'expert systems', 'systems ,', ', etc', 'etc :', ': finally', 'finally ,', ', generation', 'generation response', 'response ,', ', perhaps', 'perhaps natural-language', 'natural-language utterance', 'utterance text', 'text .'] 

 TOTAL BIGRAMS --> 53 



 ---- TRI-GRAMS ---- 

 ['Success Limitations Thus', 'Limitations Thus Far', 'Thus Far NLP', 'Far NLP systems', 'NLP systems perform', 'systems perform three', 'perform three related', 'three related functions', 'related functions :', 'functions : analysis', ': analysis (', 'analysis ( interpretation', '( interpretation )', 'interpretation ) input', ') input ,', 'input , mapping', ', mapping expression', 'mapping expression meaning', 'expression meaning representation', 'meaning representation language', 'representation language (', 'language ( MRL', '( MRL )', 'MRL ) ;', ') ; reasoning', '; reasoning interpretation', 'reasoning interpretation determine', 'interpretation determine content', 'determine content produced', 'content produced response', 'produced response user', 'response user ,', 'user , perhaps', ', perhaps accessing', 'perhaps accessing information', 'accessing information databases', 'information databases ,', 'databases , expert', ', expert systems', 'expert systems ,', 'systems , etc', ', etc :', 'etc : finally', ': finally ,', 'finally , generation', ', generation response', 'generation response ,', 'response , perhaps', ', perhaps natural-language', 'perhaps natural-language utterance', 'natural-language utterance text', 'utterance text .'] 

 TOTAL TRIGRAMS --> 52 



 ---- NOUN PHRASES ---- 

 ['analysis', 'input', 'expression', 'representation', 'language', 'interpretation', 'determine', 'content', 'response', 'user', 'information', 'etc', 'generation', 'response', 'natural-language utterance', 'text'] 

 TOTAL NOUN PHRASES --> 16 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['success', 'limit', 'thu', 'far', 'nlp', 'system', 'perform', 'three', 'relat', 'function', ':', 'analysi', '(', 'interpret', ')', 'input', ',', 'map', 'express', 'mean', 'represent', 'languag', '(', 'mrl', ')', ';', 'reason', 'interpret', 'determin', 'content', 'produc', 'respons', 'user', ',', 'perhap', 'access', 'inform', 'databas', ',', 'expert', 'system', ',', 'etc', ':', 'final', ',', 'gener', 'respons', ',', 'perhap', 'natural-languag', 'utter', 'text', '.']

 TOTAL PORTER STEM WORDS ==> 54



 ---- SNOWBALL STEMMING ----

['success', 'limit', 'thus', 'far', 'nlp', 'system', 'perform', 'three', 'relat', 'function', ':', 'analysi', '(', 'interpret', ')', 'input', ',', 'map', 'express', 'mean', 'represent', 'languag', '(', 'mrl', ')', ';', 'reason', 'interpret', 'determin', 'content', 'produc', 'respons', 'user', ',', 'perhap', 'access', 'inform', 'databas', ',', 'expert', 'system', ',', 'etc', ':', 'final', ',', 'generat', 'respons', ',', 'perhap', 'natural-languag', 'utter', 'text', '.']

 TOTAL SNOWBALL STEM WORDS ==> 54



 ---- LEMMATIZATION ----

['Success', 'Limitations', 'Thus', 'Far', 'NLP', 'system', 'perform', 'three', 'related', 'function', ':', 'analysis', '(', 'interpretation', ')', 'input', ',', 'mapping', 'expression', 'meaning', 'representation', 'language', '(', 'MRL', ')', ';', 'reasoning', 'interpretation', 'determine', 'content', 'produced', 'response', 'user', ',', 'perhaps', 'accessing', 'information', 'database', ',', 'expert', 'system', ',', 'etc', ':', 'finally', ',', 'generation', 'response', ',', 'perhaps', 'natural-language', 'utterance', 'text', '.']

 TOTAL LEMMATIZE WORDS ==> 54

************************************************************************************************************************

34 --> In translation  systems, the "response"  is in a language different from the input language. 


 ---- TOKENS ----

 ['In', 'translation', 'systems', ',', 'the', '``', 'response', "''", 'is', 'in', 'a', 'language', 'different', 'from', 'the', 'input', 'language', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('In', 'IN'), ('translation', 'NN'), ('systems', 'NNS'), (',', ','), ('the', 'DT'), ('``', '``'), ('response', 'NN'), ("''", "''"), ('is', 'VBZ'), ('in', 'IN'), ('a', 'DT'), ('language', 'NN'), ('different', 'JJ'), ('from', 'IN'), ('the', 'DT'), ('input', 'NN'), ('language', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['translation', 'systems', ',', '``', 'response', "''", 'language', 'different', 'input', 'language', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('translation', 'NN'), ('systems', 'NNS'), (',', ','), ('``', '``'), ('response', 'NN'), ("''", "''"), ('language', 'NN'), ('different', 'JJ'), ('input', 'NN'), ('language', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['translation systems', 'systems ,', ', ``', '`` response', "response ''", "'' language", 'language different', 'different input', 'input language', 'language .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['translation systems ,', 'systems , ``', ', `` response', "`` response ''", "response '' language", "'' language different", 'language different input', 'different input language', 'input language .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['translation', 'response', 'language', 'different input', 'language'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['translat', 'system', ',', '``', 'respons', "''", 'languag', 'differ', 'input', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['translat', 'system', ',', '``', 'respons', "''", 'languag', 'differ', 'input', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['translation', 'system', ',', '``', 'response', "''", 'language', 'different', 'input', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

35 --> The most visible results in NLP in the last five years are several commercially available systems for  database question-answering. 


 ---- TOKENS ----

 ['The', 'most', 'visible', 'results', 'in', 'NLP', 'in', 'the', 'last', 'five', 'years', 'are', 'several', 'commercially', 'available', 'systems', 'for', 'database', 'question-answering', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('The', 'DT'), ('most', 'RBS'), ('visible', 'JJ'), ('results', 'NNS'), ('in', 'IN'), ('NLP', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('five', 'CD'), ('years', 'NNS'), ('are', 'VBP'), ('several', 'JJ'), ('commercially', 'RB'), ('available', 'JJ'), ('systems', 'NNS'), ('for', 'IN'), ('database', 'NN'), ('question-answering', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['visible', 'results', 'NLP', 'last', 'five', 'years', 'several', 'commercially', 'available', 'systems', 'database', 'question-answering', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('visible', 'JJ'), ('results', 'NNS'), ('NLP', 'NNP'), ('last', 'JJ'), ('five', 'CD'), ('years', 'NNS'), ('several', 'JJ'), ('commercially', 'RB'), ('available', 'JJ'), ('systems', 'NNS'), ('database', 'VBD'), ('question-answering', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['visible results', 'results NLP', 'NLP last', 'last five', 'five years', 'years several', 'several commercially', 'commercially available', 'available systems', 'systems database', 'database question-answering', 'question-answering .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['visible results NLP', 'results NLP last', 'NLP last five', 'last five years', 'five years several', 'years several commercially', 'several commercially available', 'commercially available systems', 'available systems database', 'systems database question-answering', 'database question-answering .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['visibl', 'result', 'nlp', 'last', 'five', 'year', 'sever', 'commerci', 'avail', 'system', 'databas', 'question-answ', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['visibl', 'result', 'nlp', 'last', 'five', 'year', 'sever', 'commerci', 'avail', 'system', 'databas', 'question-answ', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['visible', 'result', 'NLP', 'last', 'five', 'year', 'several', 'commercially', 'available', 'system', 'database', 'question-answering', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

36 --> These systems, the result of transferring technology developed in the 1970s and early  1980s, have been successfully used to improve productivity by replacing fourth-generation database query  languages. 


 ---- TOKENS ----

 ['These', 'systems', ',', 'the', 'result', 'of', 'transferring', 'technology', 'developed', 'in', 'the', '1970s', 'and', 'early', '1980s', ',', 'have', 'been', 'successfully', 'used', 'to', 'improve', 'productivity', 'by', 'replacing', 'fourth-generation', 'database', 'query', 'languages', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('These', 'DT'), ('systems', 'NNS'), (',', ','), ('the', 'DT'), ('result', 'NN'), ('of', 'IN'), ('transferring', 'VBG'), ('technology', 'NN'), ('developed', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('1970s', 'CD'), ('and', 'CC'), ('early', 'RB'), ('1980s', 'CD'), (',', ','), ('have', 'VBP'), ('been', 'VBN'), ('successfully', 'RB'), ('used', 'VBN'), ('to', 'TO'), ('improve', 'VB'), ('productivity', 'NN'), ('by', 'IN'), ('replacing', 'VBG'), ('fourth-generation', 'JJ'), ('database', 'NN'), ('query', 'NN'), ('languages', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['systems', ',', 'result', 'transferring', 'technology', 'developed', '1970s', 'early', '1980s', ',', 'successfully', 'used', 'improve', 'productivity', 'replacing', 'fourth-generation', 'database', 'query', 'languages', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('systems', 'NNS'), (',', ','), ('result', 'NN'), ('transferring', 'VBG'), ('technology', 'NN'), ('developed', 'VBD'), ('1970s', 'CD'), ('early', 'JJ'), ('1980s', 'CD'), (',', ','), ('successfully', 'RB'), ('used', 'VBN'), ('improve', 'VB'), ('productivity', 'NN'), ('replacing', 'VBG'), ('fourth-generation', 'NN'), ('database', 'NN'), ('query', 'NN'), ('languages', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['systems ,', ', result', 'result transferring', 'transferring technology', 'technology developed', 'developed 1970s', '1970s early', 'early 1980s', '1980s ,', ', successfully', 'successfully used', 'used improve', 'improve productivity', 'productivity replacing', 'replacing fourth-generation', 'fourth-generation database', 'database query', 'query languages', 'languages .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['systems , result', ', result transferring', 'result transferring technology', 'transferring technology developed', 'technology developed 1970s', 'developed 1970s early', '1970s early 1980s', 'early 1980s ,', '1980s , successfully', ', successfully used', 'successfully used improve', 'used improve productivity', 'improve productivity replacing', 'productivity replacing fourth-generation', 'replacing fourth-generation database', 'fourth-generation database query', 'database query languages', 'query languages .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['result', 'technology', 'productivity', 'fourth-generation', 'database', 'query'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['system', ',', 'result', 'transfer', 'technolog', 'develop', '1970', 'earli', '1980', ',', 'success', 'use', 'improv', 'product', 'replac', 'fourth-gener', 'databas', 'queri', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['system', ',', 'result', 'transfer', 'technolog', 'develop', '1970s', 'earli', '1980s', ',', 'success', 'use', 'improv', 'product', 'replac', 'fourth-gener', 'databas', 'queri', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['system', ',', 'result', 'transferring', 'technology', 'developed', '1970s', 'early', '1980s', ',', 'successfully', 'used', 'improve', 'productivity', 'replacing', 'fourth-generation', 'database', 'query', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

37 --> The following case study illustrates their capabilities: with 8 person weeks, one of these systems was  ported to a Navy relational database of 666 fields (from 75 relations) with a vocabulary of over 6,000 (root) words. 


 ---- TOKENS ----

 ['The', 'following', 'case', 'study', 'illustrates', 'their', 'capabilities', ':', 'with', '8', 'person', 'weeks', ',', 'one', 'of', 'these', 'systems', 'was', 'ported', 'to', 'a', 'Navy', 'relational', 'database', 'of', '666', 'fields', '(', 'from', '75', 'relations', ')', 'with', 'a', 'vocabulary', 'of', 'over', '6,000', '(', 'root', ')', 'words', '.'] 

 TOTAL TOKENS ==> 43

 ---- POST ----

 [('The', 'DT'), ('following', 'JJ'), ('case', 'NN'), ('study', 'NN'), ('illustrates', 'VBZ'), ('their', 'PRP$'), ('capabilities', 'NNS'), (':', ':'), ('with', 'IN'), ('8', 'CD'), ('person', 'NN'), ('weeks', 'NNS'), (',', ','), ('one', 'CD'), ('of', 'IN'), ('these', 'DT'), ('systems', 'NNS'), ('was', 'VBD'), ('ported', 'VBN'), ('to', 'TO'), ('a', 'DT'), ('Navy', 'NNP'), ('relational', 'JJ'), ('database', 'NN'), ('of', 'IN'), ('666', 'CD'), ('fields', 'NNS'), ('(', '('), ('from', 'IN'), ('75', 'CD'), ('relations', 'NNS'), (')', ')'), ('with', 'IN'), ('a', 'DT'), ('vocabulary', 'NN'), ('of', 'IN'), ('over', 'IN'), ('6,000', 'CD'), ('(', '('), ('root', 'NN'), (')', ')'), ('words', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['following', 'case', 'study', 'illustrates', 'capabilities', ':', '8', 'person', 'weeks', ',', 'one', 'systems', 'ported', 'Navy', 'relational', 'database', '666', 'fields', '(', '75', 'relations', ')', 'vocabulary', '6,000', '(', 'root', ')', 'words', '.']

 TOTAL FILTERED TOKENS ==>  29

 ---- POST FOR FILTERED TOKENS ----

 [('following', 'VBG'), ('case', 'NN'), ('study', 'NN'), ('illustrates', 'VBZ'), ('capabilities', 'NNS'), (':', ':'), ('8', 'CD'), ('person', 'NN'), ('weeks', 'NNS'), (',', ','), ('one', 'CD'), ('systems', 'NNS'), ('ported', 'VBN'), ('Navy', 'NNP'), ('relational', 'JJ'), ('database', 'NN'), ('666', 'CD'), ('fields', 'NNS'), ('(', '('), ('75', 'CD'), ('relations', 'NNS'), (')', ')'), ('vocabulary', 'VBP'), ('6,000', 'CD'), ('(', '('), ('root', 'NN'), (')', ')'), ('words', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['following case', 'case study', 'study illustrates', 'illustrates capabilities', 'capabilities :', ': 8', '8 person', 'person weeks', 'weeks ,', ', one', 'one systems', 'systems ported', 'ported Navy', 'Navy relational', 'relational database', 'database 666', '666 fields', 'fields (', '( 75', '75 relations', 'relations )', ') vocabulary', 'vocabulary 6,000', '6,000 (', '( root', 'root )', ') words', 'words .'] 

 TOTAL BIGRAMS --> 28 



 ---- TRI-GRAMS ---- 

 ['following case study', 'case study illustrates', 'study illustrates capabilities', 'illustrates capabilities :', 'capabilities : 8', ': 8 person', '8 person weeks', 'person weeks ,', 'weeks , one', ', one systems', 'one systems ported', 'systems ported Navy', 'ported Navy relational', 'Navy relational database', 'relational database 666', 'database 666 fields', '666 fields (', 'fields ( 75', '( 75 relations', '75 relations )', 'relations ) vocabulary', ') vocabulary 6,000', 'vocabulary 6,000 (', '6,000 ( root', '( root )', 'root ) words', ') words .'] 

 TOTAL TRIGRAMS --> 27 



 ---- NOUN PHRASES ---- 

 ['case', 'study', 'person', 'relational database'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Navy']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['follow', 'case', 'studi', 'illustr', 'capabl', ':', '8', 'person', 'week', ',', 'one', 'system', 'port', 'navi', 'relat', 'databas', '666', 'field', '(', '75', 'relat', ')', 'vocabulari', '6,000', '(', 'root', ')', 'word', '.']

 TOTAL PORTER STEM WORDS ==> 29



 ---- SNOWBALL STEMMING ----

['follow', 'case', 'studi', 'illustr', 'capabl', ':', '8', 'person', 'week', ',', 'one', 'system', 'port', 'navi', 'relat', 'databas', '666', 'field', '(', '75', 'relat', ')', 'vocabulari', '6,000', '(', 'root', ')', 'word', '.']

 TOTAL SNOWBALL STEM WORDS ==> 29



 ---- LEMMATIZATION ----

['following', 'case', 'study', 'illustrates', 'capability', ':', '8', 'person', 'week', ',', 'one', 'system', 'ported', 'Navy', 'relational', 'database', '666', 'field', '(', '75', 'relation', ')', 'vocabulary', '6,000', '(', 'root', ')', 'word', '.']

 TOTAL LEMMATIZE WORDS ==> 29

************************************************************************************************************************

38 --> 482   Queries from a new user of one of these systems are estimated to succeed 60 to 80% of the time; with use of the  system users naturally and automatically adjust to the data that is in the database and to the limits of the language  understood by the system, giving a success rate of 80 to 95%, depending on the individual. 


 ---- TOKENS ----

 ['482', 'Queries', 'from', 'a', 'new', 'user', 'of', 'one', 'of', 'these', 'systems', 'are', 'estimated', 'to', 'succeed', '60', 'to', '80', '%', 'of', 'the', 'time', ';', 'with', 'use', 'of', 'the', 'system', 'users', 'naturally', 'and', 'automatically', 'adjust', 'to', 'the', 'data', 'that', 'is', 'in', 'the', 'database', 'and', 'to', 'the', 'limits', 'of', 'the', 'language', 'understood', 'by', 'the', 'system', ',', 'giving', 'a', 'success', 'rate', 'of', '80', 'to', '95', '%', ',', 'depending', 'on', 'the', 'individual', '.'] 

 TOTAL TOKENS ==> 68

 ---- POST ----

 [('482', 'CD'), ('Queries', 'NNS'), ('from', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('user', 'NN'), ('of', 'IN'), ('one', 'CD'), ('of', 'IN'), ('these', 'DT'), ('systems', 'NNS'), ('are', 'VBP'), ('estimated', 'VBN'), ('to', 'TO'), ('succeed', 'VB'), ('60', 'CD'), ('to', 'TO'), ('80', 'CD'), ('%', 'NN'), ('of', 'IN'), ('the', 'DT'), ('time', 'NN'), (';', ':'), ('with', 'IN'), ('use', 'NN'), ('of', 'IN'), ('the', 'DT'), ('system', 'NN'), ('users', 'NNS'), ('naturally', 'RB'), ('and', 'CC'), ('automatically', 'RB'), ('adjust', 'VBP'), ('to', 'TO'), ('the', 'DT'), ('data', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('in', 'IN'), ('the', 'DT'), ('database', 'NN'), ('and', 'CC'), ('to', 'TO'), ('the', 'DT'), ('limits', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('language', 'NN'), ('understood', 'NN'), ('by', 'IN'), ('the', 'DT'), ('system', 'NN'), (',', ','), ('giving', 'VBG'), ('a', 'DT'), ('success', 'NN'), ('rate', 'NN'), ('of', 'IN'), ('80', 'CD'), ('to', 'TO'), ('95', 'CD'), ('%', 'NN'), (',', ','), ('depending', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('individual', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['482', 'Queries', 'new', 'user', 'one', 'systems', 'estimated', 'succeed', '60', '80', '%', 'time', ';', 'use', 'system', 'users', 'naturally', 'automatically', 'adjust', 'data', 'database', 'limits', 'language', 'understood', 'system', ',', 'giving', 'success', 'rate', '80', '95', '%', ',', 'depending', 'individual', '.']

 TOTAL FILTERED TOKENS ==>  36

 ---- POST FOR FILTERED TOKENS ----

 [('482', 'CD'), ('Queries', 'NNS'), ('new', 'JJ'), ('user', 'JJ'), ('one', 'CD'), ('systems', 'NNS'), ('estimated', 'VBN'), ('succeed', 'VB'), ('60', 'CD'), ('80', 'CD'), ('%', 'NN'), ('time', 'NN'), (';', ':'), ('use', 'NN'), ('system', 'NN'), ('users', 'NNS'), ('naturally', 'RB'), ('automatically', 'RB'), ('adjust', 'JJ'), ('data', 'NNS'), ('database', 'NN'), ('limits', 'NNS'), ('language', 'NN'), ('understood', 'NN'), ('system', 'NN'), (',', ','), ('giving', 'VBG'), ('success', 'NN'), ('rate', 'NN'), ('80', 'CD'), ('95', 'CD'), ('%', 'NN'), (',', ','), ('depending', 'VBG'), ('individual', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['482 Queries', 'Queries new', 'new user', 'user one', 'one systems', 'systems estimated', 'estimated succeed', 'succeed 60', '60 80', '80 %', '% time', 'time ;', '; use', 'use system', 'system users', 'users naturally', 'naturally automatically', 'automatically adjust', 'adjust data', 'data database', 'database limits', 'limits language', 'language understood', 'understood system', 'system ,', ', giving', 'giving success', 'success rate', 'rate 80', '80 95', '95 %', '% ,', ', depending', 'depending individual', 'individual .'] 

 TOTAL BIGRAMS --> 35 



 ---- TRI-GRAMS ---- 

 ['482 Queries new', 'Queries new user', 'new user one', 'user one systems', 'one systems estimated', 'systems estimated succeed', 'estimated succeed 60', 'succeed 60 80', '60 80 %', '80 % time', '% time ;', 'time ; use', '; use system', 'use system users', 'system users naturally', 'users naturally automatically', 'naturally automatically adjust', 'automatically adjust data', 'adjust data database', 'data database limits', 'database limits language', 'limits language understood', 'language understood system', 'understood system ,', 'system , giving', ', giving success', 'giving success rate', 'success rate 80', 'rate 80 95', '80 95 %', '95 % ,', '% , depending', ', depending individual', 'depending individual .'] 

 TOTAL TRIGRAMS --> 34 



 ---- NOUN PHRASES ---- 

 ['%', 'time', 'use', 'system', 'database', 'language', 'understood', 'system', 'success', 'rate', '%'] 

 TOTAL NOUN PHRASES --> 11 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['482', 'queri', 'new', 'user', 'one', 'system', 'estim', 'succeed', '60', '80', '%', 'time', ';', 'use', 'system', 'user', 'natur', 'automat', 'adjust', 'data', 'databas', 'limit', 'languag', 'understood', 'system', ',', 'give', 'success', 'rate', '80', '95', '%', ',', 'depend', 'individu', '.']

 TOTAL PORTER STEM WORDS ==> 36



 ---- SNOWBALL STEMMING ----

['482', 'queri', 'new', 'user', 'one', 'system', 'estim', 'succeed', '60', '80', '%', 'time', ';', 'use', 'system', 'user', 'natur', 'automat', 'adjust', 'data', 'databas', 'limit', 'languag', 'understood', 'system', ',', 'give', 'success', 'rate', '80', '95', '%', ',', 'depend', 'individu', '.']

 TOTAL SNOWBALL STEM WORDS ==> 36



 ---- LEMMATIZATION ----

['482', 'Queries', 'new', 'user', 'one', 'system', 'estimated', 'succeed', '60', '80', '%', 'time', ';', 'use', 'system', 'user', 'naturally', 'automatically', 'adjust', 'data', 'database', 'limit', 'language', 'understood', 'system', ',', 'giving', 'success', 'rate', '80', '95', '%', ',', 'depending', 'individual', '.']

 TOTAL LEMMATIZE WORDS ==> 36

************************************************************************************************************************

39 --> The success of these systems has depended on the fact that sufficient coverage of the language is possible  with relatively simple semantic and discourse models. 


 ---- TOKENS ----

 ['The', 'success', 'of', 'these', 'systems', 'has', 'depended', 'on', 'the', 'fact', 'that', 'sufficient', 'coverage', 'of', 'the', 'language', 'is', 'possible', 'with', 'relatively', 'simple', 'semantic', 'and', 'discourse', 'models', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('The', 'DT'), ('success', 'NN'), ('of', 'IN'), ('these', 'DT'), ('systems', 'NNS'), ('has', 'VBZ'), ('depended', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('fact', 'NN'), ('that', 'IN'), ('sufficient', 'JJ'), ('coverage', 'NN'), ('of', 'IN'), ('the', 'DT'), ('language', 'NN'), ('is', 'VBZ'), ('possible', 'JJ'), ('with', 'IN'), ('relatively', 'RB'), ('simple', 'JJ'), ('semantic', 'JJ'), ('and', 'CC'), ('discourse', 'JJ'), ('models', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['success', 'systems', 'depended', 'fact', 'sufficient', 'coverage', 'language', 'possible', 'relatively', 'simple', 'semantic', 'discourse', 'models', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('success', 'NN'), ('systems', 'NNS'), ('depended', 'VBD'), ('fact', 'NN'), ('sufficient', 'JJ'), ('coverage', 'NN'), ('language', 'NN'), ('possible', 'JJ'), ('relatively', 'RB'), ('simple', 'JJ'), ('semantic', 'JJ'), ('discourse', 'NN'), ('models', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['success systems', 'systems depended', 'depended fact', 'fact sufficient', 'sufficient coverage', 'coverage language', 'language possible', 'possible relatively', 'relatively simple', 'simple semantic', 'semantic discourse', 'discourse models', 'models .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['success systems depended', 'systems depended fact', 'depended fact sufficient', 'fact sufficient coverage', 'sufficient coverage language', 'coverage language possible', 'language possible relatively', 'possible relatively simple', 'relatively simple semantic', 'simple semantic discourse', 'semantic discourse models', 'discourse models .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['success', 'fact', 'sufficient coverage', 'language', 'simple semantic discourse'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['success', 'system', 'depend', 'fact', 'suffici', 'coverag', 'languag', 'possibl', 'rel', 'simpl', 'semant', 'discours', 'model', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['success', 'system', 'depend', 'fact', 'suffici', 'coverag', 'languag', 'possibl', 'relat', 'simpl', 'semant', 'discours', 'model', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['success', 'system', 'depended', 'fact', 'sufficient', 'coverage', 'language', 'possible', 'relatively', 'simple', 'semantic', 'discourse', 'model', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

40 --> The semantics are bounded by the semantics of the relations  used in databases and the fact that words have a restricted number of meanings in one domain. 


 ---- TOKENS ----

 ['The', 'semantics', 'are', 'bounded', 'by', 'the', 'semantics', 'of', 'the', 'relations', 'used', 'in', 'databases', 'and', 'the', 'fact', 'that', 'words', 'have', 'a', 'restricted', 'number', 'of', 'meanings', 'in', 'one', 'domain', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('The', 'DT'), ('semantics', 'NNS'), ('are', 'VBP'), ('bounded', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('semantics', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('relations', 'NNS'), ('used', 'VBN'), ('in', 'IN'), ('databases', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('fact', 'NN'), ('that', 'IN'), ('words', 'NNS'), ('have', 'VBP'), ('a', 'DT'), ('restricted', 'JJ'), ('number', 'NN'), ('of', 'IN'), ('meanings', 'NNS'), ('in', 'IN'), ('one', 'CD'), ('domain', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['semantics', 'bounded', 'semantics', 'relations', 'used', 'databases', 'fact', 'words', 'restricted', 'number', 'meanings', 'one', 'domain', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('semantics', 'NNS'), ('bounded', 'VBD'), ('semantics', 'NNS'), ('relations', 'NNS'), ('used', 'VBN'), ('databases', 'NNS'), ('fact', 'NN'), ('words', 'NNS'), ('restricted', 'VBN'), ('number', 'NN'), ('meanings', 'NNS'), ('one', 'CD'), ('domain', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['semantics bounded', 'bounded semantics', 'semantics relations', 'relations used', 'used databases', 'databases fact', 'fact words', 'words restricted', 'restricted number', 'number meanings', 'meanings one', 'one domain', 'domain .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['semantics bounded semantics', 'bounded semantics relations', 'semantics relations used', 'relations used databases', 'used databases fact', 'databases fact words', 'fact words restricted', 'words restricted number', 'restricted number meanings', 'number meanings one', 'meanings one domain', 'one domain .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['fact', 'number', 'domain'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['semant', 'bound', 'semant', 'relat', 'use', 'databas', 'fact', 'word', 'restrict', 'number', 'mean', 'one', 'domain', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['semant', 'bound', 'semant', 'relat', 'use', 'databas', 'fact', 'word', 'restrict', 'number', 'mean', 'one', 'domain', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['semantics', 'bounded', 'semantics', 'relation', 'used', 'database', 'fact', 'word', 'restricted', 'number', 'meaning', 'one', 'domain', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

41 --> The discourse model  for a query is usually limited to the table output of the previous answer and the noun phrases mentioned in the last  few queries. 


 ---- TOKENS ----

 ['The', 'discourse', 'model', 'for', 'a', 'query', 'is', 'usually', 'limited', 'to', 'the', 'table', 'output', 'of', 'the', 'previous', 'answer', 'and', 'the', 'noun', 'phrases', 'mentioned', 'in', 'the', 'last', 'few', 'queries', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('The', 'DT'), ('discourse', 'NN'), ('model', 'NN'), ('for', 'IN'), ('a', 'DT'), ('query', 'NN'), ('is', 'VBZ'), ('usually', 'RB'), ('limited', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('table', 'NN'), ('output', 'NN'), ('of', 'IN'), ('the', 'DT'), ('previous', 'JJ'), ('answer', 'NN'), ('and', 'CC'), ('the', 'DT'), ('noun', 'JJ'), ('phrases', 'NNS'), ('mentioned', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('few', 'JJ'), ('queries', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['discourse', 'model', 'query', 'usually', 'limited', 'table', 'output', 'previous', 'answer', 'noun', 'phrases', 'mentioned', 'last', 'queries', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('discourse', 'NN'), ('model', 'NN'), ('query', 'NN'), ('usually', 'RB'), ('limited', 'VBD'), ('table', 'JJ'), ('output', 'NN'), ('previous', 'JJ'), ('answer', 'NN'), ('noun', 'NN'), ('phrases', 'NNS'), ('mentioned', 'VBD'), ('last', 'JJ'), ('queries', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['discourse model', 'model query', 'query usually', 'usually limited', 'limited table', 'table output', 'output previous', 'previous answer', 'answer noun', 'noun phrases', 'phrases mentioned', 'mentioned last', 'last queries', 'queries .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['discourse model query', 'model query usually', 'query usually limited', 'usually limited table', 'limited table output', 'table output previous', 'output previous answer', 'previous answer noun', 'answer noun phrases', 'noun phrases mentioned', 'phrases mentioned last', 'mentioned last queries', 'last queries .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['discourse', 'model', 'query', 'table output', 'previous answer', 'noun'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['discours', 'model', 'queri', 'usual', 'limit', 'tabl', 'output', 'previou', 'answer', 'noun', 'phrase', 'mention', 'last', 'queri', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['discours', 'model', 'queri', 'usual', 'limit', 'tabl', 'output', 'previous', 'answer', 'noun', 'phrase', 'mention', 'last', 'queri', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['discourse', 'model', 'query', 'usually', 'limited', 'table', 'output', 'previous', 'answer', 'noun', 'phrase', 'mentioned', 'last', 'query', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

42 --> The limitations of today's practical language processing technology are summarized as follows:  • Domains must be narrow enough that the constraints on the relevant semantic concepts and relations  can be expressed using current knowledge representation techniques, primarily in terms of types and  sorts. 


 ---- TOKENS ----

 ['The', 'limitations', 'of', 'today', "'s", 'practical', 'language', 'processing', 'technology', 'are', 'summarized', 'as', 'follows', ':', '•', 'Domains', 'must', 'be', 'narrow', 'enough', 'that', 'the', 'constraints', 'on', 'the', 'relevant', 'semantic', 'concepts', 'and', 'relations', 'can', 'be', 'expressed', 'using', 'current', 'knowledge', 'representation', 'techniques', ',', 'primarily', 'in', 'terms', 'of', 'types', 'and', 'sorts', '.'] 

 TOTAL TOKENS ==> 47

 ---- POST ----

 [('The', 'DT'), ('limitations', 'NNS'), ('of', 'IN'), ('today', 'NN'), ("'s", 'POS'), ('practical', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('technology', 'NN'), ('are', 'VBP'), ('summarized', 'VBN'), ('as', 'IN'), ('follows', 'VBZ'), (':', ':'), ('•', 'NN'), ('Domains', 'VBZ'), ('must', 'MD'), ('be', 'VB'), ('narrow', 'JJ'), ('enough', 'RB'), ('that', 'IN'), ('the', 'DT'), ('constraints', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('relevant', 'JJ'), ('semantic', 'JJ'), ('concepts', 'NNS'), ('and', 'CC'), ('relations', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('expressed', 'VBN'), ('using', 'VBG'), ('current', 'JJ'), ('knowledge', 'NN'), ('representation', 'NN'), ('techniques', 'NNS'), (',', ','), ('primarily', 'RB'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('types', 'NNS'), ('and', 'CC'), ('sorts', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['limitations', 'today', "'s", 'practical', 'language', 'processing', 'technology', 'summarized', 'follows', ':', '•', 'Domains', 'must', 'narrow', 'enough', 'constraints', 'relevant', 'semantic', 'concepts', 'relations', 'expressed', 'using', 'current', 'knowledge', 'representation', 'techniques', ',', 'primarily', 'terms', 'types', 'sorts', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('limitations', 'NNS'), ('today', 'NN'), ("'s", 'POS'), ('practical', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('technology', 'NN'), ('summarized', 'VBN'), ('follows', 'VBZ'), (':', ':'), ('•', 'NN'), ('Domains', 'VBZ'), ('must', 'MD'), ('narrow', 'VB'), ('enough', 'JJ'), ('constraints', 'NNS'), ('relevant', 'JJ'), ('semantic', 'JJ'), ('concepts', 'NNS'), ('relations', 'NNS'), ('expressed', 'VBD'), ('using', 'VBG'), ('current', 'JJ'), ('knowledge', 'NN'), ('representation', 'NN'), ('techniques', 'NNS'), (',', ','), ('primarily', 'RB'), ('terms', 'NNS'), ('types', 'NNS'), ('sorts', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['limitations today', "today 's", "'s practical", 'practical language', 'language processing', 'processing technology', 'technology summarized', 'summarized follows', 'follows :', ': •', '• Domains', 'Domains must', 'must narrow', 'narrow enough', 'enough constraints', 'constraints relevant', 'relevant semantic', 'semantic concepts', 'concepts relations', 'relations expressed', 'expressed using', 'using current', 'current knowledge', 'knowledge representation', 'representation techniques', 'techniques ,', ', primarily', 'primarily terms', 'terms types', 'types sorts', 'sorts .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ["limitations today 's", "today 's practical", "'s practical language", 'practical language processing', 'language processing technology', 'processing technology summarized', 'technology summarized follows', 'summarized follows :', 'follows : •', ': • Domains', '• Domains must', 'Domains must narrow', 'must narrow enough', 'narrow enough constraints', 'enough constraints relevant', 'constraints relevant semantic', 'relevant semantic concepts', 'semantic concepts relations', 'concepts relations expressed', 'relations expressed using', 'expressed using current', 'using current knowledge', 'current knowledge representation', 'knowledge representation techniques', 'representation techniques ,', 'techniques , primarily', ', primarily terms', 'primarily terms types', 'terms types sorts', 'types sorts .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['today', 'practical language', 'processing', 'technology', '•', 'current knowledge', 'representation'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['limit', 'today', "'s", 'practic', 'languag', 'process', 'technolog', 'summar', 'follow', ':', '•', 'domain', 'must', 'narrow', 'enough', 'constraint', 'relev', 'semant', 'concept', 'relat', 'express', 'use', 'current', 'knowledg', 'represent', 'techniqu', ',', 'primarili', 'term', 'type', 'sort', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['limit', 'today', "'s", 'practic', 'languag', 'process', 'technolog', 'summar', 'follow', ':', '•', 'domain', 'must', 'narrow', 'enough', 'constraint', 'relev', 'semant', 'concept', 'relat', 'express', 'use', 'current', 'knowledg', 'represent', 'techniqu', ',', 'primarili', 'term', 'type', 'sort', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['limitation', 'today', "'s", 'practical', 'language', 'processing', 'technology', 'summarized', 'follows', ':', '•', 'Domains', 'must', 'narrow', 'enough', 'constraint', 'relevant', 'semantic', 'concept', 'relation', 'expressed', 'using', 'current', 'knowledge', 'representation', 'technique', ',', 'primarily', 'term', 'type', 'sort', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

43 --> Processing may be viewed abstractly as the application of recursive tree rewriting rules, including  filtering out trees not matching a certain pattern. 


 ---- TOKENS ----

 ['Processing', 'may', 'be', 'viewed', 'abstractly', 'as', 'the', 'application', 'of', 'recursive', 'tree', 'rewriting', 'rules', ',', 'including', 'filtering', 'out', 'trees', 'not', 'matching', 'a', 'certain', 'pattern', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Processing', 'NN'), ('may', 'MD'), ('be', 'VB'), ('viewed', 'VBN'), ('abstractly', 'RB'), ('as', 'IN'), ('the', 'DT'), ('application', 'NN'), ('of', 'IN'), ('recursive', 'JJ'), ('tree', 'NN'), ('rewriting', 'NN'), ('rules', 'NNS'), (',', ','), ('including', 'VBG'), ('filtering', 'VBG'), ('out', 'RP'), ('trees', 'NNS'), ('not', 'RB'), ('matching', 'VBG'), ('a', 'DT'), ('certain', 'JJ'), ('pattern', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Processing', 'may', 'viewed', 'abstractly', 'application', 'recursive', 'tree', 'rewriting', 'rules', ',', 'including', 'filtering', 'trees', 'matching', 'certain', 'pattern', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Processing', 'NN'), ('may', 'MD'), ('viewed', 'VB'), ('abstractly', 'RB'), ('application', 'JJ'), ('recursive', 'JJ'), ('tree', 'NN'), ('rewriting', 'NN'), ('rules', 'NNS'), (',', ','), ('including', 'VBG'), ('filtering', 'VBG'), ('trees', 'NNS'), ('matching', 'VBG'), ('certain', 'JJ'), ('pattern', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Processing may', 'may viewed', 'viewed abstractly', 'abstractly application', 'application recursive', 'recursive tree', 'tree rewriting', 'rewriting rules', 'rules ,', ', including', 'including filtering', 'filtering trees', 'trees matching', 'matching certain', 'certain pattern', 'pattern .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Processing may viewed', 'may viewed abstractly', 'viewed abstractly application', 'abstractly application recursive', 'application recursive tree', 'recursive tree rewriting', 'tree rewriting rules', 'rewriting rules ,', 'rules , including', ', including filtering', 'including filtering trees', 'filtering trees matching', 'trees matching certain', 'matching certain pattern', 'certain pattern .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['Processing', 'application recursive tree', 'rewriting', 'certain pattern'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['process', 'may', 'view', 'abstractli', 'applic', 'recurs', 'tree', 'rewrit', 'rule', ',', 'includ', 'filter', 'tree', 'match', 'certain', 'pattern', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['process', 'may', 'view', 'abstract', 'applic', 'recurs', 'tree', 'rewrit', 'rule', ',', 'includ', 'filter', 'tree', 'match', 'certain', 'pattern', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Processing', 'may', 'viewed', 'abstractly', 'application', 'recursive', 'tree', 'rewriting', 'rule', ',', 'including', 'filtering', 'tree', 'matching', 'certain', 'pattern', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

44 --> • Handcrafting is necessary, even in the grammatical components of systems, the component technology  that exhibits least dependence on the application domain. 


 ---- TOKENS ----

 ['•', 'Handcrafting', 'is', 'necessary', ',', 'even', 'in', 'the', 'grammatical', 'components', 'of', 'systems', ',', 'the', 'component', 'technology', 'that', 'exhibits', 'least', 'dependence', 'on', 'the', 'application', 'domain', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('•', 'NN'), ('Handcrafting', 'NNP'), ('is', 'VBZ'), ('necessary', 'JJ'), (',', ','), ('even', 'RB'), ('in', 'IN'), ('the', 'DT'), ('grammatical', 'JJ'), ('components', 'NNS'), ('of', 'IN'), ('systems', 'NNS'), (',', ','), ('the', 'DT'), ('component', 'NN'), ('technology', 'NN'), ('that', 'WDT'), ('exhibits', 'VBZ'), ('least', 'JJS'), ('dependence', 'NN'), ('on', 'IN'), ('the', 'DT'), ('application', 'NN'), ('domain', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Handcrafting', 'necessary', ',', 'even', 'grammatical', 'components', 'systems', ',', 'component', 'technology', 'exhibits', 'least', 'dependence', 'application', 'domain', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'NN'), ('Handcrafting', 'NNP'), ('necessary', 'JJ'), (',', ','), ('even', 'RB'), ('grammatical', 'JJ'), ('components', 'NNS'), ('systems', 'NNS'), (',', ','), ('component', 'JJ'), ('technology', 'NN'), ('exhibits', 'NNS'), ('least', 'JJS'), ('dependence', 'NN'), ('application', 'NN'), ('domain', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Handcrafting', 'Handcrafting necessary', 'necessary ,', ', even', 'even grammatical', 'grammatical components', 'components systems', 'systems ,', ', component', 'component technology', 'technology exhibits', 'exhibits least', 'least dependence', 'dependence application', 'application domain', 'domain .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['• Handcrafting necessary', 'Handcrafting necessary ,', 'necessary , even', ', even grammatical', 'even grammatical components', 'grammatical components systems', 'components systems ,', 'systems , component', ', component technology', 'component technology exhibits', 'technology exhibits least', 'exhibits least dependence', 'least dependence application', 'dependence application domain', 'application domain .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['•', 'component technology', 'dependence', 'application', 'domain'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'handcraft', 'necessari', ',', 'even', 'grammat', 'compon', 'system', ',', 'compon', 'technolog', 'exhibit', 'least', 'depend', 'applic', 'domain', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['•', 'handcraft', 'necessari', ',', 'even', 'grammat', 'compon', 'system', ',', 'compon', 'technolog', 'exhibit', 'least', 'depend', 'applic', 'domain', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['•', 'Handcrafting', 'necessary', ',', 'even', 'grammatical', 'component', 'system', ',', 'component', 'technology', 'exhibit', 'least', 'dependence', 'application', 'domain', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

45 --> Lexicons and axiomatizations of critical facts  must be developed for each domain, and these remain time-consuming tasks. 


 ---- TOKENS ----

 ['Lexicons', 'and', 'axiomatizations', 'of', 'critical', 'facts', 'must', 'be', 'developed', 'for', 'each', 'domain', ',', 'and', 'these', 'remain', 'time-consuming', 'tasks', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Lexicons', 'NNS'), ('and', 'CC'), ('axiomatizations', 'NNS'), ('of', 'IN'), ('critical', 'JJ'), ('facts', 'NNS'), ('must', 'MD'), ('be', 'VB'), ('developed', 'VBN'), ('for', 'IN'), ('each', 'DT'), ('domain', 'NN'), (',', ','), ('and', 'CC'), ('these', 'DT'), ('remain', 'VBP'), ('time-consuming', 'JJ'), ('tasks', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Lexicons', 'axiomatizations', 'critical', 'facts', 'must', 'developed', 'domain', ',', 'remain', 'time-consuming', 'tasks', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Lexicons', 'NNS'), ('axiomatizations', 'NNS'), ('critical', 'JJ'), ('facts', 'NNS'), ('must', 'MD'), ('developed', 'VB'), ('domain', 'NN'), (',', ','), ('remain', 'VBP'), ('time-consuming', 'JJ'), ('tasks', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Lexicons axiomatizations', 'axiomatizations critical', 'critical facts', 'facts must', 'must developed', 'developed domain', 'domain ,', ', remain', 'remain time-consuming', 'time-consuming tasks', 'tasks .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Lexicons axiomatizations critical', 'axiomatizations critical facts', 'critical facts must', 'facts must developed', 'must developed domain', 'developed domain ,', 'domain , remain', ', remain time-consuming', 'remain time-consuming tasks', 'time-consuming tasks .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['domain'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['lexicon', 'axiomat', 'critic', 'fact', 'must', 'develop', 'domain', ',', 'remain', 'time-consum', 'task', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['lexicon', 'axiomat', 'critic', 'fact', 'must', 'develop', 'domain', ',', 'remain', 'time-consum', 'task', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Lexicons', 'axiomatizations', 'critical', 'fact', 'must', 'developed', 'domain', ',', 'remain', 'time-consuming', 'task', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

46 --> • The user must still adapt to the machine, but, as the products testify, can do so effectively. 


 ---- TOKENS ----

 ['•', 'The', 'user', 'must', 'still', 'adapt', 'to', 'the', 'machine', ',', 'but', ',', 'as', 'the', 'products', 'testify', ',', 'can', 'do', 'so', 'effectively', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('•', 'IN'), ('The', 'DT'), ('user', 'NN'), ('must', 'MD'), ('still', 'RB'), ('adapt', 'VB'), ('to', 'TO'), ('the', 'DT'), ('machine', 'NN'), (',', ','), ('but', 'CC'), (',', ','), ('as', 'IN'), ('the', 'DT'), ('products', 'NNS'), ('testify', 'VBP'), (',', ','), ('can', 'MD'), ('do', 'VB'), ('so', 'RB'), ('effectively', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'user', 'must', 'still', 'adapt', 'machine', ',', ',', 'products', 'testify', ',', 'effectively', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('user', 'NN'), ('must', 'MD'), ('still', 'RB'), ('adapt', 'VB'), ('machine', 'NN'), (',', ','), (',', ','), ('products', 'NNS'), ('testify', 'VBP'), (',', ','), ('effectively', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• user', 'user must', 'must still', 'still adapt', 'adapt machine', 'machine ,', ', ,', ', products', 'products testify', 'testify ,', ', effectively', 'effectively .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['• user must', 'user must still', 'must still adapt', 'still adapt machine', 'adapt machine ,', 'machine , ,', ', , products', ', products testify', 'products testify ,', 'testify , effectively', ', effectively .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['• user', 'machine'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'user', 'must', 'still', 'adapt', 'machin', ',', ',', 'product', 'testifi', ',', 'effect', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['•', 'user', 'must', 'still', 'adapt', 'machin', ',', ',', 'product', 'testifi', ',', 'effect', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['•', 'user', 'must', 'still', 'adapt', 'machine', ',', ',', 'product', 'testify', ',', 'effectively', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

47 --> • Current systems have limited discourse capabilities which are almost exclusively handcrafted. 


 ---- TOKENS ----

 ['•', 'Current', 'systems', 'have', 'limited', 'discourse', 'capabilities', 'which', 'are', 'almost', 'exclusively', 'handcrafted', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('•', 'JJ'), ('Current', 'NNP'), ('systems', 'NNS'), ('have', 'VBP'), ('limited', 'VBN'), ('discourse', 'NN'), ('capabilities', 'NNS'), ('which', 'WDT'), ('are', 'VBP'), ('almost', 'RB'), ('exclusively', 'RB'), ('handcrafted', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Current', 'systems', 'limited', 'discourse', 'capabilities', 'almost', 'exclusively', 'handcrafted', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Current', 'NNP'), ('systems', 'NNS'), ('limited', 'VBD'), ('discourse', 'JJ'), ('capabilities', 'NNS'), ('almost', 'RB'), ('exclusively', 'RB'), ('handcrafted', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Current', 'Current systems', 'systems limited', 'limited discourse', 'discourse capabilities', 'capabilities almost', 'almost exclusively', 'exclusively handcrafted', 'handcrafted .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['• Current systems', 'Current systems limited', 'systems limited discourse', 'limited discourse capabilities', 'discourse capabilities almost', 'capabilities almost exclusively', 'almost exclusively handcrafted', 'exclusively handcrafted .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'current', 'system', 'limit', 'discours', 'capabl', 'almost', 'exclus', 'handcraft', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['•', 'current', 'system', 'limit', 'discours', 'capabl', 'almost', 'exclus', 'handcraft', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['•', 'Current', 'system', 'limited', 'discourse', 'capability', 'almost', 'exclusively', 'handcrafted', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

48 --> Thus  current systems are limited to viewing interaction, translation, and writing and reading text as  processing a sequence of rather isolated sentences. 


 ---- TOKENS ----

 ['Thus', 'current', 'systems', 'are', 'limited', 'to', 'viewing', 'interaction', ',', 'translation', ',', 'and', 'writing', 'and', 'reading', 'text', 'as', 'processing', 'a', 'sequence', 'of', 'rather', 'isolated', 'sentences', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Thus', 'RB'), ('current', 'JJ'), ('systems', 'NNS'), ('are', 'VBP'), ('limited', 'JJ'), ('to', 'TO'), ('viewing', 'VBG'), ('interaction', 'NN'), (',', ','), ('translation', 'NN'), (',', ','), ('and', 'CC'), ('writing', 'VBG'), ('and', 'CC'), ('reading', 'VBG'), ('text', 'NN'), ('as', 'IN'), ('processing', 'VBG'), ('a', 'DT'), ('sequence', 'NN'), ('of', 'IN'), ('rather', 'RB'), ('isolated', 'JJ'), ('sentences', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Thus', 'current', 'systems', 'limited', 'viewing', 'interaction', ',', 'translation', ',', 'writing', 'reading', 'text', 'processing', 'sequence', 'rather', 'isolated', 'sentences', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Thus', 'RB'), ('current', 'JJ'), ('systems', 'NNS'), ('limited', 'VBD'), ('viewing', 'VBG'), ('interaction', 'NN'), (',', ','), ('translation', 'NN'), (',', ','), ('writing', 'VBG'), ('reading', 'VBG'), ('text', 'NN'), ('processing', 'NN'), ('sequence', 'NN'), ('rather', 'RB'), ('isolated', 'JJ'), ('sentences', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Thus current', 'current systems', 'systems limited', 'limited viewing', 'viewing interaction', 'interaction ,', ', translation', 'translation ,', ', writing', 'writing reading', 'reading text', 'text processing', 'processing sequence', 'sequence rather', 'rather isolated', 'isolated sentences', 'sentences .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Thus current systems', 'current systems limited', 'systems limited viewing', 'limited viewing interaction', 'viewing interaction ,', 'interaction , translation', ', translation ,', 'translation , writing', ', writing reading', 'writing reading text', 'reading text processing', 'text processing sequence', 'processing sequence rather', 'sequence rather isolated', 'rather isolated sentences', 'isolated sentences .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['interaction', 'translation', 'text', 'processing', 'sequence'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['thu', 'current', 'system', 'limit', 'view', 'interact', ',', 'translat', ',', 'write', 'read', 'text', 'process', 'sequenc', 'rather', 'isol', 'sentenc', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['thus', 'current', 'system', 'limit', 'view', 'interact', ',', 'translat', ',', 'write', 'read', 'text', 'process', 'sequenc', 'rather', 'isol', 'sentenc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Thus', 'current', 'system', 'limited', 'viewing', 'interaction', ',', 'translation', ',', 'writing', 'reading', 'text', 'processing', 'sequence', 'rather', 'isolated', 'sentence', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

49 --> Consequently, the user must adapt to such limited  discourse. 


 ---- TOKENS ----

 ['Consequently', ',', 'the', 'user', 'must', 'adapt', 'to', 'such', 'limited', 'discourse', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Consequently', 'RB'), (',', ','), ('the', 'DT'), ('user', 'NN'), ('must', 'MD'), ('adapt', 'VB'), ('to', 'TO'), ('such', 'JJ'), ('limited', 'JJ'), ('discourse', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Consequently', ',', 'user', 'must', 'adapt', 'limited', 'discourse', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Consequently', 'RB'), (',', ','), ('user', 'PRP'), ('must', 'MD'), ('adapt', 'VB'), ('limited', 'JJ'), ('discourse', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Consequently ,', ', user', 'user must', 'must adapt', 'adapt limited', 'limited discourse', 'discourse .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Consequently , user', ', user must', 'user must adapt', 'must adapt limited', 'adapt limited discourse', 'limited discourse .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['limited discourse'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['consequ', ',', 'user', 'must', 'adapt', 'limit', 'discours', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['consequ', ',', 'user', 'must', 'adapt', 'limit', 'discours', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Consequently', ',', 'user', 'must', 'adapt', 'limited', 'discourse', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

50 --> 1.2.2. 


 ---- TOKENS ----

 ['1.2.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1.2.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.2.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1.2.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.2.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.2.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1.2.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1.2.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

51 --> Status of  Evaluation in NLP  Natural language processing combines basic scientific challenges with diverse technological needs. 


 ---- TOKENS ----

 ['Status', 'of', 'Evaluation', 'in', 'NLP', 'Natural', 'language', 'processing', 'combines', 'basic', 'scientific', 'challenges', 'with', 'diverse', 'technological', 'needs', '.'] 

 TOTAL TOKENS ==> 17

 ---- POST ----

 [('Status', 'NNP'), ('of', 'IN'), ('Evaluation', 'NNP'), ('in', 'IN'), ('NLP', 'NNP'), ('Natural', 'NNP'), ('language', 'NN'), ('processing', 'NN'), ('combines', 'NNS'), ('basic', 'JJ'), ('scientific', 'JJ'), ('challenges', 'NNS'), ('with', 'IN'), ('diverse', 'JJ'), ('technological', 'JJ'), ('needs', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Status', 'Evaluation', 'NLP', 'Natural', 'language', 'processing', 'combines', 'basic', 'scientific', 'challenges', 'diverse', 'technological', 'needs', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('Status', 'NNP'), ('Evaluation', 'NNP'), ('NLP', 'NNP'), ('Natural', 'NNP'), ('language', 'NN'), ('processing', 'NN'), ('combines', 'NNS'), ('basic', 'JJ'), ('scientific', 'JJ'), ('challenges', 'NNS'), ('diverse', 'VBP'), ('technological', 'JJ'), ('needs', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Status Evaluation', 'Evaluation NLP', 'NLP Natural', 'Natural language', 'language processing', 'processing combines', 'combines basic', 'basic scientific', 'scientific challenges', 'challenges diverse', 'diverse technological', 'technological needs', 'needs .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['Status Evaluation NLP', 'Evaluation NLP Natural', 'NLP Natural language', 'Natural language processing', 'language processing combines', 'processing combines basic', 'combines basic scientific', 'basic scientific challenges', 'scientific challenges diverse', 'challenges diverse technological', 'diverse technological needs', 'technological needs .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['language', 'processing'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['Evaluation']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Status']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['statu', 'evalu', 'nlp', 'natur', 'languag', 'process', 'combin', 'basic', 'scientif', 'challeng', 'divers', 'technolog', 'need', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['status', 'evalu', 'nlp', 'natur', 'languag', 'process', 'combin', 'basic', 'scientif', 'challeng', 'divers', 'technolog', 'need', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['Status', 'Evaluation', 'NLP', 'Natural', 'language', 'processing', 'combine', 'basic', 'scientific', 'challenge', 'diverse', 'technological', 'need', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

52 --> Evaluating progress in scientific challenges for NLP is a multifaceted issue, perhaps akin to the problem of  evaluating progress in the field of programming languages. 


 ---- TOKENS ----

 ['Evaluating', 'progress', 'in', 'scientific', 'challenges', 'for', 'NLP', 'is', 'a', 'multifaceted', 'issue', ',', 'perhaps', 'akin', 'to', 'the', 'problem', 'of', 'evaluating', 'progress', 'in', 'the', 'field', 'of', 'programming', 'languages', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('Evaluating', 'VBG'), ('progress', 'NN'), ('in', 'IN'), ('scientific', 'JJ'), ('challenges', 'NNS'), ('for', 'IN'), ('NLP', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('multifaceted', 'JJ'), ('issue', 'NN'), (',', ','), ('perhaps', 'RB'), ('akin', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('problem', 'NN'), ('of', 'IN'), ('evaluating', 'VBG'), ('progress', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('programming', 'VBG'), ('languages', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Evaluating', 'progress', 'scientific', 'challenges', 'NLP', 'multifaceted', 'issue', ',', 'perhaps', 'akin', 'problem', 'evaluating', 'progress', 'field', 'programming', 'languages', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Evaluating', 'VBG'), ('progress', 'NN'), ('scientific', 'JJ'), ('challenges', 'VBZ'), ('NLP', 'NNP'), ('multifaceted', 'VBD'), ('issue', 'NN'), (',', ','), ('perhaps', 'RB'), ('akin', 'JJ'), ('problem', 'NN'), ('evaluating', 'VBG'), ('progress', 'NN'), ('field', 'NN'), ('programming', 'VBG'), ('languages', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Evaluating progress', 'progress scientific', 'scientific challenges', 'challenges NLP', 'NLP multifaceted', 'multifaceted issue', 'issue ,', ', perhaps', 'perhaps akin', 'akin problem', 'problem evaluating', 'evaluating progress', 'progress field', 'field programming', 'programming languages', 'languages .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Evaluating progress scientific', 'progress scientific challenges', 'scientific challenges NLP', 'challenges NLP multifaceted', 'NLP multifaceted issue', 'multifaceted issue ,', 'issue , perhaps', ', perhaps akin', 'perhaps akin problem', 'akin problem evaluating', 'problem evaluating progress', 'evaluating progress field', 'progress field programming', 'field programming languages', 'programming languages .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['progress', 'issue', 'akin problem', 'progress', 'field'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['evalu', 'progress', 'scientif', 'challeng', 'nlp', 'multifacet', 'issu', ',', 'perhap', 'akin', 'problem', 'evalu', 'progress', 'field', 'program', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['evalu', 'progress', 'scientif', 'challeng', 'nlp', 'multifacet', 'issu', ',', 'perhap', 'akin', 'problem', 'evalu', 'progress', 'field', 'program', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Evaluating', 'progress', 'scientific', 'challenge', 'NLP', 'multifaceted', 'issue', ',', 'perhaps', 'akin', 'problem', 'evaluating', 'progress', 'field', 'programming', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

53 --> While certain aspects of progress in that field can be  quantified, this is generally not the case; it is hard to quantify how much better one programming language is than  another, for example. 


 ---- TOKENS ----

 ['While', 'certain', 'aspects', 'of', 'progress', 'in', 'that', 'field', 'can', 'be', 'quantified', ',', 'this', 'is', 'generally', 'not', 'the', 'case', ';', 'it', 'is', 'hard', 'to', 'quantify', 'how', 'much', 'better', 'one', 'programming', 'language', 'is', 'than', 'another', ',', 'for', 'example', '.'] 

 TOTAL TOKENS ==> 37

 ---- POST ----

 [('While', 'IN'), ('certain', 'JJ'), ('aspects', 'NNS'), ('of', 'IN'), ('progress', 'NN'), ('in', 'IN'), ('that', 'DT'), ('field', 'NN'), ('can', 'MD'), ('be', 'VB'), ('quantified', 'VBN'), (',', ','), ('this', 'DT'), ('is', 'VBZ'), ('generally', 'RB'), ('not', 'RB'), ('the', 'DT'), ('case', 'NN'), (';', ':'), ('it', 'PRP'), ('is', 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('quantify', 'VB'), ('how', 'WRB'), ('much', 'JJ'), ('better', 'JJR'), ('one', 'CD'), ('programming', 'NN'), ('language', 'NN'), ('is', 'VBZ'), ('than', 'IN'), ('another', 'DT'), (',', ','), ('for', 'IN'), ('example', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['certain', 'aspects', 'progress', 'field', 'quantified', ',', 'generally', 'case', ';', 'hard', 'quantify', 'much', 'better', 'one', 'programming', 'language', 'another', ',', 'example', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('certain', 'JJ'), ('aspects', 'NNS'), ('progress', 'JJ'), ('field', 'NN'), ('quantified', 'VBD'), (',', ','), ('generally', 'RB'), ('case', 'NN'), (';', ':'), ('hard', 'JJ'), ('quantify', 'NN'), ('much', 'RB'), ('better', 'RBR'), ('one', 'CD'), ('programming', 'NN'), ('language', 'NN'), ('another', 'DT'), (',', ','), ('example', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['certain aspects', 'aspects progress', 'progress field', 'field quantified', 'quantified ,', ', generally', 'generally case', 'case ;', '; hard', 'hard quantify', 'quantify much', 'much better', 'better one', 'one programming', 'programming language', 'language another', 'another ,', ', example', 'example .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['certain aspects progress', 'aspects progress field', 'progress field quantified', 'field quantified ,', 'quantified , generally', ', generally case', 'generally case ;', 'case ; hard', '; hard quantify', 'hard quantify much', 'quantify much better', 'much better one', 'better one programming', 'one programming language', 'programming language another', 'language another ,', 'another , example', ', example .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['progress field', 'case', 'hard quantify', 'programming', 'language', 'example'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['certain', 'aspect', 'progress', 'field', 'quantifi', ',', 'gener', 'case', ';', 'hard', 'quantifi', 'much', 'better', 'one', 'program', 'languag', 'anoth', ',', 'exampl', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['certain', 'aspect', 'progress', 'field', 'quantifi', ',', 'general', 'case', ';', 'hard', 'quantifi', 'much', 'better', 'one', 'program', 'languag', 'anoth', ',', 'exampl', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['certain', 'aspect', 'progress', 'field', 'quantified', ',', 'generally', 'case', ';', 'hard', 'quantify', 'much', 'better', 'one', 'programming', 'language', 'another', ',', 'example', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

54 --> Nevertheless, there is still reason to believe that scientific issues are becoming better defined  and that progress is being made. 


 ---- TOKENS ----

 ['Nevertheless', ',', 'there', 'is', 'still', 'reason', 'to', 'believe', 'that', 'scientific', 'issues', 'are', 'becoming', 'better', 'defined', 'and', 'that', 'progress', 'is', 'being', 'made', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Nevertheless', 'RB'), (',', ','), ('there', 'EX'), ('is', 'VBZ'), ('still', 'RB'), ('reason', 'NN'), ('to', 'TO'), ('believe', 'VB'), ('that', 'IN'), ('scientific', 'JJ'), ('issues', 'NNS'), ('are', 'VBP'), ('becoming', 'VBG'), ('better', 'RBR'), ('defined', 'VBN'), ('and', 'CC'), ('that', 'IN'), ('progress', 'NN'), ('is', 'VBZ'), ('being', 'VBG'), ('made', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Nevertheless', ',', 'still', 'reason', 'believe', 'scientific', 'issues', 'becoming', 'better', 'defined', 'progress', 'made', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('Nevertheless', 'RB'), (',', ','), ('still', 'RB'), ('reason', 'NN'), ('believe', 'VBP'), ('scientific', 'JJ'), ('issues', 'NNS'), ('becoming', 'VBG'), ('better', 'RBR'), ('defined', 'JJ'), ('progress', 'NN'), ('made', 'VBD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Nevertheless ,', ', still', 'still reason', 'reason believe', 'believe scientific', 'scientific issues', 'issues becoming', 'becoming better', 'better defined', 'defined progress', 'progress made', 'made .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['Nevertheless , still', ', still reason', 'still reason believe', 'reason believe scientific', 'believe scientific issues', 'scientific issues becoming', 'issues becoming better', 'becoming better defined', 'better defined progress', 'defined progress made', 'progress made .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['reason', 'defined progress'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['nevertheless', ',', 'still', 'reason', 'believ', 'scientif', 'issu', 'becom', 'better', 'defin', 'progress', 'made', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['nevertheless', ',', 'still', 'reason', 'believ', 'scientif', 'issu', 'becom', 'better', 'defin', 'progress', 'made', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['Nevertheless', ',', 'still', 'reason', 'believe', 'scientific', 'issue', 'becoming', 'better', 'defined', 'progress', 'made', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

55 --> On the other hand, evaluation metrics for technological advances based on the science are being developed  and applied. 


 ---- TOKENS ----

 ['On', 'the', 'other', 'hand', ',', 'evaluation', 'metrics', 'for', 'technological', 'advances', 'based', 'on', 'the', 'science', 'are', 'being', 'developed', 'and', 'applied', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('On', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('hand', 'NN'), (',', ','), ('evaluation', 'NN'), ('metrics', 'NNS'), ('for', 'IN'), ('technological', 'JJ'), ('advances', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('science', 'NN'), ('are', 'VBP'), ('being', 'VBG'), ('developed', 'VBN'), ('and', 'CC'), ('applied', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['hand', ',', 'evaluation', 'metrics', 'technological', 'advances', 'based', 'science', 'developed', 'applied', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('hand', 'NN'), (',', ','), ('evaluation', 'NN'), ('metrics', 'NNS'), ('technological', 'JJ'), ('advances', 'NNS'), ('based', 'VBN'), ('science', 'NN'), ('developed', 'VBD'), ('applied', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['hand ,', ', evaluation', 'evaluation metrics', 'metrics technological', 'technological advances', 'advances based', 'based science', 'science developed', 'developed applied', 'applied .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['hand , evaluation', ', evaluation metrics', 'evaluation metrics technological', 'metrics technological advances', 'technological advances based', 'advances based science', 'based science developed', 'science developed applied', 'developed applied .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['hand', 'evaluation', 'science'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['hand', ',', 'evalu', 'metric', 'technolog', 'advanc', 'base', 'scienc', 'develop', 'appli', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['hand', ',', 'evalu', 'metric', 'technolog', 'advanc', 'base', 'scienc', 'develop', 'appli', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['hand', ',', 'evaluation', 'metric', 'technological', 'advance', 'based', 'science', 'developed', 'applied', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

56 --> In machine translation, measurements have evolved further than in other areas, and they encompass  both range of application (what kind of texts in what domain can be translated) and accuracy of the translation  (percentage of sentences that remain semantically invariant, and of those, the percentage that are stylistically  acceptable). 


 ---- TOKENS ----

 ['In', 'machine', 'translation', ',', 'measurements', 'have', 'evolved', 'further', 'than', 'in', 'other', 'areas', ',', 'and', 'they', 'encompass', 'both', 'range', 'of', 'application', '(', 'what', 'kind', 'of', 'texts', 'in', 'what', 'domain', 'can', 'be', 'translated', ')', 'and', 'accuracy', 'of', 'the', 'translation', '(', 'percentage', 'of', 'sentences', 'that', 'remain', 'semantically', 'invariant', ',', 'and', 'of', 'those', ',', 'the', 'percentage', 'that', 'are', 'stylistically', 'acceptable', ')', '.'] 

 TOTAL TOKENS ==> 58

 ---- POST ----

 [('In', 'IN'), ('machine', 'NN'), ('translation', 'NN'), (',', ','), ('measurements', 'NNS'), ('have', 'VBP'), ('evolved', 'VBN'), ('further', 'RBR'), ('than', 'IN'), ('in', 'IN'), ('other', 'JJ'), ('areas', 'NNS'), (',', ','), ('and', 'CC'), ('they', 'PRP'), ('encompass', 'VBP'), ('both', 'DT'), ('range', 'NN'), ('of', 'IN'), ('application', 'NN'), ('(', '('), ('what', 'WP'), ('kind', 'NN'), ('of', 'IN'), ('texts', 'NN'), ('in', 'IN'), ('what', 'WP'), ('domain', 'NN'), ('can', 'MD'), ('be', 'VB'), ('translated', 'VBN'), (')', ')'), ('and', 'CC'), ('accuracy', 'NN'), ('of', 'IN'), ('the', 'DT'), ('translation', 'NN'), ('(', '('), ('percentage', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('that', 'WDT'), ('remain', 'VBP'), ('semantically', 'RB'), ('invariant', 'JJ'), (',', ','), ('and', 'CC'), ('of', 'IN'), ('those', 'DT'), (',', ','), ('the', 'DT'), ('percentage', 'NN'), ('that', 'WDT'), ('are', 'VBP'), ('stylistically', 'RB'), ('acceptable', 'JJ'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['machine', 'translation', ',', 'measurements', 'evolved', 'areas', ',', 'encompass', 'range', 'application', '(', 'kind', 'texts', 'domain', 'translated', ')', 'accuracy', 'translation', '(', 'percentage', 'sentences', 'remain', 'semantically', 'invariant', ',', ',', 'percentage', 'stylistically', 'acceptable', ')', '.']

 TOTAL FILTERED TOKENS ==>  31

 ---- POST FOR FILTERED TOKENS ----

 [('machine', 'NN'), ('translation', 'NN'), (',', ','), ('measurements', 'NNS'), ('evolved', 'VBD'), ('areas', 'NNS'), (',', ','), ('encompass', 'NN'), ('range', 'NN'), ('application', 'NN'), ('(', '('), ('kind', 'NN'), ('texts', 'NN'), ('domain', 'NN'), ('translated', 'VBD'), (')', ')'), ('accuracy', 'NN'), ('translation', 'NN'), ('(', '('), ('percentage', 'NN'), ('sentences', 'NNS'), ('remain', 'VBP'), ('semantically', 'RB'), ('invariant', 'JJ'), (',', ','), (',', ','), ('percentage', 'NN'), ('stylistically', 'RB'), ('acceptable', 'JJ'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['machine translation', 'translation ,', ', measurements', 'measurements evolved', 'evolved areas', 'areas ,', ', encompass', 'encompass range', 'range application', 'application (', '( kind', 'kind texts', 'texts domain', 'domain translated', 'translated )', ') accuracy', 'accuracy translation', 'translation (', '( percentage', 'percentage sentences', 'sentences remain', 'remain semantically', 'semantically invariant', 'invariant ,', ', ,', ', percentage', 'percentage stylistically', 'stylistically acceptable', 'acceptable )', ') .'] 

 TOTAL BIGRAMS --> 30 



 ---- TRI-GRAMS ---- 

 ['machine translation ,', 'translation , measurements', ', measurements evolved', 'measurements evolved areas', 'evolved areas ,', 'areas , encompass', ', encompass range', 'encompass range application', 'range application (', 'application ( kind', '( kind texts', 'kind texts domain', 'texts domain translated', 'domain translated )', 'translated ) accuracy', ') accuracy translation', 'accuracy translation (', 'translation ( percentage', '( percentage sentences', 'percentage sentences remain', 'sentences remain semantically', 'remain semantically invariant', 'semantically invariant ,', 'invariant , ,', ', , percentage', ', percentage stylistically', 'percentage stylistically acceptable', 'stylistically acceptable )', 'acceptable ) .'] 

 TOTAL TRIGRAMS --> 29 



 ---- NOUN PHRASES ---- 

 ['machine', 'translation', 'encompass', 'range', 'application', 'accuracy', 'translation'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['machin', 'translat', ',', 'measur', 'evolv', 'area', ',', 'encompass', 'rang', 'applic', '(', 'kind', 'text', 'domain', 'translat', ')', 'accuraci', 'translat', '(', 'percentag', 'sentenc', 'remain', 'semant', 'invari', ',', ',', 'percentag', 'stylist', 'accept', ')', '.']

 TOTAL PORTER STEM WORDS ==> 31



 ---- SNOWBALL STEMMING ----

['machin', 'translat', ',', 'measur', 'evolv', 'area', ',', 'encompass', 'rang', 'applic', '(', 'kind', 'text', 'domain', 'translat', ')', 'accuraci', 'translat', '(', 'percentag', 'sentenc', 'remain', 'semant', 'invari', ',', ',', 'percentag', 'stylist', 'accept', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 31



 ---- LEMMATIZATION ----

['machine', 'translation', ',', 'measurement', 'evolved', 'area', ',', 'encompass', 'range', 'application', '(', 'kind', 'text', 'domain', 'translated', ')', 'accuracy', 'translation', '(', 'percentage', 'sentence', 'remain', 'semantically', 'invariant', ',', ',', 'percentage', 'stylistically', 'acceptable', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 31

************************************************************************************************************************

57 --> Natural language interfaces can be evaluated in terms of their habitability; that is, how well and how  fast can a user get the task accomplished? 


 ---- TOKENS ----

 ['Natural', 'language', 'interfaces', 'can', 'be', 'evaluated', 'in', 'terms', 'of', 'their', 'habitability', ';', 'that', 'is', ',', 'how', 'well', 'and', 'how', 'fast', 'can', 'a', 'user', 'get', 'the', 'task', 'accomplished', '?'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('Natural', 'JJ'), ('language', 'NN'), ('interfaces', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('evaluated', 'VBN'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('their', 'PRP$'), ('habitability', 'NN'), (';', ':'), ('that', 'WDT'), ('is', 'VBZ'), (',', ','), ('how', 'WRB'), ('well', 'RB'), ('and', 'CC'), ('how', 'WRB'), ('fast', 'RB'), ('can', 'MD'), ('a', 'DT'), ('user', 'JJ'), ('get', 'NN'), ('the', 'DT'), ('task', 'NN'), ('accomplished', 'VBD'), ('?', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Natural', 'language', 'interfaces', 'evaluated', 'terms', 'habitability', ';', ',', 'well', 'fast', 'user', 'get', 'task', 'accomplished', '?']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Natural', 'JJ'), ('language', 'NN'), ('interfaces', 'NNS'), ('evaluated', 'VBD'), ('terms', 'NNS'), ('habitability', 'NN'), (';', ':'), (',', ','), ('well', 'UH'), ('fast', 'RB'), ('user', 'JJ'), ('get', 'NN'), ('task', 'NN'), ('accomplished', 'VBN'), ('?', '.')] 



 ---- BI-GRAMS ---- 

 ['Natural language', 'language interfaces', 'interfaces evaluated', 'evaluated terms', 'terms habitability', 'habitability ;', '; ,', ', well', 'well fast', 'fast user', 'user get', 'get task', 'task accomplished', 'accomplished ?'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Natural language interfaces', 'language interfaces evaluated', 'interfaces evaluated terms', 'evaluated terms habitability', 'terms habitability ;', 'habitability ; ,', '; , well', ', well fast', 'well fast user', 'fast user get', 'user get task', 'get task accomplished', 'task accomplished ?'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['Natural language', 'habitability', 'user get', 'task'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['natur', 'languag', 'interfac', 'evalu', 'term', 'habit', ';', ',', 'well', 'fast', 'user', 'get', 'task', 'accomplish', '?']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['natur', 'languag', 'interfac', 'evalu', 'term', 'habit', ';', ',', 'well', 'fast', 'user', 'get', 'task', 'accomplish', '?']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Natural', 'language', 'interface', 'evaluated', 'term', 'habitability', ';', ',', 'well', 'fast', 'user', 'get', 'task', 'accomplished', '?']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

58 --> How often do first phrasings work? 


 ---- TOKENS ----

 ['How', 'often', 'do', 'first', 'phrasings', 'work', '?'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('How', 'WRB'), ('often', 'RB'), ('do', 'VBP'), ('first', 'JJ'), ('phrasings', 'NNS'), ('work', 'NN'), ('?', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['often', 'first', 'phrasings', 'work', '?']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('often', 'RB'), ('first', 'JJ'), ('phrasings', 'NNS'), ('work', 'NN'), ('?', '.')] 



 ---- BI-GRAMS ---- 

 ['often first', 'first phrasings', 'phrasings work', 'work ?'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['often first phrasings', 'first phrasings work', 'phrasings work ?'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 ['work'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['often', 'first', 'phrase', 'work', '?']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['often', 'first', 'phrase', 'work', '?']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['often', 'first', 'phrasing', 'work', '?']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

59 --> Do subsequent human-machine  clarification, or focused rephrasing, yield success? 


 ---- TOKENS ----

 ['Do', 'subsequent', 'human-machine', 'clarification', ',', 'or', 'focused', 'rephrasing', ',', 'yield', 'success', '?'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('Do', 'VB'), ('subsequent', 'JJ'), ('human-machine', 'NN'), ('clarification', 'NN'), (',', ','), ('or', 'CC'), ('focused', 'VBD'), ('rephrasing', 'NN'), (',', ','), ('yield', 'NN'), ('success', 'NN'), ('?', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['subsequent', 'human-machine', 'clarification', ',', 'focused', 'rephrasing', ',', 'yield', 'success', '?']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('subsequent', 'JJ'), ('human-machine', 'JJ'), ('clarification', 'NN'), (',', ','), ('focused', 'VBD'), ('rephrasing', 'NN'), (',', ','), ('yield', 'NN'), ('success', 'NN'), ('?', '.')] 



 ---- BI-GRAMS ---- 

 ['subsequent human-machine', 'human-machine clarification', 'clarification ,', ', focused', 'focused rephrasing', 'rephrasing ,', ', yield', 'yield success', 'success ?'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['subsequent human-machine clarification', 'human-machine clarification ,', 'clarification , focused', ', focused rephrasing', 'focused rephrasing ,', 'rephrasing , yield', ', yield success', 'yield success ?'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['subsequent human-machine clarification', 'rephrasing', 'yield', 'success'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['subsequ', 'human-machin', 'clarif', ',', 'focus', 'rephras', ',', 'yield', 'success', '?']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['subsequ', 'human-machin', 'clarif', ',', 'focus', 'rephras', ',', 'yield', 'success', '?']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['subsequent', 'human-machine', 'clarification', ',', 'focused', 'rephrasing', ',', 'yield', 'success', '?']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

60 --> These criteria, however, evaluate performance of the technology  in a task domain, rather than the underlying science, independent of  task. 


 ---- TOKENS ----

 ['These', 'criteria', ',', 'however', ',', 'evaluate', 'performance', 'of', 'the', 'technology', 'in', 'a', 'task', 'domain', ',', 'rather', 'than', 'the', 'underlying', 'science', ',', 'independent', 'of', 'task', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('These', 'DT'), ('criteria', 'NNS'), (',', ','), ('however', 'RB'), (',', ','), ('evaluate', 'JJ'), ('performance', 'NN'), ('of', 'IN'), ('the', 'DT'), ('technology', 'NN'), ('in', 'IN'), ('a', 'DT'), ('task', 'NN'), ('domain', 'NN'), (',', ','), ('rather', 'RB'), ('than', 'IN'), ('the', 'DT'), ('underlying', 'JJ'), ('science', 'NN'), (',', ','), ('independent', 'JJ'), ('of', 'IN'), ('task', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['criteria', ',', 'however', ',', 'evaluate', 'performance', 'technology', 'task', 'domain', ',', 'rather', 'underlying', 'science', ',', 'independent', 'task', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('criteria', 'NNS'), (',', ','), ('however', 'RB'), (',', ','), ('evaluate', 'JJ'), ('performance', 'NN'), ('technology', 'NN'), ('task', 'NN'), ('domain', 'NN'), (',', ','), ('rather', 'RB'), ('underlying', 'VBG'), ('science', 'NN'), (',', ','), ('independent', 'JJ'), ('task', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['criteria ,', ', however', 'however ,', ', evaluate', 'evaluate performance', 'performance technology', 'technology task', 'task domain', 'domain ,', ', rather', 'rather underlying', 'underlying science', 'science ,', ', independent', 'independent task', 'task .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['criteria , however', ', however ,', 'however , evaluate', ', evaluate performance', 'evaluate performance technology', 'performance technology task', 'technology task domain', 'task domain ,', 'domain , rather', ', rather underlying', 'rather underlying science', 'underlying science ,', 'science , independent', ', independent task', 'independent task .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['evaluate performance', 'technology', 'task', 'domain', 'science', 'independent task'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['criteria', ',', 'howev', ',', 'evalu', 'perform', 'technolog', 'task', 'domain', ',', 'rather', 'underli', 'scienc', ',', 'independ', 'task', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['criteria', ',', 'howev', ',', 'evalu', 'perform', 'technolog', 'task', 'domain', ',', 'rather', 'under', 'scienc', ',', 'independ', 'task', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['criterion', ',', 'however', ',', 'evaluate', 'performance', 'technology', 'task', 'domain', ',', 'rather', 'underlying', 'science', ',', 'independent', 'task', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

61 --> It behooves the field to continue refining and applying qualitative as well as quantitative measures of  progress in the NLP task domains, and to consider the issue of how to measure and evaluate research in the scientific  core, if that is to be done any differently from the standard measures of publication and scholarship of  most  established scientific fields. 


 ---- TOKENS ----

 ['It', 'behooves', 'the', 'field', 'to', 'continue', 'refining', 'and', 'applying', 'qualitative', 'as', 'well', 'as', 'quantitative', 'measures', 'of', 'progress', 'in', 'the', 'NLP', 'task', 'domains', ',', 'and', 'to', 'consider', 'the', 'issue', 'of', 'how', 'to', 'measure', 'and', 'evaluate', 'research', 'in', 'the', 'scientific', 'core', ',', 'if', 'that', 'is', 'to', 'be', 'done', 'any', 'differently', 'from', 'the', 'standard', 'measures', 'of', 'publication', 'and', 'scholarship', 'of', 'most', 'established', 'scientific', 'fields', '.'] 

 TOTAL TOKENS ==> 62

 ---- POST ----

 [('It', 'PRP'), ('behooves', 'VBZ'), ('the', 'DT'), ('field', 'NN'), ('to', 'TO'), ('continue', 'VB'), ('refining', 'NN'), ('and', 'CC'), ('applying', 'VBG'), ('qualitative', 'JJ'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('quantitative', 'JJ'), ('measures', 'NNS'), ('of', 'IN'), ('progress', 'NN'), ('in', 'IN'), ('the', 'DT'), ('NLP', 'NNP'), ('task', 'NN'), ('domains', 'NNS'), (',', ','), ('and', 'CC'), ('to', 'TO'), ('consider', 'VB'), ('the', 'DT'), ('issue', 'NN'), ('of', 'IN'), ('how', 'WRB'), ('to', 'TO'), ('measure', 'VB'), ('and', 'CC'), ('evaluate', 'VB'), ('research', 'NN'), ('in', 'IN'), ('the', 'DT'), ('scientific', 'JJ'), ('core', 'NN'), (',', ','), ('if', 'IN'), ('that', 'DT'), ('is', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('done', 'VBN'), ('any', 'DT'), ('differently', 'RB'), ('from', 'IN'), ('the', 'DT'), ('standard', 'JJ'), ('measures', 'NNS'), ('of', 'IN'), ('publication', 'NN'), ('and', 'CC'), ('scholarship', 'NN'), ('of', 'IN'), ('most', 'JJS'), ('established', 'VBN'), ('scientific', 'JJ'), ('fields', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['behooves', 'field', 'continue', 'refining', 'applying', 'qualitative', 'well', 'quantitative', 'measures', 'progress', 'NLP', 'task', 'domains', ',', 'consider', 'issue', 'measure', 'evaluate', 'research', 'scientific', 'core', ',', 'done', 'differently', 'standard', 'measures', 'publication', 'scholarship', 'established', 'scientific', 'fields', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('behooves', 'NNS'), ('field', 'NN'), ('continue', 'VBP'), ('refining', 'VBG'), ('applying', 'VBG'), ('qualitative', 'JJ'), ('well', 'RB'), ('quantitative', 'JJ'), ('measures', 'NNS'), ('progress', 'VBP'), ('NLP', 'NNP'), ('task', 'NN'), ('domains', 'NNS'), (',', ','), ('consider', 'VB'), ('issue', 'NN'), ('measure', 'NN'), ('evaluate', 'VBP'), ('research', 'NN'), ('scientific', 'JJ'), ('core', 'NN'), (',', ','), ('done', 'VBN'), ('differently', 'RB'), ('standard', 'JJ'), ('measures', 'NNS'), ('publication', 'NN'), ('scholarship', 'NN'), ('established', 'VBD'), ('scientific', 'JJ'), ('fields', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['behooves field', 'field continue', 'continue refining', 'refining applying', 'applying qualitative', 'qualitative well', 'well quantitative', 'quantitative measures', 'measures progress', 'progress NLP', 'NLP task', 'task domains', 'domains ,', ', consider', 'consider issue', 'issue measure', 'measure evaluate', 'evaluate research', 'research scientific', 'scientific core', 'core ,', ', done', 'done differently', 'differently standard', 'standard measures', 'measures publication', 'publication scholarship', 'scholarship established', 'established scientific', 'scientific fields', 'fields .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['behooves field continue', 'field continue refining', 'continue refining applying', 'refining applying qualitative', 'applying qualitative well', 'qualitative well quantitative', 'well quantitative measures', 'quantitative measures progress', 'measures progress NLP', 'progress NLP task', 'NLP task domains', 'task domains ,', 'domains , consider', ', consider issue', 'consider issue measure', 'issue measure evaluate', 'measure evaluate research', 'evaluate research scientific', 'research scientific core', 'scientific core ,', 'core , done', ', done differently', 'done differently standard', 'differently standard measures', 'standard measures publication', 'measures publication scholarship', 'publication scholarship established', 'scholarship established scientific', 'established scientific fields', 'scientific fields .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['field', 'task', 'issue', 'measure', 'research', 'scientific core', 'publication', 'scholarship'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['behoov', 'field', 'continu', 'refin', 'appli', 'qualit', 'well', 'quantit', 'measur', 'progress', 'nlp', 'task', 'domain', ',', 'consid', 'issu', 'measur', 'evalu', 'research', 'scientif', 'core', ',', 'done', 'differ', 'standard', 'measur', 'public', 'scholarship', 'establish', 'scientif', 'field', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['behoov', 'field', 'continu', 'refin', 'appli', 'qualit', 'well', 'quantit', 'measur', 'progress', 'nlp', 'task', 'domain', ',', 'consid', 'issu', 'measur', 'evalu', 'research', 'scientif', 'core', ',', 'done', 'differ', 'standard', 'measur', 'public', 'scholarship', 'establish', 'scientif', 'field', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['behooves', 'field', 'continue', 'refining', 'applying', 'qualitative', 'well', 'quantitative', 'measure', 'progress', 'NLP', 'task', 'domain', ',', 'consider', 'issue', 'measure', 'evaluate', 'research', 'scientific', 'core', ',', 'done', 'differently', 'standard', 'measure', 'publication', 'scholarship', 'established', 'scientific', 'field', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

62 --> 483   1.2.3. 


 ---- TOKENS ----

 ['483', '1.2.3', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('483', 'CD'), ('1.2.3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['483', '1.2.3', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('483', 'CD'), ('1.2.3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['483 1.2.3', '1.2.3 .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['483 1.2.3 .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['483', '1.2.3', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['483', '1.2.3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['483', '1.2.3', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

63 --> Fur the r  Scientific Work  Given the limitations of the current technology discussed in Section 1.2.1, fundamental scientific problems  in the following three broad areas should be addressed:  Adequate theories of semantics and discourse. 


 ---- TOKENS ----

 ['Fur', 'the', 'r', 'Scientific', 'Work', 'Given', 'the', 'limitations', 'of', 'the', 'current', 'technology', 'discussed', 'in', 'Section', '1.2.1', ',', 'fundamental', 'scientific', 'problems', 'in', 'the', 'following', 'three', 'broad', 'areas', 'should', 'be', 'addressed', ':', 'Adequate', 'theories', 'of', 'semantics', 'and', 'discourse', '.'] 

 TOTAL TOKENS ==> 37

 ---- POST ----

 [('Fur', 'IN'), ('the', 'DT'), ('r', 'NN'), ('Scientific', 'NNP'), ('Work', 'NNP'), ('Given', 'NNP'), ('the', 'DT'), ('limitations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('current', 'JJ'), ('technology', 'NN'), ('discussed', 'VBN'), ('in', 'IN'), ('Section', 'NNP'), ('1.2.1', 'CD'), (',', ','), ('fundamental', 'JJ'), ('scientific', 'JJ'), ('problems', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('following', 'JJ'), ('three', 'CD'), ('broad', 'JJ'), ('areas', 'NNS'), ('should', 'MD'), ('be', 'VB'), ('addressed', 'VBN'), (':', ':'), ('Adequate', 'JJ'), ('theories', 'NNS'), ('of', 'IN'), ('semantics', 'NNS'), ('and', 'CC'), ('discourse', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Fur', 'r', 'Scientific', 'Work', 'Given', 'limitations', 'current', 'technology', 'discussed', 'Section', '1.2.1', ',', 'fundamental', 'scientific', 'problems', 'following', 'three', 'broad', 'areas', 'addressed', ':', 'Adequate', 'theories', 'semantics', 'discourse', '.']

 TOTAL FILTERED TOKENS ==>  26

 ---- POST FOR FILTERED TOKENS ----

 [('Fur', 'NNP'), ('r', 'NN'), ('Scientific', 'NNP'), ('Work', 'NNP'), ('Given', 'NNP'), ('limitations', 'NNS'), ('current', 'JJ'), ('technology', 'NN'), ('discussed', 'VBD'), ('Section', 'NNP'), ('1.2.1', 'CD'), (',', ','), ('fundamental', 'JJ'), ('scientific', 'JJ'), ('problems', 'NNS'), ('following', 'VBG'), ('three', 'CD'), ('broad', 'JJ'), ('areas', 'NNS'), ('addressed', 'VBN'), (':', ':'), ('Adequate', 'JJ'), ('theories', 'NNS'), ('semantics', 'NNS'), ('discourse', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Fur r', 'r Scientific', 'Scientific Work', 'Work Given', 'Given limitations', 'limitations current', 'current technology', 'technology discussed', 'discussed Section', 'Section 1.2.1', '1.2.1 ,', ', fundamental', 'fundamental scientific', 'scientific problems', 'problems following', 'following three', 'three broad', 'broad areas', 'areas addressed', 'addressed :', ': Adequate', 'Adequate theories', 'theories semantics', 'semantics discourse', 'discourse .'] 

 TOTAL BIGRAMS --> 25 



 ---- TRI-GRAMS ---- 

 ['Fur r Scientific', 'r Scientific Work', 'Scientific Work Given', 'Work Given limitations', 'Given limitations current', 'limitations current technology', 'current technology discussed', 'technology discussed Section', 'discussed Section 1.2.1', 'Section 1.2.1 ,', '1.2.1 , fundamental', ', fundamental scientific', 'fundamental scientific problems', 'scientific problems following', 'problems following three', 'following three broad', 'three broad areas', 'broad areas addressed', 'areas addressed :', 'addressed : Adequate', ': Adequate theories', 'Adequate theories semantics', 'theories semantics discourse', 'semantics discourse .'] 

 TOTAL TRIGRAMS --> 24 



 ---- NOUN PHRASES ---- 

 ['r', 'current technology', 'discourse'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Scientific Work']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Fur']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['fur', 'r', 'scientif', 'work', 'given', 'limit', 'current', 'technolog', 'discuss', 'section', '1.2.1', ',', 'fundament', 'scientif', 'problem', 'follow', 'three', 'broad', 'area', 'address', ':', 'adequ', 'theori', 'semant', 'discours', '.']

 TOTAL PORTER STEM WORDS ==> 26



 ---- SNOWBALL STEMMING ----

['fur', 'r', 'scientif', 'work', 'given', 'limit', 'current', 'technolog', 'discuss', 'section', '1.2.1', ',', 'fundament', 'scientif', 'problem', 'follow', 'three', 'broad', 'area', 'address', ':', 'adequ', 'theori', 'semant', 'discours', '.']

 TOTAL SNOWBALL STEM WORDS ==> 26



 ---- LEMMATIZATION ----

['Fur', 'r', 'Scientific', 'Work', 'Given', 'limitation', 'current', 'technology', 'discussed', 'Section', '1.2.1', ',', 'fundamental', 'scientific', 'problem', 'following', 'three', 'broad', 'area', 'addressed', ':', 'Adequate', 'theory', 'semantics', 'discourse', '.']

 TOTAL LEMMATIZE WORDS ==> 26

************************************************************************************************************************

64 --> These theories should apply to both generation and  interpretation of  interactive dialogue and text and must support communication across a range of domains of  discourse. 


 ---- TOKENS ----

 ['These', 'theories', 'should', 'apply', 'to', 'both', 'generation', 'and', 'interpretation', 'of', 'interactive', 'dialogue', 'and', 'text', 'and', 'must', 'support', 'communication', 'across', 'a', 'range', 'of', 'domains', 'of', 'discourse', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('These', 'DT'), ('theories', 'NNS'), ('should', 'MD'), ('apply', 'VB'), ('to', 'TO'), ('both', 'DT'), ('generation', 'NN'), ('and', 'CC'), ('interpretation', 'NN'), ('of', 'IN'), ('interactive', 'JJ'), ('dialogue', 'NN'), ('and', 'CC'), ('text', 'NN'), ('and', 'CC'), ('must', 'MD'), ('support', 'VB'), ('communication', 'NN'), ('across', 'IN'), ('a', 'DT'), ('range', 'NN'), ('of', 'IN'), ('domains', 'NNS'), ('of', 'IN'), ('discourse', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['theories', 'apply', 'generation', 'interpretation', 'interactive', 'dialogue', 'text', 'must', 'support', 'communication', 'across', 'range', 'domains', 'discourse', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('theories', 'NNS'), ('apply', 'VBP'), ('generation', 'NN'), ('interpretation', 'NN'), ('interactive', 'JJ'), ('dialogue', 'NN'), ('text', 'NN'), ('must', 'MD'), ('support', 'VB'), ('communication', 'NN'), ('across', 'IN'), ('range', 'NN'), ('domains', 'NNS'), ('discourse', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['theories apply', 'apply generation', 'generation interpretation', 'interpretation interactive', 'interactive dialogue', 'dialogue text', 'text must', 'must support', 'support communication', 'communication across', 'across range', 'range domains', 'domains discourse', 'discourse .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['theories apply generation', 'apply generation interpretation', 'generation interpretation interactive', 'interpretation interactive dialogue', 'interactive dialogue text', 'dialogue text must', 'text must support', 'must support communication', 'support communication across', 'communication across range', 'across range domains', 'range domains discourse', 'domains discourse .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['generation', 'interpretation', 'interactive dialogue', 'text', 'communication', 'range', 'discourse'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['theori', 'appli', 'gener', 'interpret', 'interact', 'dialogu', 'text', 'must', 'support', 'commun', 'across', 'rang', 'domain', 'discours', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['theori', 'appli', 'generat', 'interpret', 'interact', 'dialogu', 'text', 'must', 'support', 'communic', 'across', 'rang', 'domain', 'discours', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['theory', 'apply', 'generation', 'interpretation', 'interactive', 'dialogue', 'text', 'must', 'support', 'communication', 'across', 'range', 'domain', 'discourse', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

65 --> I.n semantics, this means at a minimum that we must have a semantics of words (a lexical semantics) that  is independent of the domain and of the application, and that the meaning of a word is easily (semi-automatically)  related to the concepts of particular domains and applications. 


 ---- TOKENS ----

 ['I.n', 'semantics', ',', 'this', 'means', 'at', 'a', 'minimum', 'that', 'we', 'must', 'have', 'a', 'semantics', 'of', 'words', '(', 'a', 'lexical', 'semantics', ')', 'that', 'is', 'independent', 'of', 'the', 'domain', 'and', 'of', 'the', 'application', ',', 'and', 'that', 'the', 'meaning', 'of', 'a', 'word', 'is', 'easily', '(', 'semi-automatically', ')', 'related', 'to', 'the', 'concepts', 'of', 'particular', 'domains', 'and', 'applications', '.'] 

 TOTAL TOKENS ==> 54

 ---- POST ----

 [('I.n', 'NNP'), ('semantics', 'NNS'), (',', ','), ('this', 'DT'), ('means', 'VBZ'), ('at', 'IN'), ('a', 'DT'), ('minimum', 'NN'), ('that', 'IN'), ('we', 'PRP'), ('must', 'MD'), ('have', 'VB'), ('a', 'DT'), ('semantics', 'NNS'), ('of', 'IN'), ('words', 'NNS'), ('(', '('), ('a', 'DT'), ('lexical', 'JJ'), ('semantics', 'NNS'), (')', ')'), ('that', 'WDT'), ('is', 'VBZ'), ('independent', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('domain', 'NN'), ('and', 'CC'), ('of', 'IN'), ('the', 'DT'), ('application', 'NN'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('the', 'DT'), ('meaning', 'NN'), ('of', 'IN'), ('a', 'DT'), ('word', 'NN'), ('is', 'VBZ'), ('easily', 'RB'), ('(', '('), ('semi-automatically', 'RB'), (')', ')'), ('related', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('concepts', 'NNS'), ('of', 'IN'), ('particular', 'JJ'), ('domains', 'NNS'), ('and', 'CC'), ('applications', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['I.n', 'semantics', ',', 'means', 'minimum', 'must', 'semantics', 'words', '(', 'lexical', 'semantics', ')', 'independent', 'domain', 'application', ',', 'meaning', 'word', 'easily', '(', 'semi-automatically', ')', 'related', 'concepts', 'particular', 'domains', 'applications', '.']

 TOTAL FILTERED TOKENS ==>  28

 ---- POST FOR FILTERED TOKENS ----

 [('I.n', 'NNP'), ('semantics', 'NNS'), (',', ','), ('means', 'VBZ'), ('minimum', 'JJ'), ('must', 'MD'), ('semantics', 'VB'), ('words', 'NNS'), ('(', '('), ('lexical', 'JJ'), ('semantics', 'NNS'), (')', ')'), ('independent', 'JJ'), ('domain', 'NN'), ('application', 'NN'), (',', ','), ('meaning', 'VBG'), ('word', 'NN'), ('easily', 'RB'), ('(', '('), ('semi-automatically', 'RB'), (')', ')'), ('related', 'VBN'), ('concepts', 'NNS'), ('particular', 'JJ'), ('domains', 'NNS'), ('applications', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['I.n semantics', 'semantics ,', ', means', 'means minimum', 'minimum must', 'must semantics', 'semantics words', 'words (', '( lexical', 'lexical semantics', 'semantics )', ') independent', 'independent domain', 'domain application', 'application ,', ', meaning', 'meaning word', 'word easily', 'easily (', '( semi-automatically', 'semi-automatically )', ') related', 'related concepts', 'concepts particular', 'particular domains', 'domains applications', 'applications .'] 

 TOTAL BIGRAMS --> 27 



 ---- TRI-GRAMS ---- 

 ['I.n semantics ,', 'semantics , means', ', means minimum', 'means minimum must', 'minimum must semantics', 'must semantics words', 'semantics words (', 'words ( lexical', '( lexical semantics', 'lexical semantics )', 'semantics ) independent', ') independent domain', 'independent domain application', 'domain application ,', 'application , meaning', ', meaning word', 'meaning word easily', 'word easily (', 'easily ( semi-automatically', '( semi-automatically )', 'semi-automatically ) related', ') related concepts', 'related concepts particular', 'concepts particular domains', 'particular domains applications', 'domains applications .'] 

 TOTAL TRIGRAMS --> 26 



 ---- NOUN PHRASES ---- 

 ['independent domain', 'application', 'word'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['i.n', 'semant', ',', 'mean', 'minimum', 'must', 'semant', 'word', '(', 'lexic', 'semant', ')', 'independ', 'domain', 'applic', ',', 'mean', 'word', 'easili', '(', 'semi-automat', ')', 'relat', 'concept', 'particular', 'domain', 'applic', '.']

 TOTAL PORTER STEM WORDS ==> 28



 ---- SNOWBALL STEMMING ----

['i.n', 'semant', ',', 'mean', 'minimum', 'must', 'semant', 'word', '(', 'lexic', 'semant', ')', 'independ', 'domain', 'applic', ',', 'mean', 'word', 'easili', '(', 'semi-automat', ')', 'relat', 'concept', 'particular', 'domain', 'applic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 28



 ---- LEMMATIZATION ----

['I.n', 'semantics', ',', 'mean', 'minimum', 'must', 'semantics', 'word', '(', 'lexical', 'semantics', ')', 'independent', 'domain', 'application', ',', 'meaning', 'word', 'easily', '(', 'semi-automatically', ')', 'related', 'concept', 'particular', 'domain', 'application', '.']

 TOTAL LEMMATIZE WORDS ==> 28

************************************************************************************************************************

66 --> Accounts of the combined use of linguistic and  non-linguistic (e.g., pointing) intbrmation in interactive dialogues should also be developed. 


 ---- TOKENS ----

 ['Accounts', 'of', 'the', 'combined', 'use', 'of', 'linguistic', 'and', 'non-linguistic', '(', 'e.g.', ',', 'pointing', ')', 'intbrmation', 'in', 'interactive', 'dialogues', 'should', 'also', 'be', 'developed', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Accounts', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('combined', 'VBN'), ('use', 'NN'), ('of', 'IN'), ('linguistic', 'JJ'), ('and', 'CC'), ('non-linguistic', 'JJ'), ('(', '('), ('e.g.', 'JJ'), (',', ','), ('pointing', 'VBG'), (')', ')'), ('intbrmation', 'NN'), ('in', 'IN'), ('interactive', 'JJ'), ('dialogues', 'NNS'), ('should', 'MD'), ('also', 'RB'), ('be', 'VB'), ('developed', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Accounts', 'combined', 'use', 'linguistic', 'non-linguistic', '(', 'e.g.', ',', 'pointing', ')', 'intbrmation', 'interactive', 'dialogues', 'also', 'developed', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Accounts', 'NNS'), ('combined', 'VBN'), ('use', 'RB'), ('linguistic', 'JJ'), ('non-linguistic', 'JJ'), ('(', '('), ('e.g.', 'JJ'), (',', ','), ('pointing', 'VBG'), (')', ')'), ('intbrmation', 'NN'), ('interactive', 'JJ'), ('dialogues', 'NNS'), ('also', 'RB'), ('developed', 'VBD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Accounts combined', 'combined use', 'use linguistic', 'linguistic non-linguistic', 'non-linguistic (', '( e.g.', 'e.g. ,', ', pointing', 'pointing )', ') intbrmation', 'intbrmation interactive', 'interactive dialogues', 'dialogues also', 'also developed', 'developed .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Accounts combined use', 'combined use linguistic', 'use linguistic non-linguistic', 'linguistic non-linguistic (', 'non-linguistic ( e.g.', '( e.g. ,', 'e.g. , pointing', ', pointing )', 'pointing ) intbrmation', ') intbrmation interactive', 'intbrmation interactive dialogues', 'interactive dialogues also', 'dialogues also developed', 'also developed .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['intbrmation'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['account', 'combin', 'use', 'linguist', 'non-linguist', '(', 'e.g.', ',', 'point', ')', 'intbrmat', 'interact', 'dialogu', 'also', 'develop', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['account', 'combin', 'use', 'linguist', 'non-linguist', '(', 'e.g.', ',', 'point', ')', 'intbrmat', 'interact', 'dialogu', 'also', 'develop', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Accounts', 'combined', 'use', 'linguistic', 'non-linguistic', '(', 'e.g.', ',', 'pointing', ')', 'intbrmation', 'interactive', 'dialogue', 'also', 'developed', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

67 --> The particular styles of  certain sublanguages, e.g., Army Operations Orders, should also be accommodated. 


 ---- TOKENS ----

 ['The', 'particular', 'styles', 'of', 'certain', 'sublanguages', ',', 'e.g.', ',', 'Army', 'Operations', 'Orders', ',', 'should', 'also', 'be', 'accommodated', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('The', 'DT'), ('particular', 'JJ'), ('styles', 'NNS'), ('of', 'IN'), ('certain', 'JJ'), ('sublanguages', 'NNS'), (',', ','), ('e.g.', 'NN'), (',', ','), ('Army', 'NNP'), ('Operations', 'NNP'), ('Orders', 'NNP'), (',', ','), ('should', 'MD'), ('also', 'RB'), ('be', 'VB'), ('accommodated', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['particular', 'styles', 'certain', 'sublanguages', ',', 'e.g.', ',', 'Army', 'Operations', 'Orders', ',', 'also', 'accommodated', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('particular', 'JJ'), ('styles', 'NNS'), ('certain', 'JJ'), ('sublanguages', 'NNS'), (',', ','), ('e.g.', 'NN'), (',', ','), ('Army', 'NNP'), ('Operations', 'NNP'), ('Orders', 'NNP'), (',', ','), ('also', 'RB'), ('accommodated', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['particular styles', 'styles certain', 'certain sublanguages', 'sublanguages ,', ', e.g.', 'e.g. ,', ', Army', 'Army Operations', 'Operations Orders', 'Orders ,', ', also', 'also accommodated', 'accommodated .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['particular styles certain', 'styles certain sublanguages', 'certain sublanguages ,', 'sublanguages , e.g.', ', e.g. ,', 'e.g. , Army', ', Army Operations', 'Army Operations Orders', 'Operations Orders ,', 'Orders , also', ', also accommodated', 'also accommodated .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['e.g.'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Army Operations Orders']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['particular', 'style', 'certain', 'sublanguag', ',', 'e.g.', ',', 'armi', 'oper', 'order', ',', 'also', 'accommod', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['particular', 'style', 'certain', 'sublanguag', ',', 'e.g.', ',', 'armi', 'oper', 'order', ',', 'also', 'accommod', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['particular', 'style', 'certain', 'sublanguages', ',', 'e.g.', ',', 'Army', 'Operations', 'Orders', ',', 'also', 'accommodated', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

68 --> Acquisition of information necessary to understanding and creating communication. 


 ---- TOKENS ----

 ['Acquisition', 'of', 'information', 'necessary', 'to', 'understanding', 'and', 'creating', 'communication', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('Acquisition', 'NNP'), ('of', 'IN'), ('information', 'NN'), ('necessary', 'JJ'), ('to', 'TO'), ('understanding', 'JJ'), ('and', 'CC'), ('creating', 'VBG'), ('communication', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Acquisition', 'information', 'necessary', 'understanding', 'creating', 'communication', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('Acquisition', 'NNP'), ('information', 'NN'), ('necessary', 'JJ'), ('understanding', 'NN'), ('creating', 'VBG'), ('communication', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Acquisition information', 'information necessary', 'necessary understanding', 'understanding creating', 'creating communication', 'communication .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['Acquisition information necessary', 'information necessary understanding', 'necessary understanding creating', 'understanding creating communication', 'creating communication .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['information', 'necessary understanding', 'communication'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Acquisition']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['acquisit', 'inform', 'necessari', 'understand', 'creat', 'commun', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['acquisit', 'inform', 'necessari', 'understand', 'creat', 'communic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['Acquisition', 'information', 'necessary', 'understanding', 'creating', 'communication', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

69 --> This includes  both linguistic (e.g., words and grammatical forms) and non-linguistic information (e.g., the semantics of icons)  used by real users performing real tasks in a given domain of discourse. 


 ---- TOKENS ----

 ['This', 'includes', 'both', 'linguistic', '(', 'e.g.', ',', 'words', 'and', 'grammatical', 'forms', ')', 'and', 'non-linguistic', 'information', '(', 'e.g.', ',', 'the', 'semantics', 'of', 'icons', ')', 'used', 'by', 'real', 'users', 'performing', 'real', 'tasks', 'in', 'a', 'given', 'domain', 'of', 'discourse', '.'] 

 TOTAL TOKENS ==> 37

 ---- POST ----

 [('This', 'DT'), ('includes', 'VBZ'), ('both', 'CC'), ('linguistic', 'JJ'), ('(', '('), ('e.g.', 'JJ'), (',', ','), ('words', 'NNS'), ('and', 'CC'), ('grammatical', 'JJ'), ('forms', 'NNS'), (')', ')'), ('and', 'CC'), ('non-linguistic', 'JJ'), ('information', 'NN'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('the', 'DT'), ('semantics', 'NNS'), ('of', 'IN'), ('icons', 'NNS'), (')', ')'), ('used', 'VBN'), ('by', 'IN'), ('real', 'JJ'), ('users', 'NNS'), ('performing', 'VBG'), ('real', 'JJ'), ('tasks', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('given', 'VBN'), ('domain', 'NN'), ('of', 'IN'), ('discourse', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['includes', 'linguistic', '(', 'e.g.', ',', 'words', 'grammatical', 'forms', ')', 'non-linguistic', 'information', '(', 'e.g.', ',', 'semantics', 'icons', ')', 'used', 'real', 'users', 'performing', 'real', 'tasks', 'given', 'domain', 'discourse', '.']

 TOTAL FILTERED TOKENS ==>  27

 ---- POST FOR FILTERED TOKENS ----

 [('includes', 'VBZ'), ('linguistic', 'JJ'), ('(', '('), ('e.g.', 'JJ'), (',', ','), ('words', 'NNS'), ('grammatical', 'JJ'), ('forms', 'NNS'), (')', ')'), ('non-linguistic', 'JJ'), ('information', 'NN'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('semantics', 'NNS'), ('icons', 'NNS'), (')', ')'), ('used', 'VBD'), ('real', 'JJ'), ('users', 'NNS'), ('performing', 'VBG'), ('real', 'JJ'), ('tasks', 'NNS'), ('given', 'VBN'), ('domain', 'VBP'), ('discourse', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['includes linguistic', 'linguistic (', '( e.g.', 'e.g. ,', ', words', 'words grammatical', 'grammatical forms', 'forms )', ') non-linguistic', 'non-linguistic information', 'information (', '( e.g.', 'e.g. ,', ', semantics', 'semantics icons', 'icons )', ') used', 'used real', 'real users', 'users performing', 'performing real', 'real tasks', 'tasks given', 'given domain', 'domain discourse', 'discourse .'] 

 TOTAL BIGRAMS --> 26 



 ---- TRI-GRAMS ---- 

 ['includes linguistic (', 'linguistic ( e.g.', '( e.g. ,', 'e.g. , words', ', words grammatical', 'words grammatical forms', 'grammatical forms )', 'forms ) non-linguistic', ') non-linguistic information', 'non-linguistic information (', 'information ( e.g.', '( e.g. ,', 'e.g. , semantics', ', semantics icons', 'semantics icons )', 'icons ) used', ') used real', 'used real users', 'real users performing', 'users performing real', 'performing real tasks', 'real tasks given', 'tasks given domain', 'given domain discourse', 'domain discourse .'] 

 TOTAL TRIGRAMS --> 25 



 ---- NOUN PHRASES ---- 

 ['non-linguistic information', 'discourse'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['includ', 'linguist', '(', 'e.g.', ',', 'word', 'grammat', 'form', ')', 'non-linguist', 'inform', '(', 'e.g.', ',', 'semant', 'icon', ')', 'use', 'real', 'user', 'perform', 'real', 'task', 'given', 'domain', 'discours', '.']

 TOTAL PORTER STEM WORDS ==> 27



 ---- SNOWBALL STEMMING ----

['includ', 'linguist', '(', 'e.g.', ',', 'word', 'grammat', 'form', ')', 'non-linguist', 'inform', '(', 'e.g.', ',', 'semant', 'icon', ')', 'use', 'real', 'user', 'perform', 'real', 'task', 'given', 'domain', 'discours', '.']

 TOTAL SNOWBALL STEM WORDS ==> 27



 ---- LEMMATIZATION ----

['includes', 'linguistic', '(', 'e.g.', ',', 'word', 'grammatical', 'form', ')', 'non-linguistic', 'information', '(', 'e.g.', ',', 'semantics', 'icon', ')', 'used', 'real', 'user', 'performing', 'real', 'task', 'given', 'domain', 'discourse', '.']

 TOTAL LEMMATIZE WORDS ==> 27

************************************************************************************************************************

70 --> A calculus of partial information. 


 ---- TOKENS ----

 ['A', 'calculus', 'of', 'partial', 'information', '.'] 

 TOTAL TOKENS ==> 6

 ---- POST ----

 [('A', 'DT'), ('calculus', 'NN'), ('of', 'IN'), ('partial', 'JJ'), ('information', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['calculus', 'partial', 'information', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('calculus', 'JJ'), ('partial', 'JJ'), ('information', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['calculus partial', 'partial information', 'information .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['calculus partial information', 'partial information .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 ['calculus partial information'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['calculu', 'partial', 'inform', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['calculus', 'partial', 'inform', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['calculus', 'partial', 'information', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

71 --> In both single- and multiple-sentence texts and dialogues, generation  and interpretation requires combining information from a number of sources, such as morphological, syntactic,  semantic, pragmatic, and prosodic information. 


 ---- TOKENS ----

 ['In', 'both', 'single-', 'and', 'multiple-sentence', 'texts', 'and', 'dialogues', ',', 'generation', 'and', 'interpretation', 'requires', 'combining', 'information', 'from', 'a', 'number', 'of', 'sources', ',', 'such', 'as', 'morphological', ',', 'syntactic', ',', 'semantic', ',', 'pragmatic', ',', 'and', 'prosodic', 'information', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('In', 'IN'), ('both', 'DT'), ('single-', 'JJ'), ('and', 'CC'), ('multiple-sentence', 'JJ'), ('texts', 'NN'), ('and', 'CC'), ('dialogues', 'NNS'), (',', ','), ('generation', 'NN'), ('and', 'CC'), ('interpretation', 'NN'), ('requires', 'VBZ'), ('combining', 'VBG'), ('information', 'NN'), ('from', 'IN'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('sources', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('morphological', 'JJ'), (',', ','), ('syntactic', 'JJ'), (',', ','), ('semantic', 'JJ'), (',', ','), ('pragmatic', 'JJ'), (',', ','), ('and', 'CC'), ('prosodic', 'JJ'), ('information', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['single-', 'multiple-sentence', 'texts', 'dialogues', ',', 'generation', 'interpretation', 'requires', 'combining', 'information', 'number', 'sources', ',', 'morphological', ',', 'syntactic', ',', 'semantic', ',', 'pragmatic', ',', 'prosodic', 'information', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('single-', 'JJ'), ('multiple-sentence', 'NN'), ('texts', 'NN'), ('dialogues', 'NNS'), (',', ','), ('generation', 'NN'), ('interpretation', 'NN'), ('requires', 'VBZ'), ('combining', 'VBG'), ('information', 'NN'), ('number', 'NN'), ('sources', 'NNS'), (',', ','), ('morphological', 'JJ'), (',', ','), ('syntactic', 'JJ'), (',', ','), ('semantic', 'JJ'), (',', ','), ('pragmatic', 'JJ'), (',', ','), ('prosodic', 'JJ'), ('information', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['single- multiple-sentence', 'multiple-sentence texts', 'texts dialogues', 'dialogues ,', ', generation', 'generation interpretation', 'interpretation requires', 'requires combining', 'combining information', 'information number', 'number sources', 'sources ,', ', morphological', 'morphological ,', ', syntactic', 'syntactic ,', ', semantic', 'semantic ,', ', pragmatic', 'pragmatic ,', ', prosodic', 'prosodic information', 'information .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['single- multiple-sentence texts', 'multiple-sentence texts dialogues', 'texts dialogues ,', 'dialogues , generation', ', generation interpretation', 'generation interpretation requires', 'interpretation requires combining', 'requires combining information', 'combining information number', 'information number sources', 'number sources ,', 'sources , morphological', ', morphological ,', 'morphological , syntactic', ', syntactic ,', 'syntactic , semantic', ', semantic ,', 'semantic , pragmatic', ', pragmatic ,', 'pragmatic , prosodic', ', prosodic information', 'prosodic information .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['single- multiple-sentence', 'texts', 'generation', 'interpretation', 'information', 'number', 'prosodic information'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['single-', 'multiple-sent', 'text', 'dialogu', ',', 'gener', 'interpret', 'requir', 'combin', 'inform', 'number', 'sourc', ',', 'morpholog', ',', 'syntact', ',', 'semant', ',', 'pragmat', ',', 'prosod', 'inform', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['single-', 'multiple-sent', 'text', 'dialogu', ',', 'generat', 'interpret', 'requir', 'combin', 'inform', 'number', 'sourc', ',', 'morpholog', ',', 'syntact', ',', 'semant', ',', 'pragmat', ',', 'prosod', 'inform', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['single-', 'multiple-sentence', 'text', 'dialogue', ',', 'generation', 'interpretation', 'requires', 'combining', 'information', 'number', 'source', ',', 'morphological', ',', 'syntactic', ',', 'semantic', ',', 'pragmatic', ',', 'prosodic', 'information', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

72 --> This is particularly true with novel, errorful, and incomplete  expressions. 


 ---- TOKENS ----

 ['This', 'is', 'particularly', 'true', 'with', 'novel', ',', 'errorful', ',', 'and', 'incomplete', 'expressions', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('This', 'DT'), ('is', 'VBZ'), ('particularly', 'RB'), ('true', 'JJ'), ('with', 'IN'), ('novel', 'NN'), (',', ','), ('errorful', 'JJ'), (',', ','), ('and', 'CC'), ('incomplete', 'JJ'), ('expressions', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['particularly', 'true', 'novel', ',', 'errorful', ',', 'incomplete', 'expressions', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('particularly', 'RB'), ('true', 'JJ'), ('novel', 'NN'), (',', ','), ('errorful', 'JJ'), (',', ','), ('incomplete', 'JJ'), ('expressions', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['particularly true', 'true novel', 'novel ,', ', errorful', 'errorful ,', ', incomplete', 'incomplete expressions', 'expressions .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['particularly true novel', 'true novel ,', 'novel , errorful', ', errorful ,', 'errorful , incomplete', ', incomplete expressions', 'incomplete expressions .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['true novel'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['particularli', 'true', 'novel', ',', 'error', ',', 'incomplet', 'express', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['particular', 'true', 'novel', ',', 'error', ',', 'incomplet', 'express', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['particularly', 'true', 'novel', ',', 'errorful', ',', 'incomplete', 'expression', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

73 --> Current systems are limited in the kind of information-they bring to hear on interpretation, and the  processes by which they do so. 


 ---- TOKENS ----

 ['Current', 'systems', 'are', 'limited', 'in', 'the', 'kind', 'of', 'information-they', 'bring', 'to', 'hear', 'on', 'interpretation', ',', 'and', 'the', 'processes', 'by', 'which', 'they', 'do', 'so', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Current', 'JJ'), ('systems', 'NNS'), ('are', 'VBP'), ('limited', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('kind', 'NN'), ('of', 'IN'), ('information-they', 'JJ'), ('bring', 'NN'), ('to', 'TO'), ('hear', 'VB'), ('on', 'IN'), ('interpretation', 'NN'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('processes', 'NNS'), ('by', 'IN'), ('which', 'WDT'), ('they', 'PRP'), ('do', 'VBP'), ('so', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Current', 'systems', 'limited', 'kind', 'information-they', 'bring', 'hear', 'interpretation', ',', 'processes', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Current', 'JJ'), ('systems', 'NNS'), ('limited', 'VBD'), ('kind', 'NN'), ('information-they', 'JJ'), ('bring', 'NN'), ('hear', 'JJ'), ('interpretation', 'NN'), (',', ','), ('processes', 'VBZ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Current systems', 'systems limited', 'limited kind', 'kind information-they', 'information-they bring', 'bring hear', 'hear interpretation', 'interpretation ,', ', processes', 'processes .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Current systems limited', 'systems limited kind', 'limited kind information-they', 'kind information-they bring', 'information-they bring hear', 'bring hear interpretation', 'hear interpretation ,', 'interpretation , processes', ', processes .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['kind', 'information-they bring', 'hear interpretation'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['current', 'system', 'limit', 'kind', 'information-they', 'bring', 'hear', 'interpret', ',', 'process', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['current', 'system', 'limit', 'kind', 'information-they', 'bring', 'hear', 'interpret', ',', 'process', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Current', 'system', 'limited', 'kind', 'information-they', 'bring', 'hear', 'interpretation', ',', 'process', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

74 --> Both logical and statistical methods may be further investigated. 


 ---- TOKENS ----

 ['Both', 'logical', 'and', 'statistical', 'methods', 'may', 'be', 'further', 'investigated', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('Both', 'DT'), ('logical', 'JJ'), ('and', 'CC'), ('statistical', 'JJ'), ('methods', 'NNS'), ('may', 'MD'), ('be', 'VB'), ('further', 'RB'), ('investigated', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['logical', 'statistical', 'methods', 'may', 'investigated', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('logical', 'JJ'), ('statistical', 'JJ'), ('methods', 'NNS'), ('may', 'MD'), ('investigated', 'VB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['logical statistical', 'statistical methods', 'methods may', 'may investigated', 'investigated .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['logical statistical methods', 'statistical methods may', 'methods may investigated', 'may investigated .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['logic', 'statist', 'method', 'may', 'investig', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['logic', 'statist', 'method', 'may', 'investig', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['logical', 'statistical', 'method', 'may', 'investigated', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

75 --> 1.2.4. 


 ---- TOKENS ----

 ['1.2.4', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1.2.4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.2.4', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1.2.4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.2.4 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.2.4', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1.2.4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1.2.4', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

76 --> Non-technical Barriers  Lack of Leverage. 


 ---- TOKENS ----

 ['Non-technical', 'Barriers', 'Lack', 'of', 'Leverage', '.'] 

 TOTAL TOKENS ==> 6

 ---- POST ----

 [('Non-technical', 'JJ'), ('Barriers', 'NNP'), ('Lack', 'NNP'), ('of', 'IN'), ('Leverage', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Non-technical', 'Barriers', 'Lack', 'Leverage', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('Non-technical', 'JJ'), ('Barriers', 'NNP'), ('Lack', 'NNP'), ('Leverage', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Non-technical Barriers', 'Barriers Lack', 'Lack Leverage', 'Leverage .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['Non-technical Barriers Lack', 'Barriers Lack Leverage', 'Lack Leverage .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['Barriers Lack Leverage']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['non-techn', 'barrier', 'lack', 'leverag', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['non-techn', 'barrier', 'lack', 'leverag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['Non-technical', 'Barriers', 'Lack', 'Leverage', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

77 --> Building an NL system requires an extensive effort over several years. 


 ---- TOKENS ----

 ['Building', 'an', 'NL', 'system', 'requires', 'an', 'extensive', 'effort', 'over', 'several', 'years', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('Building', 'VBG'), ('an', 'DT'), ('NL', 'NNP'), ('system', 'NN'), ('requires', 'VBZ'), ('an', 'DT'), ('extensive', 'JJ'), ('effort', 'NN'), ('over', 'IN'), ('several', 'JJ'), ('years', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Building', 'NL', 'system', 'requires', 'extensive', 'effort', 'several', 'years', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Building', 'NNP'), ('NL', 'NNP'), ('system', 'NN'), ('requires', 'VBZ'), ('extensive', 'JJ'), ('effort', 'NN'), ('several', 'JJ'), ('years', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Building NL', 'NL system', 'system requires', 'requires extensive', 'extensive effort', 'effort several', 'several years', 'years .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Building NL system', 'NL system requires', 'system requires extensive', 'requires extensive effort', 'extensive effort several', 'effort several years', 'several years .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['system', 'extensive effort'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['build', 'nl', 'system', 'requir', 'extens', 'effort', 'sever', 'year', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['build', 'nl', 'system', 'requir', 'extens', 'effort', 'sever', 'year', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Building', 'NL', 'system', 'requires', 'extensive', 'effort', 'several', 'year', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

78 --> Most  researchers lack the resources to produce a complete system and lack access to state-of-the-art software for some  components (e.g., parsers, large grammars, task-specific lexicons, knowledge representation systems, semantic  interpreters). 


 ---- TOKENS ----

 ['Most', 'researchers', 'lack', 'the', 'resources', 'to', 'produce', 'a', 'complete', 'system', 'and', 'lack', 'access', 'to', 'state-of-the-art', 'software', 'for', 'some', 'components', '(', 'e.g.', ',', 'parsers', ',', 'large', 'grammars', ',', 'task-specific', 'lexicons', ',', 'knowledge', 'representation', 'systems', ',', 'semantic', 'interpreters', ')', '.'] 

 TOTAL TOKENS ==> 38

 ---- POST ----

 [('Most', 'JJS'), ('researchers', 'NNS'), ('lack', 'VBP'), ('the', 'DT'), ('resources', 'NNS'), ('to', 'TO'), ('produce', 'VB'), ('a', 'DT'), ('complete', 'JJ'), ('system', 'NN'), ('and', 'CC'), ('lack', 'NN'), ('access', 'NN'), ('to', 'TO'), ('state-of-the-art', 'JJ'), ('software', 'NN'), ('for', 'IN'), ('some', 'DT'), ('components', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('parsers', 'NNS'), (',', ','), ('large', 'JJ'), ('grammars', 'NNS'), (',', ','), ('task-specific', 'JJ'), ('lexicons', 'NNS'), (',', ','), ('knowledge', 'NN'), ('representation', 'NN'), ('systems', 'NNS'), (',', ','), ('semantic', 'JJ'), ('interpreters', 'NNS'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['researchers', 'lack', 'resources', 'produce', 'complete', 'system', 'lack', 'access', 'state-of-the-art', 'software', 'components', '(', 'e.g.', ',', 'parsers', ',', 'large', 'grammars', ',', 'task-specific', 'lexicons', ',', 'knowledge', 'representation', 'systems', ',', 'semantic', 'interpreters', ')', '.']

 TOTAL FILTERED TOKENS ==>  30

 ---- POST FOR FILTERED TOKENS ----

 [('researchers', 'NNS'), ('lack', 'VBP'), ('resources', 'NNS'), ('produce', 'VBP'), ('complete', 'JJ'), ('system', 'NN'), ('lack', 'JJ'), ('access', 'NN'), ('state-of-the-art', 'JJ'), ('software', 'NN'), ('components', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('parsers', 'NNS'), (',', ','), ('large', 'JJ'), ('grammars', 'NNS'), (',', ','), ('task-specific', 'JJ'), ('lexicons', 'NNS'), (',', ','), ('knowledge', 'NN'), ('representation', 'NN'), ('systems', 'NNS'), (',', ','), ('semantic', 'JJ'), ('interpreters', 'NNS'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['researchers lack', 'lack resources', 'resources produce', 'produce complete', 'complete system', 'system lack', 'lack access', 'access state-of-the-art', 'state-of-the-art software', 'software components', 'components (', '( e.g.', 'e.g. ,', ', parsers', 'parsers ,', ', large', 'large grammars', 'grammars ,', ', task-specific', 'task-specific lexicons', 'lexicons ,', ', knowledge', 'knowledge representation', 'representation systems', 'systems ,', ', semantic', 'semantic interpreters', 'interpreters )', ') .'] 

 TOTAL BIGRAMS --> 29 



 ---- TRI-GRAMS ---- 

 ['researchers lack resources', 'lack resources produce', 'resources produce complete', 'produce complete system', 'complete system lack', 'system lack access', 'lack access state-of-the-art', 'access state-of-the-art software', 'state-of-the-art software components', 'software components (', 'components ( e.g.', '( e.g. ,', 'e.g. , parsers', ', parsers ,', 'parsers , large', ', large grammars', 'large grammars ,', 'grammars , task-specific', ', task-specific lexicons', 'task-specific lexicons ,', 'lexicons , knowledge', ', knowledge representation', 'knowledge representation systems', 'representation systems ,', 'systems , semantic', ', semantic interpreters', 'semantic interpreters )', 'interpreters ) .'] 

 TOTAL TRIGRAMS --> 28 



 ---- NOUN PHRASES ---- 

 ['complete system', 'lack access', 'state-of-the-art software'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['research', 'lack', 'resourc', 'produc', 'complet', 'system', 'lack', 'access', 'state-of-the-art', 'softwar', 'compon', '(', 'e.g.', ',', 'parser', ',', 'larg', 'grammar', ',', 'task-specif', 'lexicon', ',', 'knowledg', 'represent', 'system', ',', 'semant', 'interpret', ')', '.']

 TOTAL PORTER STEM WORDS ==> 30



 ---- SNOWBALL STEMMING ----

['research', 'lack', 'resourc', 'produc', 'complet', 'system', 'lack', 'access', 'state-of-the-art', 'softwar', 'compon', '(', 'e.g.', ',', 'parser', ',', 'larg', 'grammar', ',', 'task-specif', 'lexicon', ',', 'knowledg', 'represent', 'system', ',', 'semant', 'interpret', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 30



 ---- LEMMATIZATION ----

['researcher', 'lack', 'resource', 'produce', 'complete', 'system', 'lack', 'access', 'state-of-the-art', 'software', 'component', '(', 'e.g.', ',', 'parser', ',', 'large', 'grammar', ',', 'task-specific', 'lexicon', ',', 'knowledge', 'representation', 'system', ',', 'semantic', 'interpreter', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 30

************************************************************************************************************************

79 --> Having such components would let them concentrate their efforts on novel work, demonstrate a  complete system, and test individual component theones. 


 ---- TOKENS ----

 ['Having', 'such', 'components', 'would', 'let', 'them', 'concentrate', 'their', 'efforts', 'on', 'novel', 'work', ',', 'demonstrate', 'a', 'complete', 'system', ',', 'and', 'test', 'individual', 'component', 'theones', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Having', 'VBG'), ('such', 'JJ'), ('components', 'NNS'), ('would', 'MD'), ('let', 'VB'), ('them', 'PRP'), ('concentrate', 'VB'), ('their', 'PRP$'), ('efforts', 'NNS'), ('on', 'IN'), ('novel', 'JJ'), ('work', 'NN'), (',', ','), ('demonstrate', 'VB'), ('a', 'DT'), ('complete', 'JJ'), ('system', 'NN'), (',', ','), ('and', 'CC'), ('test', 'JJS'), ('individual', 'JJ'), ('component', 'NN'), ('theones', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['components', 'would', 'let', 'concentrate', 'efforts', 'novel', 'work', ',', 'demonstrate', 'complete', 'system', ',', 'test', 'individual', 'component', 'theones', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('components', 'NNS'), ('would', 'MD'), ('let', 'VB'), ('concentrate', 'VB'), ('efforts', 'NNS'), ('novel', 'JJ'), ('work', 'NN'), (',', ','), ('demonstrate', 'VB'), ('complete', 'JJ'), ('system', 'NN'), (',', ','), ('test', 'VBP'), ('individual', 'JJ'), ('component', 'NN'), ('theones', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['components would', 'would let', 'let concentrate', 'concentrate efforts', 'efforts novel', 'novel work', 'work ,', ', demonstrate', 'demonstrate complete', 'complete system', 'system ,', ', test', 'test individual', 'individual component', 'component theones', 'theones .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['components would let', 'would let concentrate', 'let concentrate efforts', 'concentrate efforts novel', 'efforts novel work', 'novel work ,', 'work , demonstrate', ', demonstrate complete', 'demonstrate complete system', 'complete system ,', 'system , test', ', test individual', 'test individual component', 'individual component theones', 'component theones .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['novel work', 'complete system', 'individual component'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['compon', 'would', 'let', 'concentr', 'effort', 'novel', 'work', ',', 'demonstr', 'complet', 'system', ',', 'test', 'individu', 'compon', 'theon', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['compon', 'would', 'let', 'concentr', 'effort', 'novel', 'work', ',', 'demonstr', 'complet', 'system', ',', 'test', 'individu', 'compon', 'theon', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['component', 'would', 'let', 'concentrate', 'effort', 'novel', 'work', ',', 'demonstrate', 'complete', 'system', ',', 'test', 'individual', 'component', 'theones', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

80 --> Maximal sharing of components requires that a few  common tasks be selected by the community and that appropriate backend systems (databases, simulators, expert  systems, etc.) 


 ---- TOKENS ----

 ['Maximal', 'sharing', 'of', 'components', 'requires', 'that', 'a', 'few', 'common', 'tasks', 'be', 'selected', 'by', 'the', 'community', 'and', 'that', 'appropriate', 'backend', 'systems', '(', 'databases', ',', 'simulators', ',', 'expert', 'systems', ',', 'etc', '.', ')'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('Maximal', 'NNP'), ('sharing', 'NN'), ('of', 'IN'), ('components', 'NNS'), ('requires', 'VBZ'), ('that', 'IN'), ('a', 'DT'), ('few', 'JJ'), ('common', 'JJ'), ('tasks', 'NNS'), ('be', 'VB'), ('selected', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('community', 'NN'), ('and', 'CC'), ('that', 'DT'), ('appropriate', 'JJ'), ('backend', 'NN'), ('systems', 'NNS'), ('(', '('), ('databases', 'NNS'), (',', ','), ('simulators', 'NNS'), (',', ','), ('expert', 'JJ'), ('systems', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Maximal', 'sharing', 'components', 'requires', 'common', 'tasks', 'selected', 'community', 'appropriate', 'backend', 'systems', '(', 'databases', ',', 'simulators', ',', 'expert', 'systems', ',', 'etc', '.', ')']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('Maximal', 'NNP'), ('sharing', 'VBG'), ('components', 'NNS'), ('requires', 'VBZ'), ('common', 'JJ'), ('tasks', 'NNS'), ('selected', 'VBN'), ('community', 'NN'), ('appropriate', 'JJ'), ('backend', 'NN'), ('systems', 'NNS'), ('(', '('), ('databases', 'NNS'), (',', ','), ('simulators', 'NNS'), (',', ','), ('expert', 'JJ'), ('systems', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')')] 



 ---- BI-GRAMS ---- 

 ['Maximal sharing', 'sharing components', 'components requires', 'requires common', 'common tasks', 'tasks selected', 'selected community', 'community appropriate', 'appropriate backend', 'backend systems', 'systems (', '( databases', 'databases ,', ', simulators', 'simulators ,', ', expert', 'expert systems', 'systems ,', ', etc', 'etc .', '. )'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['Maximal sharing components', 'sharing components requires', 'components requires common', 'requires common tasks', 'common tasks selected', 'tasks selected community', 'selected community appropriate', 'community appropriate backend', 'appropriate backend systems', 'backend systems (', 'systems ( databases', '( databases ,', 'databases , simulators', ', simulators ,', 'simulators , expert', ', expert systems', 'expert systems ,', 'systems , etc', ', etc .', 'etc . )'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['community', 'appropriate backend'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Maximal']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['maxim', 'share', 'compon', 'requir', 'common', 'task', 'select', 'commun', 'appropri', 'backend', 'system', '(', 'databas', ',', 'simul', ',', 'expert', 'system', ',', 'etc', '.', ')']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['maxim', 'share', 'compon', 'requir', 'common', 'task', 'select', 'communiti', 'appropri', 'backend', 'system', '(', 'databas', ',', 'simul', ',', 'expert', 'system', ',', 'etc', '.', ')']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['Maximal', 'sharing', 'component', 'requires', 'common', 'task', 'selected', 'community', 'appropriate', 'backend', 'system', '(', 'database', ',', 'simulator', ',', 'expert', 'system', ',', 'etc', '.', ')']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

81 --> be made widely available. 


 ---- TOKENS ----

 ['be', 'made', 'widely', 'available', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('be', 'VB'), ('made', 'VBN'), ('widely', 'RB'), ('available', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['made', 'widely', 'available', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('made', 'VBN'), ('widely', 'RB'), ('available', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['made widely', 'widely available', 'available .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['made widely available', 'widely available .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['made', 'wide', 'avail', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['made', 'wide', 'avail', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['made', 'widely', 'available', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

82 --> Leverage can he further increased by development and support of key NL  components. 


 ---- TOKENS ----

 ['Leverage', 'can', 'he', 'further', 'increased', 'by', 'development', 'and', 'support', 'of', 'key', 'NL', 'components', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Leverage', 'NN'), ('can', 'MD'), ('he', 'PRP'), ('further', 'RB'), ('increased', 'VBD'), ('by', 'IN'), ('development', 'NN'), ('and', 'CC'), ('support', 'NN'), ('of', 'IN'), ('key', 'JJ'), ('NL', 'NNP'), ('components', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Leverage', 'increased', 'development', 'support', 'key', 'NL', 'components', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Leverage', 'NN'), ('increased', 'VBD'), ('development', 'NN'), ('support', 'NN'), ('key', 'NN'), ('NL', 'NNP'), ('components', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Leverage increased', 'increased development', 'development support', 'support key', 'key NL', 'NL components', 'components .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Leverage increased development', 'increased development support', 'development support key', 'support key NL', 'key NL components', 'NL components .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['Leverage', 'development', 'support', 'key'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Leverage']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['leverag', 'increas', 'develop', 'support', 'key', 'nl', 'compon', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['leverag', 'increas', 'develop', 'support', 'key', 'nl', 'compon', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Leverage', 'increased', 'development', 'support', 'key', 'NL', 'component', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

83 --> Collection and dissemination of large linguistic data sets will support development of broad-coverage  grammars, better lexicons, systematic evaluation procedures, and statistical measures. 


 ---- TOKENS ----

 ['Collection', 'and', 'dissemination', 'of', 'large', 'linguistic', 'data', 'sets', 'will', 'support', 'development', 'of', 'broad-coverage', 'grammars', ',', 'better', 'lexicons', ',', 'systematic', 'evaluation', 'procedures', ',', 'and', 'statistical', 'measures', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Collection', 'NN'), ('and', 'CC'), ('dissemination', 'NN'), ('of', 'IN'), ('large', 'JJ'), ('linguistic', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('will', 'MD'), ('support', 'VB'), ('development', 'NN'), ('of', 'IN'), ('broad-coverage', 'NN'), ('grammars', 'NNS'), (',', ','), ('better', 'JJR'), ('lexicons', 'NNS'), (',', ','), ('systematic', 'JJ'), ('evaluation', 'NN'), ('procedures', 'NNS'), (',', ','), ('and', 'CC'), ('statistical', 'JJ'), ('measures', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Collection', 'dissemination', 'large', 'linguistic', 'data', 'sets', 'support', 'development', 'broad-coverage', 'grammars', ',', 'better', 'lexicons', ',', 'systematic', 'evaluation', 'procedures', ',', 'statistical', 'measures', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('Collection', 'NNP'), ('dissemination', 'NN'), ('large', 'JJ'), ('linguistic', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('support', 'VBP'), ('development', 'NN'), ('broad-coverage', 'NN'), ('grammars', 'NNS'), (',', ','), ('better', 'JJR'), ('lexicons', 'NNS'), (',', ','), ('systematic', 'JJ'), ('evaluation', 'NN'), ('procedures', 'NNS'), (',', ','), ('statistical', 'JJ'), ('measures', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Collection dissemination', 'dissemination large', 'large linguistic', 'linguistic data', 'data sets', 'sets support', 'support development', 'development broad-coverage', 'broad-coverage grammars', 'grammars ,', ', better', 'better lexicons', 'lexicons ,', ', systematic', 'systematic evaluation', 'evaluation procedures', 'procedures ,', ', statistical', 'statistical measures', 'measures .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['Collection dissemination large', 'dissemination large linguistic', 'large linguistic data', 'linguistic data sets', 'data sets support', 'sets support development', 'support development broad-coverage', 'development broad-coverage grammars', 'broad-coverage grammars ,', 'grammars , better', ', better lexicons', 'better lexicons ,', 'lexicons , systematic', ', systematic evaluation', 'systematic evaluation procedures', 'evaluation procedures ,', 'procedures , statistical', ', statistical measures', 'statistical measures .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['dissemination', 'development', 'broad-coverage', 'systematic evaluation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Collection']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['collect', 'dissemin', 'larg', 'linguist', 'data', 'set', 'support', 'develop', 'broad-coverag', 'grammar', ',', 'better', 'lexicon', ',', 'systemat', 'evalu', 'procedur', ',', 'statist', 'measur', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['collect', 'dissemin', 'larg', 'linguist', 'data', 'set', 'support', 'develop', 'broad-coverag', 'grammar', ',', 'better', 'lexicon', ',', 'systemat', 'evalu', 'procedur', ',', 'statist', 'measur', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['Collection', 'dissemination', 'large', 'linguistic', 'data', 'set', 'support', 'development', 'broad-coverage', 'grammar', ',', 'better', 'lexicon', ',', 'systematic', 'evaluation', 'procedure', ',', 'statistical', 'measure', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

84 --> Funding. 


 ---- TOKENS ----

 ['Funding', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('Funding', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Funding', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('Funding', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Funding .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 ['Funding'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Funding']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['fund', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['fund', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['Funding', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

85 --> Overall funding for NLP has been strong from 1984 through 1988. 


 ---- TOKENS ----

 ['Overall', 'funding', 'for', 'NLP', 'has', 'been', 'strong', 'from', '1984', 'through', '1988', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('Overall', 'JJ'), ('funding', 'NN'), ('for', 'IN'), ('NLP', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('strong', 'JJ'), ('from', 'IN'), ('1984', 'CD'), ('through', 'IN'), ('1988', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Overall', 'funding', 'NLP', 'strong', '1984', '1988', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('Overall', 'JJ'), ('funding', 'NN'), ('NLP', 'NNP'), ('strong', 'JJ'), ('1984', 'CD'), ('1988', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Overall funding', 'funding NLP', 'NLP strong', 'strong 1984', '1984 1988', '1988 .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['Overall funding NLP', 'funding NLP strong', 'NLP strong 1984', 'strong 1984 1988', '1984 1988 .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['Overall funding'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Overall']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['overal', 'fund', 'nlp', 'strong', '1984', '1988', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['overal', 'fund', 'nlp', 'strong', '1984', '1988', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['Overall', 'funding', 'NLP', 'strong', '1984', '1988', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

86 --> However, DARPA funding  in the last several years has increasingly emphasized technology transfer and near-term results. 


 ---- TOKENS ----

 ['However', ',', 'DARPA', 'funding', 'in', 'the', 'last', 'several', 'years', 'has', 'increasingly', 'emphasized', 'technology', 'transfer', 'and', 'near-term', 'results', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('However', 'RB'), (',', ','), ('DARPA', 'NNP'), ('funding', 'NN'), ('in', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('several', 'JJ'), ('years', 'NNS'), ('has', 'VBZ'), ('increasingly', 'RB'), ('emphasized', 'VBN'), ('technology', 'NN'), ('transfer', 'NN'), ('and', 'CC'), ('near-term', 'JJ'), ('results', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['However', ',', 'DARPA', 'funding', 'last', 'several', 'years', 'increasingly', 'emphasized', 'technology', 'transfer', 'near-term', 'results', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('However', 'RB'), (',', ','), ('DARPA', 'NNP'), ('funding', 'NN'), ('last', 'JJ'), ('several', 'JJ'), ('years', 'NNS'), ('increasingly', 'RB'), ('emphasized', 'VBD'), ('technology', 'NN'), ('transfer', 'NN'), ('near-term', 'JJ'), ('results', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['However ,', ', DARPA', 'DARPA funding', 'funding last', 'last several', 'several years', 'years increasingly', 'increasingly emphasized', 'emphasized technology', 'technology transfer', 'transfer near-term', 'near-term results', 'results .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['However , DARPA', ', DARPA funding', 'DARPA funding last', 'funding last several', 'last several years', 'several years increasingly', 'years increasingly emphasized', 'increasingly emphasized technology', 'emphasized technology transfer', 'technology transfer near-term', 'transfer near-term results', 'near-term results .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['funding', 'technology', 'transfer'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['DARPA']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['howev', ',', 'darpa', 'fund', 'last', 'sever', 'year', 'increasingli', 'emphas', 'technolog', 'transfer', 'near-term', 'result', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['howev', ',', 'darpa', 'fund', 'last', 'sever', 'year', 'increas', 'emphas', 'technolog', 'transfer', 'near-term', 'result', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['However', ',', 'DARPA', 'funding', 'last', 'several', 'year', 'increasingly', 'emphasized', 'technology', 'transfer', 'near-term', 'result', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

87 --> Although this  emphasis has had some positive as well as negative results, the overall trend is cause for concern. 


 ---- TOKENS ----

 ['Although', 'this', 'emphasis', 'has', 'had', 'some', 'positive', 'as', 'well', 'as', 'negative', 'results', ',', 'the', 'overall', 'trend', 'is', 'cause', 'for', 'concern', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Although', 'IN'), ('this', 'DT'), ('emphasis', 'NN'), ('has', 'VBZ'), ('had', 'VBN'), ('some', 'DT'), ('positive', 'JJ'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('negative', 'JJ'), ('results', 'NNS'), (',', ','), ('the', 'DT'), ('overall', 'JJ'), ('trend', 'NN'), ('is', 'VBZ'), ('cause', 'NN'), ('for', 'IN'), ('concern', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Although', 'emphasis', 'positive', 'well', 'negative', 'results', ',', 'overall', 'trend', 'cause', 'concern', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Although', 'IN'), ('emphasis', 'NN'), ('positive', 'JJ'), ('well', 'RB'), ('negative', 'JJ'), ('results', 'NNS'), (',', ','), ('overall', 'JJ'), ('trend', 'NN'), ('cause', 'NN'), ('concern', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Although emphasis', 'emphasis positive', 'positive well', 'well negative', 'negative results', 'results ,', ', overall', 'overall trend', 'trend cause', 'cause concern', 'concern .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Although emphasis positive', 'emphasis positive well', 'positive well negative', 'well negative results', 'negative results ,', 'results , overall', ', overall trend', 'overall trend cause', 'trend cause concern', 'cause concern .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['emphasis', 'overall trend', 'cause', 'concern'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['although', 'emphasi', 'posit', 'well', 'neg', 'result', ',', 'overal', 'trend', 'caus', 'concern', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['although', 'emphasi', 'posit', 'well', 'negat', 'result', ',', 'overal', 'trend', 'caus', 'concern', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Although', 'emphasis', 'positive', 'well', 'negative', 'result', ',', 'overall', 'trend', 'cause', 'concern', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

88 --> On the positive  side, the focus on shorter term performance has forced the community to focus on the development of prototypes  addressing specific tasks in specific domains and to think about evaluation methods and resource sharing. 


 ---- TOKENS ----

 ['On', 'the', 'positive', 'side', ',', 'the', 'focus', 'on', 'shorter', 'term', 'performance', 'has', 'forced', 'the', 'community', 'to', 'focus', 'on', 'the', 'development', 'of', 'prototypes', 'addressing', 'specific', 'tasks', 'in', 'specific', 'domains', 'and', 'to', 'think', 'about', 'evaluation', 'methods', 'and', 'resource', 'sharing', '.'] 

 TOTAL TOKENS ==> 38

 ---- POST ----

 [('On', 'IN'), ('the', 'DT'), ('positive', 'JJ'), ('side', 'NN'), (',', ','), ('the', 'DT'), ('focus', 'NN'), ('on', 'IN'), ('shorter', 'JJR'), ('term', 'NN'), ('performance', 'NN'), ('has', 'VBZ'), ('forced', 'VBN'), ('the', 'DT'), ('community', 'NN'), ('to', 'TO'), ('focus', 'VB'), ('on', 'IN'), ('the', 'DT'), ('development', 'NN'), ('of', 'IN'), ('prototypes', 'NNS'), ('addressing', 'VBG'), ('specific', 'JJ'), ('tasks', 'NNS'), ('in', 'IN'), ('specific', 'JJ'), ('domains', 'NNS'), ('and', 'CC'), ('to', 'TO'), ('think', 'VB'), ('about', 'IN'), ('evaluation', 'NN'), ('methods', 'NNS'), ('and', 'CC'), ('resource', 'NN'), ('sharing', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['positive', 'side', ',', 'focus', 'shorter', 'term', 'performance', 'forced', 'community', 'focus', 'development', 'prototypes', 'addressing', 'specific', 'tasks', 'specific', 'domains', 'think', 'evaluation', 'methods', 'resource', 'sharing', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('positive', 'JJ'), ('side', 'NN'), (',', ','), ('focus', 'NN'), ('shorter', 'JJR'), ('term', 'NN'), ('performance', 'NN'), ('forced', 'VBD'), ('community', 'NN'), ('focus', 'NN'), ('development', 'NN'), ('prototypes', 'NNS'), ('addressing', 'VBG'), ('specific', 'JJ'), ('tasks', 'NNS'), ('specific', 'JJ'), ('domains', 'NNS'), ('think', 'VBP'), ('evaluation', 'NN'), ('methods', 'NNS'), ('resource', 'NN'), ('sharing', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['positive side', 'side ,', ', focus', 'focus shorter', 'shorter term', 'term performance', 'performance forced', 'forced community', 'community focus', 'focus development', 'development prototypes', 'prototypes addressing', 'addressing specific', 'specific tasks', 'tasks specific', 'specific domains', 'domains think', 'think evaluation', 'evaluation methods', 'methods resource', 'resource sharing', 'sharing .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['positive side ,', 'side , focus', ', focus shorter', 'focus shorter term', 'shorter term performance', 'term performance forced', 'performance forced community', 'forced community focus', 'community focus development', 'focus development prototypes', 'development prototypes addressing', 'prototypes addressing specific', 'addressing specific tasks', 'specific tasks specific', 'tasks specific domains', 'specific domains think', 'domains think evaluation', 'think evaluation methods', 'evaluation methods resource', 'methods resource sharing', 'resource sharing .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['positive side', 'focus', 'term', 'performance', 'community', 'focus', 'development', 'evaluation', 'resource', 'sharing'] 

 TOTAL NOUN PHRASES --> 10 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['posit', 'side', ',', 'focu', 'shorter', 'term', 'perform', 'forc', 'commun', 'focu', 'develop', 'prototyp', 'address', 'specif', 'task', 'specif', 'domain', 'think', 'evalu', 'method', 'resourc', 'share', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['posit', 'side', ',', 'focus', 'shorter', 'term', 'perform', 'forc', 'communiti', 'focus', 'develop', 'prototyp', 'address', 'specif', 'task', 'specif', 'domain', 'think', 'evalu', 'method', 'resourc', 'share', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['positive', 'side', ',', 'focus', 'shorter', 'term', 'performance', 'forced', 'community', 'focus', 'development', 'prototype', 'addressing', 'specific', 'task', 'specific', 'domain', 'think', 'evaluation', 'method', 'resource', 'sharing', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

89 --> On the  negative side, it has left little room for developing the theoretical basis of the next generation of systems. 


 ---- TOKENS ----

 ['On', 'the', 'negative', 'side', ',', 'it', 'has', 'left', 'little', 'room', 'for', 'developing', 'the', 'theoretical', 'basis', 'of', 'the', 'next', 'generation', 'of', 'systems', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('On', 'IN'), ('the', 'DT'), ('negative', 'JJ'), ('side', 'NN'), (',', ','), ('it', 'PRP'), ('has', 'VBZ'), ('left', 'VBN'), ('little', 'JJ'), ('room', 'NN'), ('for', 'IN'), ('developing', 'VBG'), ('the', 'DT'), ('theoretical', 'JJ'), ('basis', 'NN'), ('of', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('generation', 'NN'), ('of', 'IN'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['negative', 'side', ',', 'left', 'little', 'room', 'developing', 'theoretical', 'basis', 'next', 'generation', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('negative', 'JJ'), ('side', 'NN'), (',', ','), ('left', 'VBD'), ('little', 'JJ'), ('room', 'NN'), ('developing', 'VBG'), ('theoretical', 'JJ'), ('basis', 'NN'), ('next', 'JJ'), ('generation', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['negative side', 'side ,', ', left', 'left little', 'little room', 'room developing', 'developing theoretical', 'theoretical basis', 'basis next', 'next generation', 'generation systems', 'systems .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['negative side ,', 'side , left', ', left little', 'left little room', 'little room developing', 'room developing theoretical', 'developing theoretical basis', 'theoretical basis next', 'basis next generation', 'next generation systems', 'generation systems .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['negative side', 'little room', 'theoretical basis', 'next generation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['neg', 'side', ',', 'left', 'littl', 'room', 'develop', 'theoret', 'basi', 'next', 'gener', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['negat', 'side', ',', 'left', 'littl', 'room', 'develop', 'theoret', 'basi', 'next', 'generat', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['negative', 'side', ',', 'left', 'little', 'room', 'developing', 'theoretical', 'basis', 'next', 'generation', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

90 --> Some of  this responsibility has been taken on by other sources (notably the Systems Development Foundation and Japanese  industry), but support from the former is coming to an end, and there are obvious reasons for not wanting to depend  too heavily on the latter. 


 ---- TOKENS ----

 ['Some', 'of', 'this', 'responsibility', 'has', 'been', 'taken', 'on', 'by', 'other', 'sources', '(', 'notably', 'the', 'Systems', 'Development', 'Foundation', 'and', 'Japanese', 'industry', ')', ',', 'but', 'support', 'from', 'the', 'former', 'is', 'coming', 'to', 'an', 'end', ',', 'and', 'there', 'are', 'obvious', 'reasons', 'for', 'not', 'wanting', 'to', 'depend', 'too', 'heavily', 'on', 'the', 'latter', '.'] 

 TOTAL TOKENS ==> 49

 ---- POST ----

 [('Some', 'DT'), ('of', 'IN'), ('this', 'DT'), ('responsibility', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('taken', 'VBN'), ('on', 'IN'), ('by', 'IN'), ('other', 'JJ'), ('sources', 'NNS'), ('(', '('), ('notably', 'RB'), ('the', 'DT'), ('Systems', 'NNPS'), ('Development', 'NNP'), ('Foundation', 'NNP'), ('and', 'CC'), ('Japanese', 'JJ'), ('industry', 'NN'), (')', ')'), (',', ','), ('but', 'CC'), ('support', 'NN'), ('from', 'IN'), ('the', 'DT'), ('former', 'JJ'), ('is', 'VBZ'), ('coming', 'VBG'), ('to', 'TO'), ('an', 'DT'), ('end', 'NN'), (',', ','), ('and', 'CC'), ('there', 'EX'), ('are', 'VBP'), ('obvious', 'JJ'), ('reasons', 'NNS'), ('for', 'IN'), ('not', 'RB'), ('wanting', 'VBG'), ('to', 'TO'), ('depend', 'VB'), ('too', 'RB'), ('heavily', 'RB'), ('on', 'IN'), ('the', 'DT'), ('latter', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['responsibility', 'taken', 'sources', '(', 'notably', 'Systems', 'Development', 'Foundation', 'Japanese', 'industry', ')', ',', 'support', 'former', 'coming', 'end', ',', 'obvious', 'reasons', 'wanting', 'depend', 'heavily', 'latter', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('responsibility', 'NN'), ('taken', 'VBN'), ('sources', 'NNS'), ('(', '('), ('notably', 'RB'), ('Systems', 'NNP'), ('Development', 'NNP'), ('Foundation', 'NNP'), ('Japanese', 'NNP'), ('industry', 'NN'), (')', ')'), (',', ','), ('support', 'JJ'), ('former', 'JJ'), ('coming', 'VBG'), ('end', 'NN'), (',', ','), ('obvious', 'JJ'), ('reasons', 'NNS'), ('wanting', 'VBG'), ('depend', 'VBP'), ('heavily', 'RB'), ('latter', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['responsibility taken', 'taken sources', 'sources (', '( notably', 'notably Systems', 'Systems Development', 'Development Foundation', 'Foundation Japanese', 'Japanese industry', 'industry )', ') ,', ', support', 'support former', 'former coming', 'coming end', 'end ,', ', obvious', 'obvious reasons', 'reasons wanting', 'wanting depend', 'depend heavily', 'heavily latter', 'latter .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['responsibility taken sources', 'taken sources (', 'sources ( notably', '( notably Systems', 'notably Systems Development', 'Systems Development Foundation', 'Development Foundation Japanese', 'Foundation Japanese industry', 'Japanese industry )', 'industry ) ,', ') , support', ', support former', 'support former coming', 'former coming end', 'coming end ,', 'end , obvious', ', obvious reasons', 'obvious reasons wanting', 'reasons wanting depend', 'wanting depend heavily', 'depend heavily latter', 'heavily latter .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['responsibility', 'end'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['respons', 'taken', 'sourc', '(', 'notabl', 'system', 'develop', 'foundat', 'japanes', 'industri', ')', ',', 'support', 'former', 'come', 'end', ',', 'obviou', 'reason', 'want', 'depend', 'heavili', 'latter', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['respons', 'taken', 'sourc', '(', 'notabl', 'system', 'develop', 'foundat', 'japanes', 'industri', ')', ',', 'support', 'former', 'come', 'end', ',', 'obvious', 'reason', 'want', 'depend', 'heavili', 'latter', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['responsibility', 'taken', 'source', '(', 'notably', 'Systems', 'Development', 'Foundation', 'Japanese', 'industry', ')', ',', 'support', 'former', 'coming', 'end', ',', 'obvious', 'reason', 'wanting', 'depend', 'heavily', 'latter', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

91 --> Given these factors, we have serious concern for future levels of basic research funding. 


 ---- TOKENS ----

 ['Given', 'these', 'factors', ',', 'we', 'have', 'serious', 'concern', 'for', 'future', 'levels', 'of', 'basic', 'research', 'funding', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('Given', 'VBN'), ('these', 'DT'), ('factors', 'NNS'), (',', ','), ('we', 'PRP'), ('have', 'VBP'), ('serious', 'JJ'), ('concern', 'NN'), ('for', 'IN'), ('future', 'JJ'), ('levels', 'NNS'), ('of', 'IN'), ('basic', 'JJ'), ('research', 'NN'), ('funding', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Given', 'factors', ',', 'serious', 'concern', 'future', 'levels', 'basic', 'research', 'funding', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Given', 'VBN'), ('factors', 'NNS'), (',', ','), ('serious', 'JJ'), ('concern', 'NN'), ('future', 'NN'), ('levels', 'NNS'), ('basic', 'JJ'), ('research', 'NN'), ('funding', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Given factors', 'factors ,', ', serious', 'serious concern', 'concern future', 'future levels', 'levels basic', 'basic research', 'research funding', 'funding .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Given factors ,', 'factors , serious', ', serious concern', 'serious concern future', 'concern future levels', 'future levels basic', 'levels basic research', 'basic research funding', 'research funding .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['serious concern', 'future', 'basic research', 'funding'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['given', 'factor', ',', 'seriou', 'concern', 'futur', 'level', 'basic', 'research', 'fund', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['given', 'factor', ',', 'serious', 'concern', 'futur', 'level', 'basic', 'research', 'fund', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Given', 'factor', ',', 'serious', 'concern', 'future', 'level', 'basic', 'research', 'funding', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

92 --> Training of Researchers. 


 ---- TOKENS ----

 ['Training', 'of', 'Researchers', '.'] 

 TOTAL TOKENS ==> 4

 ---- POST ----

 [('Training', 'NN'), ('of', 'IN'), ('Researchers', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Training', 'Researchers', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Training', 'VBG'), ('Researchers', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Training Researchers', 'Researchers .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Training Researchers .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['train', 'research', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['train', 'research', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Training', 'Researchers', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

93 --> Researchers in NLP need a broad exposure to AI, computer science, linguistics,  logic, and increasingly to probability and statistics. 


 ---- TOKENS ----

 ['Researchers', 'in', 'NLP', 'need', 'a', 'broad', 'exposure', 'to', 'AI', ',', 'computer', 'science', ',', 'linguistics', ',', 'logic', ',', 'and', 'increasingly', 'to', 'probability', 'and', 'statistics', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Researchers', 'NNS'), ('in', 'IN'), ('NLP', 'NNP'), ('need', 'VBP'), ('a', 'DT'), ('broad', 'JJ'), ('exposure', 'NN'), ('to', 'TO'), ('AI', 'NNP'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('linguistics', 'NNS'), (',', ','), ('logic', 'NN'), (',', ','), ('and', 'CC'), ('increasingly', 'RB'), ('to', 'TO'), ('probability', 'NN'), ('and', 'CC'), ('statistics', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Researchers', 'NLP', 'need', 'broad', 'exposure', 'AI', ',', 'computer', 'science', ',', 'linguistics', ',', 'logic', ',', 'increasingly', 'probability', 'statistics', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Researchers', 'NNS'), ('NLP', 'NNP'), ('need', 'VBP'), ('broad', 'JJ'), ('exposure', 'NN'), ('AI', 'NNP'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('linguistics', 'NNS'), (',', ','), ('logic', 'NN'), (',', ','), ('increasingly', 'RB'), ('probability', 'JJ'), ('statistics', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Researchers NLP', 'NLP need', 'need broad', 'broad exposure', 'exposure AI', 'AI ,', ', computer', 'computer science', 'science ,', ', linguistics', 'linguistics ,', ', logic', 'logic ,', ', increasingly', 'increasingly probability', 'probability statistics', 'statistics .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Researchers NLP need', 'NLP need broad', 'need broad exposure', 'broad exposure AI', 'exposure AI ,', 'AI , computer', ', computer science', 'computer science ,', 'science , linguistics', ', linguistics ,', 'linguistics , logic', ', logic ,', 'logic , increasingly', ', increasingly probability', 'increasingly probability statistics', 'probability statistics .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['broad exposure', 'computer', 'science', 'logic'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['research', 'nlp', 'need', 'broad', 'exposur', 'ai', ',', 'comput', 'scienc', ',', 'linguist', ',', 'logic', ',', 'increasingli', 'probabl', 'statist', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['research', 'nlp', 'need', 'broad', 'exposur', 'ai', ',', 'comput', 'scienc', ',', 'linguist', ',', 'logic', ',', 'increas', 'probabl', 'statist', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Researchers', 'NLP', 'need', 'broad', 'exposure', 'AI', ',', 'computer', 'science', ',', 'linguistics', ',', 'logic', ',', 'increasingly', 'probability', 'statistic', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

94 --> It is important that the funding of research projects, in and out  of universities, allow for student participation. 


 ---- TOKENS ----

 ['It', 'is', 'important', 'that', 'the', 'funding', 'of', 'research', 'projects', ',', 'in', 'and', 'out', 'of', 'universities', ',', 'allow', 'for', 'student', 'participation', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('It', 'PRP'), ('is', 'VBZ'), ('important', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('funding', 'NN'), ('of', 'IN'), ('research', 'NN'), ('projects', 'NNS'), (',', ','), ('in', 'IN'), ('and', 'CC'), ('out', 'IN'), ('of', 'IN'), ('universities', 'NNS'), (',', ','), ('allow', 'VB'), ('for', 'IN'), ('student', 'NN'), ('participation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['important', 'funding', 'research', 'projects', ',', 'universities', ',', 'allow', 'student', 'participation', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('important', 'JJ'), ('funding', 'NN'), ('research', 'NN'), ('projects', 'NNS'), (',', ','), ('universities', 'NNS'), (',', ','), ('allow', 'JJ'), ('student', 'NN'), ('participation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['important funding', 'funding research', 'research projects', 'projects ,', ', universities', 'universities ,', ', allow', 'allow student', 'student participation', 'participation .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['important funding research', 'funding research projects', 'research projects ,', 'projects , universities', ', universities ,', 'universities , allow', ', allow student', 'allow student participation', 'student participation .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['important funding', 'research', 'allow student', 'participation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['import', 'fund', 'research', 'project', ',', 'univers', ',', 'allow', 'student', 'particip', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['import', 'fund', 'research', 'project', ',', 'univers', ',', 'allow', 'student', 'particip', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['important', 'funding', 'research', 'project', ',', 'university', ',', 'allow', 'student', 'participation', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

95 --> 484   1.3. 


 ---- TOKENS ----

 ['484', '1.3', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('484', 'CD'), ('1.3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['484', '1.3', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('484', 'CD'), ('1.3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['484 1.3', '1.3 .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['484 1.3 .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['484', '1.3', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['484', '1.3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['484', '1.3', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

96 --> A n t i c i p a t e d  Deve lopmen t s   During the next decade, we anticipate several scientific breakthroughs which shouM bring about impact  noticable to the user community. 


 ---- TOKENS ----

 ['A', 'n', 't', 'i', 'c', 'i', 'p', 'a', 't', 'e', 'd', 'Deve', 'lopmen', 't', 's', 'During', 'the', 'next', 'decade', ',', 'we', 'anticipate', 'several', 'scientific', 'breakthroughs', 'which', 'shouM', 'bring', 'about', 'impact', 'noticable', 'to', 'the', 'user', 'community', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('A', 'DT'), ('n', 'JJ'), ('t', 'NN'), ('i', 'NN'), ('c', 'VBP'), ('i', 'NN'), ('p', 'VBP'), ('a', 'DT'), ('t', 'NN'), ('e', 'NN'), ('d', 'NN'), ('Deve', 'NNP'), ('lopmen', 'NNS'), ('t', 'VBP'), ('s', 'NN'), ('During', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('decade', 'NN'), (',', ','), ('we', 'PRP'), ('anticipate', 'VBP'), ('several', 'JJ'), ('scientific', 'JJ'), ('breakthroughs', 'NNS'), ('which', 'WDT'), ('shouM', 'VBP'), ('bring', 'VBG'), ('about', 'IN'), ('impact', 'NN'), ('noticable', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('user', 'NNP'), ('community', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['n', 'c', 'p', 'e', 'Deve', 'lopmen', 'next', 'decade', ',', 'anticipate', 'several', 'scientific', 'breakthroughs', 'shouM', 'bring', 'impact', 'noticable', 'user', 'community', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('n', 'JJ'), ('c', 'NN'), ('p', 'NN'), ('e', 'NN'), ('Deve', 'NNP'), ('lopmen', 'NNS'), ('next', 'IN'), ('decade', 'NN'), (',', ','), ('anticipate', 'JJ'), ('several', 'JJ'), ('scientific', 'JJ'), ('breakthroughs', 'NNS'), ('shouM', 'JJ'), ('bring', 'JJ'), ('impact', 'NN'), ('noticable', 'JJ'), ('user', 'NN'), ('community', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['n c', 'c p', 'p e', 'e Deve', 'Deve lopmen', 'lopmen next', 'next decade', 'decade ,', ', anticipate', 'anticipate several', 'several scientific', 'scientific breakthroughs', 'breakthroughs shouM', 'shouM bring', 'bring impact', 'impact noticable', 'noticable user', 'user community', 'community .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['n c p', 'c p e', 'p e Deve', 'e Deve lopmen', 'Deve lopmen next', 'lopmen next decade', 'next decade ,', 'decade , anticipate', ', anticipate several', 'anticipate several scientific', 'several scientific breakthroughs', 'scientific breakthroughs shouM', 'breakthroughs shouM bring', 'shouM bring impact', 'bring impact noticable', 'impact noticable user', 'noticable user community', 'user community .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['n c', 'p', 'e', 'decade', 'shouM bring impact', 'noticable user', 'community'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> ['shouM']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['n', 'c', 'p', 'e', 'deve', 'lopmen', 'next', 'decad', ',', 'anticip', 'sever', 'scientif', 'breakthrough', 'shoum', 'bring', 'impact', 'notic', 'user', 'commun', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['n', 'c', 'p', 'e', 'deve', 'lopmen', 'next', 'decad', ',', 'anticip', 'sever', 'scientif', 'breakthrough', 'shoum', 'bring', 'impact', 'notic', 'user', 'communiti', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['n', 'c', 'p', 'e', 'Deve', 'lopmen', 'next', 'decade', ',', 'anticipate', 'several', 'scientific', 'breakthrough', 'shouM', 'bring', 'impact', 'noticable', 'user', 'community', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

97 --> 1.3.1. 


 ---- TOKENS ----

 ['1.3.1', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1.3.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.3.1', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1.3.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.3.1 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.3.1', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1.3.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1.3.1', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

98 --> Scientific Breakthroughs  Within the next 3 to 10 years we foresee the following scientific breakthroughs:  • Architectures that support coordinating syntactic, semantic, and pragmatic constraints, that deal with  partial information, and that understand novel, errofful, and vague forms. 


 ---- TOKENS ----

 ['Scientific', 'Breakthroughs', 'Within', 'the', 'next', '3', 'to', '10', 'years', 'we', 'foresee', 'the', 'following', 'scientific', 'breakthroughs', ':', '•', 'Architectures', 'that', 'support', 'coordinating', 'syntactic', ',', 'semantic', ',', 'and', 'pragmatic', 'constraints', ',', 'that', 'deal', 'with', 'partial', 'information', ',', 'and', 'that', 'understand', 'novel', ',', 'errofful', ',', 'and', 'vague', 'forms', '.'] 

 TOTAL TOKENS ==> 46

 ---- POST ----

 [('Scientific', 'NNP'), ('Breakthroughs', 'NNP'), ('Within', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('3', 'CD'), ('to', 'TO'), ('10', 'CD'), ('years', 'NNS'), ('we', 'PRP'), ('foresee', 'VBP'), ('the', 'DT'), ('following', 'JJ'), ('scientific', 'JJ'), ('breakthroughs', 'NNS'), (':', ':'), ('•', 'NN'), ('Architectures', 'VBZ'), ('that', 'IN'), ('support', 'NN'), ('coordinating', 'VBG'), ('syntactic', 'JJ'), (',', ','), ('semantic', 'JJ'), (',', ','), ('and', 'CC'), ('pragmatic', 'JJ'), ('constraints', 'NNS'), (',', ','), ('that', 'IN'), ('deal', 'NN'), ('with', 'IN'), ('partial', 'JJ'), ('information', 'NN'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('understand', 'VBP'), ('novel', 'NN'), (',', ','), ('errofful', 'JJ'), (',', ','), ('and', 'CC'), ('vague', 'JJ'), ('forms', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Scientific', 'Breakthroughs', 'Within', 'next', '3', '10', 'years', 'foresee', 'following', 'scientific', 'breakthroughs', ':', '•', 'Architectures', 'support', 'coordinating', 'syntactic', ',', 'semantic', ',', 'pragmatic', 'constraints', ',', 'deal', 'partial', 'information', ',', 'understand', 'novel', ',', 'errofful', ',', 'vague', 'forms', '.']

 TOTAL FILTERED TOKENS ==>  35

 ---- POST FOR FILTERED TOKENS ----

 [('Scientific', 'NNP'), ('Breakthroughs', 'NNP'), ('Within', 'NNP'), ('next', 'JJ'), ('3', 'CD'), ('10', 'CD'), ('years', 'NNS'), ('foresee', 'VBP'), ('following', 'VBG'), ('scientific', 'JJ'), ('breakthroughs', 'NNS'), (':', ':'), ('•', 'NN'), ('Architectures', 'VBZ'), ('support', 'NN'), ('coordinating', 'VBG'), ('syntactic', 'JJ'), (',', ','), ('semantic', 'JJ'), (',', ','), ('pragmatic', 'JJ'), ('constraints', 'NNS'), (',', ','), ('deal', 'VB'), ('partial', 'JJ'), ('information', 'NN'), (',', ','), ('understand', 'NN'), ('novel', 'NN'), (',', ','), ('errofful', 'JJ'), (',', ','), ('vague', 'JJ'), ('forms', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Scientific Breakthroughs', 'Breakthroughs Within', 'Within next', 'next 3', '3 10', '10 years', 'years foresee', 'foresee following', 'following scientific', 'scientific breakthroughs', 'breakthroughs :', ': •', '• Architectures', 'Architectures support', 'support coordinating', 'coordinating syntactic', 'syntactic ,', ', semantic', 'semantic ,', ', pragmatic', 'pragmatic constraints', 'constraints ,', ', deal', 'deal partial', 'partial information', 'information ,', ', understand', 'understand novel', 'novel ,', ', errofful', 'errofful ,', ', vague', 'vague forms', 'forms .'] 

 TOTAL BIGRAMS --> 34 



 ---- TRI-GRAMS ---- 

 ['Scientific Breakthroughs Within', 'Breakthroughs Within next', 'Within next 3', 'next 3 10', '3 10 years', '10 years foresee', 'years foresee following', 'foresee following scientific', 'following scientific breakthroughs', 'scientific breakthroughs :', 'breakthroughs : •', ': • Architectures', '• Architectures support', 'Architectures support coordinating', 'support coordinating syntactic', 'coordinating syntactic ,', 'syntactic , semantic', ', semantic ,', 'semantic , pragmatic', ', pragmatic constraints', 'pragmatic constraints ,', 'constraints , deal', ', deal partial', 'deal partial information', 'partial information ,', 'information , understand', ', understand novel', 'understand novel ,', 'novel , errofful', ', errofful ,', 'errofful , vague', ', vague forms', 'vague forms .'] 

 TOTAL TRIGRAMS --> 33 



 ---- NOUN PHRASES ---- 

 ['•', 'support', 'partial information', 'understand', 'novel'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['Breakthroughs']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Scientific']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['scientif', 'breakthrough', 'within', 'next', '3', '10', 'year', 'forese', 'follow', 'scientif', 'breakthrough', ':', '•', 'architectur', 'support', 'coordin', 'syntact', ',', 'semant', ',', 'pragmat', 'constraint', ',', 'deal', 'partial', 'inform', ',', 'understand', 'novel', ',', 'errof', ',', 'vagu', 'form', '.']

 TOTAL PORTER STEM WORDS ==> 35



 ---- SNOWBALL STEMMING ----

['scientif', 'breakthrough', 'within', 'next', '3', '10', 'year', 'forese', 'follow', 'scientif', 'breakthrough', ':', '•', 'architectur', 'support', 'coordin', 'syntact', ',', 'semant', ',', 'pragmat', 'constraint', ',', 'deal', 'partial', 'inform', ',', 'understand', 'novel', ',', 'errof', ',', 'vagu', 'form', '.']

 TOTAL SNOWBALL STEM WORDS ==> 35



 ---- LEMMATIZATION ----

['Scientific', 'Breakthroughs', 'Within', 'next', '3', '10', 'year', 'foresee', 'following', 'scientific', 'breakthrough', ':', '•', 'Architectures', 'support', 'coordinating', 'syntactic', ',', 'semantic', ',', 'pragmatic', 'constraint', ',', 'deal', 'partial', 'information', ',', 'understand', 'novel', ',', 'errofful', ',', 'vague', 'form', '.']

 TOTAL LEMMATIZE WORDS ==> 35

************************************************************************************************************************

99 --> • A robust, task-independent, compositional semantics, including more thorough treatment of problems  relevant to major application areas, such as time and tense, adverbs and adjectives, conjunctions and  ellipsis. 


 ---- TOKENS ----

 ['•', 'A', 'robust', ',', 'task-independent', ',', 'compositional', 'semantics', ',', 'including', 'more', 'thorough', 'treatment', 'of', 'problems', 'relevant', 'to', 'major', 'application', 'areas', ',', 'such', 'as', 'time', 'and', 'tense', ',', 'adverbs', 'and', 'adjectives', ',', 'conjunctions', 'and', 'ellipsis', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('•', 'VB'), ('A', 'DT'), ('robust', 'JJ'), (',', ','), ('task-independent', 'JJ'), (',', ','), ('compositional', 'JJ'), ('semantics', 'NNS'), (',', ','), ('including', 'VBG'), ('more', 'JJR'), ('thorough', 'JJ'), ('treatment', 'NN'), ('of', 'IN'), ('problems', 'NNS'), ('relevant', 'VBP'), ('to', 'TO'), ('major', 'JJ'), ('application', 'NN'), ('areas', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('time', 'NN'), ('and', 'CC'), ('tense', 'NN'), (',', ','), ('adverbs', 'NN'), ('and', 'CC'), ('adjectives', 'NNS'), (',', ','), ('conjunctions', 'NNS'), ('and', 'CC'), ('ellipsis', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'robust', ',', 'task-independent', ',', 'compositional', 'semantics', ',', 'including', 'thorough', 'treatment', 'problems', 'relevant', 'major', 'application', 'areas', ',', 'time', 'tense', ',', 'adverbs', 'adjectives', ',', 'conjunctions', 'ellipsis', '.']

 TOTAL FILTERED TOKENS ==>  26

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'NN'), ('robust', 'NN'), (',', ','), ('task-independent', 'JJ'), (',', ','), ('compositional', 'JJ'), ('semantics', 'NNS'), (',', ','), ('including', 'VBG'), ('thorough', 'JJ'), ('treatment', 'NN'), ('problems', 'NNS'), ('relevant', 'VBP'), ('major', 'JJ'), ('application', 'NN'), ('areas', 'NNS'), (',', ','), ('time', 'NN'), ('tense', 'NN'), (',', ','), ('adverbs', 'JJ'), ('adjectives', 'NNS'), (',', ','), ('conjunctions', 'NNS'), ('ellipsis', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• robust', 'robust ,', ', task-independent', 'task-independent ,', ', compositional', 'compositional semantics', 'semantics ,', ', including', 'including thorough', 'thorough treatment', 'treatment problems', 'problems relevant', 'relevant major', 'major application', 'application areas', 'areas ,', ', time', 'time tense', 'tense ,', ', adverbs', 'adverbs adjectives', 'adjectives ,', ', conjunctions', 'conjunctions ellipsis', 'ellipsis .'] 

 TOTAL BIGRAMS --> 25 



 ---- TRI-GRAMS ---- 

 ['• robust ,', 'robust , task-independent', ', task-independent ,', 'task-independent , compositional', ', compositional semantics', 'compositional semantics ,', 'semantics , including', ', including thorough', 'including thorough treatment', 'thorough treatment problems', 'treatment problems relevant', 'problems relevant major', 'relevant major application', 'major application areas', 'application areas ,', 'areas , time', ', time tense', 'time tense ,', 'tense , adverbs', ', adverbs adjectives', 'adverbs adjectives ,', 'adjectives , conjunctions', ', conjunctions ellipsis', 'conjunctions ellipsis .'] 

 TOTAL TRIGRAMS --> 24 



 ---- NOUN PHRASES ---- 

 ['•', 'robust', 'thorough treatment', 'major application', 'time', 'tense', 'ellipsis'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'robust', ',', 'task-independ', ',', 'composit', 'semant', ',', 'includ', 'thorough', 'treatment', 'problem', 'relev', 'major', 'applic', 'area', ',', 'time', 'tens', ',', 'adverb', 'adject', ',', 'conjunct', 'ellipsi', '.']

 TOTAL PORTER STEM WORDS ==> 26



 ---- SNOWBALL STEMMING ----

['•', 'robust', ',', 'task-independ', ',', 'composit', 'semant', ',', 'includ', 'thorough', 'treatment', 'problem', 'relev', 'major', 'applic', 'area', ',', 'time', 'tens', ',', 'adverb', 'adject', ',', 'conjunct', 'ellipsi', '.']

 TOTAL SNOWBALL STEM WORDS ==> 26



 ---- LEMMATIZATION ----

['•', 'robust', ',', 'task-independent', ',', 'compositional', 'semantics', ',', 'including', 'thorough', 'treatment', 'problem', 'relevant', 'major', 'application', 'area', ',', 'time', 'tense', ',', 'adverb', 'adjective', ',', 'conjunction', 'ellipsis', '.']

 TOTAL LEMMATIZE WORDS ==> 26

************************************************************************************************************************

100 --> • Automatic acquisition of substantial glammars and lexicons. 


 ---- TOKENS ----

 ['•', 'Automatic', 'acquisition', 'of', 'substantial', 'glammars', 'and', 'lexicons', '.'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('•', 'JJ'), ('Automatic', 'NNP'), ('acquisition', 'NN'), ('of', 'IN'), ('substantial', 'JJ'), ('glammars', 'NNS'), ('and', 'CC'), ('lexicons', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Automatic', 'acquisition', 'substantial', 'glammars', 'lexicons', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Automatic', 'NNP'), ('acquisition', 'NN'), ('substantial', 'JJ'), ('glammars', 'NNS'), ('lexicons', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Automatic', 'Automatic acquisition', 'acquisition substantial', 'substantial glammars', 'glammars lexicons', 'lexicons .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['• Automatic acquisition', 'Automatic acquisition substantial', 'acquisition substantial glammars', 'substantial glammars lexicons', 'glammars lexicons .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['acquisition'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Automatic']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'automat', 'acquisit', 'substanti', 'glammar', 'lexicon', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['•', 'automat', 'acquisit', 'substanti', 'glammar', 'lexicon', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['•', 'Automatic', 'acquisition', 'substantial', 'glammars', 'lexicon', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

101 --> • Parallel algorithms for key processes. 


 ---- TOKENS ----

 ['•', 'Parallel', 'algorithms', 'for', 'key', 'processes', '.'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('•', 'JJ'), ('Parallel', 'NNP'), ('algorithms', 'NN'), ('for', 'IN'), ('key', 'JJ'), ('processes', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Parallel', 'algorithms', 'key', 'processes', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Parallel', 'NNP'), ('algorithms', 'NN'), ('key', 'JJ'), ('processes', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Parallel', 'Parallel algorithms', 'algorithms key', 'key processes', 'processes .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['• Parallel algorithms', 'Parallel algorithms key', 'algorithms key processes', 'key processes .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 ['algorithms'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Parallel']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'parallel', 'algorithm', 'key', 'process', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['•', 'parallel', 'algorithm', 'key', 'process', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['•', 'Parallel', 'algorithm', 'key', 'process', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

102 --> • Computational models of discourse structure and speaker intention adequate to support dialogue  participation and text generation. 


 ---- TOKENS ----

 ['•', 'Computational', 'models', 'of', 'discourse', 'structure', 'and', 'speaker', 'intention', 'adequate', 'to', 'support', 'dialogue', 'participation', 'and', 'text', 'generation', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('•', 'JJ'), ('Computational', 'NNP'), ('models', 'NNS'), ('of', 'IN'), ('discourse', 'JJ'), ('structure', 'NN'), ('and', 'CC'), ('speaker', 'NN'), ('intention', 'NN'), ('adequate', 'NN'), ('to', 'TO'), ('support', 'VB'), ('dialogue', 'NN'), ('participation', 'NN'), ('and', 'CC'), ('text', 'JJ'), ('generation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Computational', 'models', 'discourse', 'structure', 'speaker', 'intention', 'adequate', 'support', 'dialogue', 'participation', 'text', 'generation', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Computational', 'NNP'), ('models', 'NNS'), ('discourse', 'NN'), ('structure', 'NN'), ('speaker', 'NN'), ('intention', 'NN'), ('adequate', 'JJ'), ('support', 'NN'), ('dialogue', 'NN'), ('participation', 'NN'), ('text', 'NN'), ('generation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Computational', 'Computational models', 'models discourse', 'discourse structure', 'structure speaker', 'speaker intention', 'intention adequate', 'adequate support', 'support dialogue', 'dialogue participation', 'participation text', 'text generation', 'generation .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['• Computational models', 'Computational models discourse', 'models discourse structure', 'discourse structure speaker', 'structure speaker intention', 'speaker intention adequate', 'intention adequate support', 'adequate support dialogue', 'support dialogue participation', 'dialogue participation text', 'participation text generation', 'text generation .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['discourse', 'structure', 'speaker', 'intention', 'adequate support', 'dialogue', 'participation', 'text', 'generation'] 

 TOTAL NOUN PHRASES --> 9 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'comput', 'model', 'discours', 'structur', 'speaker', 'intent', 'adequ', 'support', 'dialogu', 'particip', 'text', 'gener', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['•', 'comput', 'model', 'discours', 'structur', 'speaker', 'intent', 'adequ', 'support', 'dialogu', 'particip', 'text', 'generat', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['•', 'Computational', 'model', 'discourse', 'structure', 'speaker', 'intention', 'adequate', 'support', 'dialogue', 'participation', 'text', 'generation', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

103 --> 1.3.2. 


 ---- TOKENS ----

 ['1.3.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('1.3.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1.3.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('1.3.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1.3.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1.3.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['1.3.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['1.3.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

104 --> Technology Transfer   Existing laboratory prototypes coupled with the scientific breakthroughs projected above suggest that in  the next decade a new generation of systems, having the properties below, will be available:  • Text analysis systems for automatic database update, m restricted domain areas. 


 ---- TOKENS ----

 ['Technology', 'Transfer', 'Existing', 'laboratory', 'prototypes', 'coupled', 'with', 'the', 'scientific', 'breakthroughs', 'projected', 'above', 'suggest', 'that', 'in', 'the', 'next', 'decade', 'a', 'new', 'generation', 'of', 'systems', ',', 'having', 'the', 'properties', 'below', ',', 'will', 'be', 'available', ':', '•', 'Text', 'analysis', 'systems', 'for', 'automatic', 'database', 'update', ',', 'm', 'restricted', 'domain', 'areas', '.'] 

 TOTAL TOKENS ==> 47

 ---- POST ----

 [('Technology', 'NN'), ('Transfer', 'NNP'), ('Existing', 'NNP'), ('laboratory', 'NN'), ('prototypes', 'NNS'), ('coupled', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('scientific', 'JJ'), ('breakthroughs', 'NN'), ('projected', 'VBN'), ('above', 'IN'), ('suggest', 'NN'), ('that', 'IN'), ('in', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('decade', 'NN'), ('a', 'DT'), ('new', 'JJ'), ('generation', 'NN'), ('of', 'IN'), ('systems', 'NNS'), (',', ','), ('having', 'VBG'), ('the', 'DT'), ('properties', 'NNS'), ('below', 'IN'), (',', ','), ('will', 'MD'), ('be', 'VB'), ('available', 'JJ'), (':', ':'), ('•', 'JJ'), ('Text', 'NNP'), ('analysis', 'NN'), ('systems', 'NNS'), ('for', 'IN'), ('automatic', 'JJ'), ('database', 'NN'), ('update', 'NN'), (',', ','), ('m', 'RB'), ('restricted', 'VBD'), ('domain', 'JJ'), ('areas', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Technology', 'Transfer', 'Existing', 'laboratory', 'prototypes', 'coupled', 'scientific', 'breakthroughs', 'projected', 'suggest', 'next', 'decade', 'new', 'generation', 'systems', ',', 'properties', ',', 'available', ':', '•', 'Text', 'analysis', 'systems', 'automatic', 'database', 'update', ',', 'restricted', 'domain', 'areas', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('Technology', 'NN'), ('Transfer', 'NNP'), ('Existing', 'NNP'), ('laboratory', 'NN'), ('prototypes', 'NNS'), ('coupled', 'VBN'), ('scientific', 'JJ'), ('breakthroughs', 'NNS'), ('projected', 'VBN'), ('suggest', 'VBP'), ('next', 'JJ'), ('decade', 'NN'), ('new', 'JJ'), ('generation', 'NN'), ('systems', 'NNS'), (',', ','), ('properties', 'NNS'), (',', ','), ('available', 'JJ'), (':', ':'), ('•', 'JJ'), ('Text', 'NNP'), ('analysis', 'NN'), ('systems', 'NNS'), ('automatic', 'JJ'), ('database', 'NN'), ('update', 'NN'), (',', ','), ('restricted', 'VBD'), ('domain', 'NN'), ('areas', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Technology Transfer', 'Transfer Existing', 'Existing laboratory', 'laboratory prototypes', 'prototypes coupled', 'coupled scientific', 'scientific breakthroughs', 'breakthroughs projected', 'projected suggest', 'suggest next', 'next decade', 'decade new', 'new generation', 'generation systems', 'systems ,', ', properties', 'properties ,', ', available', 'available :', ': •', '• Text', 'Text analysis', 'analysis systems', 'systems automatic', 'automatic database', 'database update', 'update ,', ', restricted', 'restricted domain', 'domain areas', 'areas .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['Technology Transfer Existing', 'Transfer Existing laboratory', 'Existing laboratory prototypes', 'laboratory prototypes coupled', 'prototypes coupled scientific', 'coupled scientific breakthroughs', 'scientific breakthroughs projected', 'breakthroughs projected suggest', 'projected suggest next', 'suggest next decade', 'next decade new', 'decade new generation', 'new generation systems', 'generation systems ,', 'systems , properties', ', properties ,', 'properties , available', ', available :', 'available : •', ': • Text', '• Text analysis', 'Text analysis systems', 'analysis systems automatic', 'systems automatic database', 'automatic database update', 'database update ,', 'update , restricted', ', restricted domain', 'restricted domain areas', 'domain areas .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['Technology', 'laboratory', 'next decade', 'new generation', 'analysis', 'automatic database', 'update', 'domain'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Technology Transfer Existing']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['technolog', 'transfer', 'exist', 'laboratori', 'prototyp', 'coupl', 'scientif', 'breakthrough', 'project', 'suggest', 'next', 'decad', 'new', 'gener', 'system', ',', 'properti', ',', 'avail', ':', '•', 'text', 'analysi', 'system', 'automat', 'databas', 'updat', ',', 'restrict', 'domain', 'area', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['technolog', 'transfer', 'exist', 'laboratori', 'prototyp', 'coupl', 'scientif', 'breakthrough', 'project', 'suggest', 'next', 'decad', 'new', 'generat', 'system', ',', 'properti', ',', 'avail', ':', '•', 'text', 'analysi', 'system', 'automat', 'databas', 'updat', ',', 'restrict', 'domain', 'area', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['Technology', 'Transfer', 'Existing', 'laboratory', 'prototype', 'coupled', 'scientific', 'breakthrough', 'projected', 'suggest', 'next', 'decade', 'new', 'generation', 'system', ',', 'property', ',', 'available', ':', '•', 'Text', 'analysis', 'system', 'automatic', 'database', 'update', ',', 'restricted', 'domain', 'area', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

105 --> • Interactive problem-solving systems combining NL, pointing, and graphical access to several target  systems (e.g., databases, simulators, expert systems); exhibiting extended conversations including  clarifications, suggestions, and confirmations; and allowing rapid, low-cost portability from one  (constrained) application domain to another. 


 ---- TOKENS ----

 ['•', 'Interactive', 'problem-solving', 'systems', 'combining', 'NL', ',', 'pointing', ',', 'and', 'graphical', 'access', 'to', 'several', 'target', 'systems', '(', 'e.g.', ',', 'databases', ',', 'simulators', ',', 'expert', 'systems', ')', ';', 'exhibiting', 'extended', 'conversations', 'including', 'clarifications', ',', 'suggestions', ',', 'and', 'confirmations', ';', 'and', 'allowing', 'rapid', ',', 'low-cost', 'portability', 'from', 'one', '(', 'constrained', ')', 'application', 'domain', 'to', 'another', '.'] 

 TOTAL TOKENS ==> 54

 ---- POST ----

 [('•', 'JJ'), ('Interactive', 'NNP'), ('problem-solving', 'NN'), ('systems', 'NNS'), ('combining', 'VBG'), ('NL', 'NNP'), (',', ','), ('pointing', 'VBG'), (',', ','), ('and', 'CC'), ('graphical', 'JJ'), ('access', 'NN'), ('to', 'TO'), ('several', 'JJ'), ('target', 'NN'), ('systems', 'NNS'), ('(', '('), ('e.g.', 'JJ'), (',', ','), ('databases', 'NNS'), (',', ','), ('simulators', 'NNS'), (',', ','), ('expert', 'JJ'), ('systems', 'NNS'), (')', ')'), (';', ':'), ('exhibiting', 'VBG'), ('extended', 'VBD'), ('conversations', 'NNS'), ('including', 'VBG'), ('clarifications', 'NNS'), (',', ','), ('suggestions', 'NNS'), (',', ','), ('and', 'CC'), ('confirmations', 'NNS'), (';', ':'), ('and', 'CC'), ('allowing', 'VBG'), ('rapid', 'JJ'), (',', ','), ('low-cost', 'JJ'), ('portability', 'NN'), ('from', 'IN'), ('one', 'CD'), ('(', '('), ('constrained', 'VBN'), (')', ')'), ('application', 'NN'), ('domain', 'NN'), ('to', 'TO'), ('another', 'DT'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Interactive', 'problem-solving', 'systems', 'combining', 'NL', ',', 'pointing', ',', 'graphical', 'access', 'several', 'target', 'systems', '(', 'e.g.', ',', 'databases', ',', 'simulators', ',', 'expert', 'systems', ')', ';', 'exhibiting', 'extended', 'conversations', 'including', 'clarifications', ',', 'suggestions', ',', 'confirmations', ';', 'allowing', 'rapid', ',', 'low-cost', 'portability', 'one', '(', 'constrained', ')', 'application', 'domain', 'another', '.']

 TOTAL FILTERED TOKENS ==>  48

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Interactive', 'NNP'), ('problem-solving', 'NN'), ('systems', 'NNS'), ('combining', 'VBG'), ('NL', 'NNP'), (',', ','), ('pointing', 'VBG'), (',', ','), ('graphical', 'JJ'), ('access', 'NN'), ('several', 'JJ'), ('target', 'NN'), ('systems', 'NNS'), ('(', '('), ('e.g.', 'JJ'), (',', ','), ('databases', 'NNS'), (',', ','), ('simulators', 'NNS'), (',', ','), ('expert', 'JJ'), ('systems', 'NNS'), (')', ')'), (';', ':'), ('exhibiting', 'VBG'), ('extended', 'VBD'), ('conversations', 'NNS'), ('including', 'VBG'), ('clarifications', 'NNS'), (',', ','), ('suggestions', 'NNS'), (',', ','), ('confirmations', 'NNS'), (';', ':'), ('allowing', 'VBG'), ('rapid', 'JJ'), (',', ','), ('low-cost', 'JJ'), ('portability', 'NN'), ('one', 'CD'), ('(', '('), ('constrained', 'VBN'), (')', ')'), ('application', 'NN'), ('domain', 'NN'), ('another', 'DT'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Interactive', 'Interactive problem-solving', 'problem-solving systems', 'systems combining', 'combining NL', 'NL ,', ', pointing', 'pointing ,', ', graphical', 'graphical access', 'access several', 'several target', 'target systems', 'systems (', '( e.g.', 'e.g. ,', ', databases', 'databases ,', ', simulators', 'simulators ,', ', expert', 'expert systems', 'systems )', ') ;', '; exhibiting', 'exhibiting extended', 'extended conversations', 'conversations including', 'including clarifications', 'clarifications ,', ', suggestions', 'suggestions ,', ', confirmations', 'confirmations ;', '; allowing', 'allowing rapid', 'rapid ,', ', low-cost', 'low-cost portability', 'portability one', 'one (', '( constrained', 'constrained )', ') application', 'application domain', 'domain another', 'another .'] 

 TOTAL BIGRAMS --> 47 



 ---- TRI-GRAMS ---- 

 ['• Interactive problem-solving', 'Interactive problem-solving systems', 'problem-solving systems combining', 'systems combining NL', 'combining NL ,', 'NL , pointing', ', pointing ,', 'pointing , graphical', ', graphical access', 'graphical access several', 'access several target', 'several target systems', 'target systems (', 'systems ( e.g.', '( e.g. ,', 'e.g. , databases', ', databases ,', 'databases , simulators', ', simulators ,', 'simulators , expert', ', expert systems', 'expert systems )', 'systems ) ;', ') ; exhibiting', '; exhibiting extended', 'exhibiting extended conversations', 'extended conversations including', 'conversations including clarifications', 'including clarifications ,', 'clarifications , suggestions', ', suggestions ,', 'suggestions , confirmations', ', confirmations ;', 'confirmations ; allowing', '; allowing rapid', 'allowing rapid ,', 'rapid , low-cost', ', low-cost portability', 'low-cost portability one', 'portability one (', 'one ( constrained', '( constrained )', 'constrained ) application', ') application domain', 'application domain another', 'domain another .'] 

 TOTAL TRIGRAMS --> 46 



 ---- NOUN PHRASES ---- 

 ['problem-solving', 'graphical access', 'several target', 'low-cost portability', 'application', 'domain'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['NL']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'interact', 'problem-solv', 'system', 'combin', 'nl', ',', 'point', ',', 'graphic', 'access', 'sever', 'target', 'system', '(', 'e.g.', ',', 'databas', ',', 'simul', ',', 'expert', 'system', ')', ';', 'exhibit', 'extend', 'convers', 'includ', 'clarif', ',', 'suggest', ',', 'confirm', ';', 'allow', 'rapid', ',', 'low-cost', 'portabl', 'one', '(', 'constrain', ')', 'applic', 'domain', 'anoth', '.']

 TOTAL PORTER STEM WORDS ==> 48



 ---- SNOWBALL STEMMING ----

['•', 'interact', 'problem-solv', 'system', 'combin', 'nl', ',', 'point', ',', 'graphic', 'access', 'sever', 'target', 'system', '(', 'e.g.', ',', 'databas', ',', 'simul', ',', 'expert', 'system', ')', ';', 'exhibit', 'extend', 'convers', 'includ', 'clarif', ',', 'suggest', ',', 'confirm', ';', 'allow', 'rapid', ',', 'low-cost', 'portabl', 'one', '(', 'constrain', ')', 'applic', 'domain', 'anoth', '.']

 TOTAL SNOWBALL STEM WORDS ==> 48



 ---- LEMMATIZATION ----

['•', 'Interactive', 'problem-solving', 'system', 'combining', 'NL', ',', 'pointing', ',', 'graphical', 'access', 'several', 'target', 'system', '(', 'e.g.', ',', 'database', ',', 'simulator', ',', 'expert', 'system', ')', ';', 'exhibiting', 'extended', 'conversation', 'including', 'clarification', ',', 'suggestion', ',', 'confirmation', ';', 'allowing', 'rapid', ',', 'low-cost', 'portability', 'one', '(', 'constrained', ')', 'application', 'domain', 'another', '.']

 TOTAL LEMMATIZE WORDS ==> 48

************************************************************************************************************************

106 --> • Language generation systems producing extended texts in limited applications (e.g., summarization of  databases or output and explanations of expert systems' decisions). 


 ---- TOKENS ----

 ['•', 'Language', 'generation', 'systems', 'producing', 'extended', 'texts', 'in', 'limited', 'applications', '(', 'e.g.', ',', 'summarization', 'of', 'databases', 'or', 'output', 'and', 'explanations', 'of', 'expert', 'systems', "'", 'decisions', ')', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('•', 'JJ'), ('Language', 'NNP'), ('generation', 'NN'), ('systems', 'NNS'), ('producing', 'VBG'), ('extended', 'JJ'), ('texts', 'NN'), ('in', 'IN'), ('limited', 'JJ'), ('applications', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('summarization', 'NN'), ('of', 'IN'), ('databases', 'NNS'), ('or', 'CC'), ('output', 'NN'), ('and', 'CC'), ('explanations', 'NNS'), ('of', 'IN'), ('expert', 'JJ'), ('systems', 'NNS'), ("'", 'POS'), ('decisions', 'NNS'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Language', 'generation', 'systems', 'producing', 'extended', 'texts', 'limited', 'applications', '(', 'e.g.', ',', 'summarization', 'databases', 'output', 'explanations', 'expert', 'systems', "'", 'decisions', ')', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Language', 'NNP'), ('generation', 'NN'), ('systems', 'NNS'), ('producing', 'VBG'), ('extended', 'JJ'), ('texts', 'NN'), ('limited', 'VBD'), ('applications', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('summarization', 'NN'), ('databases', 'NNS'), ('output', 'NN'), ('explanations', 'NNS'), ('expert', 'VBP'), ('systems', 'NNS'), ("'", 'POS'), ('decisions', 'NNS'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Language', 'Language generation', 'generation systems', 'systems producing', 'producing extended', 'extended texts', 'texts limited', 'limited applications', 'applications (', '( e.g.', 'e.g. ,', ', summarization', 'summarization databases', 'databases output', 'output explanations', 'explanations expert', 'expert systems', "systems '", "' decisions", 'decisions )', ') .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['• Language generation', 'Language generation systems', 'generation systems producing', 'systems producing extended', 'producing extended texts', 'extended texts limited', 'texts limited applications', 'limited applications (', 'applications ( e.g.', '( e.g. ,', 'e.g. , summarization', ', summarization databases', 'summarization databases output', 'databases output explanations', 'output explanations expert', 'explanations expert systems', "expert systems '", "systems ' decisions", "' decisions )", 'decisions ) .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['generation', 'extended texts'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'languag', 'gener', 'system', 'produc', 'extend', 'text', 'limit', 'applic', '(', 'e.g.', ',', 'summar', 'databas', 'output', 'explan', 'expert', 'system', "'", 'decis', ')', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['•', 'languag', 'generat', 'system', 'produc', 'extend', 'text', 'limit', 'applic', '(', 'e.g.', ',', 'summar', 'databas', 'output', 'explan', 'expert', 'system', "'", 'decis', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['•', 'Language', 'generation', 'system', 'producing', 'extended', 'text', 'limited', 'application', '(', 'e.g.', ',', 'summarization', 'database', 'output', 'explanation', 'expert', 'system', "'", 'decision', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

107 --> 2. 


 ---- TOKENS ----

 ['2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

108 --> B a c k g r o u n d   2.1. 


 ---- TOKENS ----

 ['B', 'a', 'c', 'k', 'g', 'r', 'o', 'u', 'n', 'd', '2.1', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('B', 'IN'), ('a', 'DT'), ('c', 'NN'), ('k', 'NN'), ('g', 'NN'), ('r', 'NN'), ('o', 'NN'), ('u', 'JJ'), ('n', 'JJ'), ('d', 'NN'), ('2.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['B', 'c', 'k', 'g', 'r', 'u', 'n', '2.1', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('B', 'NNP'), ('c', 'NN'), ('k', 'NN'), ('g', 'NN'), ('r', 'NN'), ('u', 'JJ'), ('n', 'RB'), ('2.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['B c', 'c k', 'k g', 'g r', 'r u', 'u n', 'n 2.1', '2.1 .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['B c k', 'c k g', 'k g r', 'g r u', 'r u n', 'u n 2.1', 'n 2.1 .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['c', 'k', 'g', 'r'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['b', 'c', 'k', 'g', 'r', 'u', 'n', '2.1', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['b', 'c', 'k', 'g', 'r', 'u', 'n', '2.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['B', 'c', 'k', 'g', 'r', 'u', 'n', '2.1', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

109 --> C u r r e n t  Assessment  Products. 


 ---- TOKENS ----

 ['C', 'u', 'r', 'r', 'e', 'n', 't', 'Assessment', 'Products', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('C', 'NNP'), ('u', 'JJ'), ('r', 'NN'), ('r', 'NN'), ('e', 'NN'), ('n', 'JJ'), ('t', 'JJ'), ('Assessment', 'NNP'), ('Products', 'NNPS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['C', 'u', 'r', 'r', 'e', 'n', 'Assessment', 'Products', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('C', 'NNP'), ('u', 'JJ'), ('r', 'NN'), ('r', 'NN'), ('e', 'NN'), ('n', 'JJ'), ('Assessment', 'NNP'), ('Products', 'NNPS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['C u', 'u r', 'r r', 'r e', 'e n', 'n Assessment', 'Assessment Products', 'Products .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['C u r', 'u r r', 'r r e', 'r e n', 'e n Assessment', 'n Assessment Products', 'Assessment Products .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['u r', 'r', 'e'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['Assessment Products']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['c', 'u', 'r', 'r', 'e', 'n', 'assess', 'product', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['c', 'u', 'r', 'r', 'e', 'n', 'assess', 'product', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['C', 'u', 'r', 'r', 'e', 'n', 'Assessment', 'Products', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

110 --> In the decade since 1978, at least eight commercial products for natural language access to  databases have been released. 


 ---- TOKENS ----

 ['In', 'the', 'decade', 'since', '1978', ',', 'at', 'least', 'eight', 'commercial', 'products', 'for', 'natural', 'language', 'access', 'to', 'databases', 'have', 'been', 'released', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('In', 'IN'), ('the', 'DT'), ('decade', 'NN'), ('since', 'IN'), ('1978', 'CD'), (',', ','), ('at', 'IN'), ('least', 'JJS'), ('eight', 'CD'), ('commercial', 'JJ'), ('products', 'NNS'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('access', 'NN'), ('to', 'TO'), ('databases', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('released', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['decade', 'since', '1978', ',', 'least', 'eight', 'commercial', 'products', 'natural', 'language', 'access', 'databases', 'released', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('decade', 'NN'), ('since', 'IN'), ('1978', 'CD'), (',', ','), ('least', 'JJS'), ('eight', 'CD'), ('commercial', 'JJ'), ('products', 'NNS'), ('natural', 'JJ'), ('language', 'NN'), ('access', 'NN'), ('databases', 'NNS'), ('released', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['decade since', 'since 1978', '1978 ,', ', least', 'least eight', 'eight commercial', 'commercial products', 'products natural', 'natural language', 'language access', 'access databases', 'databases released', 'released .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['decade since 1978', 'since 1978 ,', '1978 , least', ', least eight', 'least eight commercial', 'eight commercial products', 'commercial products natural', 'products natural language', 'natural language access', 'language access databases', 'access databases released', 'databases released .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['decade', 'natural language', 'access'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['decad', 'sinc', '1978', ',', 'least', 'eight', 'commerci', 'product', 'natur', 'languag', 'access', 'databas', 'releas', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['decad', 'sinc', '1978', ',', 'least', 'eight', 'commerci', 'product', 'natur', 'languag', 'access', 'databas', 'releas', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['decade', 'since', '1978', ',', 'least', 'eight', 'commercial', 'product', 'natural', 'language', 'access', 'database', 'released', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

111 --> Two message processing systems are m daily use, one for the U.S. Coast Guard. 


 ---- TOKENS ----

 ['Two', 'message', 'processing', 'systems', 'are', 'm', 'daily', 'use', ',', 'one', 'for', 'the', 'U.S.', 'Coast', 'Guard', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('Two', 'CD'), ('message', 'NN'), ('processing', 'NN'), ('systems', 'NNS'), ('are', 'VBP'), ('m', 'JJ'), ('daily', 'JJ'), ('use', 'NN'), (',', ','), ('one', 'CD'), ('for', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), ('Coast', 'NNP'), ('Guard', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Two', 'message', 'processing', 'systems', 'daily', 'use', ',', 'one', 'U.S.', 'Coast', 'Guard', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Two', 'CD'), ('message', 'NN'), ('processing', 'VBG'), ('systems', 'NNS'), ('daily', 'RB'), ('use', 'VBP'), (',', ','), ('one', 'CD'), ('U.S.', 'NNP'), ('Coast', 'NNP'), ('Guard', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Two message', 'message processing', 'processing systems', 'systems daily', 'daily use', 'use ,', ', one', 'one U.S.', 'U.S. Coast', 'Coast Guard', 'Guard .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Two message processing', 'message processing systems', 'processing systems daily', 'systems daily use', 'daily use ,', 'use , one', ', one U.S.', 'one U.S. Coast', 'U.S. Coast Guard', 'Coast Guard .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['message'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['U.S.']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['two', 'messag', 'process', 'system', 'daili', 'use', ',', 'one', 'u.s.', 'coast', 'guard', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['two', 'messag', 'process', 'system', 'daili', 'use', ',', 'one', 'u.s.', 'coast', 'guard', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Two', 'message', 'processing', 'system', 'daily', 'use', ',', 'one', 'U.S.', 'Coast', 'Guard', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

112 --> In  the U.S. alone, four companies offer machine translation systems. 


 ---- TOKENS ----

 ['In', 'the', 'U.S.', 'alone', ',', 'four', 'companies', 'offer', 'machine', 'translation', 'systems', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('In', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), ('alone', 'RB'), (',', ','), ('four', 'CD'), ('companies', 'NNS'), ('offer', 'VBP'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['U.S.', 'alone', ',', 'four', 'companies', 'offer', 'machine', 'translation', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('U.S.', 'NNP'), ('alone', 'RB'), (',', ','), ('four', 'CD'), ('companies', 'NNS'), ('offer', 'VBP'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['U.S. alone', 'alone ,', ', four', 'four companies', 'companies offer', 'offer machine', 'machine translation', 'translation systems', 'systems .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['U.S. alone ,', 'alone , four', ', four companies', 'four companies offer', 'companies offer machine', 'offer machine translation', 'machine translation systems', 'translation systems .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['machine', 'translation'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['U.S.']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['u.s.', 'alon', ',', 'four', 'compani', 'offer', 'machin', 'translat', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['u.s.', 'alon', ',', 'four', 'compani', 'offer', 'machin', 'translat', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['U.S.', 'alone', ',', 'four', 'company', 'offer', 'machine', 'translation', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

113 --> Limitations of current systems. 


 ---- TOKENS ----

 ['Limitations', 'of', 'current', 'systems', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('Limitations', 'NNS'), ('of', 'IN'), ('current', 'JJ'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Limitations', 'current', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('Limitations', 'NNP'), ('current', 'JJ'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Limitations current', 'current systems', 'systems .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['Limitations current systems', 'current systems .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Limitations']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['limit', 'current', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['limit', 'current', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['Limitations', 'current', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

114 --> The limitations of the current technology, described in Section 1.2.1. of  this paper, can be illustrated by considering NL access to databases, the application that has probably received more  support than any other in the U.S. in the last ten years. 


 ---- TOKENS ----

 ['The', 'limitations', 'of', 'the', 'current', 'technology', ',', 'described', 'in', 'Section', '1.2.1.', 'of', 'this', 'paper', ',', 'can', 'be', 'illustrated', 'by', 'considering', 'NL', 'access', 'to', 'databases', ',', 'the', 'application', 'that', 'has', 'probably', 'received', 'more', 'support', 'than', 'any', 'other', 'in', 'the', 'U.S.', 'in', 'the', 'last', 'ten', 'years', '.'] 

 TOTAL TOKENS ==> 45

 ---- POST ----

 [('The', 'DT'), ('limitations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('current', 'JJ'), ('technology', 'NN'), (',', ','), ('described', 'VBN'), ('in', 'IN'), ('Section', 'NNP'), ('1.2.1.', 'CD'), ('of', 'IN'), ('this', 'DT'), ('paper', 'NN'), (',', ','), ('can', 'MD'), ('be', 'VB'), ('illustrated', 'VBN'), ('by', 'IN'), ('considering', 'VBG'), ('NL', 'NNP'), ('access', 'NN'), ('to', 'TO'), ('databases', 'NNS'), (',', ','), ('the', 'DT'), ('application', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('probably', 'RB'), ('received', 'VBN'), ('more', 'JJR'), ('support', 'NN'), ('than', 'IN'), ('any', 'DT'), ('other', 'JJ'), ('in', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('ten', 'JJ'), ('years', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['limitations', 'current', 'technology', ',', 'described', 'Section', '1.2.1.', 'paper', ',', 'illustrated', 'considering', 'NL', 'access', 'databases', ',', 'application', 'probably', 'received', 'support', 'U.S.', 'last', 'ten', 'years', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('limitations', 'NNS'), ('current', 'JJ'), ('technology', 'NN'), (',', ','), ('described', 'VBN'), ('Section', 'NN'), ('1.2.1.', 'CD'), ('paper', 'NN'), (',', ','), ('illustrated', 'VBD'), ('considering', 'VBG'), ('NL', 'NNP'), ('access', 'NN'), ('databases', 'NNS'), (',', ','), ('application', 'NN'), ('probably', 'RB'), ('received', 'VBD'), ('support', 'JJ'), ('U.S.', 'NNP'), ('last', 'JJ'), ('ten', 'JJ'), ('years', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['limitations current', 'current technology', 'technology ,', ', described', 'described Section', 'Section 1.2.1.', '1.2.1. paper', 'paper ,', ', illustrated', 'illustrated considering', 'considering NL', 'NL access', 'access databases', 'databases ,', ', application', 'application probably', 'probably received', 'received support', 'support U.S.', 'U.S. last', 'last ten', 'ten years', 'years .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['limitations current technology', 'current technology ,', 'technology , described', ', described Section', 'described Section 1.2.1.', 'Section 1.2.1. paper', '1.2.1. paper ,', 'paper , illustrated', ', illustrated considering', 'illustrated considering NL', 'considering NL access', 'NL access databases', 'access databases ,', 'databases , application', ', application probably', 'application probably received', 'probably received support', 'received support U.S.', 'support U.S. last', 'U.S. last ten', 'last ten years', 'ten years .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['current technology', 'Section', 'paper', 'access', 'application'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['U.S.']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['limit', 'current', 'technolog', ',', 'describ', 'section', '1.2.1.', 'paper', ',', 'illustr', 'consid', 'nl', 'access', 'databas', ',', 'applic', 'probabl', 'receiv', 'support', 'u.s.', 'last', 'ten', 'year', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['limit', 'current', 'technolog', ',', 'describ', 'section', '1.2.1.', 'paper', ',', 'illustr', 'consid', 'nl', 'access', 'databas', ',', 'applic', 'probabl', 'receiv', 'support', 'u.s.', 'last', 'ten', 'year', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['limitation', 'current', 'technology', ',', 'described', 'Section', '1.2.1.', 'paper', ',', 'illustrated', 'considering', 'NL', 'access', 'database', ',', 'application', 'probably', 'received', 'support', 'U.S.', 'last', 'ten', 'year', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

115 --> The nature of the task limits the range of inputs the system  can expect to see and the semantic distinctions that need to be reflected m the MRL. 


 ---- TOKENS ----

 ['The', 'nature', 'of', 'the', 'task', 'limits', 'the', 'range', 'of', 'inputs', 'the', 'system', 'can', 'expect', 'to', 'see', 'and', 'the', 'semantic', 'distinctions', 'that', 'need', 'to', 'be', 'reflected', 'm', 'the', 'MRL', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('The', 'DT'), ('nature', 'NN'), ('of', 'IN'), ('the', 'DT'), ('task', 'NN'), ('limits', 'VBZ'), ('the', 'DT'), ('range', 'NN'), ('of', 'IN'), ('inputs', 'NNS'), ('the', 'DT'), ('system', 'NN'), ('can', 'MD'), ('expect', 'VB'), ('to', 'TO'), ('see', 'VB'), ('and', 'CC'), ('the', 'DT'), ('semantic', 'JJ'), ('distinctions', 'NNS'), ('that', 'WDT'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('reflected', 'VBN'), ('m', 'PDT'), ('the', 'DT'), ('MRL', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['nature', 'task', 'limits', 'range', 'inputs', 'system', 'expect', 'see', 'semantic', 'distinctions', 'need', 'reflected', 'MRL', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('nature', 'NN'), ('task', 'NN'), ('limits', 'NNS'), ('range', 'VBP'), ('inputs', 'NNS'), ('system', 'NN'), ('expect', 'VBP'), ('see', 'VB'), ('semantic', 'JJ'), ('distinctions', 'NNS'), ('need', 'VBP'), ('reflected', 'VBN'), ('MRL', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['nature task', 'task limits', 'limits range', 'range inputs', 'inputs system', 'system expect', 'expect see', 'see semantic', 'semantic distinctions', 'distinctions need', 'need reflected', 'reflected MRL', 'MRL .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['nature task limits', 'task limits range', 'limits range inputs', 'range inputs system', 'inputs system expect', 'system expect see', 'expect see semantic', 'see semantic distinctions', 'semantic distinctions need', 'distinctions need reflected', 'need reflected MRL', 'reflected MRL .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['nature', 'task', 'system'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['MRL']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['natur', 'task', 'limit', 'rang', 'input', 'system', 'expect', 'see', 'semant', 'distinct', 'need', 'reflect', 'mrl', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['natur', 'task', 'limit', 'rang', 'input', 'system', 'expect', 'see', 'semant', 'distinct', 'need', 'reflect', 'mrl', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['nature', 'task', 'limit', 'range', 'input', 'system', 'expect', 'see', 'semantic', 'distinction', 'need', 'reflected', 'MRL', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

116 --> Reasoning m relational  databases is limited to the operations of relational algebra on purely extensional information, so certain concepts,  such as tense and modality, need not be reflected in the MRL either. 


 ---- TOKENS ----

 ['Reasoning', 'm', 'relational', 'databases', 'is', 'limited', 'to', 'the', 'operations', 'of', 'relational', 'algebra', 'on', 'purely', 'extensional', 'information', ',', 'so', 'certain', 'concepts', ',', 'such', 'as', 'tense', 'and', 'modality', ',', 'need', 'not', 'be', 'reflected', 'in', 'the', 'MRL', 'either', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('Reasoning', 'VBG'), ('m', 'JJ'), ('relational', 'JJ'), ('databases', 'NNS'), ('is', 'VBZ'), ('limited', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('operations', 'NNS'), ('of', 'IN'), ('relational', 'JJ'), ('algebra', 'NN'), ('on', 'IN'), ('purely', 'JJ'), ('extensional', 'JJ'), ('information', 'NN'), (',', ','), ('so', 'RB'), ('certain', 'JJ'), ('concepts', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('tense', 'NN'), ('and', 'CC'), ('modality', 'NN'), (',', ','), ('need', 'MD'), ('not', 'RB'), ('be', 'VB'), ('reflected', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('MRL', 'NNP'), ('either', 'CC'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Reasoning', 'relational', 'databases', 'limited', 'operations', 'relational', 'algebra', 'purely', 'extensional', 'information', ',', 'certain', 'concepts', ',', 'tense', 'modality', ',', 'need', 'reflected', 'MRL', 'either', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('Reasoning', 'VBG'), ('relational', 'JJ'), ('databases', 'NNS'), ('limited', 'JJ'), ('operations', 'NNS'), ('relational', 'JJ'), ('algebra', 'NN'), ('purely', 'RB'), ('extensional', 'JJ'), ('information', 'NN'), (',', ','), ('certain', 'JJ'), ('concepts', 'NNS'), (',', ','), ('tense', 'JJ'), ('modality', 'NN'), (',', ','), ('need', 'VBP'), ('reflected', 'VBN'), ('MRL', 'NNP'), ('either', 'DT'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Reasoning relational', 'relational databases', 'databases limited', 'limited operations', 'operations relational', 'relational algebra', 'algebra purely', 'purely extensional', 'extensional information', 'information ,', ', certain', 'certain concepts', 'concepts ,', ', tense', 'tense modality', 'modality ,', ', need', 'need reflected', 'reflected MRL', 'MRL either', 'either .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['Reasoning relational databases', 'relational databases limited', 'databases limited operations', 'limited operations relational', 'operations relational algebra', 'relational algebra purely', 'algebra purely extensional', 'purely extensional information', 'extensional information ,', 'information , certain', ', certain concepts', 'certain concepts ,', 'concepts , tense', ', tense modality', 'tense modality ,', 'modality , need', ', need reflected', 'need reflected MRL', 'reflected MRL either', 'MRL either .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['relational algebra', 'extensional information', 'tense modality'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['MRL']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['reason', 'relat', 'databas', 'limit', 'oper', 'relat', 'algebra', 'pure', 'extension', 'inform', ',', 'certain', 'concept', ',', 'tens', 'modal', ',', 'need', 'reflect', 'mrl', 'either', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['reason', 'relat', 'databas', 'limit', 'oper', 'relat', 'algebra', 'pure', 'extension', 'inform', ',', 'certain', 'concept', ',', 'tens', 'modal', ',', 'need', 'reflect', 'mrl', 'either', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['Reasoning', 'relational', 'database', 'limited', 'operation', 'relational', 'algebra', 'purely', 'extensional', 'information', ',', 'certain', 'concept', ',', 'tense', 'modality', ',', 'need', 'reflected', 'MRL', 'either', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

117 --> Limitations on the content of a database can  485   guarantee that certain interpretation ambiguities will not arise, or that they can often be resolved by simple means. 


 ---- TOKENS ----

 ['Limitations', 'on', 'the', 'content', 'of', 'a', 'database', 'can', '485', 'guarantee', 'that', 'certain', 'interpretation', 'ambiguities', 'will', 'not', 'arise', ',', 'or', 'that', 'they', 'can', 'often', 'be', 'resolved', 'by', 'simple', 'means', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('Limitations', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('content', 'NN'), ('of', 'IN'), ('a', 'DT'), ('database', 'NN'), ('can', 'MD'), ('485', 'CD'), ('guarantee', 'NN'), ('that', 'WDT'), ('certain', 'JJ'), ('interpretation', 'NN'), ('ambiguities', 'NNS'), ('will', 'MD'), ('not', 'RB'), ('arise', 'VB'), (',', ','), ('or', 'CC'), ('that', 'IN'), ('they', 'PRP'), ('can', 'MD'), ('often', 'RB'), ('be', 'VB'), ('resolved', 'VBN'), ('by', 'IN'), ('simple', 'JJ'), ('means', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Limitations', 'content', 'database', '485', 'guarantee', 'certain', 'interpretation', 'ambiguities', 'arise', ',', 'often', 'resolved', 'simple', 'means', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Limitations', 'NNS'), ('content', 'JJ'), ('database', 'NN'), ('485', 'CD'), ('guarantee', 'NN'), ('certain', 'JJ'), ('interpretation', 'NN'), ('ambiguities', 'NNS'), ('arise', 'VBP'), (',', ','), ('often', 'RB'), ('resolved', 'VBN'), ('simple', 'JJ'), ('means', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Limitations content', 'content database', 'database 485', '485 guarantee', 'guarantee certain', 'certain interpretation', 'interpretation ambiguities', 'ambiguities arise', 'arise ,', ', often', 'often resolved', 'resolved simple', 'simple means', 'means .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Limitations content database', 'content database 485', 'database 485 guarantee', '485 guarantee certain', 'guarantee certain interpretation', 'certain interpretation ambiguities', 'interpretation ambiguities arise', 'ambiguities arise ,', 'arise , often', ', often resolved', 'often resolved simple', 'resolved simple means', 'simple means .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['content database', 'guarantee', 'certain interpretation'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['limit', 'content', 'databas', '485', 'guarante', 'certain', 'interpret', 'ambigu', 'aris', ',', 'often', 'resolv', 'simpl', 'mean', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['limit', 'content', 'databas', '485', 'guarante', 'certain', 'interpret', 'ambigu', 'aris', ',', 'often', 'resolv', 'simpl', 'mean', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Limitations', 'content', 'database', '485', 'guarantee', 'certain', 'interpretation', 'ambiguity', 'arise', ',', 'often', 'resolved', 'simple', 'mean', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

118 --> In a geographical database, occurrences of the noun "bank"  as a financial institution probably never need be  considered at all in interpreting "What are the cities on the left bank of the Rhone?". 


 ---- TOKENS ----

 ['In', 'a', 'geographical', 'database', ',', 'occurrences', 'of', 'the', 'noun', '``', 'bank', "''", 'as', 'a', 'financial', 'institution', 'probably', 'never', 'need', 'be', 'considered', 'at', 'all', 'in', 'interpreting', '``', 'What', 'are', 'the', 'cities', 'on', 'the', 'left', 'bank', 'of', 'the', 'Rhone', '?', '``', '.'] 

 TOTAL TOKENS ==> 40

 ---- POST ----

 [('In', 'IN'), ('a', 'DT'), ('geographical', 'JJ'), ('database', 'NN'), (',', ','), ('occurrences', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('noun', 'NN'), ('``', '``'), ('bank', 'NN'), ("''", "''"), ('as', 'IN'), ('a', 'DT'), ('financial', 'JJ'), ('institution', 'NN'), ('probably', 'RB'), ('never', 'RB'), ('need', 'VBP'), ('be', 'VB'), ('considered', 'VBN'), ('at', 'IN'), ('all', 'DT'), ('in', 'IN'), ('interpreting', 'VBG'), ('``', '``'), ('What', 'WP'), ('are', 'VBP'), ('the', 'DT'), ('cities', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('left', 'JJ'), ('bank', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Rhone', 'NNP'), ('?', '.'), ('``', '``'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['geographical', 'database', ',', 'occurrences', 'noun', '``', 'bank', "''", 'financial', 'institution', 'probably', 'never', 'need', 'considered', 'interpreting', '``', 'cities', 'left', 'bank', 'Rhone', '?', '``', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('geographical', 'JJ'), ('database', 'NN'), (',', ','), ('occurrences', 'VBZ'), ('noun', 'CC'), ('``', '``'), ('bank', 'NN'), ("''", "''"), ('financial', 'JJ'), ('institution', 'NN'), ('probably', 'RB'), ('never', 'RB'), ('need', 'VB'), ('considered', 'VBN'), ('interpreting', 'VBG'), ('``', '``'), ('cities', 'NNS'), ('left', 'VBD'), ('bank', 'NN'), ('Rhone', 'NNP'), ('?', '.'), ('``', '``'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['geographical database', 'database ,', ', occurrences', 'occurrences noun', 'noun ``', '`` bank', "bank ''", "'' financial", 'financial institution', 'institution probably', 'probably never', 'never need', 'need considered', 'considered interpreting', 'interpreting ``', '`` cities', 'cities left', 'left bank', 'bank Rhone', 'Rhone ?', '? ``', '`` .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['geographical database ,', 'database , occurrences', ', occurrences noun', 'occurrences noun ``', 'noun `` bank', "`` bank ''", "bank '' financial", "'' financial institution", 'financial institution probably', 'institution probably never', 'probably never need', 'never need considered', 'need considered interpreting', 'considered interpreting ``', 'interpreting `` cities', '`` cities left', 'cities left bank', 'left bank Rhone', 'bank Rhone ?', 'Rhone ? ``', '? `` .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['geographical database', 'bank', 'financial institution', 'bank'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Rhone']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['geograph', 'databas', ',', 'occurr', 'noun', '``', 'bank', "''", 'financi', 'institut', 'probabl', 'never', 'need', 'consid', 'interpret', '``', 'citi', 'left', 'bank', 'rhone', '?', '``', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['geograph', 'databas', ',', 'occurr', 'noun', '``', 'bank', "''", 'financi', 'institut', 'probabl', 'never', 'need', 'consid', 'interpret', '``', 'citi', 'left', 'bank', 'rhone', '?', '``', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['geographical', 'database', ',', 'occurrence', 'noun', '``', 'bank', "''", 'financial', 'institution', 'probably', 'never', 'need', 'considered', 'interpreting', '``', 'city', 'left', 'bank', 'Rhone', '?', '``', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

119 --> If countries but not mountains  have populations, then in "What is the population of Kenya? 


 ---- TOKENS ----

 ['If', 'countries', 'but', 'not', 'mountains', 'have', 'populations', ',', 'then', 'in', '``', 'What', 'is', 'the', 'population', 'of', 'Kenya', '?'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('If', 'IN'), ('countries', 'NNS'), ('but', 'CC'), ('not', 'RB'), ('mountains', 'NNS'), ('have', 'VBP'), ('populations', 'NNS'), (',', ','), ('then', 'RB'), ('in', 'IN'), ('``', '``'), ('What', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('population', 'NN'), ('of', 'IN'), ('Kenya', 'NNP'), ('?', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['countries', 'mountains', 'populations', ',', '``', 'population', 'Kenya', '?']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('countries', 'NNS'), ('mountains', 'VBZ'), ('populations', 'NNS'), (',', ','), ('``', '``'), ('population', 'NN'), ('Kenya', 'NNP'), ('?', '.')] 



 ---- BI-GRAMS ---- 

 ['countries mountains', 'mountains populations', 'populations ,', ', ``', '`` population', 'population Kenya', 'Kenya ?'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['countries mountains populations', 'mountains populations ,', 'populations , ``', ', `` population', '`` population Kenya', 'population Kenya ?'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['population'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Kenya']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['countri', 'mountain', 'popul', ',', '``', 'popul', 'kenya', '?']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['countri', 'mountain', 'popul', ',', '``', 'popul', 'kenya', '?']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['country', 'mountain', 'population', ',', '``', 'population', 'Kenya', '?']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

120 --> ", Kenya means the country, not the mountain. 


 ---- TOKENS ----

 ['``', ',', 'Kenya', 'means', 'the', 'country', ',', 'not', 'the', 'mountain', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('``', '``'), (',', ','), ('Kenya', 'NNP'), ('means', 'VBZ'), ('the', 'DT'), ('country', 'NN'), (',', ','), ('not', 'RB'), ('the', 'DT'), ('mountain', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['``', ',', 'Kenya', 'means', 'country', ',', 'mountain', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('``', '``'), (',', ','), ('Kenya', 'NNP'), ('means', 'VBZ'), ('country', 'NN'), (',', ','), ('mountain', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['`` ,', ', Kenya', 'Kenya means', 'means country', 'country ,', ', mountain', 'mountain .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['`` , Kenya', ', Kenya means', 'Kenya means country', 'means country ,', 'country , mountain', ', mountain .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['country', 'mountain'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Kenya']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['``', ',', 'kenya', 'mean', 'countri', ',', 'mountain', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['``', ',', 'kenya', 'mean', 'countri', ',', 'mountain', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['``', ',', 'Kenya', 'mean', 'country', ',', 'mountain', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

121 --> By  assuming the user will adapt to the system and that NL can substitute for an artificial language, the NL interface  treats each question in isolation with only a very general, weak notion of tim goal in an utterance. 


 ---- TOKENS ----

 ['By', 'assuming', 'the', 'user', 'will', 'adapt', 'to', 'the', 'system', 'and', 'that', 'NL', 'can', 'substitute', 'for', 'an', 'artificial', 'language', ',', 'the', 'NL', 'interface', 'treats', 'each', 'question', 'in', 'isolation', 'with', 'only', 'a', 'very', 'general', ',', 'weak', 'notion', 'of', 'tim', 'goal', 'in', 'an', 'utterance', '.'] 

 TOTAL TOKENS ==> 42

 ---- POST ----

 [('By', 'IN'), ('assuming', 'VBG'), ('the', 'DT'), ('user', 'NN'), ('will', 'MD'), ('adapt', 'VB'), ('to', 'TO'), ('the', 'DT'), ('system', 'NN'), ('and', 'CC'), ('that', 'IN'), ('NL', 'NNP'), ('can', 'MD'), ('substitute', 'VB'), ('for', 'IN'), ('an', 'DT'), ('artificial', 'JJ'), ('language', 'NN'), (',', ','), ('the', 'DT'), ('NL', 'NNP'), ('interface', 'NN'), ('treats', 'VBZ'), ('each', 'DT'), ('question', 'NN'), ('in', 'IN'), ('isolation', 'NN'), ('with', 'IN'), ('only', 'RB'), ('a', 'DT'), ('very', 'RB'), ('general', 'JJ'), (',', ','), ('weak', 'JJ'), ('notion', 'NN'), ('of', 'IN'), ('tim', 'JJ'), ('goal', 'NN'), ('in', 'IN'), ('an', 'DT'), ('utterance', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['assuming', 'user', 'adapt', 'system', 'NL', 'substitute', 'artificial', 'language', ',', 'NL', 'interface', 'treats', 'question', 'isolation', 'general', ',', 'weak', 'notion', 'tim', 'goal', 'utterance', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('assuming', 'VBG'), ('user', 'NN'), ('adapt', 'NN'), ('system', 'NN'), ('NL', 'NNP'), ('substitute', 'NN'), ('artificial', 'JJ'), ('language', 'NN'), (',', ','), ('NL', 'NNP'), ('interface', 'NN'), ('treats', 'NNS'), ('question', 'VBP'), ('isolation', 'NN'), ('general', 'NN'), (',', ','), ('weak', 'JJ'), ('notion', 'NN'), ('tim', 'NN'), ('goal', 'NN'), ('utterance', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['assuming user', 'user adapt', 'adapt system', 'system NL', 'NL substitute', 'substitute artificial', 'artificial language', 'language ,', ', NL', 'NL interface', 'interface treats', 'treats question', 'question isolation', 'isolation general', 'general ,', ', weak', 'weak notion', 'notion tim', 'tim goal', 'goal utterance', 'utterance .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['assuming user adapt', 'user adapt system', 'adapt system NL', 'system NL substitute', 'NL substitute artificial', 'substitute artificial language', 'artificial language ,', 'language , NL', ', NL interface', 'NL interface treats', 'interface treats question', 'treats question isolation', 'question isolation general', 'isolation general ,', 'general , weak', ', weak notion', 'weak notion tim', 'notion tim goal', 'tim goal utterance', 'goal utterance .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['user', 'adapt', 'system', 'substitute', 'artificial language', 'interface', 'isolation', 'general', 'weak notion', 'tim', 'goal', 'utterance'] 

 TOTAL NOUN PHRASES --> 12 



 ---- NER ----

 
 ORGANIZATION ---> ['NL']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['assum', 'user', 'adapt', 'system', 'nl', 'substitut', 'artifici', 'languag', ',', 'nl', 'interfac', 'treat', 'question', 'isol', 'gener', ',', 'weak', 'notion', 'tim', 'goal', 'utter', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['assum', 'user', 'adapt', 'system', 'nl', 'substitut', 'artifici', 'languag', ',', 'nl', 'interfac', 'treat', 'question', 'isol', 'general', ',', 'weak', 'notion', 'tim', 'goal', 'utter', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['assuming', 'user', 'adapt', 'system', 'NL', 'substitute', 'artificial', 'language', ',', 'NL', 'interface', 'treat', 'question', 'isolation', 'general', ',', 'weak', 'notion', 'tim', 'goal', 'utterance', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

122 --> The availability of these kinds of restrictions has aUowed NL database query systems to be successful  using relatively simple frameworks in which to encode the necessary knowledge sources {grammars, type and sortal  information, lists of mentioned entities) applied in relatively simple ways (parsing, recursive tree transformations). 


 ---- TOKENS ----

 ['The', 'availability', 'of', 'these', 'kinds', 'of', 'restrictions', 'has', 'aUowed', 'NL', 'database', 'query', 'systems', 'to', 'be', 'successful', 'using', 'relatively', 'simple', 'frameworks', 'in', 'which', 'to', 'encode', 'the', 'necessary', 'knowledge', 'sources', '{', 'grammars', ',', 'type', 'and', 'sortal', 'information', ',', 'lists', 'of', 'mentioned', 'entities', ')', 'applied', 'in', 'relatively', 'simple', 'ways', '(', 'parsing', ',', 'recursive', 'tree', 'transformations', ')', '.'] 

 TOTAL TOKENS ==> 54

 ---- POST ----

 [('The', 'DT'), ('availability', 'NN'), ('of', 'IN'), ('these', 'DT'), ('kinds', 'NNS'), ('of', 'IN'), ('restrictions', 'NNS'), ('has', 'VBZ'), ('aUowed', 'VBN'), ('NL', 'NNP'), ('database', 'NN'), ('query', 'NN'), ('systems', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('successful', 'JJ'), ('using', 'VBG'), ('relatively', 'RB'), ('simple', 'JJ'), ('frameworks', 'NNS'), ('in', 'IN'), ('which', 'WDT'), ('to', 'TO'), ('encode', 'VB'), ('the', 'DT'), ('necessary', 'JJ'), ('knowledge', 'NN'), ('sources', 'NNS'), ('{', '('), ('grammars', 'NNS'), (',', ','), ('type', 'NN'), ('and', 'CC'), ('sortal', 'JJ'), ('information', 'NN'), (',', ','), ('lists', 'NNS'), ('of', 'IN'), ('mentioned', 'JJ'), ('entities', 'NNS'), (')', ')'), ('applied', 'VBN'), ('in', 'IN'), ('relatively', 'RB'), ('simple', 'JJ'), ('ways', 'NNS'), ('(', '('), ('parsing', 'VBG'), (',', ','), ('recursive', 'JJ'), ('tree', 'NN'), ('transformations', 'NNS'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['availability', 'kinds', 'restrictions', 'aUowed', 'NL', 'database', 'query', 'systems', 'successful', 'using', 'relatively', 'simple', 'frameworks', 'encode', 'necessary', 'knowledge', 'sources', '{', 'grammars', ',', 'type', 'sortal', 'information', ',', 'lists', 'mentioned', 'entities', ')', 'applied', 'relatively', 'simple', 'ways', '(', 'parsing', ',', 'recursive', 'tree', 'transformations', ')', '.']

 TOTAL FILTERED TOKENS ==>  40

 ---- POST FOR FILTERED TOKENS ----

 [('availability', 'NN'), ('kinds', 'NNS'), ('restrictions', 'NNS'), ('aUowed', 'VBD'), ('NL', 'NNP'), ('database', 'NN'), ('query', 'NN'), ('systems', 'NNS'), ('successful', 'JJ'), ('using', 'VBG'), ('relatively', 'RB'), ('simple', 'JJ'), ('frameworks', 'NNS'), ('encode', 'VBP'), ('necessary', 'JJ'), ('knowledge', 'NN'), ('sources', 'NNS'), ('{', '('), ('grammars', 'NNS'), (',', ','), ('type', 'JJ'), ('sortal', 'JJ'), ('information', 'NN'), (',', ','), ('lists', 'NNS'), ('mentioned', 'VBD'), ('entities', 'NNS'), (')', ')'), ('applied', 'VBD'), ('relatively', 'RB'), ('simple', 'JJ'), ('ways', 'NNS'), ('(', '('), ('parsing', 'VBG'), (',', ','), ('recursive', 'JJ'), ('tree', 'NN'), ('transformations', 'NNS'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['availability kinds', 'kinds restrictions', 'restrictions aUowed', 'aUowed NL', 'NL database', 'database query', 'query systems', 'systems successful', 'successful using', 'using relatively', 'relatively simple', 'simple frameworks', 'frameworks encode', 'encode necessary', 'necessary knowledge', 'knowledge sources', 'sources {', '{ grammars', 'grammars ,', ', type', 'type sortal', 'sortal information', 'information ,', ', lists', 'lists mentioned', 'mentioned entities', 'entities )', ') applied', 'applied relatively', 'relatively simple', 'simple ways', 'ways (', '( parsing', 'parsing ,', ', recursive', 'recursive tree', 'tree transformations', 'transformations )', ') .'] 

 TOTAL BIGRAMS --> 39 



 ---- TRI-GRAMS ---- 

 ['availability kinds restrictions', 'kinds restrictions aUowed', 'restrictions aUowed NL', 'aUowed NL database', 'NL database query', 'database query systems', 'query systems successful', 'systems successful using', 'successful using relatively', 'using relatively simple', 'relatively simple frameworks', 'simple frameworks encode', 'frameworks encode necessary', 'encode necessary knowledge', 'necessary knowledge sources', 'knowledge sources {', 'sources { grammars', '{ grammars ,', 'grammars , type', ', type sortal', 'type sortal information', 'sortal information ,', 'information , lists', ', lists mentioned', 'lists mentioned entities', 'mentioned entities )', 'entities ) applied', ') applied relatively', 'applied relatively simple', 'relatively simple ways', 'simple ways (', 'ways ( parsing', '( parsing ,', 'parsing , recursive', ', recursive tree', 'recursive tree transformations', 'tree transformations )', 'transformations ) .'] 

 TOTAL TRIGRAMS --> 38 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['avail', 'kind', 'restrict', 'auow', 'nl', 'databas', 'queri', 'system', 'success', 'use', 'rel', 'simpl', 'framework', 'encod', 'necessari', 'knowledg', 'sourc', '{', 'grammar', ',', 'type', 'sortal', 'inform', ',', 'list', 'mention', 'entiti', ')', 'appli', 'rel', 'simpl', 'way', '(', 'pars', ',', 'recurs', 'tree', 'transform', ')', '.']

 TOTAL PORTER STEM WORDS ==> 40



 ---- SNOWBALL STEMMING ----

['avail', 'kind', 'restrict', 'auow', 'nl', 'databas', 'queri', 'system', 'success', 'use', 'relat', 'simpl', 'framework', 'encod', 'necessari', 'knowledg', 'sourc', '{', 'grammar', ',', 'type', 'sortal', 'inform', ',', 'list', 'mention', 'entiti', ')', 'appli', 'relat', 'simpl', 'way', '(', 'pars', ',', 'recurs', 'tree', 'transform', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 40



 ---- LEMMATIZATION ----

['availability', 'kind', 'restriction', 'aUowed', 'NL', 'database', 'query', 'system', 'successful', 'using', 'relatively', 'simple', 'framework', 'encode', 'necessary', 'knowledge', 'source', '{', 'grammar', ',', 'type', 'sortal', 'information', ',', 'list', 'mentioned', 'entity', ')', 'applied', 'relatively', 'simple', 'way', '(', 'parsing', ',', 'recursive', 'tree', 'transformation', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 40

************************************************************************************************************************

123 --> This is not to minimize the effort required to build the grammar, semantic model, etc. 


 ---- TOKENS ----

 ['This', 'is', 'not', 'to', 'minimize', 'the', 'effort', 'required', 'to', 'build', 'the', 'grammar', ',', 'semantic', 'model', ',', 'etc', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('This', 'DT'), ('is', 'VBZ'), ('not', 'RB'), ('to', 'TO'), ('minimize', 'VB'), ('the', 'DT'), ('effort', 'NN'), ('required', 'VBN'), ('to', 'TO'), ('build', 'VB'), ('the', 'DT'), ('grammar', 'NN'), (',', ','), ('semantic', 'JJ'), ('model', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['minimize', 'effort', 'required', 'build', 'grammar', ',', 'semantic', 'model', ',', 'etc', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('minimize', 'VB'), ('effort', 'NN'), ('required', 'VBN'), ('build', 'JJ'), ('grammar', 'NN'), (',', ','), ('semantic', 'JJ'), ('model', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['minimize effort', 'effort required', 'required build', 'build grammar', 'grammar ,', ', semantic', 'semantic model', 'model ,', ', etc', 'etc .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['minimize effort required', 'effort required build', 'required build grammar', 'build grammar ,', 'grammar , semantic', ', semantic model', 'semantic model ,', 'model , etc', ', etc .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['effort', 'build grammar', 'semantic model'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['minim', 'effort', 'requir', 'build', 'grammar', ',', 'semant', 'model', ',', 'etc', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['minim', 'effort', 'requir', 'build', 'grammar', ',', 'semant', 'model', ',', 'etc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['minimize', 'effort', 'required', 'build', 'grammar', ',', 'semantic', 'model', ',', 'etc', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

124 --> for a particular application. 


 ---- TOKENS ----

 ['for', 'a', 'particular', 'application', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('for', 'IN'), ('a', 'DT'), ('particular', 'JJ'), ('application', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['particular', 'application', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('particular', 'JJ'), ('application', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['particular application', 'application .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['particular application .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['particular application'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['particular', 'applic', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['particular', 'applic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['particular', 'application', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

125 --> The size of the vocabulary per  se is not a limiting factor, though it does impact the initial cost of bringing  up the NLP. 


 ---- TOKENS ----

 ['The', 'size', 'of', 'the', 'vocabulary', 'per', 'se', 'is', 'not', 'a', 'limiting', 'factor', ',', 'though', 'it', 'does', 'impact', 'the', 'initial', 'cost', 'of', 'bringing', 'up', 'the', 'NLP', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('The', 'DT'), ('size', 'NN'), ('of', 'IN'), ('the', 'DT'), ('vocabulary', 'JJ'), ('per', 'IN'), ('se', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('a', 'DT'), ('limiting', 'JJ'), ('factor', 'NN'), (',', ','), ('though', 'IN'), ('it', 'PRP'), ('does', 'VBZ'), ('impact', 'VB'), ('the', 'DT'), ('initial', 'JJ'), ('cost', 'NN'), ('of', 'IN'), ('bringing', 'VBG'), ('up', 'RP'), ('the', 'DT'), ('NLP', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['size', 'vocabulary', 'per', 'se', 'limiting', 'factor', ',', 'though', 'impact', 'initial', 'cost', 'bringing', 'NLP', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('size', 'NN'), ('vocabulary', 'JJ'), ('per', 'IN'), ('se', 'NN'), ('limiting', 'VBG'), ('factor', 'NN'), (',', ','), ('though', 'IN'), ('impact', 'JJ'), ('initial', 'JJ'), ('cost', 'NN'), ('bringing', 'NN'), ('NLP', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['size vocabulary', 'vocabulary per', 'per se', 'se limiting', 'limiting factor', 'factor ,', ', though', 'though impact', 'impact initial', 'initial cost', 'cost bringing', 'bringing NLP', 'NLP .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['size vocabulary per', 'vocabulary per se', 'per se limiting', 'se limiting factor', 'limiting factor ,', 'factor , though', ', though impact', 'though impact initial', 'impact initial cost', 'initial cost bringing', 'cost bringing NLP', 'bringing NLP .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['size', 'se', 'factor', 'impact initial cost', 'bringing'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['size', 'vocabulari', 'per', 'se', 'limit', 'factor', ',', 'though', 'impact', 'initi', 'cost', 'bring', 'nlp', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['size', 'vocabulari', 'per', 'se', 'limit', 'factor', ',', 'though', 'impact', 'initi', 'cost', 'bring', 'nlp', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['size', 'vocabulary', 'per', 'se', 'limiting', 'factor', ',', 'though', 'impact', 'initial', 'cost', 'bringing', 'NLP', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

126 --> Rather what is limiting is the number of word senses per word in the vocabulary, whether the language  involves substantial intersentential effects (discourse structure), and whether the underlying semantics is richer than  that of relational databases. 


 ---- TOKENS ----

 ['Rather', 'what', 'is', 'limiting', 'is', 'the', 'number', 'of', 'word', 'senses', 'per', 'word', 'in', 'the', 'vocabulary', ',', 'whether', 'the', 'language', 'involves', 'substantial', 'intersentential', 'effects', '(', 'discourse', 'structure', ')', ',', 'and', 'whether', 'the', 'underlying', 'semantics', 'is', 'richer', 'than', 'that', 'of', 'relational', 'databases', '.'] 

 TOTAL TOKENS ==> 41

 ---- POST ----

 [('Rather', 'RB'), ('what', 'WP'), ('is', 'VBZ'), ('limiting', 'VBG'), ('is', 'VBZ'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('word', 'NN'), ('senses', 'NNS'), ('per', 'IN'), ('word', 'NN'), ('in', 'IN'), ('the', 'DT'), ('vocabulary', 'NN'), (',', ','), ('whether', 'IN'), ('the', 'DT'), ('language', 'NN'), ('involves', 'VBZ'), ('substantial', 'JJ'), ('intersentential', 'JJ'), ('effects', 'NNS'), ('(', '('), ('discourse', 'JJ'), ('structure', 'NN'), (')', ')'), (',', ','), ('and', 'CC'), ('whether', 'IN'), ('the', 'DT'), ('underlying', 'JJ'), ('semantics', 'NNS'), ('is', 'VBZ'), ('richer', 'JJR'), ('than', 'IN'), ('that', 'DT'), ('of', 'IN'), ('relational', 'JJ'), ('databases', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Rather', 'limiting', 'number', 'word', 'senses', 'per', 'word', 'vocabulary', ',', 'whether', 'language', 'involves', 'substantial', 'intersentential', 'effects', '(', 'discourse', 'structure', ')', ',', 'whether', 'underlying', 'semantics', 'richer', 'relational', 'databases', '.']

 TOTAL FILTERED TOKENS ==>  27

 ---- POST FOR FILTERED TOKENS ----

 [('Rather', 'RB'), ('limiting', 'VBG'), ('number', 'NN'), ('word', 'NN'), ('senses', 'VBZ'), ('per', 'IN'), ('word', 'NN'), ('vocabulary', 'NN'), (',', ','), ('whether', 'IN'), ('language', 'NN'), ('involves', 'VBZ'), ('substantial', 'JJ'), ('intersentential', 'JJ'), ('effects', 'NNS'), ('(', '('), ('discourse', 'JJ'), ('structure', 'NN'), (')', ')'), (',', ','), ('whether', 'IN'), ('underlying', 'VBG'), ('semantics', 'NNS'), ('richer', 'VBP'), ('relational', 'JJ'), ('databases', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Rather limiting', 'limiting number', 'number word', 'word senses', 'senses per', 'per word', 'word vocabulary', 'vocabulary ,', ', whether', 'whether language', 'language involves', 'involves substantial', 'substantial intersentential', 'intersentential effects', 'effects (', '( discourse', 'discourse structure', 'structure )', ') ,', ', whether', 'whether underlying', 'underlying semantics', 'semantics richer', 'richer relational', 'relational databases', 'databases .'] 

 TOTAL BIGRAMS --> 26 



 ---- TRI-GRAMS ---- 

 ['Rather limiting number', 'limiting number word', 'number word senses', 'word senses per', 'senses per word', 'per word vocabulary', 'word vocabulary ,', 'vocabulary , whether', ', whether language', 'whether language involves', 'language involves substantial', 'involves substantial intersentential', 'substantial intersentential effects', 'intersentential effects (', 'effects ( discourse', '( discourse structure', 'discourse structure )', 'structure ) ,', ') , whether', ', whether underlying', 'whether underlying semantics', 'underlying semantics richer', 'semantics richer relational', 'richer relational databases', 'relational databases .'] 

 TOTAL TRIGRAMS --> 25 



 ---- NOUN PHRASES ---- 

 ['number', 'word', 'word', 'vocabulary', 'language'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['rather', 'limit', 'number', 'word', 'sens', 'per', 'word', 'vocabulari', ',', 'whether', 'languag', 'involv', 'substanti', 'intersententi', 'effect', '(', 'discours', 'structur', ')', ',', 'whether', 'underli', 'semant', 'richer', 'relat', 'databas', '.']

 TOTAL PORTER STEM WORDS ==> 27



 ---- SNOWBALL STEMMING ----

['rather', 'limit', 'number', 'word', 'sens', 'per', 'word', 'vocabulari', ',', 'whether', 'languag', 'involv', 'substanti', 'intersententi', 'effect', '(', 'discours', 'structur', ')', ',', 'whether', 'under', 'semant', 'richer', 'relat', 'databas', '.']

 TOTAL SNOWBALL STEM WORDS ==> 27



 ---- LEMMATIZATION ----

['Rather', 'limiting', 'number', 'word', 'sens', 'per', 'word', 'vocabulary', ',', 'whether', 'language', 'involves', 'substantial', 'intersentential', 'effect', '(', 'discourse', 'structure', ')', ',', 'whether', 'underlying', 'semantics', 'richer', 'relational', 'database', '.']

 TOTAL LEMMATIZE WORDS ==> 27

************************************************************************************************************************

127 --> Scientific progress. 


 ---- TOKENS ----

 ['Scientific', 'progress', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('Scientific', 'NNP'), ('progress', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Scientific', 'progress', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Scientific', 'NNP'), ('progress', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Scientific progress', 'progress .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Scientific progress .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['progress'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Scientific']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['scientif', 'progress', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['scientif', 'progress', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Scientific', 'progress', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

128 --> The scientific progress of the last 10 years can be described in terms of traditional  linguistic areas and in terms of task areas. 


 ---- TOKENS ----

 ['The', 'scientific', 'progress', 'of', 'the', 'last', '10', 'years', 'can', 'be', 'described', 'in', 'terms', 'of', 'traditional', 'linguistic', 'areas', 'and', 'in', 'terms', 'of', 'task', 'areas', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('The', 'DT'), ('scientific', 'JJ'), ('progress', 'NN'), ('of', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('10', 'CD'), ('years', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('described', 'VBN'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('traditional', 'JJ'), ('linguistic', 'JJ'), ('areas', 'NNS'), ('and', 'CC'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('task', 'NN'), ('areas', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['scientific', 'progress', 'last', '10', 'years', 'described', 'terms', 'traditional', 'linguistic', 'areas', 'terms', 'task', 'areas', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('scientific', 'JJ'), ('progress', 'NN'), ('last', 'JJ'), ('10', 'CD'), ('years', 'NNS'), ('described', 'VBD'), ('terms', 'NNS'), ('traditional', 'JJ'), ('linguistic', 'JJ'), ('areas', 'NNS'), ('terms', 'NNS'), ('task', 'VBP'), ('areas', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['scientific progress', 'progress last', 'last 10', '10 years', 'years described', 'described terms', 'terms traditional', 'traditional linguistic', 'linguistic areas', 'areas terms', 'terms task', 'task areas', 'areas .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['scientific progress last', 'progress last 10', 'last 10 years', '10 years described', 'years described terms', 'described terms traditional', 'terms traditional linguistic', 'traditional linguistic areas', 'linguistic areas terms', 'areas terms task', 'terms task areas', 'task areas .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['scientific progress'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['scientif', 'progress', 'last', '10', 'year', 'describ', 'term', 'tradit', 'linguist', 'area', 'term', 'task', 'area', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['scientif', 'progress', 'last', '10', 'year', 'describ', 'term', 'tradit', 'linguist', 'area', 'term', 'task', 'area', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['scientific', 'progress', 'last', '10', 'year', 'described', 'term', 'traditional', 'linguistic', 'area', 'term', 'task', 'area', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

129 --> The main development in syntax has been the shift from grammars including procedural constructs to ones  expressed purely declaratively. 


 ---- TOKENS ----

 ['The', 'main', 'development', 'in', 'syntax', 'has', 'been', 'the', 'shift', 'from', 'grammars', 'including', 'procedural', 'constructs', 'to', 'ones', 'expressed', 'purely', 'declaratively', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('The', 'DT'), ('main', 'JJ'), ('development', 'NN'), ('in', 'IN'), ('syntax', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('the', 'DT'), ('shift', 'NN'), ('from', 'IN'), ('grammars', 'NNS'), ('including', 'VBG'), ('procedural', 'JJ'), ('constructs', 'NNS'), ('to', 'TO'), ('ones', 'NNS'), ('expressed', 'VBN'), ('purely', 'RB'), ('declaratively', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['main', 'development', 'syntax', 'shift', 'grammars', 'including', 'procedural', 'constructs', 'ones', 'expressed', 'purely', 'declaratively', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('main', 'JJ'), ('development', 'NN'), ('syntax', 'NN'), ('shift', 'NN'), ('grammars', 'NNS'), ('including', 'VBG'), ('procedural', 'JJ'), ('constructs', 'NNS'), ('ones', 'NNS'), ('expressed', 'VBD'), ('purely', 'RB'), ('declaratively', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['main development', 'development syntax', 'syntax shift', 'shift grammars', 'grammars including', 'including procedural', 'procedural constructs', 'constructs ones', 'ones expressed', 'expressed purely', 'purely declaratively', 'declaratively .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['main development syntax', 'development syntax shift', 'syntax shift grammars', 'shift grammars including', 'grammars including procedural', 'including procedural constructs', 'procedural constructs ones', 'constructs ones expressed', 'ones expressed purely', 'expressed purely declaratively', 'purely declaratively .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['main development', 'syntax', 'shift'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['main', 'develop', 'syntax', 'shift', 'grammar', 'includ', 'procedur', 'construct', 'one', 'express', 'pure', 'declar', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['main', 'develop', 'syntax', 'shift', 'grammar', 'includ', 'procedur', 'construct', 'one', 'express', 'pure', 'declar', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['main', 'development', 'syntax', 'shift', 'grammar', 'including', 'procedural', 'construct', 'one', 'expressed', 'purely', 'declaratively', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

130 --> In contrast to context-free grammars, which use atomic symbols only, these so called  unification grammars use complex terms instead, with term unification instead of equality checking as the main  operation. 


 ---- TOKENS ----

 ['In', 'contrast', 'to', 'context-free', 'grammars', ',', 'which', 'use', 'atomic', 'symbols', 'only', ',', 'these', 'so', 'called', 'unification', 'grammars', 'use', 'complex', 'terms', 'instead', ',', 'with', 'term', 'unification', 'instead', 'of', 'equality', 'checking', 'as', 'the', 'main', 'operation', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('In', 'IN'), ('contrast', 'NN'), ('to', 'TO'), ('context-free', 'JJ'), ('grammars', 'NNS'), (',', ','), ('which', 'WDT'), ('use', 'VBP'), ('atomic', 'JJ'), ('symbols', 'NNS'), ('only', 'RB'), (',', ','), ('these', 'DT'), ('so', 'RB'), ('called', 'JJ'), ('unification', 'NN'), ('grammars', 'NNS'), ('use', 'VBP'), ('complex', 'JJ'), ('terms', 'NNS'), ('instead', 'RB'), (',', ','), ('with', 'IN'), ('term', 'NN'), ('unification', 'NN'), ('instead', 'RB'), ('of', 'IN'), ('equality', 'NN'), ('checking', 'NN'), ('as', 'IN'), ('the', 'DT'), ('main', 'JJ'), ('operation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['contrast', 'context-free', 'grammars', ',', 'use', 'atomic', 'symbols', ',', 'called', 'unification', 'grammars', 'use', 'complex', 'terms', 'instead', ',', 'term', 'unification', 'instead', 'equality', 'checking', 'main', 'operation', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('contrast', 'NN'), ('context-free', 'JJ'), ('grammars', 'NNS'), (',', ','), ('use', 'VBP'), ('atomic', 'JJ'), ('symbols', 'NNS'), (',', ','), ('called', 'VBN'), ('unification', 'NN'), ('grammars', 'NNS'), ('use', 'VBP'), ('complex', 'JJ'), ('terms', 'NNS'), ('instead', 'RB'), (',', ','), ('term', 'NN'), ('unification', 'NN'), ('instead', 'RB'), ('equality', 'NN'), ('checking', 'VBG'), ('main', 'JJ'), ('operation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['contrast context-free', 'context-free grammars', 'grammars ,', ', use', 'use atomic', 'atomic symbols', 'symbols ,', ', called', 'called unification', 'unification grammars', 'grammars use', 'use complex', 'complex terms', 'terms instead', 'instead ,', ', term', 'term unification', 'unification instead', 'instead equality', 'equality checking', 'checking main', 'main operation', 'operation .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['contrast context-free grammars', 'context-free grammars ,', 'grammars , use', ', use atomic', 'use atomic symbols', 'atomic symbols ,', 'symbols , called', ', called unification', 'called unification grammars', 'unification grammars use', 'grammars use complex', 'use complex terms', 'complex terms instead', 'terms instead ,', 'instead , term', ', term unification', 'term unification instead', 'unification instead equality', 'instead equality checking', 'equality checking main', 'checking main operation', 'main operation .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['contrast', 'unification', 'term', 'unification', 'equality', 'main operation'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['contrast', 'context-fre', 'grammar', ',', 'use', 'atom', 'symbol', ',', 'call', 'unif', 'grammar', 'use', 'complex', 'term', 'instead', ',', 'term', 'unif', 'instead', 'equal', 'check', 'main', 'oper', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['contrast', 'context-fre', 'grammar', ',', 'use', 'atom', 'symbol', ',', 'call', 'unif', 'grammar', 'use', 'complex', 'term', 'instead', ',', 'term', 'unif', 'instead', 'equal', 'check', 'main', 'oper', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['contrast', 'context-free', 'grammar', ',', 'use', 'atomic', 'symbol', ',', 'called', 'unification', 'grammar', 'use', 'complex', 'term', 'instead', ',', 'term', 'unification', 'instead', 'equality', 'checking', 'main', 'operation', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

131 --> "nais has allowed for the use of the same grammars with a range of algorithms, both sequential and  parallel, for analysis and generation. 


 ---- TOKENS ----

 ['``', 'nais', 'has', 'allowed', 'for', 'the', 'use', 'of', 'the', 'same', 'grammars', 'with', 'a', 'range', 'of', 'algorithms', ',', 'both', 'sequential', 'and', 'parallel', ',', 'for', 'analysis', 'and', 'generation', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('``', '``'), ('nais', 'NN'), ('has', 'VBZ'), ('allowed', 'VBN'), ('for', 'IN'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('grammars', 'NNS'), ('with', 'IN'), ('a', 'DT'), ('range', 'NN'), ('of', 'IN'), ('algorithms', 'NN'), (',', ','), ('both', 'DT'), ('sequential', 'JJ'), ('and', 'CC'), ('parallel', 'JJ'), (',', ','), ('for', 'IN'), ('analysis', 'NN'), ('and', 'CC'), ('generation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['``', 'nais', 'allowed', 'use', 'grammars', 'range', 'algorithms', ',', 'sequential', 'parallel', ',', 'analysis', 'generation', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('``', '``'), ('nais', 'NN'), ('allowed', 'VBN'), ('use', 'IN'), ('grammars', 'NNS'), ('range', 'VBP'), ('algorithms', 'RB'), (',', ','), ('sequential', 'JJ'), ('parallel', 'NN'), (',', ','), ('analysis', 'NN'), ('generation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['`` nais', 'nais allowed', 'allowed use', 'use grammars', 'grammars range', 'range algorithms', 'algorithms ,', ', sequential', 'sequential parallel', 'parallel ,', ', analysis', 'analysis generation', 'generation .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['`` nais allowed', 'nais allowed use', 'allowed use grammars', 'use grammars range', 'grammars range algorithms', 'range algorithms ,', 'algorithms , sequential', ', sequential parallel', 'sequential parallel ,', 'parallel , analysis', ', analysis generation', 'analysis generation .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['nais', 'sequential parallel', 'analysis', 'generation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['``', 'nai', 'allow', 'use', 'grammar', 'rang', 'algorithm', ',', 'sequenti', 'parallel', ',', 'analysi', 'gener', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['``', 'nai', 'allow', 'use', 'grammar', 'rang', 'algorithm', ',', 'sequenti', 'parallel', ',', 'analysi', 'generat', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['``', 'nais', 'allowed', 'use', 'grammar', 'range', 'algorithm', ',', 'sequential', 'parallel', ',', 'analysis', 'generation', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

132 --> Grammar development tools have been written in a variety of unification-  based frameworks, and widely distributed. 


 ---- TOKENS ----

 ['Grammar', 'development', 'tools', 'have', 'been', 'written', 'in', 'a', 'variety', 'of', 'unification-', 'based', 'frameworks', ',', 'and', 'widely', 'distributed', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('Grammar', 'NNP'), ('development', 'NN'), ('tools', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('written', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('variety', 'NN'), ('of', 'IN'), ('unification-', 'JJ'), ('based', 'VBN'), ('frameworks', 'NNS'), (',', ','), ('and', 'CC'), ('widely', 'RB'), ('distributed', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Grammar', 'development', 'tools', 'written', 'variety', 'unification-', 'based', 'frameworks', ',', 'widely', 'distributed', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Grammar', 'NNP'), ('development', 'NN'), ('tools', 'NNS'), ('written', 'VBN'), ('variety', 'NN'), ('unification-', 'JJ'), ('based', 'VBN'), ('frameworks', 'NNS'), (',', ','), ('widely', 'RB'), ('distributed', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Grammar development', 'development tools', 'tools written', 'written variety', 'variety unification-', 'unification- based', 'based frameworks', 'frameworks ,', ', widely', 'widely distributed', 'distributed .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Grammar development tools', 'development tools written', 'tools written variety', 'written variety unification-', 'variety unification- based', 'unification- based frameworks', 'based frameworks ,', 'frameworks , widely', ', widely distributed', 'widely distributed .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['development', 'variety'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Grammar']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['grammar', 'develop', 'tool', 'written', 'varieti', 'unification-', 'base', 'framework', ',', 'wide', 'distribut', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['grammar', 'develop', 'tool', 'written', 'varieti', 'unification-', 'base', 'framework', ',', 'wide', 'distribut', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Grammar', 'development', 'tool', 'written', 'variety', 'unification-', 'based', 'framework', ',', 'widely', 'distributed', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

133 --> Unification grammars are currently being used to apply syntactic (and  some semantic) constraints in speech recognition. 


 ---- TOKENS ----

 ['Unification', 'grammars', 'are', 'currently', 'being', 'used', 'to', 'apply', 'syntactic', '(', 'and', 'some', 'semantic', ')', 'constraints', 'in', 'speech', 'recognition', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Unification', 'NN'), ('grammars', 'NNS'), ('are', 'VBP'), ('currently', 'RB'), ('being', 'VBG'), ('used', 'VBN'), ('to', 'TO'), ('apply', 'VB'), ('syntactic', 'JJ'), ('(', '('), ('and', 'CC'), ('some', 'DT'), ('semantic', 'JJ'), (')', ')'), ('constraints', 'NNS'), ('in', 'IN'), ('speech', 'NN'), ('recognition', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Unification', 'grammars', 'currently', 'used', 'apply', 'syntactic', '(', 'semantic', ')', 'constraints', 'speech', 'recognition', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('Unification', 'NN'), ('grammars', 'NNS'), ('currently', 'RB'), ('used', 'VBN'), ('apply', 'RB'), ('syntactic', 'JJ'), ('(', '('), ('semantic', 'JJ'), (')', ')'), ('constraints', 'NNS'), ('speech', 'JJ'), ('recognition', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Unification grammars', 'grammars currently', 'currently used', 'used apply', 'apply syntactic', 'syntactic (', '( semantic', 'semantic )', ') constraints', 'constraints speech', 'speech recognition', 'recognition .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['Unification grammars currently', 'grammars currently used', 'currently used apply', 'used apply syntactic', 'apply syntactic (', 'syntactic ( semantic', '( semantic )', 'semantic ) constraints', ') constraints speech', 'constraints speech recognition', 'speech recognition .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['Unification', 'speech recognition'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Unification']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['unif', 'grammar', 'current', 'use', 'appli', 'syntact', '(', 'semant', ')', 'constraint', 'speech', 'recognit', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['unif', 'grammar', 'current', 'use', 'appli', 'syntact', '(', 'semant', ')', 'constraint', 'speech', 'recognit', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['Unification', 'grammar', 'currently', 'used', 'apply', 'syntactic', '(', 'semantic', ')', 'constraint', 'speech', 'recognition', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

134 --> Within the family of unification grammars lie the "mildly  context-sensitive grammars" -- a class that properly contains the context-free grammars, and allows the expression  of observed syntactic constraints not expressible in CFGs, but whose recognition problem is polynomial-time  computable. 


 ---- TOKENS ----

 ['Within', 'the', 'family', 'of', 'unification', 'grammars', 'lie', 'the', '``', 'mildly', 'context-sensitive', 'grammars', "''", '--', 'a', 'class', 'that', 'properly', 'contains', 'the', 'context-free', 'grammars', ',', 'and', 'allows', 'the', 'expression', 'of', 'observed', 'syntactic', 'constraints', 'not', 'expressible', 'in', 'CFGs', ',', 'but', 'whose', 'recognition', 'problem', 'is', 'polynomial-time', 'computable', '.'] 

 TOTAL TOKENS ==> 44

 ---- POST ----

 [('Within', 'IN'), ('the', 'DT'), ('family', 'NN'), ('of', 'IN'), ('unification', 'JJ'), ('grammars', 'NNS'), ('lie', 'VBP'), ('the', 'DT'), ('``', '``'), ('mildly', 'RB'), ('context-sensitive', 'JJ'), ('grammars', 'NNS'), ("''", "''"), ('--', ':'), ('a', 'DT'), ('class', 'NN'), ('that', 'WDT'), ('properly', 'RB'), ('contains', 'VBZ'), ('the', 'DT'), ('context-free', 'JJ'), ('grammars', 'NNS'), (',', ','), ('and', 'CC'), ('allows', 'VBZ'), ('the', 'DT'), ('expression', 'NN'), ('of', 'IN'), ('observed', 'JJ'), ('syntactic', 'JJ'), ('constraints', 'NNS'), ('not', 'RB'), ('expressible', 'JJ'), ('in', 'IN'), ('CFGs', 'NNP'), (',', ','), ('but', 'CC'), ('whose', 'WP$'), ('recognition', 'NN'), ('problem', 'NN'), ('is', 'VBZ'), ('polynomial-time', 'JJ'), ('computable', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Within', 'family', 'unification', 'grammars', 'lie', '``', 'mildly', 'context-sensitive', 'grammars', "''", '--', 'class', 'properly', 'contains', 'context-free', 'grammars', ',', 'allows', 'expression', 'observed', 'syntactic', 'constraints', 'expressible', 'CFGs', ',', 'whose', 'recognition', 'problem', 'polynomial-time', 'computable', '.']

 TOTAL FILTERED TOKENS ==>  31

 ---- POST FOR FILTERED TOKENS ----

 [('Within', 'IN'), ('family', 'NN'), ('unification', 'NN'), ('grammars', 'VBZ'), ('lie', 'VBZ'), ('``', '``'), ('mildly', 'RB'), ('context-sensitive', 'JJ'), ('grammars', 'NNS'), ("''", "''"), ('--', ':'), ('class', 'NN'), ('properly', 'RB'), ('contains', 'VBZ'), ('context-free', 'JJ'), ('grammars', 'NNS'), (',', ','), ('allows', 'VBZ'), ('expression', 'NN'), ('observed', 'VBD'), ('syntactic', 'JJ'), ('constraints', 'NNS'), ('expressible', 'JJ'), ('CFGs', 'NNP'), (',', ','), ('whose', 'WP$'), ('recognition', 'NN'), ('problem', 'NN'), ('polynomial-time', 'NN'), ('computable', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Within family', 'family unification', 'unification grammars', 'grammars lie', 'lie ``', '`` mildly', 'mildly context-sensitive', 'context-sensitive grammars', "grammars ''", "'' --", '-- class', 'class properly', 'properly contains', 'contains context-free', 'context-free grammars', 'grammars ,', ', allows', 'allows expression', 'expression observed', 'observed syntactic', 'syntactic constraints', 'constraints expressible', 'expressible CFGs', 'CFGs ,', ', whose', 'whose recognition', 'recognition problem', 'problem polynomial-time', 'polynomial-time computable', 'computable .'] 

 TOTAL BIGRAMS --> 30 



 ---- TRI-GRAMS ---- 

 ['Within family unification', 'family unification grammars', 'unification grammars lie', 'grammars lie ``', 'lie `` mildly', '`` mildly context-sensitive', 'mildly context-sensitive grammars', "context-sensitive grammars ''", "grammars '' --", "'' -- class", '-- class properly', 'class properly contains', 'properly contains context-free', 'contains context-free grammars', 'context-free grammars ,', 'grammars , allows', ', allows expression', 'allows expression observed', 'expression observed syntactic', 'observed syntactic constraints', 'syntactic constraints expressible', 'constraints expressible CFGs', 'expressible CFGs ,', 'CFGs , whose', ', whose recognition', 'whose recognition problem', 'recognition problem polynomial-time', 'problem polynomial-time computable', 'polynomial-time computable .'] 

 TOTAL TRIGRAMS --> 29 



 ---- NOUN PHRASES ---- 

 ['family', 'unification', 'class', 'expression', 'recognition', 'problem', 'polynomial-time', 'computable'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['CFGs']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['within', 'famili', 'unif', 'grammar', 'lie', '``', 'mildli', 'context-sensit', 'grammar', "''", '--', 'class', 'properli', 'contain', 'context-fre', 'grammar', ',', 'allow', 'express', 'observ', 'syntact', 'constraint', 'express', 'cfg', ',', 'whose', 'recognit', 'problem', 'polynomial-tim', 'comput', '.']

 TOTAL PORTER STEM WORDS ==> 31



 ---- SNOWBALL STEMMING ----

['within', 'famili', 'unif', 'grammar', 'lie', '``', 'mild', 'context-sensit', 'grammar', "''", '--', 'class', 'proper', 'contain', 'context-fre', 'grammar', ',', 'allow', 'express', 'observ', 'syntact', 'constraint', 'express', 'cfgs', ',', 'whose', 'recognit', 'problem', 'polynomial-tim', 'comput', '.']

 TOTAL SNOWBALL STEM WORDS ==> 31



 ---- LEMMATIZATION ----

['Within', 'family', 'unification', 'grammar', 'lie', '``', 'mildly', 'context-sensitive', 'grammar', "''", '--', 'class', 'properly', 'contains', 'context-free', 'grammar', ',', 'allows', 'expression', 'observed', 'syntactic', 'constraint', 'expressible', 'CFGs', ',', 'whose', 'recognition', 'problem', 'polynomial-time', 'computable', '.']

 TOTAL LEMMATIZE WORDS ==> 31

************************************************************************************************************************

135 --> In semantics, the major aspects of the contribution of sentence structure to meaning are understood and  implemented. 


 ---- TOKENS ----

 ['In', 'semantics', ',', 'the', 'major', 'aspects', 'of', 'the', 'contribution', 'of', 'sentence', 'structure', 'to', 'meaning', 'are', 'understood', 'and', 'implemented', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('In', 'IN'), ('semantics', 'NNS'), (',', ','), ('the', 'DT'), ('major', 'JJ'), ('aspects', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('contribution', 'NN'), ('of', 'IN'), ('sentence', 'NN'), ('structure', 'NN'), ('to', 'TO'), ('meaning', 'NN'), ('are', 'VBP'), ('understood', 'JJ'), ('and', 'CC'), ('implemented', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['semantics', ',', 'major', 'aspects', 'contribution', 'sentence', 'structure', 'meaning', 'understood', 'implemented', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('semantics', 'NNS'), (',', ','), ('major', 'JJ'), ('aspects', 'NNS'), ('contribution', 'NN'), ('sentence', 'NN'), ('structure', 'NN'), ('meaning', 'VBG'), ('understood', 'JJ'), ('implemented', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['semantics ,', ', major', 'major aspects', 'aspects contribution', 'contribution sentence', 'sentence structure', 'structure meaning', 'meaning understood', 'understood implemented', 'implemented .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['semantics , major', ', major aspects', 'major aspects contribution', 'aspects contribution sentence', 'contribution sentence structure', 'sentence structure meaning', 'structure meaning understood', 'meaning understood implemented', 'understood implemented .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['contribution', 'sentence', 'structure'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['semant', ',', 'major', 'aspect', 'contribut', 'sentenc', 'structur', 'mean', 'understood', 'implement', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['semant', ',', 'major', 'aspect', 'contribut', 'sentenc', 'structur', 'mean', 'understood', 'implement', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['semantics', ',', 'major', 'aspect', 'contribution', 'sentence', 'structure', 'meaning', 'understood', 'implemented', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

136 --> First steps toward automatically extracting aspects of lexical meaning from machine-readable  dictionaries have been taken. 


 ---- TOKENS ----

 ['First', 'steps', 'toward', 'automatically', 'extracting', 'aspects', 'of', 'lexical', 'meaning', 'from', 'machine-readable', 'dictionaries', 'have', 'been', 'taken', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('First', 'RB'), ('steps', 'VBZ'), ('toward', 'IN'), ('automatically', 'RB'), ('extracting', 'VBG'), ('aspects', 'NNS'), ('of', 'IN'), ('lexical', 'JJ'), ('meaning', 'NN'), ('from', 'IN'), ('machine-readable', 'JJ'), ('dictionaries', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('taken', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['First', 'steps', 'toward', 'automatically', 'extracting', 'aspects', 'lexical', 'meaning', 'machine-readable', 'dictionaries', 'taken', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('First', 'RB'), ('steps', 'VBZ'), ('toward', 'IN'), ('automatically', 'RB'), ('extracting', 'VBG'), ('aspects', 'NNS'), ('lexical', 'JJ'), ('meaning', 'VBG'), ('machine-readable', 'JJ'), ('dictionaries', 'NNS'), ('taken', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['First steps', 'steps toward', 'toward automatically', 'automatically extracting', 'extracting aspects', 'aspects lexical', 'lexical meaning', 'meaning machine-readable', 'machine-readable dictionaries', 'dictionaries taken', 'taken .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['First steps toward', 'steps toward automatically', 'toward automatically extracting', 'automatically extracting aspects', 'extracting aspects lexical', 'aspects lexical meaning', 'lexical meaning machine-readable', 'meaning machine-readable dictionaries', 'machine-readable dictionaries taken', 'dictionaries taken .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['first', 'step', 'toward', 'automat', 'extract', 'aspect', 'lexic', 'mean', 'machine-read', 'dictionari', 'taken', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['first', 'step', 'toward', 'automat', 'extract', 'aspect', 'lexic', 'mean', 'machine-read', 'dictionari', 'taken', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['First', 'step', 'toward', 'automatically', 'extracting', 'aspect', 'lexical', 'meaning', 'machine-readable', 'dictionary', 'taken', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

137 --> Understanding and generating connected sentences introduces questions such as how texts and dialogues  are structured; how this structure affects interpretation, particularly of referential expressions; how the beliefs,  intentions, and plans of a speaker are conveyed by what is said and how they constrain what is meant, as well as  what appropriate responses are. 


 ---- TOKENS ----

 ['Understanding', 'and', 'generating', 'connected', 'sentences', 'introduces', 'questions', 'such', 'as', 'how', 'texts', 'and', 'dialogues', 'are', 'structured', ';', 'how', 'this', 'structure', 'affects', 'interpretation', ',', 'particularly', 'of', 'referential', 'expressions', ';', 'how', 'the', 'beliefs', ',', 'intentions', ',', 'and', 'plans', 'of', 'a', 'speaker', 'are', 'conveyed', 'by', 'what', 'is', 'said', 'and', 'how', 'they', 'constrain', 'what', 'is', 'meant', ',', 'as', 'well', 'as', 'what', 'appropriate', 'responses', 'are', '.'] 

 TOTAL TOKENS ==> 60

 ---- POST ----

 [('Understanding', 'VBG'), ('and', 'CC'), ('generating', 'VBG'), ('connected', 'JJ'), ('sentences', 'NNS'), ('introduces', 'NNS'), ('questions', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('how', 'WRB'), ('texts', 'JJ'), ('and', 'CC'), ('dialogues', 'NNS'), ('are', 'VBP'), ('structured', 'VBN'), (';', ':'), ('how', 'WRB'), ('this', 'DT'), ('structure', 'NN'), ('affects', 'VBZ'), ('interpretation', 'NN'), (',', ','), ('particularly', 'RB'), ('of', 'IN'), ('referential', 'JJ'), ('expressions', 'NNS'), (';', ':'), ('how', 'WRB'), ('the', 'DT'), ('beliefs', 'NN'), (',', ','), ('intentions', 'NNS'), (',', ','), ('and', 'CC'), ('plans', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('speaker', 'NN'), ('are', 'VBP'), ('conveyed', 'VBN'), ('by', 'IN'), ('what', 'WP'), ('is', 'VBZ'), ('said', 'VBD'), ('and', 'CC'), ('how', 'WRB'), ('they', 'PRP'), ('constrain', 'VBP'), ('what', 'WP'), ('is', 'VBZ'), ('meant', 'JJ'), (',', ','), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('what', 'WP'), ('appropriate', 'JJ'), ('responses', 'NNS'), ('are', 'VBP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Understanding', 'generating', 'connected', 'sentences', 'introduces', 'questions', 'texts', 'dialogues', 'structured', ';', 'structure', 'affects', 'interpretation', ',', 'particularly', 'referential', 'expressions', ';', 'beliefs', ',', 'intentions', ',', 'plans', 'speaker', 'conveyed', 'said', 'constrain', 'meant', ',', 'well', 'appropriate', 'responses', '.']

 TOTAL FILTERED TOKENS ==>  33

 ---- POST FOR FILTERED TOKENS ----

 [('Understanding', 'VBG'), ('generating', 'VBG'), ('connected', 'JJ'), ('sentences', 'NNS'), ('introduces', 'NNS'), ('questions', 'NNS'), ('texts', 'VBP'), ('dialogues', 'NNS'), ('structured', 'VBN'), (';', ':'), ('structure', 'NN'), ('affects', 'VBZ'), ('interpretation', 'NN'), (',', ','), ('particularly', 'RB'), ('referential', 'JJ'), ('expressions', 'NNS'), (';', ':'), ('beliefs', 'NNS'), (',', ','), ('intentions', 'NNS'), (',', ','), ('plans', 'VBZ'), ('speaker', 'NN'), ('conveyed', 'VBN'), ('said', 'VBD'), ('constrain', 'NN'), ('meant', 'NN'), (',', ','), ('well', 'RB'), ('appropriate', 'JJ'), ('responses', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Understanding generating', 'generating connected', 'connected sentences', 'sentences introduces', 'introduces questions', 'questions texts', 'texts dialogues', 'dialogues structured', 'structured ;', '; structure', 'structure affects', 'affects interpretation', 'interpretation ,', ', particularly', 'particularly referential', 'referential expressions', 'expressions ;', '; beliefs', 'beliefs ,', ', intentions', 'intentions ,', ', plans', 'plans speaker', 'speaker conveyed', 'conveyed said', 'said constrain', 'constrain meant', 'meant ,', ', well', 'well appropriate', 'appropriate responses', 'responses .'] 

 TOTAL BIGRAMS --> 32 



 ---- TRI-GRAMS ---- 

 ['Understanding generating connected', 'generating connected sentences', 'connected sentences introduces', 'sentences introduces questions', 'introduces questions texts', 'questions texts dialogues', 'texts dialogues structured', 'dialogues structured ;', 'structured ; structure', '; structure affects', 'structure affects interpretation', 'affects interpretation ,', 'interpretation , particularly', ', particularly referential', 'particularly referential expressions', 'referential expressions ;', 'expressions ; beliefs', '; beliefs ,', 'beliefs , intentions', ', intentions ,', 'intentions , plans', ', plans speaker', 'plans speaker conveyed', 'speaker conveyed said', 'conveyed said constrain', 'said constrain meant', 'constrain meant ,', 'meant , well', ', well appropriate', 'well appropriate responses', 'appropriate responses .'] 

 TOTAL TRIGRAMS --> 31 



 ---- NOUN PHRASES ---- 

 ['structure', 'interpretation', 'speaker', 'constrain', 'meant'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['understand', 'gener', 'connect', 'sentenc', 'introduc', 'question', 'text', 'dialogu', 'structur', ';', 'structur', 'affect', 'interpret', ',', 'particularli', 'referenti', 'express', ';', 'belief', ',', 'intent', ',', 'plan', 'speaker', 'convey', 'said', 'constrain', 'meant', ',', 'well', 'appropri', 'respons', '.']

 TOTAL PORTER STEM WORDS ==> 33



 ---- SNOWBALL STEMMING ----

['understand', 'generat', 'connect', 'sentenc', 'introduc', 'question', 'text', 'dialogu', 'structur', ';', 'structur', 'affect', 'interpret', ',', 'particular', 'referenti', 'express', ';', 'belief', ',', 'intent', ',', 'plan', 'speaker', 'convey', 'said', 'constrain', 'meant', ',', 'well', 'appropri', 'respons', '.']

 TOTAL SNOWBALL STEM WORDS ==> 33



 ---- LEMMATIZATION ----

['Understanding', 'generating', 'connected', 'sentence', 'introduces', 'question', 'text', 'dialogue', 'structured', ';', 'structure', 'affect', 'interpretation', ',', 'particularly', 'referential', 'expression', ';', 'belief', ',', 'intention', ',', 'plan', 'speaker', 'conveyed', 'said', 'constrain', 'meant', ',', 'well', 'appropriate', 'response', '.']

 TOTAL LEMMATIZE WORDS ==> 33

************************************************************************************************************************

138 --> All these questions have been and continue to be investigated. 


 ---- TOKENS ----

 ['All', 'these', 'questions', 'have', 'been', 'and', 'continue', 'to', 'be', 'investigated', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('All', 'PDT'), ('these', 'DT'), ('questions', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('and', 'CC'), ('continue', 'VB'), ('to', 'TO'), ('be', 'VB'), ('investigated', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['questions', 'continue', 'investigated', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('questions', 'NNS'), ('continue', 'VBP'), ('investigated', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['questions continue', 'continue investigated', 'investigated .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['questions continue investigated', 'continue investigated .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['question', 'continu', 'investig', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['question', 'continu', 'investig', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['question', 'continue', 'investigated', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

139 --> Underlying logics  and algorithms for reasoning about knowledge, belief, intention, and action have been proposed, as have initial  computational models for discourse structure and methods for planning and plan recognition for discourse. 


 ---- TOKENS ----

 ['Underlying', 'logics', 'and', 'algorithms', 'for', 'reasoning', 'about', 'knowledge', ',', 'belief', ',', 'intention', ',', 'and', 'action', 'have', 'been', 'proposed', ',', 'as', 'have', 'initial', 'computational', 'models', 'for', 'discourse', 'structure', 'and', 'methods', 'for', 'planning', 'and', 'plan', 'recognition', 'for', 'discourse', '.'] 

 TOTAL TOKENS ==> 37

 ---- POST ----

 [('Underlying', 'VBG'), ('logics', 'NNS'), ('and', 'CC'), ('algorithms', 'NN'), ('for', 'IN'), ('reasoning', 'VBG'), ('about', 'IN'), ('knowledge', 'NN'), (',', ','), ('belief', 'NN'), (',', ','), ('intention', 'NN'), (',', ','), ('and', 'CC'), ('action', 'NN'), ('have', 'VBP'), ('been', 'VBN'), ('proposed', 'VBN'), (',', ','), ('as', 'IN'), ('have', 'VBP'), ('initial', 'JJ'), ('computational', 'JJ'), ('models', 'NNS'), ('for', 'IN'), ('discourse', 'JJ'), ('structure', 'NN'), ('and', 'CC'), ('methods', 'NNS'), ('for', 'IN'), ('planning', 'NN'), ('and', 'CC'), ('plan', 'NN'), ('recognition', 'NN'), ('for', 'IN'), ('discourse', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Underlying', 'logics', 'algorithms', 'reasoning', 'knowledge', ',', 'belief', ',', 'intention', ',', 'action', 'proposed', ',', 'initial', 'computational', 'models', 'discourse', 'structure', 'methods', 'planning', 'plan', 'recognition', 'discourse', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('Underlying', 'VBG'), ('logics', 'NNS'), ('algorithms', 'JJ'), ('reasoning', 'VBG'), ('knowledge', 'NN'), (',', ','), ('belief', 'NN'), (',', ','), ('intention', 'NN'), (',', ','), ('action', 'NN'), ('proposed', 'VBN'), (',', ','), ('initial', 'JJ'), ('computational', 'JJ'), ('models', 'NNS'), ('discourse', 'VBP'), ('structure', 'NN'), ('methods', 'NNS'), ('planning', 'VBG'), ('plan', 'NN'), ('recognition', 'NN'), ('discourse', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Underlying logics', 'logics algorithms', 'algorithms reasoning', 'reasoning knowledge', 'knowledge ,', ', belief', 'belief ,', ', intention', 'intention ,', ', action', 'action proposed', 'proposed ,', ', initial', 'initial computational', 'computational models', 'models discourse', 'discourse structure', 'structure methods', 'methods planning', 'planning plan', 'plan recognition', 'recognition discourse', 'discourse .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['Underlying logics algorithms', 'logics algorithms reasoning', 'algorithms reasoning knowledge', 'reasoning knowledge ,', 'knowledge , belief', ', belief ,', 'belief , intention', ', intention ,', 'intention , action', ', action proposed', 'action proposed ,', 'proposed , initial', ', initial computational', 'initial computational models', 'computational models discourse', 'models discourse structure', 'discourse structure methods', 'structure methods planning', 'methods planning plan', 'planning plan recognition', 'plan recognition discourse', 'recognition discourse .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['knowledge', 'belief', 'intention', 'action', 'structure', 'plan', 'recognition', 'discourse'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['underli', 'logic', 'algorithm', 'reason', 'knowledg', ',', 'belief', ',', 'intent', ',', 'action', 'propos', ',', 'initi', 'comput', 'model', 'discours', 'structur', 'method', 'plan', 'plan', 'recognit', 'discours', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['under', 'logic', 'algorithm', 'reason', 'knowledg', ',', 'belief', ',', 'intent', ',', 'action', 'propos', ',', 'initi', 'comput', 'model', 'discours', 'structur', 'method', 'plan', 'plan', 'recognit', 'discours', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['Underlying', 'logic', 'algorithm', 'reasoning', 'knowledge', ',', 'belief', ',', 'intention', ',', 'action', 'proposed', ',', 'initial', 'computational', 'model', 'discourse', 'structure', 'method', 'planning', 'plan', 'recognition', 'discourse', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

140 --> Although progress continues to be made on query systems, substantial systems have been developed for  other applications, all of which were unexplored 10 years ago. 


 ---- TOKENS ----

 ['Although', 'progress', 'continues', 'to', 'be', 'made', 'on', 'query', 'systems', ',', 'substantial', 'systems', 'have', 'been', 'developed', 'for', 'other', 'applications', ',', 'all', 'of', 'which', 'were', 'unexplored', '10', 'years', 'ago', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('Although', 'IN'), ('progress', 'NN'), ('continues', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('made', 'VBN'), ('on', 'IN'), ('query', 'NN'), ('systems', 'NNS'), (',', ','), ('substantial', 'JJ'), ('systems', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('developed', 'VBN'), ('for', 'IN'), ('other', 'JJ'), ('applications', 'NNS'), (',', ','), ('all', 'DT'), ('of', 'IN'), ('which', 'WDT'), ('were', 'VBD'), ('unexplored', 'JJ'), ('10', 'CD'), ('years', 'NNS'), ('ago', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Although', 'progress', 'continues', 'made', 'query', 'systems', ',', 'substantial', 'systems', 'developed', 'applications', ',', 'unexplored', '10', 'years', 'ago', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Although', 'IN'), ('progress', 'NN'), ('continues', 'VBZ'), ('made', 'VBN'), ('query', 'NN'), ('systems', 'NNS'), (',', ','), ('substantial', 'JJ'), ('systems', 'NNS'), ('developed', 'VBD'), ('applications', 'NNS'), (',', ','), ('unexplored', 'VBD'), ('10', 'CD'), ('years', 'NNS'), ('ago', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Although progress', 'progress continues', 'continues made', 'made query', 'query systems', 'systems ,', ', substantial', 'substantial systems', 'systems developed', 'developed applications', 'applications ,', ', unexplored', 'unexplored 10', '10 years', 'years ago', 'ago .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Although progress continues', 'progress continues made', 'continues made query', 'made query systems', 'query systems ,', 'systems , substantial', ', substantial systems', 'substantial systems developed', 'systems developed applications', 'developed applications ,', 'applications , unexplored', ', unexplored 10', 'unexplored 10 years', '10 years ago', 'years ago .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['progress', 'query'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['although', 'progress', 'continu', 'made', 'queri', 'system', ',', 'substanti', 'system', 'develop', 'applic', ',', 'unexplor', '10', 'year', 'ago', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['although', 'progress', 'continu', 'made', 'queri', 'system', ',', 'substanti', 'system', 'develop', 'applic', ',', 'unexplor', '10', 'year', 'ago', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Although', 'progress', 'continues', 'made', 'query', 'system', ',', 'substantial', 'system', 'developed', 'application', ',', 'unexplored', '10', 'year', 'ago', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

141 --> These include several text processing systems  supported by DARPA's Strategic Computing Imtiative (SCI), ranging from systems with very detailed models of  one domain, to more general ones adapted to several domains (e.g., Naval Casualty Reports, RAINFORMS, terrorist  reports). 


 ---- TOKENS ----

 ['These', 'include', 'several', 'text', 'processing', 'systems', 'supported', 'by', 'DARPA', "'s", 'Strategic', 'Computing', 'Imtiative', '(', 'SCI', ')', ',', 'ranging', 'from', 'systems', 'with', 'very', 'detailed', 'models', 'of', 'one', 'domain', ',', 'to', 'more', 'general', 'ones', 'adapted', 'to', 'several', 'domains', '(', 'e.g.', ',', 'Naval', 'Casualty', 'Reports', ',', 'RAINFORMS', ',', 'terrorist', 'reports', ')', '.'] 

 TOTAL TOKENS ==> 49

 ---- POST ----

 [('These', 'DT'), ('include', 'VBP'), ('several', 'JJ'), ('text', 'JJ'), ('processing', 'VBG'), ('systems', 'NNS'), ('supported', 'VBN'), ('by', 'IN'), ('DARPA', 'NNP'), ("'s", 'POS'), ('Strategic', 'NNP'), ('Computing', 'NNP'), ('Imtiative', 'NNP'), ('(', '('), ('SCI', 'NNP'), (')', ')'), (',', ','), ('ranging', 'VBG'), ('from', 'IN'), ('systems', 'NNS'), ('with', 'IN'), ('very', 'RB'), ('detailed', 'JJ'), ('models', 'NNS'), ('of', 'IN'), ('one', 'CD'), ('domain', 'NN'), (',', ','), ('to', 'TO'), ('more', 'RBR'), ('general', 'JJ'), ('ones', 'NNS'), ('adapted', 'VBN'), ('to', 'TO'), ('several', 'JJ'), ('domains', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('Naval', 'NNP'), ('Casualty', 'NNP'), ('Reports', 'NNP'), (',', ','), ('RAINFORMS', 'NNP'), (',', ','), ('terrorist', 'JJ'), ('reports', 'NNS'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['include', 'several', 'text', 'processing', 'systems', 'supported', 'DARPA', "'s", 'Strategic', 'Computing', 'Imtiative', '(', 'SCI', ')', ',', 'ranging', 'systems', 'detailed', 'models', 'one', 'domain', ',', 'general', 'ones', 'adapted', 'several', 'domains', '(', 'e.g.', ',', 'Naval', 'Casualty', 'Reports', ',', 'RAINFORMS', ',', 'terrorist', 'reports', ')', '.']

 TOTAL FILTERED TOKENS ==>  40

 ---- POST FOR FILTERED TOKENS ----

 [('include', 'VB'), ('several', 'JJ'), ('text', 'JJ'), ('processing', 'VBG'), ('systems', 'NNS'), ('supported', 'VBD'), ('DARPA', 'NNP'), ("'s", 'POS'), ('Strategic', 'NNP'), ('Computing', 'NNP'), ('Imtiative', 'NNP'), ('(', '('), ('SCI', 'NNP'), (')', ')'), (',', ','), ('ranging', 'VBG'), ('systems', 'NNS'), ('detailed', 'VBN'), ('models', 'NNS'), ('one', 'CD'), ('domain', 'NN'), (',', ','), ('general', 'JJ'), ('ones', 'NNS'), ('adapted', 'VBD'), ('several', 'JJ'), ('domains', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('Naval', 'NNP'), ('Casualty', 'NNP'), ('Reports', 'NNP'), (',', ','), ('RAINFORMS', 'NNP'), (',', ','), ('terrorist', 'JJ'), ('reports', 'NNS'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['include several', 'several text', 'text processing', 'processing systems', 'systems supported', 'supported DARPA', "DARPA 's", "'s Strategic", 'Strategic Computing', 'Computing Imtiative', 'Imtiative (', '( SCI', 'SCI )', ') ,', ', ranging', 'ranging systems', 'systems detailed', 'detailed models', 'models one', 'one domain', 'domain ,', ', general', 'general ones', 'ones adapted', 'adapted several', 'several domains', 'domains (', '( e.g.', 'e.g. ,', ', Naval', 'Naval Casualty', 'Casualty Reports', 'Reports ,', ', RAINFORMS', 'RAINFORMS ,', ', terrorist', 'terrorist reports', 'reports )', ') .'] 

 TOTAL BIGRAMS --> 39 



 ---- TRI-GRAMS ---- 

 ['include several text', 'several text processing', 'text processing systems', 'processing systems supported', 'systems supported DARPA', "supported DARPA 's", "DARPA 's Strategic", "'s Strategic Computing", 'Strategic Computing Imtiative', 'Computing Imtiative (', 'Imtiative ( SCI', '( SCI )', 'SCI ) ,', ') , ranging', ', ranging systems', 'ranging systems detailed', 'systems detailed models', 'detailed models one', 'models one domain', 'one domain ,', 'domain , general', ', general ones', 'general ones adapted', 'ones adapted several', 'adapted several domains', 'several domains (', 'domains ( e.g.', '( e.g. ,', 'e.g. , Naval', ', Naval Casualty', 'Naval Casualty Reports', 'Casualty Reports ,', 'Reports , RAINFORMS', ', RAINFORMS ,', 'RAINFORMS , terrorist', ', terrorist reports', 'terrorist reports )', 'reports ) .'] 

 TOTAL TRIGRAMS --> 38 



 ---- NOUN PHRASES ---- 

 ['domain'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['DARPA']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Strategic Computing Imtiative']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['includ', 'sever', 'text', 'process', 'system', 'support', 'darpa', "'s", 'strateg', 'comput', 'imti', '(', 'sci', ')', ',', 'rang', 'system', 'detail', 'model', 'one', 'domain', ',', 'gener', 'one', 'adapt', 'sever', 'domain', '(', 'e.g.', ',', 'naval', 'casualti', 'report', ',', 'rainform', ',', 'terrorist', 'report', ')', '.']

 TOTAL PORTER STEM WORDS ==> 40



 ---- SNOWBALL STEMMING ----

['includ', 'sever', 'text', 'process', 'system', 'support', 'darpa', "'s", 'strateg', 'comput', 'imtiat', '(', 'sci', ')', ',', 'rang', 'system', 'detail', 'model', 'one', 'domain', ',', 'general', 'one', 'adapt', 'sever', 'domain', '(', 'e.g.', ',', 'naval', 'casualti', 'report', ',', 'rainform', ',', 'terrorist', 'report', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 40



 ---- LEMMATIZATION ----

['include', 'several', 'text', 'processing', 'system', 'supported', 'DARPA', "'s", 'Strategic', 'Computing', 'Imtiative', '(', 'SCI', ')', ',', 'ranging', 'system', 'detailed', 'model', 'one', 'domain', ',', 'general', 'one', 'adapted', 'several', 'domain', '(', 'e.g.', ',', 'Naval', 'Casualty', 'Reports', ',', 'RAINFORMS', ',', 'terrorist', 'report', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 40

************************************************************************************************************************

142 --> Multi-media interactive problem solving systems have been developed for the environment of Navy Fleet  Command Center decision making and for factory control. 


 ---- TOKENS ----

 ['Multi-media', 'interactive', 'problem', 'solving', 'systems', 'have', 'been', 'developed', 'for', 'the', 'environment', 'of', 'Navy', 'Fleet', 'Command', 'Center', 'decision', 'making', 'and', 'for', 'factory', 'control', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Multi-media', 'NNP'), ('interactive', 'JJ'), ('problem', 'NN'), ('solving', 'VBG'), ('systems', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('developed', 'VBN'), ('for', 'IN'), ('the', 'DT'), ('environment', 'NN'), ('of', 'IN'), ('Navy', 'NNP'), ('Fleet', 'NNP'), ('Command', 'NNP'), ('Center', 'NNP'), ('decision', 'NN'), ('making', 'NN'), ('and', 'CC'), ('for', 'IN'), ('factory', 'NN'), ('control', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Multi-media', 'interactive', 'problem', 'solving', 'systems', 'developed', 'environment', 'Navy', 'Fleet', 'Command', 'Center', 'decision', 'making', 'factory', 'control', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Multi-media', 'NNP'), ('interactive', 'JJ'), ('problem', 'NN'), ('solving', 'VBG'), ('systems', 'NNS'), ('developed', 'VBD'), ('environment', 'NN'), ('Navy', 'NNP'), ('Fleet', 'NNP'), ('Command', 'NNP'), ('Center', 'NNP'), ('decision', 'NN'), ('making', 'VBG'), ('factory', 'JJ'), ('control', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Multi-media interactive', 'interactive problem', 'problem solving', 'solving systems', 'systems developed', 'developed environment', 'environment Navy', 'Navy Fleet', 'Fleet Command', 'Command Center', 'Center decision', 'decision making', 'making factory', 'factory control', 'control .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Multi-media interactive problem', 'interactive problem solving', 'problem solving systems', 'solving systems developed', 'systems developed environment', 'developed environment Navy', 'environment Navy Fleet', 'Navy Fleet Command', 'Fleet Command Center', 'Command Center decision', 'Center decision making', 'decision making factory', 'making factory control', 'factory control .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['interactive problem', 'environment', 'decision', 'factory control'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Navy Fleet Command Center']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['multi-media', 'interact', 'problem', 'solv', 'system', 'develop', 'environ', 'navi', 'fleet', 'command', 'center', 'decis', 'make', 'factori', 'control', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['multi-media', 'interact', 'problem', 'solv', 'system', 'develop', 'environ', 'navi', 'fleet', 'command', 'center', 'decis', 'make', 'factori', 'control', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Multi-media', 'interactive', 'problem', 'solving', 'system', 'developed', 'environment', 'Navy', 'Fleet', 'Command', 'Center', 'decision', 'making', 'factory', 'control', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

143 --> Language generation systems have been implemented to  486   generate multi-sentence explanations of expert system decisions, object or situation descriptions, and instructions  from an expert. 


 ---- TOKENS ----

 ['Language', 'generation', 'systems', 'have', 'been', 'implemented', 'to', '486', 'generate', 'multi-sentence', 'explanations', 'of', 'expert', 'system', 'decisions', ',', 'object', 'or', 'situation', 'descriptions', ',', 'and', 'instructions', 'from', 'an', 'expert', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('Language', 'JJ'), ('generation', 'NN'), ('systems', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('implemented', 'VBN'), ('to', 'TO'), ('486', 'CD'), ('generate', 'NN'), ('multi-sentence', 'NN'), ('explanations', 'NNS'), ('of', 'IN'), ('expert', 'NN'), ('system', 'NN'), ('decisions', 'NNS'), (',', ','), ('object', 'NN'), ('or', 'CC'), ('situation', 'NN'), ('descriptions', 'NNS'), (',', ','), ('and', 'CC'), ('instructions', 'NNS'), ('from', 'IN'), ('an', 'DT'), ('expert', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Language', 'generation', 'systems', 'implemented', '486', 'generate', 'multi-sentence', 'explanations', 'expert', 'system', 'decisions', ',', 'object', 'situation', 'descriptions', ',', 'instructions', 'expert', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Language', 'JJ'), ('generation', 'NN'), ('systems', 'NNS'), ('implemented', 'VBD'), ('486', 'CD'), ('generate', 'JJ'), ('multi-sentence', 'NN'), ('explanations', 'NNS'), ('expert', 'VBP'), ('system', 'NN'), ('decisions', 'NNS'), (',', ','), ('object', 'JJ'), ('situation', 'NN'), ('descriptions', 'NNS'), (',', ','), ('instructions', 'NNS'), ('expert', 'VBP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Language generation', 'generation systems', 'systems implemented', 'implemented 486', '486 generate', 'generate multi-sentence', 'multi-sentence explanations', 'explanations expert', 'expert system', 'system decisions', 'decisions ,', ', object', 'object situation', 'situation descriptions', 'descriptions ,', ', instructions', 'instructions expert', 'expert .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Language generation systems', 'generation systems implemented', 'systems implemented 486', 'implemented 486 generate', '486 generate multi-sentence', 'generate multi-sentence explanations', 'multi-sentence explanations expert', 'explanations expert system', 'expert system decisions', 'system decisions ,', 'decisions , object', ', object situation', 'object situation descriptions', 'situation descriptions ,', 'descriptions , instructions', ', instructions expert', 'instructions expert .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['Language generation', 'generate multi-sentence', 'system', 'object situation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Language']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['languag', 'gener', 'system', 'implement', '486', 'gener', 'multi-sent', 'explan', 'expert', 'system', 'decis', ',', 'object', 'situat', 'descript', ',', 'instruct', 'expert', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['languag', 'generat', 'system', 'implement', '486', 'generat', 'multi-sent', 'explan', 'expert', 'system', 'decis', ',', 'object', 'situat', 'descript', ',', 'instruct', 'expert', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Language', 'generation', 'system', 'implemented', '486', 'generate', 'multi-sentence', 'explanation', 'expert', 'system', 'decision', ',', 'object', 'situation', 'description', ',', 'instruction', 'expert', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

144 --> 2.2. 


 ---- TOKENS ----

 ['2.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

145 --> Relationships To Other Areas  Historically, NLP's strongest interaction has been with other areas of artificial intelligence, e.g., with work  in knowledge representation and planning. 


 ---- TOKENS ----

 ['Relationships', 'To', 'Other', 'Areas', 'Historically', ',', 'NLP', "'s", 'strongest', 'interaction', 'has', 'been', 'with', 'other', 'areas', 'of', 'artificial', 'intelligence', ',', 'e.g.', ',', 'with', 'work', 'in', 'knowledge', 'representation', 'and', 'planning', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('Relationships', 'NNS'), ('To', 'TO'), ('Other', 'JJ'), ('Areas', 'NNP'), ('Historically', 'NNP'), (',', ','), ('NLP', 'NNP'), ("'s", 'POS'), ('strongest', 'JJS'), ('interaction', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('with', 'IN'), ('other', 'JJ'), ('areas', 'NNS'), ('of', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), (',', ','), ('e.g.', 'NN'), (',', ','), ('with', 'IN'), ('work', 'NN'), ('in', 'IN'), ('knowledge', 'NN'), ('representation', 'NN'), ('and', 'CC'), ('planning', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Relationships', 'Areas', 'Historically', ',', 'NLP', "'s", 'strongest', 'interaction', 'areas', 'artificial', 'intelligence', ',', 'e.g.', ',', 'work', 'knowledge', 'representation', 'planning', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('Relationships', 'NNP'), ('Areas', 'NNP'), ('Historically', 'NNP'), (',', ','), ('NLP', 'NNP'), ("'s", 'POS'), ('strongest', 'JJS'), ('interaction', 'NN'), ('areas', 'NNS'), ('artificial', 'JJ'), ('intelligence', 'NN'), (',', ','), ('e.g.', 'NN'), (',', ','), ('work', 'NN'), ('knowledge', 'NN'), ('representation', 'NN'), ('planning', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Relationships Areas', 'Areas Historically', 'Historically ,', ', NLP', "NLP 's", "'s strongest", 'strongest interaction', 'interaction areas', 'areas artificial', 'artificial intelligence', 'intelligence ,', ', e.g.', 'e.g. ,', ', work', 'work knowledge', 'knowledge representation', 'representation planning', 'planning .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['Relationships Areas Historically', 'Areas Historically ,', 'Historically , NLP', ", NLP 's", "NLP 's strongest", "'s strongest interaction", 'strongest interaction areas', 'interaction areas artificial', 'areas artificial intelligence', 'artificial intelligence ,', 'intelligence , e.g.', ', e.g. ,', 'e.g. , work', ', work knowledge', 'work knowledge representation', 'knowledge representation planning', 'representation planning .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['interaction', 'artificial intelligence', 'e.g.', 'work', 'knowledge', 'representation', 'planning'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Relationships', 'Areas Historically']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['relationship', 'area', 'histor', ',', 'nlp', "'s", 'strongest', 'interact', 'area', 'artifici', 'intellig', ',', 'e.g.', ',', 'work', 'knowledg', 'represent', 'plan', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['relationship', 'area', 'histor', ',', 'nlp', "'s", 'strongest', 'interact', 'area', 'artifici', 'intellig', ',', 'e.g.', ',', 'work', 'knowledg', 'represent', 'plan', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['Relationships', 'Areas', 'Historically', ',', 'NLP', "'s", 'strongest', 'interaction', 'area', 'artificial', 'intelligence', ',', 'e.g.', ',', 'work', 'knowledge', 'representation', 'planning', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

146 --> During the 1980s, collaboration with theoretical linguistics and cognitive  science has been growing. 


 ---- TOKENS ----

 ['During', 'the', '1980s', ',', 'collaboration', 'with', 'theoretical', 'linguistics', 'and', 'cognitive', 'science', 'has', 'been', 'growing', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('During', 'IN'), ('the', 'DT'), ('1980s', 'CD'), (',', ','), ('collaboration', 'NN'), ('with', 'IN'), ('theoretical', 'JJ'), ('linguistics', 'NNS'), ('and', 'CC'), ('cognitive', 'JJ'), ('science', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('growing', 'VBG'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['1980s', ',', 'collaboration', 'theoretical', 'linguistics', 'cognitive', 'science', 'growing', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('1980s', 'CD'), (',', ','), ('collaboration', 'NN'), ('theoretical', 'JJ'), ('linguistics', 'NNS'), ('cognitive', 'JJ'), ('science', 'NN'), ('growing', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['1980s ,', ', collaboration', 'collaboration theoretical', 'theoretical linguistics', 'linguistics cognitive', 'cognitive science', 'science growing', 'growing .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['1980s , collaboration', ', collaboration theoretical', 'collaboration theoretical linguistics', 'theoretical linguistics cognitive', 'linguistics cognitive science', 'cognitive science growing', 'science growing .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['collaboration', 'cognitive science', 'growing'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['1980', ',', 'collabor', 'theoret', 'linguist', 'cognit', 'scienc', 'grow', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['1980s', ',', 'collabor', 'theoret', 'linguist', 'cognit', 'scienc', 'grow', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['1980s', ',', 'collaboration', 'theoretical', 'linguistics', 'cognitive', 'science', 'growing', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

147 --> Lack of widespread availability of high-performance, parallel computers thus far has  limited the algorithms considered; however, efforts in parallelism, including work in connectionist neural network  modeling, may grow in the next decade. 


 ---- TOKENS ----

 ['Lack', 'of', 'widespread', 'availability', 'of', 'high-performance', ',', 'parallel', 'computers', 'thus', 'far', 'has', 'limited', 'the', 'algorithms', 'considered', ';', 'however', ',', 'efforts', 'in', 'parallelism', ',', 'including', 'work', 'in', 'connectionist', 'neural', 'network', 'modeling', ',', 'may', 'grow', 'in', 'the', 'next', 'decade', '.'] 

 TOTAL TOKENS ==> 38

 ---- POST ----

 [('Lack', 'NN'), ('of', 'IN'), ('widespread', 'JJ'), ('availability', 'NN'), ('of', 'IN'), ('high-performance', 'NN'), (',', ','), ('parallel', 'JJ'), ('computers', 'NNS'), ('thus', 'RB'), ('far', 'RB'), ('has', 'VBZ'), ('limited', 'VBN'), ('the', 'DT'), ('algorithms', 'NN'), ('considered', 'VBD'), (';', ':'), ('however', 'RB'), (',', ','), ('efforts', 'NNS'), ('in', 'IN'), ('parallelism', 'NN'), (',', ','), ('including', 'VBG'), ('work', 'NN'), ('in', 'IN'), ('connectionist', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('modeling', 'NN'), (',', ','), ('may', 'MD'), ('grow', 'VB'), ('in', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('decade', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Lack', 'widespread', 'availability', 'high-performance', ',', 'parallel', 'computers', 'thus', 'far', 'limited', 'algorithms', 'considered', ';', 'however', ',', 'efforts', 'parallelism', ',', 'including', 'work', 'connectionist', 'neural', 'network', 'modeling', ',', 'may', 'grow', 'next', 'decade', '.']

 TOTAL FILTERED TOKENS ==>  30

 ---- POST FOR FILTERED TOKENS ----

 [('Lack', 'NNP'), ('widespread', 'JJ'), ('availability', 'NN'), ('high-performance', 'NN'), (',', ','), ('parallel', 'JJ'), ('computers', 'NNS'), ('thus', 'RB'), ('far', 'RB'), ('limited', 'JJ'), ('algorithms', 'NN'), ('considered', 'VBN'), (';', ':'), ('however', 'RB'), (',', ','), ('efforts', 'NNS'), ('parallelism', 'NN'), (',', ','), ('including', 'VBG'), ('work', 'NN'), ('connectionist', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('modeling', 'NN'), (',', ','), ('may', 'MD'), ('grow', 'VB'), ('next', 'JJ'), ('decade', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Lack widespread', 'widespread availability', 'availability high-performance', 'high-performance ,', ', parallel', 'parallel computers', 'computers thus', 'thus far', 'far limited', 'limited algorithms', 'algorithms considered', 'considered ;', '; however', 'however ,', ', efforts', 'efforts parallelism', 'parallelism ,', ', including', 'including work', 'work connectionist', 'connectionist neural', 'neural network', 'network modeling', 'modeling ,', ', may', 'may grow', 'grow next', 'next decade', 'decade .'] 

 TOTAL BIGRAMS --> 29 



 ---- TRI-GRAMS ---- 

 ['Lack widespread availability', 'widespread availability high-performance', 'availability high-performance ,', 'high-performance , parallel', ', parallel computers', 'parallel computers thus', 'computers thus far', 'thus far limited', 'far limited algorithms', 'limited algorithms considered', 'algorithms considered ;', 'considered ; however', '; however ,', 'however , efforts', ', efforts parallelism', 'efforts parallelism ,', 'parallelism , including', ', including work', 'including work connectionist', 'work connectionist neural', 'connectionist neural network', 'neural network modeling', 'network modeling ,', 'modeling , may', ', may grow', 'may grow next', 'grow next decade', 'next decade .'] 

 TOTAL TRIGRAMS --> 28 



 ---- NOUN PHRASES ---- 

 ['widespread availability', 'high-performance', 'limited algorithms', 'parallelism', 'work', 'connectionist', 'neural network', 'modeling', 'next decade'] 

 TOTAL NOUN PHRASES --> 9 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Lack']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['lack', 'widespread', 'avail', 'high-perform', ',', 'parallel', 'comput', 'thu', 'far', 'limit', 'algorithm', 'consid', ';', 'howev', ',', 'effort', 'parallel', ',', 'includ', 'work', 'connectionist', 'neural', 'network', 'model', ',', 'may', 'grow', 'next', 'decad', '.']

 TOTAL PORTER STEM WORDS ==> 30



 ---- SNOWBALL STEMMING ----

['lack', 'widespread', 'avail', 'high-perform', ',', 'parallel', 'comput', 'thus', 'far', 'limit', 'algorithm', 'consid', ';', 'howev', ',', 'effort', 'parallel', ',', 'includ', 'work', 'connectionist', 'neural', 'network', 'model', ',', 'may', 'grow', 'next', 'decad', '.']

 TOTAL SNOWBALL STEM WORDS ==> 30



 ---- LEMMATIZATION ----

['Lack', 'widespread', 'availability', 'high-performance', ',', 'parallel', 'computer', 'thus', 'far', 'limited', 'algorithm', 'considered', ';', 'however', ',', 'effort', 'parallelism', ',', 'including', 'work', 'connectionist', 'neural', 'network', 'modeling', ',', 'may', 'grow', 'next', 'decade', '.']

 TOTAL LEMMATIZE WORDS ==> 30

************************************************************************************************************************

148 --> Until two years ago, interaction with speech scientists had been minimal since the end of the DARPA  Speech Understanding Program in 1976. 


 ---- TOKENS ----

 ['Until', 'two', 'years', 'ago', ',', 'interaction', 'with', 'speech', 'scientists', 'had', 'been', 'minimal', 'since', 'the', 'end', 'of', 'the', 'DARPA', 'Speech', 'Understanding', 'Program', 'in', '1976', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Until', 'IN'), ('two', 'CD'), ('years', 'NNS'), ('ago', 'RB'), (',', ','), ('interaction', 'NN'), ('with', 'IN'), ('speech', 'NN'), ('scientists', 'NNS'), ('had', 'VBD'), ('been', 'VBN'), ('minimal', 'JJ'), ('since', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('the', 'DT'), ('DARPA', 'NNP'), ('Speech', 'NNP'), ('Understanding', 'NNP'), ('Program', 'NNP'), ('in', 'IN'), ('1976', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['two', 'years', 'ago', ',', 'interaction', 'speech', 'scientists', 'minimal', 'since', 'end', 'DARPA', 'Speech', 'Understanding', 'Program', '1976', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('two', 'CD'), ('years', 'NNS'), ('ago', 'RB'), (',', ','), ('interaction', 'NN'), ('speech', 'NN'), ('scientists', 'NNS'), ('minimal', 'VBD'), ('since', 'IN'), ('end', 'NN'), ('DARPA', 'NNP'), ('Speech', 'NNP'), ('Understanding', 'NNP'), ('Program', 'NNP'), ('1976', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['two years', 'years ago', 'ago ,', ', interaction', 'interaction speech', 'speech scientists', 'scientists minimal', 'minimal since', 'since end', 'end DARPA', 'DARPA Speech', 'Speech Understanding', 'Understanding Program', 'Program 1976', '1976 .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['two years ago', 'years ago ,', 'ago , interaction', ', interaction speech', 'interaction speech scientists', 'speech scientists minimal', 'scientists minimal since', 'minimal since end', 'since end DARPA', 'end DARPA Speech', 'DARPA Speech Understanding', 'Speech Understanding Program', 'Understanding Program 1976', 'Program 1976 .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['interaction', 'speech', 'end'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['DARPA Speech']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['two', 'year', 'ago', ',', 'interact', 'speech', 'scientist', 'minim', 'sinc', 'end', 'darpa', 'speech', 'understand', 'program', '1976', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['two', 'year', 'ago', ',', 'interact', 'speech', 'scientist', 'minim', 'sinc', 'end', 'darpa', 'speech', 'understand', 'program', '1976', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['two', 'year', 'ago', ',', 'interaction', 'speech', 'scientist', 'minimal', 'since', 'end', 'DARPA', 'Speech', 'Understanding', 'Program', '1976', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

149 --> Progress ha natural language processing should contribute directly to  spoken language systems. 


 ---- TOKENS ----

 ['Progress', 'ha', 'natural', 'language', 'processing', 'should', 'contribute', 'directly', 'to', 'spoken', 'language', 'systems', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Progress', 'NNP'), ('ha', 'PRP'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('should', 'MD'), ('contribute', 'VB'), ('directly', 'RB'), ('to', 'TO'), ('spoken', 'VB'), ('language', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Progress', 'ha', 'natural', 'language', 'processing', 'contribute', 'directly', 'spoken', 'language', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Progress', 'NNP'), ('ha', 'PRP'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'VBG'), ('contribute', 'NN'), ('directly', 'RB'), ('spoken', 'JJ'), ('language', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Progress ha', 'ha natural', 'natural language', 'language processing', 'processing contribute', 'contribute directly', 'directly spoken', 'spoken language', 'language systems', 'systems .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Progress ha natural', 'ha natural language', 'natural language processing', 'language processing contribute', 'processing contribute directly', 'contribute directly spoken', 'directly spoken language', 'spoken language systems', 'language systems .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['natural language', 'contribute', 'spoken language'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['progress', 'ha', 'natur', 'languag', 'process', 'contribut', 'directli', 'spoken', 'languag', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['progress', 'ha', 'natur', 'languag', 'process', 'contribut', 'direct', 'spoken', 'languag', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Progress', 'ha', 'natural', 'language', 'processing', 'contribute', 'directly', 'spoken', 'language', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

150 --> This is true not only where understanding seems to be necessary, e.g., voice commands  and requests, translation of speech, etc., but also in speech transcription. 


 ---- TOKENS ----

 ['This', 'is', 'true', 'not', 'only', 'where', 'understanding', 'seems', 'to', 'be', 'necessary', ',', 'e.g.', ',', 'voice', 'commands', 'and', 'requests', ',', 'translation', 'of', 'speech', ',', 'etc.', ',', 'but', 'also', 'in', 'speech', 'transcription', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('This', 'DT'), ('is', 'VBZ'), ('true', 'JJ'), ('not', 'RB'), ('only', 'RB'), ('where', 'WRB'), ('understanding', 'VBG'), ('seems', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('necessary', 'JJ'), (',', ','), ('e.g.', 'JJ'), (',', ','), ('voice', 'JJ'), ('commands', 'NNS'), ('and', 'CC'), ('requests', 'NNS'), (',', ','), ('translation', 'NN'), ('of', 'IN'), ('speech', 'NN'), (',', ','), ('etc.', 'NN'), (',', ','), ('but', 'CC'), ('also', 'RB'), ('in', 'IN'), ('speech', 'JJ'), ('transcription', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['true', 'understanding', 'seems', 'necessary', ',', 'e.g.', ',', 'voice', 'commands', 'requests', ',', 'translation', 'speech', ',', 'etc.', ',', 'also', 'speech', 'transcription', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('true', 'JJ'), ('understanding', 'NN'), ('seems', 'VBZ'), ('necessary', 'JJ'), (',', ','), ('e.g.', 'JJ'), (',', ','), ('voice', 'JJ'), ('commands', 'NNS'), ('requests', 'NNS'), (',', ','), ('translation', 'NN'), ('speech', 'NN'), (',', ','), ('etc.', 'NN'), (',', ','), ('also', 'RB'), ('speech', 'JJ'), ('transcription', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['true understanding', 'understanding seems', 'seems necessary', 'necessary ,', ', e.g.', 'e.g. ,', ', voice', 'voice commands', 'commands requests', 'requests ,', ', translation', 'translation speech', 'speech ,', ', etc.', 'etc. ,', ', also', 'also speech', 'speech transcription', 'transcription .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['true understanding seems', 'understanding seems necessary', 'seems necessary ,', 'necessary , e.g.', ', e.g. ,', 'e.g. , voice', ', voice commands', 'voice commands requests', 'commands requests ,', 'requests , translation', ', translation speech', 'translation speech ,', 'speech , etc.', ', etc. ,', 'etc. , also', ', also speech', 'also speech transcription', 'speech transcription .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['true understanding', 'translation', 'speech', 'etc.', 'speech transcription'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['true', 'understand', 'seem', 'necessari', ',', 'e.g.', ',', 'voic', 'command', 'request', ',', 'translat', 'speech', ',', 'etc.', ',', 'also', 'speech', 'transcript', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['true', 'understand', 'seem', 'necessari', ',', 'e.g.', ',', 'voic', 'command', 'request', ',', 'translat', 'speech', ',', 'etc.', ',', 'also', 'speech', 'transcript', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['true', 'understanding', 'seems', 'necessary', ',', 'e.g.', ',', 'voice', 'command', 'request', ',', 'translation', 'speech', ',', 'etc.', ',', 'also', 'speech', 'transcription', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

151 --> The error rate of speech recognition  systems is directly correlated with the perplexity of the language to be recognized. 


 ---- TOKENS ----

 ['The', 'error', 'rate', 'of', 'speech', 'recognition', 'systems', 'is', 'directly', 'correlated', 'with', 'the', 'perplexity', 'of', 'the', 'language', 'to', 'be', 'recognized', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('The', 'DT'), ('error', 'NN'), ('rate', 'NN'), ('of', 'IN'), ('speech', 'NN'), ('recognition', 'NN'), ('systems', 'NNS'), ('is', 'VBZ'), ('directly', 'RB'), ('correlated', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('perplexity', 'NN'), ('of', 'IN'), ('the', 'DT'), ('language', 'NN'), ('to', 'TO'), ('be', 'VB'), ('recognized', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['error', 'rate', 'speech', 'recognition', 'systems', 'directly', 'correlated', 'perplexity', 'language', 'recognized', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('error', 'NN'), ('rate', 'NN'), ('speech', 'NN'), ('recognition', 'NN'), ('systems', 'NNS'), ('directly', 'RB'), ('correlated', 'VBN'), ('perplexity', 'NN'), ('language', 'NN'), ('recognized', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['error rate', 'rate speech', 'speech recognition', 'recognition systems', 'systems directly', 'directly correlated', 'correlated perplexity', 'perplexity language', 'language recognized', 'recognized .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['error rate speech', 'rate speech recognition', 'speech recognition systems', 'recognition systems directly', 'systems directly correlated', 'directly correlated perplexity', 'correlated perplexity language', 'perplexity language recognized', 'language recognized .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['error', 'rate', 'speech', 'recognition', 'perplexity', 'language'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['error', 'rate', 'speech', 'recognit', 'system', 'directli', 'correl', 'perplex', 'languag', 'recogn', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['error', 'rate', 'speech', 'recognit', 'system', 'direct', 'correl', 'perplex', 'languag', 'recogn', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['error', 'rate', 'speech', 'recognition', 'system', 'directly', 'correlated', 'perplexity', 'language', 'recognized', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

152 --> Statistical language models in  speech transcription have given the lowest perplexity thus far, and therefore, the best performance. 


 ---- TOKENS ----

 ['Statistical', 'language', 'models', 'in', 'speech', 'transcription', 'have', 'given', 'the', 'lowest', 'perplexity', 'thus', 'far', ',', 'and', 'therefore', ',', 'the', 'best', 'performance', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Statistical', 'JJ'), ('language', 'NN'), ('models', 'NNS'), ('in', 'IN'), ('speech', 'NN'), ('transcription', 'NN'), ('have', 'VB'), ('given', 'VBN'), ('the', 'DT'), ('lowest', 'JJS'), ('perplexity', 'NN'), ('thus', 'RB'), ('far', 'RB'), (',', ','), ('and', 'CC'), ('therefore', 'RB'), (',', ','), ('the', 'DT'), ('best', 'JJS'), ('performance', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Statistical', 'language', 'models', 'speech', 'transcription', 'given', 'lowest', 'perplexity', 'thus', 'far', ',', 'therefore', ',', 'best', 'performance', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Statistical', 'JJ'), ('language', 'NN'), ('models', 'NNS'), ('speech', 'VBP'), ('transcription', 'NN'), ('given', 'VBN'), ('lowest', 'JJS'), ('perplexity', 'NN'), ('thus', 'RB'), ('far', 'RB'), (',', ','), ('therefore', 'RB'), (',', ','), ('best', 'JJS'), ('performance', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Statistical language', 'language models', 'models speech', 'speech transcription', 'transcription given', 'given lowest', 'lowest perplexity', 'perplexity thus', 'thus far', 'far ,', ', therefore', 'therefore ,', ', best', 'best performance', 'performance .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Statistical language models', 'language models speech', 'models speech transcription', 'speech transcription given', 'transcription given lowest', 'given lowest perplexity', 'lowest perplexity thus', 'perplexity thus far', 'thus far ,', 'far , therefore', ', therefore ,', 'therefore , best', ', best performance', 'best performance .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['Statistical language', 'transcription', 'perplexity', 'performance'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['statist', 'languag', 'model', 'speech', 'transcript', 'given', 'lowest', 'perplex', 'thu', 'far', ',', 'therefor', ',', 'best', 'perform', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['statist', 'languag', 'model', 'speech', 'transcript', 'given', 'lowest', 'perplex', 'thus', 'far', ',', 'therefor', ',', 'best', 'perform', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Statistical', 'language', 'model', 'speech', 'transcription', 'given', 'lowest', 'perplexity', 'thus', 'far', ',', 'therefore', ',', 'best', 'performance', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

153 --> Language  processing techniques, whether supplemental or in place of current statistical models, offer the potential of providing  even lower perplexity due to modeling both local and global constraints, as well as supporting speech applications  other than transcription. 


 ---- TOKENS ----

 ['Language', 'processing', 'techniques', ',', 'whether', 'supplemental', 'or', 'in', 'place', 'of', 'current', 'statistical', 'models', ',', 'offer', 'the', 'potential', 'of', 'providing', 'even', 'lower', 'perplexity', 'due', 'to', 'modeling', 'both', 'local', 'and', 'global', 'constraints', ',', 'as', 'well', 'as', 'supporting', 'speech', 'applications', 'other', 'than', 'transcription', '.'] 

 TOTAL TOKENS ==> 41

 ---- POST ----

 [('Language', 'NN'), ('processing', 'NN'), ('techniques', 'NNS'), (',', ','), ('whether', 'IN'), ('supplemental', 'JJ'), ('or', 'CC'), ('in', 'IN'), ('place', 'NN'), ('of', 'IN'), ('current', 'JJ'), ('statistical', 'JJ'), ('models', 'NNS'), (',', ','), ('offer', 'VBP'), ('the', 'DT'), ('potential', 'NN'), ('of', 'IN'), ('providing', 'VBG'), ('even', 'RB'), ('lower', 'JJR'), ('perplexity', 'NN'), ('due', 'JJ'), ('to', 'TO'), ('modeling', 'VBG'), ('both', 'DT'), ('local', 'JJ'), ('and', 'CC'), ('global', 'JJ'), ('constraints', 'NNS'), (',', ','), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('supporting', 'VBG'), ('speech', 'NN'), ('applications', 'NNS'), ('other', 'JJ'), ('than', 'IN'), ('transcription', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Language', 'processing', 'techniques', ',', 'whether', 'supplemental', 'place', 'current', 'statistical', 'models', ',', 'offer', 'potential', 'providing', 'even', 'lower', 'perplexity', 'due', 'modeling', 'local', 'global', 'constraints', ',', 'well', 'supporting', 'speech', 'applications', 'transcription', '.']

 TOTAL FILTERED TOKENS ==>  29

 ---- POST FOR FILTERED TOKENS ----

 [('Language', 'NN'), ('processing', 'NN'), ('techniques', 'NNS'), (',', ','), ('whether', 'IN'), ('supplemental', 'JJ'), ('place', 'NN'), ('current', 'JJ'), ('statistical', 'JJ'), ('models', 'NNS'), (',', ','), ('offer', 'VBP'), ('potential', 'JJ'), ('providing', 'VBG'), ('even', 'RB'), ('lower', 'JJR'), ('perplexity', 'NN'), ('due', 'JJ'), ('modeling', 'VBG'), ('local', 'JJ'), ('global', 'JJ'), ('constraints', 'NNS'), (',', ','), ('well', 'RB'), ('supporting', 'VBG'), ('speech', 'NN'), ('applications', 'NNS'), ('transcription', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Language processing', 'processing techniques', 'techniques ,', ', whether', 'whether supplemental', 'supplemental place', 'place current', 'current statistical', 'statistical models', 'models ,', ', offer', 'offer potential', 'potential providing', 'providing even', 'even lower', 'lower perplexity', 'perplexity due', 'due modeling', 'modeling local', 'local global', 'global constraints', 'constraints ,', ', well', 'well supporting', 'supporting speech', 'speech applications', 'applications transcription', 'transcription .'] 

 TOTAL BIGRAMS --> 28 



 ---- TRI-GRAMS ---- 

 ['Language processing techniques', 'processing techniques ,', 'techniques , whether', ', whether supplemental', 'whether supplemental place', 'supplemental place current', 'place current statistical', 'current statistical models', 'statistical models ,', 'models , offer', ', offer potential', 'offer potential providing', 'potential providing even', 'providing even lower', 'even lower perplexity', 'lower perplexity due', 'perplexity due modeling', 'due modeling local', 'modeling local global', 'local global constraints', 'global constraints ,', 'constraints , well', ', well supporting', 'well supporting speech', 'supporting speech applications', 'speech applications transcription', 'applications transcription .'] 

 TOTAL TRIGRAMS --> 27 



 ---- NOUN PHRASES ---- 

 ['Language', 'processing', 'supplemental place', 'perplexity', 'speech', 'transcription'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Language']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['languag', 'process', 'techniqu', ',', 'whether', 'supplement', 'place', 'current', 'statist', 'model', ',', 'offer', 'potenti', 'provid', 'even', 'lower', 'perplex', 'due', 'model', 'local', 'global', 'constraint', ',', 'well', 'support', 'speech', 'applic', 'transcript', '.']

 TOTAL PORTER STEM WORDS ==> 29



 ---- SNOWBALL STEMMING ----

['languag', 'process', 'techniqu', ',', 'whether', 'supplement', 'place', 'current', 'statist', 'model', ',', 'offer', 'potenti', 'provid', 'even', 'lower', 'perplex', 'due', 'model', 'local', 'global', 'constraint', ',', 'well', 'support', 'speech', 'applic', 'transcript', '.']

 TOTAL SNOWBALL STEM WORDS ==> 29



 ---- LEMMATIZATION ----

['Language', 'processing', 'technique', ',', 'whether', 'supplemental', 'place', 'current', 'statistical', 'model', ',', 'offer', 'potential', 'providing', 'even', 'lower', 'perplexity', 'due', 'modeling', 'local', 'global', 'constraint', ',', 'well', 'supporting', 'speech', 'application', 'transcription', '.']

 TOTAL LEMMATIZE WORDS ==> 29

************************************************************************************************************************

154 --> 3. 


 ---- TOKENS ----

 ['3', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['3', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

155 --> R e s e a r c h  O p p o r t u n i t i e s   To Complement our discussion of ultimate goals and the scientific work needed to achieve them, we here  outline some nearer term research objectives and address evaluation issues. 


 ---- TOKENS ----

 ['R', 'e', 's', 'e', 'a', 'r', 'c', 'h', 'O', 'p', 'p', 'o', 'r', 't', 'u', 'n', 'i', 't', 'i', 'e', 's', 'To', 'Complement', 'our', 'discussion', 'of', 'ultimate', 'goals', 'and', 'the', 'scientific', 'work', 'needed', 'to', 'achieve', 'them', ',', 'we', 'here', 'outline', 'some', 'nearer', 'term', 'research', 'objectives', 'and', 'address', 'evaluation', 'issues', '.'] 

 TOTAL TOKENS ==> 50

 ---- POST ----

 [('R', 'NNP'), ('e', 'NN'), ('s', 'NN'), ('e', 'VBZ'), ('a', 'DT'), ('r', 'NN'), ('c', 'NN'), ('h', 'NN'), ('O', 'NNP'), ('p', 'NN'), ('p', 'NN'), ('o', 'NN'), ('r', 'NN'), ('t', 'NN'), ('u', 'JJ'), ('n', 'NN'), ('i', 'NN'), ('t', 'VBP'), ('i', 'NN'), ('e', 'VBP'), ('s', 'NN'), ('To', 'TO'), ('Complement', 'VB'), ('our', 'PRP$'), ('discussion', 'NN'), ('of', 'IN'), ('ultimate', 'JJ'), ('goals', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('scientific', 'JJ'), ('work', 'NN'), ('needed', 'VBN'), ('to', 'TO'), ('achieve', 'VB'), ('them', 'PRP'), (',', ','), ('we', 'PRP'), ('here', 'RB'), ('outline', 'VBP'), ('some', 'DT'), ('nearer', 'JJ'), ('term', 'NN'), ('research', 'NN'), ('objectives', 'NNS'), ('and', 'CC'), ('address', 'JJ'), ('evaluation', 'NN'), ('issues', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['R', 'e', 'e', 'r', 'c', 'h', 'p', 'p', 'r', 'u', 'n', 'e', 'Complement', 'discussion', 'ultimate', 'goals', 'scientific', 'work', 'needed', 'achieve', ',', 'outline', 'nearer', 'term', 'research', 'objectives', 'address', 'evaluation', 'issues', '.']

 TOTAL FILTERED TOKENS ==>  30

 ---- POST FOR FILTERED TOKENS ----

 [('R', 'NNP'), ('e', 'NN'), ('e', 'NN'), ('r', 'NN'), ('c', 'NN'), ('h', 'NN'), ('p', 'NN'), ('p', 'NN'), ('r', 'NN'), ('u', 'JJ'), ('n', 'JJ'), ('e', 'NN'), ('Complement', 'NNP'), ('discussion', 'NN'), ('ultimate', 'JJ'), ('goals', 'NNS'), ('scientific', 'JJ'), ('work', 'NN'), ('needed', 'VBN'), ('achieve', 'RB'), (',', ','), ('outline', 'JJ'), ('nearer', 'JJR'), ('term', 'NN'), ('research', 'NN'), ('objectives', 'VBZ'), ('address', 'JJ'), ('evaluation', 'NN'), ('issues', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['R e', 'e e', 'e r', 'r c', 'c h', 'h p', 'p p', 'p r', 'r u', 'u n', 'n e', 'e Complement', 'Complement discussion', 'discussion ultimate', 'ultimate goals', 'goals scientific', 'scientific work', 'work needed', 'needed achieve', 'achieve ,', ', outline', 'outline nearer', 'nearer term', 'term research', 'research objectives', 'objectives address', 'address evaluation', 'evaluation issues', 'issues .'] 

 TOTAL BIGRAMS --> 29 



 ---- TRI-GRAMS ---- 

 ['R e e', 'e e r', 'e r c', 'r c h', 'c h p', 'h p p', 'p p r', 'p r u', 'r u n', 'u n e', 'n e Complement', 'e Complement discussion', 'Complement discussion ultimate', 'discussion ultimate goals', 'ultimate goals scientific', 'goals scientific work', 'scientific work needed', 'work needed achieve', 'needed achieve ,', 'achieve , outline', ', outline nearer', 'outline nearer term', 'nearer term research', 'term research objectives', 'research objectives address', 'objectives address evaluation', 'address evaluation issues', 'evaluation issues .'] 

 TOTAL TRIGRAMS --> 28 



 ---- NOUN PHRASES ---- 

 ['e', 'e', 'r', 'c', 'h', 'p', 'p', 'r', 'u n e', 'discussion', 'scientific work', 'term', 'research', 'address evaluation'] 

 TOTAL NOUN PHRASES --> 14 



 ---- NER ----

 
 ORGANIZATION ---> ['Complement']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['r', 'e', 'e', 'r', 'c', 'h', 'p', 'p', 'r', 'u', 'n', 'e', 'complement', 'discuss', 'ultim', 'goal', 'scientif', 'work', 'need', 'achiev', ',', 'outlin', 'nearer', 'term', 'research', 'object', 'address', 'evalu', 'issu', '.']

 TOTAL PORTER STEM WORDS ==> 30



 ---- SNOWBALL STEMMING ----

['r', 'e', 'e', 'r', 'c', 'h', 'p', 'p', 'r', 'u', 'n', 'e', 'complement', 'discuss', 'ultim', 'goal', 'scientif', 'work', 'need', 'achiev', ',', 'outlin', 'nearer', 'term', 'research', 'object', 'address', 'evalu', 'issu', '.']

 TOTAL SNOWBALL STEM WORDS ==> 30



 ---- LEMMATIZATION ----

['R', 'e', 'e', 'r', 'c', 'h', 'p', 'p', 'r', 'u', 'n', 'e', 'Complement', 'discussion', 'ultimate', 'goal', 'scientific', 'work', 'needed', 'achieve', ',', 'outline', 'nearer', 'term', 'research', 'objective', 'address', 'evaluation', 'issue', '.']

 TOTAL LEMMATIZE WORDS ==> 30

************************************************************************************************************************

156 --> 3.1. 


 ---- TOKENS ----

 ['3.1', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('3.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3.1', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('3.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3.1 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3.1', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['3.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['3.1', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

157 --> Scientific Objectives  Acquisition of corpora, grammars, and lexicons. 


 ---- TOKENS ----

 ['Scientific', 'Objectives', 'Acquisition', 'of', 'corpora', ',', 'grammars', ',', 'and', 'lexicons', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Scientific', 'NNP'), ('Objectives', 'NNP'), ('Acquisition', 'NNP'), ('of', 'IN'), ('corpora', 'NN'), (',', ','), ('grammars', 'NNS'), (',', ','), ('and', 'CC'), ('lexicons', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Scientific', 'Objectives', 'Acquisition', 'corpora', ',', 'grammars', ',', 'lexicons', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Scientific', 'NNP'), ('Objectives', 'NNP'), ('Acquisition', 'NNP'), ('corpora', 'NN'), (',', ','), ('grammars', 'NNS'), (',', ','), ('lexicons', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Scientific Objectives', 'Objectives Acquisition', 'Acquisition corpora', 'corpora ,', ', grammars', 'grammars ,', ', lexicons', 'lexicons .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Scientific Objectives Acquisition', 'Objectives Acquisition corpora', 'Acquisition corpora ,', 'corpora , grammars', ', grammars ,', 'grammars , lexicons', ', lexicons .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['corpora'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Objectives Acquisition']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Scientific']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['scientif', 'object', 'acquisit', 'corpora', ',', 'grammar', ',', 'lexicon', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['scientif', 'object', 'acquisit', 'corpora', ',', 'grammar', ',', 'lexicon', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Scientific', 'Objectives', 'Acquisition', 'corpus', ',', 'grammar', ',', 'lexicon', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

158 --> The development of useful systems requires observation  of the behavior of potential users of interactive systems under realistic circumstances, and the collection of corpora  of typical data for text analysis and machine translation systems. 


 ---- TOKENS ----

 ['The', 'development', 'of', 'useful', 'systems', 'requires', 'observation', 'of', 'the', 'behavior', 'of', 'potential', 'users', 'of', 'interactive', 'systems', 'under', 'realistic', 'circumstances', ',', 'and', 'the', 'collection', 'of', 'corpora', 'of', 'typical', 'data', 'for', 'text', 'analysis', 'and', 'machine', 'translation', 'systems', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('The', 'DT'), ('development', 'NN'), ('of', 'IN'), ('useful', 'JJ'), ('systems', 'NNS'), ('requires', 'VBZ'), ('observation', 'NN'), ('of', 'IN'), ('the', 'DT'), ('behavior', 'NN'), ('of', 'IN'), ('potential', 'JJ'), ('users', 'NNS'), ('of', 'IN'), ('interactive', 'JJ'), ('systems', 'NNS'), ('under', 'IN'), ('realistic', 'JJ'), ('circumstances', 'NNS'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('corpora', 'NN'), ('of', 'IN'), ('typical', 'JJ'), ('data', 'NNS'), ('for', 'IN'), ('text', 'JJ'), ('analysis', 'NN'), ('and', 'CC'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['development', 'useful', 'systems', 'requires', 'observation', 'behavior', 'potential', 'users', 'interactive', 'systems', 'realistic', 'circumstances', ',', 'collection', 'corpora', 'typical', 'data', 'text', 'analysis', 'machine', 'translation', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('development', 'NN'), ('useful', 'JJ'), ('systems', 'NNS'), ('requires', 'VBZ'), ('observation', 'JJ'), ('behavior', 'RB'), ('potential', 'JJ'), ('users', 'NNS'), ('interactive', 'JJ'), ('systems', 'NNS'), ('realistic', 'JJ'), ('circumstances', 'NNS'), (',', ','), ('collection', 'NN'), ('corpora', 'NNS'), ('typical', 'JJ'), ('data', 'NNS'), ('text', 'NN'), ('analysis', 'NN'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['development useful', 'useful systems', 'systems requires', 'requires observation', 'observation behavior', 'behavior potential', 'potential users', 'users interactive', 'interactive systems', 'systems realistic', 'realistic circumstances', 'circumstances ,', ', collection', 'collection corpora', 'corpora typical', 'typical data', 'data text', 'text analysis', 'analysis machine', 'machine translation', 'translation systems', 'systems .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['development useful systems', 'useful systems requires', 'systems requires observation', 'requires observation behavior', 'observation behavior potential', 'behavior potential users', 'potential users interactive', 'users interactive systems', 'interactive systems realistic', 'systems realistic circumstances', 'realistic circumstances ,', 'circumstances , collection', ', collection corpora', 'collection corpora typical', 'corpora typical data', 'typical data text', 'data text analysis', 'text analysis machine', 'analysis machine translation', 'machine translation systems', 'translation systems .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['development', 'collection', 'text', 'analysis', 'machine', 'translation'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['develop', 'use', 'system', 'requir', 'observ', 'behavior', 'potenti', 'user', 'interact', 'system', 'realist', 'circumst', ',', 'collect', 'corpora', 'typic', 'data', 'text', 'analysi', 'machin', 'translat', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['develop', 'use', 'system', 'requir', 'observ', 'behavior', 'potenti', 'user', 'interact', 'system', 'realist', 'circumst', ',', 'collect', 'corpora', 'typic', 'data', 'text', 'analysi', 'machin', 'translat', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['development', 'useful', 'system', 'requires', 'observation', 'behavior', 'potential', 'user', 'interactive', 'system', 'realistic', 'circumstance', ',', 'collection', 'corpus', 'typical', 'data', 'text', 'analysis', 'machine', 'translation', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

159 --> Although we believe it is unlikely that full  grammars and lexicons can be induced completely automatically in the near future, useful results may be obtained  soon from induction and acquisition techniques based on annotated corpora and machine-readable dictionaries. 


 ---- TOKENS ----

 ['Although', 'we', 'believe', 'it', 'is', 'unlikely', 'that', 'full', 'grammars', 'and', 'lexicons', 'can', 'be', 'induced', 'completely', 'automatically', 'in', 'the', 'near', 'future', ',', 'useful', 'results', 'may', 'be', 'obtained', 'soon', 'from', 'induction', 'and', 'acquisition', 'techniques', 'based', 'on', 'annotated', 'corpora', 'and', 'machine-readable', 'dictionaries', '.'] 

 TOTAL TOKENS ==> 40

 ---- POST ----

 [('Although', 'IN'), ('we', 'PRP'), ('believe', 'VBP'), ('it', 'PRP'), ('is', 'VBZ'), ('unlikely', 'JJ'), ('that', 'IN'), ('full', 'JJ'), ('grammars', 'NNS'), ('and', 'CC'), ('lexicons', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('induced', 'VBN'), ('completely', 'RB'), ('automatically', 'RB'), ('in', 'IN'), ('the', 'DT'), ('near', 'JJ'), ('future', 'NN'), (',', ','), ('useful', 'JJ'), ('results', 'NNS'), ('may', 'MD'), ('be', 'VB'), ('obtained', 'VBN'), ('soon', 'RB'), ('from', 'IN'), ('induction', 'NN'), ('and', 'CC'), ('acquisition', 'NN'), ('techniques', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('annotated', 'JJ'), ('corpora', 'NNS'), ('and', 'CC'), ('machine-readable', 'JJ'), ('dictionaries', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Although', 'believe', 'unlikely', 'full', 'grammars', 'lexicons', 'induced', 'completely', 'automatically', 'near', 'future', ',', 'useful', 'results', 'may', 'obtained', 'soon', 'induction', 'acquisition', 'techniques', 'based', 'annotated', 'corpora', 'machine-readable', 'dictionaries', '.']

 TOTAL FILTERED TOKENS ==>  26

 ---- POST FOR FILTERED TOKENS ----

 [('Although', 'IN'), ('believe', 'VBP'), ('unlikely', 'JJ'), ('full', 'JJ'), ('grammars', 'NNS'), ('lexicons', 'NNS'), ('induced', 'VBD'), ('completely', 'RB'), ('automatically', 'RB'), ('near', 'IN'), ('future', 'JJ'), (',', ','), ('useful', 'JJ'), ('results', 'NNS'), ('may', 'MD'), ('obtained', 'VBN'), ('soon', 'RB'), ('induction', 'JJ'), ('acquisition', 'NN'), ('techniques', 'NNS'), ('based', 'VBN'), ('annotated', 'JJ'), ('corpora', 'NNS'), ('machine-readable', 'JJ'), ('dictionaries', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Although believe', 'believe unlikely', 'unlikely full', 'full grammars', 'grammars lexicons', 'lexicons induced', 'induced completely', 'completely automatically', 'automatically near', 'near future', 'future ,', ', useful', 'useful results', 'results may', 'may obtained', 'obtained soon', 'soon induction', 'induction acquisition', 'acquisition techniques', 'techniques based', 'based annotated', 'annotated corpora', 'corpora machine-readable', 'machine-readable dictionaries', 'dictionaries .'] 

 TOTAL BIGRAMS --> 25 



 ---- TRI-GRAMS ---- 

 ['Although believe unlikely', 'believe unlikely full', 'unlikely full grammars', 'full grammars lexicons', 'grammars lexicons induced', 'lexicons induced completely', 'induced completely automatically', 'completely automatically near', 'automatically near future', 'near future ,', 'future , useful', ', useful results', 'useful results may', 'results may obtained', 'may obtained soon', 'obtained soon induction', 'soon induction acquisition', 'induction acquisition techniques', 'acquisition techniques based', 'techniques based annotated', 'based annotated corpora', 'annotated corpora machine-readable', 'corpora machine-readable dictionaries', 'machine-readable dictionaries .'] 

 TOTAL TRIGRAMS --> 24 



 ---- NOUN PHRASES ---- 

 ['induction acquisition'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['although', 'believ', 'unlik', 'full', 'grammar', 'lexicon', 'induc', 'complet', 'automat', 'near', 'futur', ',', 'use', 'result', 'may', 'obtain', 'soon', 'induct', 'acquisit', 'techniqu', 'base', 'annot', 'corpora', 'machine-read', 'dictionari', '.']

 TOTAL PORTER STEM WORDS ==> 26



 ---- SNOWBALL STEMMING ----

['although', 'believ', 'unlik', 'full', 'grammar', 'lexicon', 'induc', 'complet', 'automat', 'near', 'futur', ',', 'use', 'result', 'may', 'obtain', 'soon', 'induct', 'acquisit', 'techniqu', 'base', 'annot', 'corpora', 'machine-read', 'dictionari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 26



 ---- LEMMATIZATION ----

['Although', 'believe', 'unlikely', 'full', 'grammar', 'lexicon', 'induced', 'completely', 'automatically', 'near', 'future', ',', 'useful', 'result', 'may', 'obtained', 'soon', 'induction', 'acquisition', 'technique', 'based', 'annotated', 'corpus', 'machine-readable', 'dictionary', '.']

 TOTAL LEMMATIZE WORDS ==> 26

************************************************************************************************************************

160 --> It is  also [ikely that statistical measures useful for biasing algorithms can be extracted from a handcrafted grammar and a  corpus. 


 ---- TOKENS ----

 ['It', 'is', 'also', '[', 'ikely', 'that', 'statistical', 'measures', 'useful', 'for', 'biasing', 'algorithms', 'can', 'be', 'extracted', 'from', 'a', 'handcrafted', 'grammar', 'and', 'a', 'corpus', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('It', 'PRP'), ('is', 'VBZ'), ('also', 'RB'), ('[', 'JJ'), ('ikely', 'RB'), ('that', 'IN'), ('statistical', 'JJ'), ('measures', 'NNS'), ('useful', 'JJ'), ('for', 'IN'), ('biasing', 'VBG'), ('algorithms', 'NN'), ('can', 'MD'), ('be', 'VB'), ('extracted', 'VBN'), ('from', 'IN'), ('a', 'DT'), ('handcrafted', 'VBN'), ('grammar', 'NN'), ('and', 'CC'), ('a', 'DT'), ('corpus', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['also', '[', 'ikely', 'statistical', 'measures', 'useful', 'biasing', 'algorithms', 'extracted', 'handcrafted', 'grammar', 'corpus', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('also', 'RB'), ('[', 'NNP'), ('ikely', 'RB'), ('statistical', 'JJ'), ('measures', 'NNS'), ('useful', 'JJ'), ('biasing', 'VBG'), ('algorithms', 'NN'), ('extracted', 'VBD'), ('handcrafted', 'JJ'), ('grammar', 'NN'), ('corpus', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['also [', '[ ikely', 'ikely statistical', 'statistical measures', 'measures useful', 'useful biasing', 'biasing algorithms', 'algorithms extracted', 'extracted handcrafted', 'handcrafted grammar', 'grammar corpus', 'corpus .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['also [ ikely', '[ ikely statistical', 'ikely statistical measures', 'statistical measures useful', 'measures useful biasing', 'useful biasing algorithms', 'biasing algorithms extracted', 'algorithms extracted handcrafted', 'extracted handcrafted grammar', 'handcrafted grammar corpus', 'grammar corpus .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['algorithms', 'handcrafted grammar', 'corpus'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['also', '[', 'ike', 'statist', 'measur', 'use', 'bias', 'algorithm', 'extract', 'handcraft', 'grammar', 'corpu', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['also', '[', 'ike', 'statist', 'measur', 'use', 'bias', 'algorithm', 'extract', 'handcraft', 'grammar', 'corpus', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['also', '[', 'ikely', 'statistical', 'measure', 'useful', 'biasing', 'algorithm', 'extracted', 'handcrafted', 'grammar', 'corpus', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

161 --> Approaches that appear promising axe 1) the learning of grammatical structures where the input has already  been annotated by part of speech and/or phrase structure, and 2) the learning of lexical syntaMsemantics from  examples and/or queries to the user given some pre-coded domain knowledge. 


 ---- TOKENS ----

 ['Approaches', 'that', 'appear', 'promising', 'axe', '1', ')', 'the', 'learning', 'of', 'grammatical', 'structures', 'where', 'the', 'input', 'has', 'already', 'been', 'annotated', 'by', 'part', 'of', 'speech', 'and/or', 'phrase', 'structure', ',', 'and', '2', ')', 'the', 'learning', 'of', 'lexical', 'syntaMsemantics', 'from', 'examples', 'and/or', 'queries', 'to', 'the', 'user', 'given', 'some', 'pre-coded', 'domain', 'knowledge', '.'] 

 TOTAL TOKENS ==> 48

 ---- POST ----

 [('Approaches', 'NNS'), ('that', 'WDT'), ('appear', 'VBP'), ('promising', 'VBG'), ('axe', 'RB'), ('1', 'CD'), (')', ')'), ('the', 'DT'), ('learning', 'NN'), ('of', 'IN'), ('grammatical', 'JJ'), ('structures', 'NNS'), ('where', 'WRB'), ('the', 'DT'), ('input', 'NN'), ('has', 'VBZ'), ('already', 'RB'), ('been', 'VBN'), ('annotated', 'VBN'), ('by', 'IN'), ('part', 'NN'), ('of', 'IN'), ('speech', 'NN'), ('and/or', 'JJ'), ('phrase', 'NN'), ('structure', 'NN'), (',', ','), ('and', 'CC'), ('2', 'CD'), (')', ')'), ('the', 'DT'), ('learning', 'NN'), ('of', 'IN'), ('lexical', 'JJ'), ('syntaMsemantics', 'NNS'), ('from', 'IN'), ('examples', 'NNS'), ('and/or', 'JJ'), ('queries', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('user', 'NN'), ('given', 'VBN'), ('some', 'DT'), ('pre-coded', 'JJ'), ('domain', 'NN'), ('knowledge', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Approaches', 'appear', 'promising', 'axe', '1', ')', 'learning', 'grammatical', 'structures', 'input', 'already', 'annotated', 'part', 'speech', 'and/or', 'phrase', 'structure', ',', '2', ')', 'learning', 'lexical', 'syntaMsemantics', 'examples', 'and/or', 'queries', 'user', 'given', 'pre-coded', 'domain', 'knowledge', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('Approaches', 'NNS'), ('appear', 'VBP'), ('promising', 'VBG'), ('axe', 'RB'), ('1', 'CD'), (')', ')'), ('learning', 'VBG'), ('grammatical', 'JJ'), ('structures', 'NNS'), ('input', 'VBP'), ('already', 'RB'), ('annotated', 'VBN'), ('part', 'NN'), ('speech', 'NN'), ('and/or', 'JJ'), ('phrase', 'NN'), ('structure', 'NN'), (',', ','), ('2', 'CD'), (')', ')'), ('learning', 'VBG'), ('lexical', 'JJ'), ('syntaMsemantics', 'NNS'), ('examples', 'NNS'), ('and/or', 'VBP'), ('queries', 'NNS'), ('user', 'RBR'), ('given', 'VBN'), ('pre-coded', 'JJ'), ('domain', 'NN'), ('knowledge', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Approaches appear', 'appear promising', 'promising axe', 'axe 1', '1 )', ') learning', 'learning grammatical', 'grammatical structures', 'structures input', 'input already', 'already annotated', 'annotated part', 'part speech', 'speech and/or', 'and/or phrase', 'phrase structure', 'structure ,', ', 2', '2 )', ') learning', 'learning lexical', 'lexical syntaMsemantics', 'syntaMsemantics examples', 'examples and/or', 'and/or queries', 'queries user', 'user given', 'given pre-coded', 'pre-coded domain', 'domain knowledge', 'knowledge .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['Approaches appear promising', 'appear promising axe', 'promising axe 1', 'axe 1 )', '1 ) learning', ') learning grammatical', 'learning grammatical structures', 'grammatical structures input', 'structures input already', 'input already annotated', 'already annotated part', 'annotated part speech', 'part speech and/or', 'speech and/or phrase', 'and/or phrase structure', 'phrase structure ,', 'structure , 2', ', 2 )', '2 ) learning', ') learning lexical', 'learning lexical syntaMsemantics', 'lexical syntaMsemantics examples', 'syntaMsemantics examples and/or', 'examples and/or queries', 'and/or queries user', 'queries user given', 'user given pre-coded', 'given pre-coded domain', 'pre-coded domain knowledge', 'domain knowledge .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['approach', 'appear', 'promis', 'axe', '1', ')', 'learn', 'grammat', 'structur', 'input', 'alreadi', 'annot', 'part', 'speech', 'and/or', 'phrase', 'structur', ',', '2', ')', 'learn', 'lexic', 'syntamsemant', 'exampl', 'and/or', 'queri', 'user', 'given', 'pre-cod', 'domain', 'knowledg', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['approach', 'appear', 'promis', 'axe', '1', ')', 'learn', 'grammat', 'structur', 'input', 'alreadi', 'annot', 'part', 'speech', 'and/or', 'phrase', 'structur', ',', '2', ')', 'learn', 'lexic', 'syntamsemant', 'exampl', 'and/or', 'queri', 'user', 'given', 'pre-cod', 'domain', 'knowledg', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['Approaches', 'appear', 'promising', 'axe', '1', ')', 'learning', 'grammatical', 'structure', 'input', 'already', 'annotated', 'part', 'speech', 'and/or', 'phrase', 'structure', ',', '2', ')', 'learning', 'lexical', 'syntaMsemantics', 'example', 'and/or', 'query', 'user', 'given', 'pre-coded', 'domain', 'knowledge', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

162 --> Increasing expressive power ~ Meaning Representation Languages. 


 ---- TOKENS ----

 ['Increasing', 'expressive', 'power', '~', 'Meaning', 'Representation', 'Languages', '.'] 

 TOTAL TOKENS ==> 8

 ---- POST ----

 [('Increasing', 'VBG'), ('expressive', 'JJ'), ('power', 'NN'), ('~', 'NNP'), ('Meaning', 'NNP'), ('Representation', 'NNP'), ('Languages', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Increasing', 'expressive', 'power', '~', 'Meaning', 'Representation', 'Languages', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Increasing', 'VBG'), ('expressive', 'JJ'), ('power', 'NN'), ('~', 'NNP'), ('Meaning', 'NNP'), ('Representation', 'NNP'), ('Languages', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Increasing expressive', 'expressive power', 'power ~', '~ Meaning', 'Meaning Representation', 'Representation Languages', 'Languages .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Increasing expressive power', 'expressive power ~', 'power ~ Meaning', '~ Meaning Representation', 'Meaning Representation Languages', 'Representation Languages .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['expressive power'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['increas', 'express', 'power', '~', 'mean', 'represent', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['increas', 'express', 'power', '~', 'mean', 'represent', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Increasing', 'expressive', 'power', '~', 'Meaning', 'Representation', 'Languages', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

163 --> Moving beyond database query  systems will require increasing the expressive power of the MRL to include at least modal and higher order  constructs. 


 ---- TOKENS ----

 ['Moving', 'beyond', 'database', 'query', 'systems', 'will', 'require', 'increasing', 'the', 'expressive', 'power', 'of', 'the', 'MRL', 'to', 'include', 'at', 'least', 'modal', 'and', 'higher', 'order', 'constructs', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Moving', 'VBG'), ('beyond', 'IN'), ('database', 'NN'), ('query', 'NN'), ('systems', 'NNS'), ('will', 'MD'), ('require', 'VB'), ('increasing', 'VBG'), ('the', 'DT'), ('expressive', 'JJ'), ('power', 'NN'), ('of', 'IN'), ('the', 'DT'), ('MRL', 'NNP'), ('to', 'TO'), ('include', 'VB'), ('at', 'IN'), ('least', 'JJS'), ('modal', 'NN'), ('and', 'CC'), ('higher', 'JJR'), ('order', 'NN'), ('constructs', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Moving', 'beyond', 'database', 'query', 'systems', 'require', 'increasing', 'expressive', 'power', 'MRL', 'include', 'least', 'modal', 'higher', 'order', 'constructs', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Moving', 'VBG'), ('beyond', 'IN'), ('database', 'NN'), ('query', 'NN'), ('systems', 'NNS'), ('require', 'VBP'), ('increasing', 'VBG'), ('expressive', 'JJ'), ('power', 'NN'), ('MRL', 'NNP'), ('include', 'VBP'), ('least', 'JJS'), ('modal', 'JJ'), ('higher', 'JJR'), ('order', 'NN'), ('constructs', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Moving beyond', 'beyond database', 'database query', 'query systems', 'systems require', 'require increasing', 'increasing expressive', 'expressive power', 'power MRL', 'MRL include', 'include least', 'least modal', 'modal higher', 'higher order', 'order constructs', 'constructs .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Moving beyond database', 'beyond database query', 'database query systems', 'query systems require', 'systems require increasing', 'require increasing expressive', 'increasing expressive power', 'expressive power MRL', 'power MRL include', 'MRL include least', 'include least modal', 'least modal higher', 'modal higher order', 'higher order constructs', 'order constructs .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['database', 'query', 'expressive power', 'order'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['move', 'beyond', 'databas', 'queri', 'system', 'requir', 'increas', 'express', 'power', 'mrl', 'includ', 'least', 'modal', 'higher', 'order', 'construct', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['move', 'beyond', 'databas', 'queri', 'system', 'requir', 'increas', 'express', 'power', 'mrl', 'includ', 'least', 'modal', 'higher', 'order', 'construct', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Moving', 'beyond', 'database', 'query', 'system', 'require', 'increasing', 'expressive', 'power', 'MRL', 'include', 'least', 'modal', 'higher', 'order', 'construct', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

164 --> Reasoning tools for modal logics and for second-order logics already exist, but they appear intractable  for language processing tasks. 


 ---- TOKENS ----

 ['Reasoning', 'tools', 'for', 'modal', 'logics', 'and', 'for', 'second-order', 'logics', 'already', 'exist', ',', 'but', 'they', 'appear', 'intractable', 'for', 'language', 'processing', 'tasks', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Reasoning', 'VBG'), ('tools', 'NNS'), ('for', 'IN'), ('modal', 'JJ'), ('logics', 'NNS'), ('and', 'CC'), ('for', 'IN'), ('second-order', 'JJ'), ('logics', 'NNS'), ('already', 'RB'), ('exist', 'VBP'), (',', ','), ('but', 'CC'), ('they', 'PRP'), ('appear', 'VBP'), ('intractable', 'JJ'), ('for', 'IN'), ('language', 'NN'), ('processing', 'NN'), ('tasks', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Reasoning', 'tools', 'modal', 'logics', 'second-order', 'logics', 'already', 'exist', ',', 'appear', 'intractable', 'language', 'processing', 'tasks', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Reasoning', 'VBG'), ('tools', 'NNS'), ('modal', 'JJ'), ('logics', 'NNS'), ('second-order', 'JJ'), ('logics', 'NNS'), ('already', 'RB'), ('exist', 'VBP'), (',', ','), ('appear', 'VBP'), ('intractable', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('tasks', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Reasoning tools', 'tools modal', 'modal logics', 'logics second-order', 'second-order logics', 'logics already', 'already exist', 'exist ,', ', appear', 'appear intractable', 'intractable language', 'language processing', 'processing tasks', 'tasks .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Reasoning tools modal', 'tools modal logics', 'modal logics second-order', 'logics second-order logics', 'second-order logics already', 'logics already exist', 'already exist ,', 'exist , appear', ', appear intractable', 'appear intractable language', 'intractable language processing', 'language processing tasks', 'processing tasks .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['intractable language', 'processing'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['reason', 'tool', 'modal', 'logic', 'second-ord', 'logic', 'alreadi', 'exist', ',', 'appear', 'intract', 'languag', 'process', 'task', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['reason', 'tool', 'modal', 'logic', 'second-ord', 'logic', 'alreadi', 'exist', ',', 'appear', 'intract', 'languag', 'process', 'task', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Reasoning', 'tool', 'modal', 'logic', 'second-order', 'logic', 'already', 'exist', ',', 'appear', 'intractable', 'language', 'processing', 'task', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

165 --> Approaches that seem promising include encoding modal constructs in first-order  logic, hybrid approaches to representation and reasoning, and approaches to resource-limited or shallow reasoning,  such as adding weights to formulae and subformulae. 


 ---- TOKENS ----

 ['Approaches', 'that', 'seem', 'promising', 'include', 'encoding', 'modal', 'constructs', 'in', 'first-order', 'logic', ',', 'hybrid', 'approaches', 'to', 'representation', 'and', 'reasoning', ',', 'and', 'approaches', 'to', 'resource-limited', 'or', 'shallow', 'reasoning', ',', 'such', 'as', 'adding', 'weights', 'to', 'formulae', 'and', 'subformulae', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('Approaches', 'NNS'), ('that', 'WDT'), ('seem', 'VBP'), ('promising', 'VBG'), ('include', 'VBP'), ('encoding', 'VBG'), ('modal', 'JJ'), ('constructs', 'NNS'), ('in', 'IN'), ('first-order', 'JJ'), ('logic', 'NN'), (',', ','), ('hybrid', 'JJ'), ('approaches', 'NNS'), ('to', 'TO'), ('representation', 'NN'), ('and', 'CC'), ('reasoning', 'NN'), (',', ','), ('and', 'CC'), ('approaches', 'NNS'), ('to', 'TO'), ('resource-limited', 'JJ'), ('or', 'CC'), ('shallow', 'JJ'), ('reasoning', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('adding', 'VBG'), ('weights', 'NNS'), ('to', 'TO'), ('formulae', 'VB'), ('and', 'CC'), ('subformulae', 'VB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Approaches', 'seem', 'promising', 'include', 'encoding', 'modal', 'constructs', 'first-order', 'logic', ',', 'hybrid', 'approaches', 'representation', 'reasoning', ',', 'approaches', 'resource-limited', 'shallow', 'reasoning', ',', 'adding', 'weights', 'formulae', 'subformulae', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('Approaches', 'NNP'), ('seem', 'VBP'), ('promising', 'VBG'), ('include', 'VBP'), ('encoding', 'VBG'), ('modal', 'JJ'), ('constructs', 'NNS'), ('first-order', 'JJ'), ('logic', 'NN'), (',', ','), ('hybrid', 'JJ'), ('approaches', 'NNS'), ('representation', 'NN'), ('reasoning', 'NN'), (',', ','), ('approaches', 'VBZ'), ('resource-limited', 'JJ'), ('shallow', 'NN'), ('reasoning', 'NN'), (',', ','), ('adding', 'VBG'), ('weights', 'NNS'), ('formulae', 'JJ'), ('subformulae', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Approaches seem', 'seem promising', 'promising include', 'include encoding', 'encoding modal', 'modal constructs', 'constructs first-order', 'first-order logic', 'logic ,', ', hybrid', 'hybrid approaches', 'approaches representation', 'representation reasoning', 'reasoning ,', ', approaches', 'approaches resource-limited', 'resource-limited shallow', 'shallow reasoning', 'reasoning ,', ', adding', 'adding weights', 'weights formulae', 'formulae subformulae', 'subformulae .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['Approaches seem promising', 'seem promising include', 'promising include encoding', 'include encoding modal', 'encoding modal constructs', 'modal constructs first-order', 'constructs first-order logic', 'first-order logic ,', 'logic , hybrid', ', hybrid approaches', 'hybrid approaches representation', 'approaches representation reasoning', 'representation reasoning ,', 'reasoning , approaches', ', approaches resource-limited', 'approaches resource-limited shallow', 'resource-limited shallow reasoning', 'shallow reasoning ,', 'reasoning , adding', ', adding weights', 'adding weights formulae', 'weights formulae subformulae', 'formulae subformulae .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['first-order logic', 'representation', 'reasoning', 'resource-limited shallow', 'reasoning', 'formulae subformulae'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['approach', 'seem', 'promis', 'includ', 'encod', 'modal', 'construct', 'first-ord', 'logic', ',', 'hybrid', 'approach', 'represent', 'reason', ',', 'approach', 'resource-limit', 'shallow', 'reason', ',', 'ad', 'weight', 'formula', 'subformula', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['approach', 'seem', 'promis', 'includ', 'encod', 'modal', 'construct', 'first-ord', 'logic', ',', 'hybrid', 'approach', 'represent', 'reason', ',', 'approach', 'resource-limit', 'shallow', 'reason', ',', 'ad', 'weight', 'formula', 'subformula', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['Approaches', 'seem', 'promising', 'include', 'encoding', 'modal', 'construct', 'first-order', 'logic', ',', 'hybrid', 'approach', 'representation', 'reasoning', ',', 'approach', 'resource-limited', 'shallow', 'reasoning', ',', 'adding', 'weight', 'formula', 'subformulae', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

166 --> Reasoning about plans. 


 ---- TOKENS ----

 ['Reasoning', 'about', 'plans', '.'] 

 TOTAL TOKENS ==> 4

 ---- POST ----

 [('Reasoning', 'VBG'), ('about', 'IN'), ('plans', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Reasoning', 'plans', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Reasoning', 'VBG'), ('plans', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Reasoning plans', 'plans .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Reasoning plans .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['reason', 'plan', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['reason', 'plan', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Reasoning', 'plan', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

167 --> Recent work on plan recognition (the inference of the beliefs and intentions of  agents in context) has provided formal definitions of the problem and some new algorithms. 


 ---- TOKENS ----

 ['Recent', 'work', 'on', 'plan', 'recognition', '(', 'the', 'inference', 'of', 'the', 'beliefs', 'and', 'intentions', 'of', 'agents', 'in', 'context', ')', 'has', 'provided', 'formal', 'definitions', 'of', 'the', 'problem', 'and', 'some', 'new', 'algorithms', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('Recent', 'JJ'), ('work', 'NN'), ('on', 'IN'), ('plan', 'NN'), ('recognition', 'NN'), ('(', '('), ('the', 'DT'), ('inference', 'NN'), ('of', 'IN'), ('the', 'DT'), ('beliefs', 'NNS'), ('and', 'CC'), ('intentions', 'NNS'), ('of', 'IN'), ('agents', 'NNS'), ('in', 'IN'), ('context', 'NN'), (')', ')'), ('has', 'VBZ'), ('provided', 'VBN'), ('formal', 'JJ'), ('definitions', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('problem', 'NN'), ('and', 'CC'), ('some', 'DT'), ('new', 'JJ'), ('algorithms', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Recent', 'work', 'plan', 'recognition', '(', 'inference', 'beliefs', 'intentions', 'agents', 'context', ')', 'provided', 'formal', 'definitions', 'problem', 'new', 'algorithms', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Recent', 'JJ'), ('work', 'NN'), ('plan', 'NN'), ('recognition', 'NN'), ('(', '('), ('inference', 'NN'), ('beliefs', 'NNS'), ('intentions', 'NNS'), ('agents', 'NNS'), ('context', 'NN'), (')', ')'), ('provided', 'VBD'), ('formal', 'JJ'), ('definitions', 'NNS'), ('problem', 'NN'), ('new', 'JJ'), ('algorithms', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Recent work', 'work plan', 'plan recognition', 'recognition (', '( inference', 'inference beliefs', 'beliefs intentions', 'intentions agents', 'agents context', 'context )', ') provided', 'provided formal', 'formal definitions', 'definitions problem', 'problem new', 'new algorithms', 'algorithms .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Recent work plan', 'work plan recognition', 'plan recognition (', 'recognition ( inference', '( inference beliefs', 'inference beliefs intentions', 'beliefs intentions agents', 'intentions agents context', 'agents context )', 'context ) provided', ') provided formal', 'provided formal definitions', 'formal definitions problem', 'definitions problem new', 'problem new algorithms', 'new algorithms .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['Recent work', 'plan', 'recognition', 'problem', 'new algorithms'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['recent', 'work', 'plan', 'recognit', '(', 'infer', 'belief', 'intent', 'agent', 'context', ')', 'provid', 'formal', 'definit', 'problem', 'new', 'algorithm', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['recent', 'work', 'plan', 'recognit', '(', 'infer', 'belief', 'intent', 'agent', 'context', ')', 'provid', 'formal', 'definit', 'problem', 'new', 'algorithm', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Recent', 'work', 'plan', 'recognition', '(', 'inference', 'belief', 'intention', 'agent', 'context', ')', 'provided', 'formal', 'definition', 'problem', 'new', 'algorithm', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

168 --> These have not yet  487   been used as part of a discourse component to help resolve reference, quantification, and modification ambiguiues  or to formulate an appropriate response. 


 ---- TOKENS ----

 ['These', 'have', 'not', 'yet', '487', 'been', 'used', 'as', 'part', 'of', 'a', 'discourse', 'component', 'to', 'help', 'resolve', 'reference', ',', 'quantification', ',', 'and', 'modification', 'ambiguiues', 'or', 'to', 'formulate', 'an', 'appropriate', 'response', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('These', 'DT'), ('have', 'VBP'), ('not', 'RB'), ('yet', 'RB'), ('487', 'CD'), ('been', 'VBN'), ('used', 'VBN'), ('as', 'IN'), ('part', 'NN'), ('of', 'IN'), ('a', 'DT'), ('discourse', 'JJ'), ('component', 'NN'), ('to', 'TO'), ('help', 'VB'), ('resolve', 'VB'), ('reference', 'NN'), (',', ','), ('quantification', 'NN'), (',', ','), ('and', 'CC'), ('modification', 'NN'), ('ambiguiues', 'NNS'), ('or', 'CC'), ('to', 'TO'), ('formulate', 'VB'), ('an', 'DT'), ('appropriate', 'JJ'), ('response', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['yet', '487', 'used', 'part', 'discourse', 'component', 'help', 'resolve', 'reference', ',', 'quantification', ',', 'modification', 'ambiguiues', 'formulate', 'appropriate', 'response', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('yet', 'RB'), ('487', 'CD'), ('used', 'JJ'), ('part', 'NN'), ('discourse', 'NN'), ('component', 'NN'), ('help', 'NN'), ('resolve', 'VB'), ('reference', 'NN'), (',', ','), ('quantification', 'NN'), (',', ','), ('modification', 'NN'), ('ambiguiues', 'NNS'), ('formulate', 'VBP'), ('appropriate', 'JJ'), ('response', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['yet 487', '487 used', 'used part', 'part discourse', 'discourse component', 'component help', 'help resolve', 'resolve reference', 'reference ,', ', quantification', 'quantification ,', ', modification', 'modification ambiguiues', 'ambiguiues formulate', 'formulate appropriate', 'appropriate response', 'response .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['yet 487 used', '487 used part', 'used part discourse', 'part discourse component', 'discourse component help', 'component help resolve', 'help resolve reference', 'resolve reference ,', 'reference , quantification', ', quantification ,', 'quantification , modification', ', modification ambiguiues', 'modification ambiguiues formulate', 'ambiguiues formulate appropriate', 'formulate appropriate response', 'appropriate response .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['used part', 'discourse', 'component', 'help', 'reference', 'quantification', 'modification', 'appropriate response'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['yet', '487', 'use', 'part', 'discours', 'compon', 'help', 'resolv', 'refer', ',', 'quantif', ',', 'modif', 'ambiguiu', 'formul', 'appropri', 'respons', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['yet', '487', 'use', 'part', 'discours', 'compon', 'help', 'resolv', 'refer', ',', 'quantif', ',', 'modif', 'ambiguiu', 'formul', 'appropri', 'respons', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['yet', '487', 'used', 'part', 'discourse', 'component', 'help', 'resolve', 'reference', ',', 'quantification', ',', 'modification', 'ambiguiues', 'formulate', 'appropriate', 'response', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

169 --> The interaction between plans, discourse structure, and focus of attention  also needs to be investigated. 


 ---- TOKENS ----

 ['The', 'interaction', 'between', 'plans', ',', 'discourse', 'structure', ',', 'and', 'focus', 'of', 'attention', 'also', 'needs', 'to', 'be', 'investigated', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('The', 'DT'), ('interaction', 'NN'), ('between', 'IN'), ('plans', 'NNS'), (',', ','), ('discourse', 'NN'), ('structure', 'NN'), (',', ','), ('and', 'CC'), ('focus', 'NN'), ('of', 'IN'), ('attention', 'NN'), ('also', 'RB'), ('needs', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('investigated', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['interaction', 'plans', ',', 'discourse', 'structure', ',', 'focus', 'attention', 'also', 'needs', 'investigated', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('interaction', 'NN'), ('plans', 'NNS'), (',', ','), ('discourse', 'NN'), ('structure', 'NN'), (',', ','), ('focus', 'NN'), ('attention', 'NN'), ('also', 'RB'), ('needs', 'VBZ'), ('investigated', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['interaction plans', 'plans ,', ', discourse', 'discourse structure', 'structure ,', ', focus', 'focus attention', 'attention also', 'also needs', 'needs investigated', 'investigated .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['interaction plans ,', 'plans , discourse', ', discourse structure', 'discourse structure ,', 'structure , focus', ', focus attention', 'focus attention also', 'attention also needs', 'also needs investigated', 'needs investigated .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['interaction', 'discourse', 'structure', 'focus', 'attention'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['interact', 'plan', ',', 'discours', 'structur', ',', 'focu', 'attent', 'also', 'need', 'investig', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['interact', 'plan', ',', 'discours', 'structur', ',', 'focus', 'attent', 'also', 'need', 'investig', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['interaction', 'plan', ',', 'discourse', 'structure', ',', 'focus', 'attention', 'also', 'need', 'investigated', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

170 --> Promising approaches include incorporation of beliefs of the discourse participants,  integrating existing models into discourse processing under simplifying conditions, and exploring prosodic and  linguistic cues to dialogue. 


 ---- TOKENS ----

 ['Promising', 'approaches', 'include', 'incorporation', 'of', 'beliefs', 'of', 'the', 'discourse', 'participants', ',', 'integrating', 'existing', 'models', 'into', 'discourse', 'processing', 'under', 'simplifying', 'conditions', ',', 'and', 'exploring', 'prosodic', 'and', 'linguistic', 'cues', 'to', 'dialogue', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('Promising', 'VBG'), ('approaches', 'NNS'), ('include', 'VBP'), ('incorporation', 'NN'), ('of', 'IN'), ('beliefs', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('discourse', 'NN'), ('participants', 'NNS'), (',', ','), ('integrating', 'VBG'), ('existing', 'VBG'), ('models', 'NNS'), ('into', 'IN'), ('discourse', 'JJ'), ('processing', 'VBG'), ('under', 'IN'), ('simplifying', 'VBG'), ('conditions', 'NNS'), (',', ','), ('and', 'CC'), ('exploring', 'VBG'), ('prosodic', 'JJ'), ('and', 'CC'), ('linguistic', 'JJ'), ('cues', 'NNS'), ('to', 'TO'), ('dialogue', 'VB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Promising', 'approaches', 'include', 'incorporation', 'beliefs', 'discourse', 'participants', ',', 'integrating', 'existing', 'models', 'discourse', 'processing', 'simplifying', 'conditions', ',', 'exploring', 'prosodic', 'linguistic', 'cues', 'dialogue', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('Promising', 'VBG'), ('approaches', 'NNS'), ('include', 'VBP'), ('incorporation', 'NN'), ('beliefs', 'NNS'), ('discourse', 'JJ'), ('participants', 'NNS'), (',', ','), ('integrating', 'VBG'), ('existing', 'VBG'), ('models', 'NNS'), ('discourse', 'VBP'), ('processing', 'VBG'), ('simplifying', 'VBG'), ('conditions', 'NNS'), (',', ','), ('exploring', 'VBG'), ('prosodic', 'JJ'), ('linguistic', 'JJ'), ('cues', 'NNS'), ('dialogue', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Promising approaches', 'approaches include', 'include incorporation', 'incorporation beliefs', 'beliefs discourse', 'discourse participants', 'participants ,', ', integrating', 'integrating existing', 'existing models', 'models discourse', 'discourse processing', 'processing simplifying', 'simplifying conditions', 'conditions ,', ', exploring', 'exploring prosodic', 'prosodic linguistic', 'linguistic cues', 'cues dialogue', 'dialogue .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['Promising approaches include', 'approaches include incorporation', 'include incorporation beliefs', 'incorporation beliefs discourse', 'beliefs discourse participants', 'discourse participants ,', 'participants , integrating', ', integrating existing', 'integrating existing models', 'existing models discourse', 'models discourse processing', 'discourse processing simplifying', 'processing simplifying conditions', 'simplifying conditions ,', 'conditions , exploring', ', exploring prosodic', 'exploring prosodic linguistic', 'prosodic linguistic cues', 'linguistic cues dialogue', 'cues dialogue .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['incorporation', 'dialogue'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['promis', 'approach', 'includ', 'incorpor', 'belief', 'discours', 'particip', ',', 'integr', 'exist', 'model', 'discours', 'process', 'simplifi', 'condit', ',', 'explor', 'prosod', 'linguist', 'cue', 'dialogu', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['promis', 'approach', 'includ', 'incorpor', 'belief', 'discours', 'particip', ',', 'integr', 'exist', 'model', 'discours', 'process', 'simplifi', 'condit', ',', 'explor', 'prosod', 'linguist', 'cue', 'dialogu', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['Promising', 'approach', 'include', 'incorporation', 'belief', 'discourse', 'participant', ',', 'integrating', 'existing', 'model', 'discourse', 'processing', 'simplifying', 'condition', ',', 'exploring', 'prosodic', 'linguistic', 'cue', 'dialogue', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

171 --> Combination of partial information. 


 ---- TOKENS ----

 ['Combination', 'of', 'partial', 'information', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('Combination', 'NN'), ('of', 'IN'), ('partial', 'JJ'), ('information', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Combination', 'partial', 'information', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('Combination', 'NNP'), ('partial', 'JJ'), ('information', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Combination partial', 'partial information', 'information .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['Combination partial information', 'partial information .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 ['partial information'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['combin', 'partial', 'inform', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['combin', 'partial', 'inform', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['Combination', 'partial', 'information', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

172 --> The standard control structure by which various sources of  information are combined in language interpretanon seems to limit what NL systems can do. 


 ---- TOKENS ----

 ['The', 'standard', 'control', 'structure', 'by', 'which', 'various', 'sources', 'of', 'information', 'are', 'combined', 'in', 'language', 'interpretanon', 'seems', 'to', 'limit', 'what', 'NL', 'systems', 'can', 'do', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('The', 'DT'), ('standard', 'JJ'), ('control', 'NN'), ('structure', 'NN'), ('by', 'IN'), ('which', 'WDT'), ('various', 'JJ'), ('sources', 'NNS'), ('of', 'IN'), ('information', 'NN'), ('are', 'VBP'), ('combined', 'VBN'), ('in', 'IN'), ('language', 'NN'), ('interpretanon', 'NN'), ('seems', 'VBZ'), ('to', 'TO'), ('limit', 'VB'), ('what', 'WP'), ('NL', 'NNP'), ('systems', 'NNS'), ('can', 'MD'), ('do', 'VB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['standard', 'control', 'structure', 'various', 'sources', 'information', 'combined', 'language', 'interpretanon', 'seems', 'limit', 'NL', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('standard', 'JJ'), ('control', 'NN'), ('structure', 'NN'), ('various', 'JJ'), ('sources', 'NNS'), ('information', 'NN'), ('combined', 'VBN'), ('language', 'NN'), ('interpretanon', 'NN'), ('seems', 'VBZ'), ('limit', 'JJ'), ('NL', 'NNP'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['standard control', 'control structure', 'structure various', 'various sources', 'sources information', 'information combined', 'combined language', 'language interpretanon', 'interpretanon seems', 'seems limit', 'limit NL', 'NL systems', 'systems .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['standard control structure', 'control structure various', 'structure various sources', 'various sources information', 'sources information combined', 'information combined language', 'combined language interpretanon', 'language interpretanon seems', 'interpretanon seems limit', 'seems limit NL', 'limit NL systems', 'NL systems .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['standard control', 'structure', 'information', 'language', 'interpretanon'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['standard', 'control', 'structur', 'variou', 'sourc', 'inform', 'combin', 'languag', 'interpretanon', 'seem', 'limit', 'nl', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['standard', 'control', 'structur', 'various', 'sourc', 'inform', 'combin', 'languag', 'interpretanon', 'seem', 'limit', 'nl', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['standard', 'control', 'structure', 'various', 'source', 'information', 'combined', 'language', 'interpretanon', 'seems', 'limit', 'NL', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

173 --> Several proposals for  more flexible control structures have been made recendy, each covering a subset of the knowledge sources  available. 


 ---- TOKENS ----

 ['Several', 'proposals', 'for', 'more', 'flexible', 'control', 'structures', 'have', 'been', 'made', 'recendy', ',', 'each', 'covering', 'a', 'subset', 'of', 'the', 'knowledge', 'sources', 'available', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Several', 'JJ'), ('proposals', 'NNS'), ('for', 'IN'), ('more', 'RBR'), ('flexible', 'JJ'), ('control', 'NN'), ('structures', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('made', 'VBN'), ('recendy', 'NN'), (',', ','), ('each', 'DT'), ('covering', 'VBG'), ('a', 'DT'), ('subset', 'NN'), ('of', 'IN'), ('the', 'DT'), ('knowledge', 'NN'), ('sources', 'NNS'), ('available', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Several', 'proposals', 'flexible', 'control', 'structures', 'made', 'recendy', ',', 'covering', 'subset', 'knowledge', 'sources', 'available', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('Several', 'JJ'), ('proposals', 'NNS'), ('flexible', 'JJ'), ('control', 'NN'), ('structures', 'NNS'), ('made', 'VBN'), ('recendy', 'NN'), (',', ','), ('covering', 'VBG'), ('subset', 'VBN'), ('knowledge', 'NN'), ('sources', 'NNS'), ('available', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Several proposals', 'proposals flexible', 'flexible control', 'control structures', 'structures made', 'made recendy', 'recendy ,', ', covering', 'covering subset', 'subset knowledge', 'knowledge sources', 'sources available', 'available .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['Several proposals flexible', 'proposals flexible control', 'flexible control structures', 'control structures made', 'structures made recendy', 'made recendy ,', 'recendy , covering', ', covering subset', 'covering subset knowledge', 'subset knowledge sources', 'knowledge sources available', 'sources available .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['flexible control', 'recendy', 'knowledge'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['sever', 'propos', 'flexibl', 'control', 'structur', 'made', 'recendi', ',', 'cover', 'subset', 'knowledg', 'sourc', 'avail', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['sever', 'propos', 'flexibl', 'control', 'structur', 'made', 'recendi', ',', 'cover', 'subset', 'knowledg', 'sourc', 'avail', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['Several', 'proposal', 'flexible', 'control', 'structure', 'made', 'recendy', ',', 'covering', 'subset', 'knowledge', 'source', 'available', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

174 --> More comprehensive schemes need to be developed. 


 ---- TOKENS ----

 ['More', 'comprehensive', 'schemes', 'need', 'to', 'be', 'developed', '.'] 

 TOTAL TOKENS ==> 8

 ---- POST ----

 [('More', 'RBR'), ('comprehensive', 'JJ'), ('schemes', 'NNS'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('developed', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['comprehensive', 'schemes', 'need', 'developed', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('comprehensive', 'JJ'), ('schemes', 'NNS'), ('need', 'VBP'), ('developed', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['comprehensive schemes', 'schemes need', 'need developed', 'developed .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['comprehensive schemes need', 'schemes need developed', 'need developed .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['comprehens', 'scheme', 'need', 'develop', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['comprehens', 'scheme', 'need', 'develop', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['comprehensive', 'scheme', 'need', 'developed', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

175 --> Two promising approaches are generalization of  unification to NL architectures and use of global, weighted control strategies, as in evidential reasoning. 


 ---- TOKENS ----

 ['Two', 'promising', 'approaches', 'are', 'generalization', 'of', 'unification', 'to', 'NL', 'architectures', 'and', 'use', 'of', 'global', ',', 'weighted', 'control', 'strategies', ',', 'as', 'in', 'evidential', 'reasoning', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Two', 'CD'), ('promising', 'JJ'), ('approaches', 'NNS'), ('are', 'VBP'), ('generalization', 'NN'), ('of', 'IN'), ('unification', 'NN'), ('to', 'TO'), ('NL', 'NNP'), ('architectures', 'NNS'), ('and', 'CC'), ('use', 'NN'), ('of', 'IN'), ('global', 'JJ'), (',', ','), ('weighted', 'JJ'), ('control', 'NN'), ('strategies', 'NNS'), (',', ','), ('as', 'IN'), ('in', 'IN'), ('evidential', 'JJ'), ('reasoning', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Two', 'promising', 'approaches', 'generalization', 'unification', 'NL', 'architectures', 'use', 'global', ',', 'weighted', 'control', 'strategies', ',', 'evidential', 'reasoning', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Two', 'CD'), ('promising', 'JJ'), ('approaches', 'NNS'), ('generalization', 'NN'), ('unification', 'NN'), ('NL', 'NNP'), ('architectures', 'VBZ'), ('use', 'NN'), ('global', 'JJ'), (',', ','), ('weighted', 'JJ'), ('control', 'NN'), ('strategies', 'NNS'), (',', ','), ('evidential', 'JJ'), ('reasoning', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Two promising', 'promising approaches', 'approaches generalization', 'generalization unification', 'unification NL', 'NL architectures', 'architectures use', 'use global', 'global ,', ', weighted', 'weighted control', 'control strategies', 'strategies ,', ', evidential', 'evidential reasoning', 'reasoning .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Two promising approaches', 'promising approaches generalization', 'approaches generalization unification', 'generalization unification NL', 'unification NL architectures', 'NL architectures use', 'architectures use global', 'use global ,', 'global , weighted', ', weighted control', 'weighted control strategies', 'control strategies ,', 'strategies , evidential', ', evidential reasoning', 'evidential reasoning .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['generalization', 'unification', 'use', 'weighted control', 'evidential reasoning'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['two', 'promis', 'approach', 'gener', 'unif', 'nl', 'architectur', 'use', 'global', ',', 'weight', 'control', 'strategi', ',', 'evidenti', 'reason', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['two', 'promis', 'approach', 'general', 'unif', 'nl', 'architectur', 'use', 'global', ',', 'weight', 'control', 'strategi', ',', 'evidenti', 'reason', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Two', 'promising', 'approach', 'generalization', 'unification', 'NL', 'architecture', 'use', 'global', ',', 'weighted', 'control', 'strategy', ',', 'evidential', 'reasoning', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

176 --> Improving robustness. 


 ---- TOKENS ----

 ['Improving', 'robustness', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('Improving', 'VBG'), ('robustness', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Improving', 'robustness', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('Improving', 'VBG'), ('robustness', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Improving robustness', 'robustness .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['Improving robustness .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['robustness'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['improv', 'robust', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['improv', 'robust', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['Improving', 'robustness', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

177 --> Published studies suggest that as much as 25 to 30% of typed input contains errors,  is incomplete, uses novel language, or otherwise involves challenging phenomena that are not well handled  theoretically. 


 ---- TOKENS ----

 ['Published', 'studies', 'suggest', 'that', 'as', 'much', 'as', '25', 'to', '30', '%', 'of', 'typed', 'input', 'contains', 'errors', ',', 'is', 'incomplete', ',', 'uses', 'novel', 'language', ',', 'or', 'otherwise', 'involves', 'challenging', 'phenomena', 'that', 'are', 'not', 'well', 'handled', 'theoretically', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('Published', 'VBN'), ('studies', 'NNS'), ('suggest', 'VBP'), ('that', 'IN'), ('as', 'RB'), ('much', 'JJ'), ('as', 'IN'), ('25', 'CD'), ('to', 'TO'), ('30', 'CD'), ('%', 'NN'), ('of', 'IN'), ('typed', 'JJ'), ('input', 'NN'), ('contains', 'NNS'), ('errors', 'NNS'), (',', ','), ('is', 'VBZ'), ('incomplete', 'JJ'), (',', ','), ('uses', 'VBZ'), ('novel', 'JJ'), ('language', 'NN'), (',', ','), ('or', 'CC'), ('otherwise', 'RB'), ('involves', 'VBZ'), ('challenging', 'VBG'), ('phenomena', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('not', 'RB'), ('well', 'RB'), ('handled', 'VBN'), ('theoretically', 'RB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Published', 'studies', 'suggest', 'much', '25', '30', '%', 'typed', 'input', 'contains', 'errors', ',', 'incomplete', ',', 'uses', 'novel', 'language', ',', 'otherwise', 'involves', 'challenging', 'phenomena', 'well', 'handled', 'theoretically', '.']

 TOTAL FILTERED TOKENS ==>  26

 ---- POST FOR FILTERED TOKENS ----

 [('Published', 'VBN'), ('studies', 'NNS'), ('suggest', 'VBP'), ('much', 'RB'), ('25', 'CD'), ('30', 'CD'), ('%', 'NN'), ('typed', 'VBD'), ('input', 'NN'), ('contains', 'NNS'), ('errors', 'NNS'), (',', ','), ('incomplete', 'JJ'), (',', ','), ('uses', 'VBZ'), ('novel', 'JJ'), ('language', 'NN'), (',', ','), ('otherwise', 'RB'), ('involves', 'VBZ'), ('challenging', 'VBG'), ('phenomena', 'RB'), ('well', 'RB'), ('handled', 'VBN'), ('theoretically', 'RB'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Published studies', 'studies suggest', 'suggest much', 'much 25', '25 30', '30 %', '% typed', 'typed input', 'input contains', 'contains errors', 'errors ,', ', incomplete', 'incomplete ,', ', uses', 'uses novel', 'novel language', 'language ,', ', otherwise', 'otherwise involves', 'involves challenging', 'challenging phenomena', 'phenomena well', 'well handled', 'handled theoretically', 'theoretically .'] 

 TOTAL BIGRAMS --> 25 



 ---- TRI-GRAMS ---- 

 ['Published studies suggest', 'studies suggest much', 'suggest much 25', 'much 25 30', '25 30 %', '30 % typed', '% typed input', 'typed input contains', 'input contains errors', 'contains errors ,', 'errors , incomplete', ', incomplete ,', 'incomplete , uses', ', uses novel', 'uses novel language', 'novel language ,', 'language , otherwise', ', otherwise involves', 'otherwise involves challenging', 'involves challenging phenomena', 'challenging phenomena well', 'phenomena well handled', 'well handled theoretically', 'handled theoretically .'] 

 TOTAL TRIGRAMS --> 24 



 ---- NOUN PHRASES ---- 

 ['%', 'input', 'novel language'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['publish', 'studi', 'suggest', 'much', '25', '30', '%', 'type', 'input', 'contain', 'error', ',', 'incomplet', ',', 'use', 'novel', 'languag', ',', 'otherwis', 'involv', 'challeng', 'phenomena', 'well', 'handl', 'theoret', '.']

 TOTAL PORTER STEM WORDS ==> 26



 ---- SNOWBALL STEMMING ----

['publish', 'studi', 'suggest', 'much', '25', '30', '%', 'type', 'input', 'contain', 'error', ',', 'incomplet', ',', 'use', 'novel', 'languag', ',', 'otherwis', 'involv', 'challeng', 'phenomena', 'well', 'handl', 'theoret', '.']

 TOTAL SNOWBALL STEM WORDS ==> 26



 ---- LEMMATIZATION ----

['Published', 'study', 'suggest', 'much', '25', '30', '%', 'typed', 'input', 'contains', 'error', ',', 'incomplete', ',', 'us', 'novel', 'language', ',', 'otherwise', 'involves', 'challenging', 'phenomenon', 'well', 'handled', 'theoretically', '.']

 TOTAL LEMMATIZE WORDS ==> 26

************************************************************************************************************************

178 --> Some experts believe the frequency of occurrence for these classes is even higher in spoken language  than in wntten language. 


 ---- TOKENS ----

 ['Some', 'experts', 'believe', 'the', 'frequency', 'of', 'occurrence', 'for', 'these', 'classes', 'is', 'even', 'higher', 'in', 'spoken', 'language', 'than', 'in', 'wntten', 'language', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Some', 'DT'), ('experts', 'NNS'), ('believe', 'VBP'), ('the', 'DT'), ('frequency', 'NN'), ('of', 'IN'), ('occurrence', 'NN'), ('for', 'IN'), ('these', 'DT'), ('classes', 'NNS'), ('is', 'VBZ'), ('even', 'RB'), ('higher', 'JJR'), ('in', 'IN'), ('spoken', 'JJ'), ('language', 'NN'), ('than', 'IN'), ('in', 'IN'), ('wntten', 'JJ'), ('language', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['experts', 'believe', 'frequency', 'occurrence', 'classes', 'even', 'higher', 'spoken', 'language', 'wntten', 'language', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('experts', 'NNS'), ('believe', 'VBP'), ('frequency', 'NN'), ('occurrence', 'NN'), ('classes', 'NNS'), ('even', 'RB'), ('higher', 'JJR'), ('spoken', 'JJ'), ('language', 'NN'), ('wntten', 'JJ'), ('language', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['experts believe', 'believe frequency', 'frequency occurrence', 'occurrence classes', 'classes even', 'even higher', 'higher spoken', 'spoken language', 'language wntten', 'wntten language', 'language .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['experts believe frequency', 'believe frequency occurrence', 'frequency occurrence classes', 'occurrence classes even', 'classes even higher', 'even higher spoken', 'higher spoken language', 'spoken language wntten', 'language wntten language', 'wntten language .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['frequency', 'occurrence', 'spoken language', 'wntten language'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['expert', 'believ', 'frequenc', 'occurr', 'class', 'even', 'higher', 'spoken', 'languag', 'wntten', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['expert', 'believ', 'frequenc', 'occurr', 'class', 'even', 'higher', 'spoken', 'languag', 'wntten', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['expert', 'believe', 'frequency', 'occurrence', 'class', 'even', 'higher', 'spoken', 'language', 'wntten', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

179 --> The text of some messages, such as Navy RAINFORM and CASREP messages and bank  telexes, is highly telegraphic. 


 ---- TOKENS ----

 ['The', 'text', 'of', 'some', 'messages', ',', 'such', 'as', 'Navy', 'RAINFORM', 'and', 'CASREP', 'messages', 'and', 'bank', 'telexes', ',', 'is', 'highly', 'telegraphic', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('The', 'DT'), ('text', 'NN'), ('of', 'IN'), ('some', 'DT'), ('messages', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('Navy', 'NNP'), ('RAINFORM', 'NNP'), ('and', 'CC'), ('CASREP', 'NNP'), ('messages', 'NNS'), ('and', 'CC'), ('bank', 'NN'), ('telexes', 'NNS'), (',', ','), ('is', 'VBZ'), ('highly', 'RB'), ('telegraphic', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['text', 'messages', ',', 'Navy', 'RAINFORM', 'CASREP', 'messages', 'bank', 'telexes', ',', 'highly', 'telegraphic', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('text', 'NN'), ('messages', 'NNS'), (',', ','), ('Navy', 'NNP'), ('RAINFORM', 'NNP'), ('CASREP', 'NNP'), ('messages', 'NNS'), ('bank', 'NN'), ('telexes', 'NNS'), (',', ','), ('highly', 'RB'), ('telegraphic', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['text messages', 'messages ,', ', Navy', 'Navy RAINFORM', 'RAINFORM CASREP', 'CASREP messages', 'messages bank', 'bank telexes', 'telexes ,', ', highly', 'highly telegraphic', 'telegraphic .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['text messages ,', 'messages , Navy', ', Navy RAINFORM', 'Navy RAINFORM CASREP', 'RAINFORM CASREP messages', 'CASREP messages bank', 'messages bank telexes', 'bank telexes ,', 'telexes , highly', ', highly telegraphic', 'highly telegraphic .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['text', 'bank'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Navy RAINFORM']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['text', 'messag', ',', 'navi', 'rainform', 'casrep', 'messag', 'bank', 'telex', ',', 'highli', 'telegraph', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['text', 'messag', ',', 'navi', 'rainform', 'casrep', 'messag', 'bank', 'telex', ',', 'high', 'telegraph', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['text', 'message', ',', 'Navy', 'RAINFORM', 'CASREP', 'message', 'bank', 'telex', ',', 'highly', 'telegraphic', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

180 --> It should be possible to develop a domain-independent theory that allows at least  partial understanding of some of these novel and errorful uses, and to test it in narrowly defined domains. 


 ---- TOKENS ----

 ['It', 'should', 'be', 'possible', 'to', 'develop', 'a', 'domain-independent', 'theory', 'that', 'allows', 'at', 'least', 'partial', 'understanding', 'of', 'some', 'of', 'these', 'novel', 'and', 'errorful', 'uses', ',', 'and', 'to', 'test', 'it', 'in', 'narrowly', 'defined', 'domains', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('It', 'PRP'), ('should', 'MD'), ('be', 'VB'), ('possible', 'JJ'), ('to', 'TO'), ('develop', 'VB'), ('a', 'DT'), ('domain-independent', 'JJ'), ('theory', 'NN'), ('that', 'WDT'), ('allows', 'VBZ'), ('at', 'IN'), ('least', 'JJS'), ('partial', 'JJ'), ('understanding', 'NN'), ('of', 'IN'), ('some', 'DT'), ('of', 'IN'), ('these', 'DT'), ('novel', 'NNS'), ('and', 'CC'), ('errorful', 'JJ'), ('uses', 'NNS'), (',', ','), ('and', 'CC'), ('to', 'TO'), ('test', 'VB'), ('it', 'PRP'), ('in', 'IN'), ('narrowly', 'RB'), ('defined', 'JJ'), ('domains', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['possible', 'develop', 'domain-independent', 'theory', 'allows', 'least', 'partial', 'understanding', 'novel', 'errorful', 'uses', ',', 'test', 'narrowly', 'defined', 'domains', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('possible', 'JJ'), ('develop', 'VB'), ('domain-independent', 'JJ'), ('theory', 'NN'), ('allows', 'VBZ'), ('least', 'JJS'), ('partial', 'JJ'), ('understanding', 'NN'), ('novel', 'NN'), ('errorful', 'JJ'), ('uses', 'NNS'), (',', ','), ('test', 'NN'), ('narrowly', 'RB'), ('defined', 'VBD'), ('domains', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['possible develop', 'develop domain-independent', 'domain-independent theory', 'theory allows', 'allows least', 'least partial', 'partial understanding', 'understanding novel', 'novel errorful', 'errorful uses', 'uses ,', ', test', 'test narrowly', 'narrowly defined', 'defined domains', 'domains .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['possible develop domain-independent', 'develop domain-independent theory', 'domain-independent theory allows', 'theory allows least', 'allows least partial', 'least partial understanding', 'partial understanding novel', 'understanding novel errorful', 'novel errorful uses', 'errorful uses ,', 'uses , test', ', test narrowly', 'test narrowly defined', 'narrowly defined domains', 'defined domains .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['domain-independent theory', 'partial understanding', 'novel', 'test'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['possibl', 'develop', 'domain-independ', 'theori', 'allow', 'least', 'partial', 'understand', 'novel', 'error', 'use', ',', 'test', 'narrowli', 'defin', 'domain', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['possibl', 'develop', 'domain-independ', 'theori', 'allow', 'least', 'partial', 'understand', 'novel', 'error', 'use', ',', 'test', 'narrowli', 'defin', 'domain', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['possible', 'develop', 'domain-independent', 'theory', 'allows', 'least', 'partial', 'understanding', 'novel', 'errorful', 'us', ',', 'test', 'narrowly', 'defined', 'domain', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

181 --> Promising  approaches are to employ unification strategies, plan recognition, and weighted control strategies to determine the  most likely interpretation and the most appropriate response/action. 


 ---- TOKENS ----

 ['Promising', 'approaches', 'are', 'to', 'employ', 'unification', 'strategies', ',', 'plan', 'recognition', ',', 'and', 'weighted', 'control', 'strategies', 'to', 'determine', 'the', 'most', 'likely', 'interpretation', 'and', 'the', 'most', 'appropriate', 'response/action', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('Promising', 'VBG'), ('approaches', 'NNS'), ('are', 'VBP'), ('to', 'TO'), ('employ', 'VB'), ('unification', 'NN'), ('strategies', 'NNS'), (',', ','), ('plan', 'NN'), ('recognition', 'NN'), (',', ','), ('and', 'CC'), ('weighted', 'VBD'), ('control', 'NN'), ('strategies', 'NNS'), ('to', 'TO'), ('determine', 'VB'), ('the', 'DT'), ('most', 'RBS'), ('likely', 'JJ'), ('interpretation', 'NN'), ('and', 'CC'), ('the', 'DT'), ('most', 'RBS'), ('appropriate', 'JJ'), ('response/action', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Promising', 'approaches', 'employ', 'unification', 'strategies', ',', 'plan', 'recognition', ',', 'weighted', 'control', 'strategies', 'determine', 'likely', 'interpretation', 'appropriate', 'response/action', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Promising', 'VBG'), ('approaches', 'NNS'), ('employ', 'JJ'), ('unification', 'NN'), ('strategies', 'NNS'), (',', ','), ('plan', 'NN'), ('recognition', 'NN'), (',', ','), ('weighted', 'VBD'), ('control', 'NN'), ('strategies', 'NNS'), ('determine', 'VBP'), ('likely', 'JJ'), ('interpretation', 'NN'), ('appropriate', 'JJ'), ('response/action', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Promising approaches', 'approaches employ', 'employ unification', 'unification strategies', 'strategies ,', ', plan', 'plan recognition', 'recognition ,', ', weighted', 'weighted control', 'control strategies', 'strategies determine', 'determine likely', 'likely interpretation', 'interpretation appropriate', 'appropriate response/action', 'response/action .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Promising approaches employ', 'approaches employ unification', 'employ unification strategies', 'unification strategies ,', 'strategies , plan', ', plan recognition', 'plan recognition ,', 'recognition , weighted', ', weighted control', 'weighted control strategies', 'control strategies determine', 'strategies determine likely', 'determine likely interpretation', 'likely interpretation appropriate', 'interpretation appropriate response/action', 'appropriate response/action .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['employ unification', 'plan', 'recognition', 'control', 'likely interpretation', 'appropriate response'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['promis', 'approach', 'employ', 'unif', 'strategi', ',', 'plan', 'recognit', ',', 'weight', 'control', 'strategi', 'determin', 'like', 'interpret', 'appropri', 'response/act', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['promis', 'approach', 'employ', 'unif', 'strategi', ',', 'plan', 'recognit', ',', 'weight', 'control', 'strategi', 'determin', 'like', 'interpret', 'appropri', 'response/act', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Promising', 'approach', 'employ', 'unification', 'strategy', ',', 'plan', 'recognition', ',', 'weighted', 'control', 'strategy', 'determine', 'likely', 'interpretation', 'appropriate', 'response/action', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

182 --> Explonng ~ relationship between linguistic and conceptual knowledge. 


 ---- TOKENS ----

 ['Explonng', '~', 'relationship', 'between', 'linguistic', 'and', 'conceptual', 'knowledge', '.'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('Explonng', 'NNP'), ('~', 'NNP'), ('relationship', 'NN'), ('between', 'IN'), ('linguistic', 'JJ'), ('and', 'CC'), ('conceptual', 'JJ'), ('knowledge', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Explonng', '~', 'relationship', 'linguistic', 'conceptual', 'knowledge', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('Explonng', 'NNP'), ('~', 'NNP'), ('relationship', 'NN'), ('linguistic', 'JJ'), ('conceptual', 'JJ'), ('knowledge', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Explonng ~', '~ relationship', 'relationship linguistic', 'linguistic conceptual', 'conceptual knowledge', 'knowledge .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['Explonng ~ relationship', '~ relationship linguistic', 'relationship linguistic conceptual', 'linguistic conceptual knowledge', 'conceptual knowledge .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['relationship', 'linguistic conceptual knowledge'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Explonng']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['explonng', '~', 'relationship', 'linguist', 'conceptu', 'knowledg', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['explonng', '~', 'relationship', 'linguist', 'conceptu', 'knowledg', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['Explonng', '~', 'relationship', 'linguistic', 'conceptual', 'knowledge', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

183 --> Use and interpretation of  metaphor illustrates a prevalent relationship between linguistic and conceptual knowledge. 


 ---- TOKENS ----

 ['Use', 'and', 'interpretation', 'of', 'metaphor', 'illustrates', 'a', 'prevalent', 'relationship', 'between', 'linguistic', 'and', 'conceptual', 'knowledge', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('Use', 'NNP'), ('and', 'CC'), ('interpretation', 'NN'), ('of', 'IN'), ('metaphor', 'NN'), ('illustrates', 'VBZ'), ('a', 'DT'), ('prevalent', 'NN'), ('relationship', 'NN'), ('between', 'IN'), ('linguistic', 'JJ'), ('and', 'CC'), ('conceptual', 'JJ'), ('knowledge', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Use', 'interpretation', 'metaphor', 'illustrates', 'prevalent', 'relationship', 'linguistic', 'conceptual', 'knowledge', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Use', 'NNP'), ('interpretation', 'NN'), ('metaphor', 'NN'), ('illustrates', 'VBZ'), ('prevalent', 'JJ'), ('relationship', 'NN'), ('linguistic', 'JJ'), ('conceptual', 'JJ'), ('knowledge', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Use interpretation', 'interpretation metaphor', 'metaphor illustrates', 'illustrates prevalent', 'prevalent relationship', 'relationship linguistic', 'linguistic conceptual', 'conceptual knowledge', 'knowledge .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Use interpretation metaphor', 'interpretation metaphor illustrates', 'metaphor illustrates prevalent', 'illustrates prevalent relationship', 'prevalent relationship linguistic', 'relationship linguistic conceptual', 'linguistic conceptual knowledge', 'conceptual knowledge .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['interpretation', 'metaphor', 'prevalent relationship', 'linguistic conceptual knowledge'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Use']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['use', 'interpret', 'metaphor', 'illustr', 'preval', 'relationship', 'linguist', 'conceptu', 'knowledg', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['use', 'interpret', 'metaphor', 'illustr', 'preval', 'relationship', 'linguist', 'conceptu', 'knowledg', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Use', 'interpretation', 'metaphor', 'illustrates', 'prevalent', 'relationship', 'linguistic', 'conceptual', 'knowledge', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

184 --> For example, there is  obvious systematicity in the use of expressions like "kill the engine" and "my engine died" which extends to other  domains ("kill that process" and "my  process died"). 


 ---- TOKENS ----

 ['For', 'example', ',', 'there', 'is', 'obvious', 'systematicity', 'in', 'the', 'use', 'of', 'expressions', 'like', '``', 'kill', 'the', 'engine', "''", 'and', '``', 'my', 'engine', 'died', "''", 'which', 'extends', 'to', 'other', 'domains', '(', '``', 'kill', 'that', 'process', "''", 'and', '``', 'my', 'process', 'died', "''", ')', '.'] 

 TOTAL TOKENS ==> 43

 ---- POST ----

 [('For', 'IN'), ('example', 'NN'), (',', ','), ('there', 'EX'), ('is', 'VBZ'), ('obvious', 'JJ'), ('systematicity', 'NN'), ('in', 'IN'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('expressions', 'NNS'), ('like', 'IN'), ('``', '``'), ('kill', 'VB'), ('the', 'DT'), ('engine', 'NN'), ("''", "''"), ('and', 'CC'), ('``', '``'), ('my', 'PRP$'), ('engine', 'NN'), ('died', 'VBD'), ("''", "''"), ('which', 'WDT'), ('extends', 'VBZ'), ('to', 'TO'), ('other', 'JJ'), ('domains', 'NNS'), ('(', '('), ('``', '``'), ('kill', 'VB'), ('that', 'DT'), ('process', 'NN'), ("''", "''"), ('and', 'CC'), ('``', '``'), ('my', 'PRP$'), ('process', 'NN'), ('died', 'VBD'), ("''", "''"), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['example', ',', 'obvious', 'systematicity', 'use', 'expressions', 'like', '``', 'kill', 'engine', "''", '``', 'engine', 'died', "''", 'extends', 'domains', '(', '``', 'kill', 'process', "''", '``', 'process', 'died', "''", ')', '.']

 TOTAL FILTERED TOKENS ==>  28

 ---- POST FOR FILTERED TOKENS ----

 [('example', 'NN'), (',', ','), ('obvious', 'JJ'), ('systematicity', 'NN'), ('use', 'VBP'), ('expressions', 'NNS'), ('like', 'IN'), ('``', '``'), ('kill', 'FW'), ('engine', 'NN'), ("''", "''"), ('``', '``'), ('engine', 'NN'), ('died', 'VBD'), ("''", "''"), ('extends', 'VBZ'), ('domains', 'NNS'), ('(', '('), ('``', '``'), ('kill', 'VB'), ('process', 'NN'), ("''", "''"), ('``', '``'), ('process', 'NN'), ('died', 'VBD'), ("''", "''"), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['example ,', ', obvious', 'obvious systematicity', 'systematicity use', 'use expressions', 'expressions like', 'like ``', '`` kill', 'kill engine', "engine ''", "'' ``", '`` engine', 'engine died', "died ''", "'' extends", 'extends domains', 'domains (', '( ``', '`` kill', 'kill process', "process ''", "'' ``", '`` process', 'process died', "died ''", "'' )", ') .'] 

 TOTAL BIGRAMS --> 27 



 ---- TRI-GRAMS ---- 

 ['example , obvious', ', obvious systematicity', 'obvious systematicity use', 'systematicity use expressions', 'use expressions like', 'expressions like ``', 'like `` kill', '`` kill engine', "kill engine ''", "engine '' ``", "'' `` engine", '`` engine died', "engine died ''", "died '' extends", "'' extends domains", 'extends domains (', 'domains ( ``', '( `` kill', '`` kill process', "kill process ''", "process '' ``", "'' `` process", '`` process died', "process died ''", "died '' )", "'' ) ."] 

 TOTAL TRIGRAMS --> 26 



 ---- NOUN PHRASES ---- 

 ['example', 'obvious systematicity', 'engine', 'engine'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['exampl', ',', 'obviou', 'systemat', 'use', 'express', 'like', '``', 'kill', 'engin', "''", '``', 'engin', 'die', "''", 'extend', 'domain', '(', '``', 'kill', 'process', "''", '``', 'process', 'die', "''", ')', '.']

 TOTAL PORTER STEM WORDS ==> 28



 ---- SNOWBALL STEMMING ----

['exampl', ',', 'obvious', 'systemat', 'use', 'express', 'like', '``', 'kill', 'engin', "''", '``', 'engin', 'die', "''", 'extend', 'domain', '(', '``', 'kill', 'process', "''", '``', 'process', 'die', "''", ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 28



 ---- LEMMATIZATION ----

['example', ',', 'obvious', 'systematicity', 'use', 'expression', 'like', '``', 'kill', 'engine', "''", '``', 'engine', 'died', "''", 'extends', 'domain', '(', '``', 'kill', 'process', "''", '``', 'process', 'died', "''", ')', '.']

 TOTAL LEMMATIZE WORDS ==> 28

************************************************************************************************************************

185 --> An understanding of such issues has been shown in the lab  to be effective for language learning, where such regularities have been effectively exploited to learn extended word  meanings. 


 ---- TOKENS ----

 ['An', 'understanding', 'of', 'such', 'issues', 'has', 'been', 'shown', 'in', 'the', 'lab', 'to', 'be', 'effective', 'for', 'language', 'learning', ',', 'where', 'such', 'regularities', 'have', 'been', 'effectively', 'exploited', 'to', 'learn', 'extended', 'word', 'meanings', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('An', 'DT'), ('understanding', 'NN'), ('of', 'IN'), ('such', 'JJ'), ('issues', 'NNS'), ('has', 'VBZ'), ('been', 'VBN'), ('shown', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('lab', 'NN'), ('to', 'TO'), ('be', 'VB'), ('effective', 'JJ'), ('for', 'IN'), ('language', 'NN'), ('learning', 'NN'), (',', ','), ('where', 'WRB'), ('such', 'JJ'), ('regularities', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('effectively', 'RB'), ('exploited', 'VBN'), ('to', 'TO'), ('learn', 'VB'), ('extended', 'JJ'), ('word', 'NN'), ('meanings', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['understanding', 'issues', 'shown', 'lab', 'effective', 'language', 'learning', ',', 'regularities', 'effectively', 'exploited', 'learn', 'extended', 'word', 'meanings', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('understanding', 'VBG'), ('issues', 'NNS'), ('shown', 'VBN'), ('lab', 'JJ'), ('effective', 'JJ'), ('language', 'NN'), ('learning', 'NN'), (',', ','), ('regularities', 'NNS'), ('effectively', 'RB'), ('exploited', 'VBD'), ('learn', 'NN'), ('extended', 'VBN'), ('word', 'NN'), ('meanings', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['understanding issues', 'issues shown', 'shown lab', 'lab effective', 'effective language', 'language learning', 'learning ,', ', regularities', 'regularities effectively', 'effectively exploited', 'exploited learn', 'learn extended', 'extended word', 'word meanings', 'meanings .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['understanding issues shown', 'issues shown lab', 'shown lab effective', 'lab effective language', 'effective language learning', 'language learning ,', 'learning , regularities', ', regularities effectively', 'regularities effectively exploited', 'effectively exploited learn', 'exploited learn extended', 'learn extended word', 'extended word meanings', 'word meanings .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['lab effective language', 'learning', 'learn', 'word'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['understand', 'issu', 'shown', 'lab', 'effect', 'languag', 'learn', ',', 'regular', 'effect', 'exploit', 'learn', 'extend', 'word', 'mean', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['understand', 'issu', 'shown', 'lab', 'effect', 'languag', 'learn', ',', 'regular', 'effect', 'exploit', 'learn', 'extend', 'word', 'mean', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['understanding', 'issue', 'shown', 'lab', 'effective', 'language', 'learning', ',', 'regularity', 'effectively', 'exploited', 'learn', 'extended', 'word', 'meaning', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

186 --> A domain-independent theory of the relationship could he developed and tested. 


 ---- TOKENS ----

 ['A', 'domain-independent', 'theory', 'of', 'the', 'relationship', 'could', 'he', 'developed', 'and', 'tested', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('A', 'DT'), ('domain-independent', 'JJ'), ('theory', 'NN'), ('of', 'IN'), ('the', 'DT'), ('relationship', 'NN'), ('could', 'MD'), ('he', 'PRP'), ('developed', 'VBD'), ('and', 'CC'), ('tested', 'VBD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['domain-independent', 'theory', 'relationship', 'could', 'developed', 'tested', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('domain-independent', 'JJ'), ('theory', 'NN'), ('relationship', 'NN'), ('could', 'MD'), ('developed', 'VB'), ('tested', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['domain-independent theory', 'theory relationship', 'relationship could', 'could developed', 'developed tested', 'tested .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['domain-independent theory relationship', 'theory relationship could', 'relationship could developed', 'could developed tested', 'developed tested .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['domain-independent theory', 'relationship'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['domain-independ', 'theori', 'relationship', 'could', 'develop', 'test', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['domain-independ', 'theori', 'relationship', 'could', 'develop', 'test', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['domain-independent', 'theory', 'relationship', 'could', 'developed', 'tested', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

187 --> Relating interpretation and action. 


 ---- TOKENS ----

 ['Relating', 'interpretation', 'and', 'action', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('Relating', 'VBG'), ('interpretation', 'NN'), ('and', 'CC'), ('action', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Relating', 'interpretation', 'action', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('Relating', 'VBG'), ('interpretation', 'NN'), ('action', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Relating interpretation', 'interpretation action', 'action .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['Relating interpretation action', 'interpretation action .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 ['interpretation', 'action'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['relat', 'interpret', 'action', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['relat', 'interpret', 'action', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['Relating', 'interpretation', 'action', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

188 --> The problem of how to relate interpretations expressed in an MRL and  calls to application systems (databases, summarizing algorithms, etc.) 


 ---- TOKENS ----

 ['The', 'problem', 'of', 'how', 'to', 'relate', 'interpretations', 'expressed', 'in', 'an', 'MRL', 'and', 'calls', 'to', 'application', 'systems', '(', 'databases', ',', 'summarizing', 'algorithms', ',', 'etc', '.', ')'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('The', 'DT'), ('problem', 'NN'), ('of', 'IN'), ('how', 'WRB'), ('to', 'TO'), ('relate', 'VB'), ('interpretations', 'NNS'), ('expressed', 'VBN'), ('in', 'IN'), ('an', 'DT'), ('MRL', 'NNP'), ('and', 'CC'), ('calls', 'VBZ'), ('to', 'TO'), ('application', 'VB'), ('systems', 'NNS'), ('(', '('), ('databases', 'NNS'), (',', ','), ('summarizing', 'VBG'), ('algorithms', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['problem', 'relate', 'interpretations', 'expressed', 'MRL', 'calls', 'application', 'systems', '(', 'databases', ',', 'summarizing', 'algorithms', ',', 'etc', '.', ')']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('problem', 'NN'), ('relate', 'NN'), ('interpretations', 'NNS'), ('expressed', 'VBD'), ('MRL', 'NNP'), ('calls', 'VBZ'), ('application', 'NN'), ('systems', 'NNS'), ('(', '('), ('databases', 'NNS'), (',', ','), ('summarizing', 'VBG'), ('algorithms', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')')] 



 ---- BI-GRAMS ---- 

 ['problem relate', 'relate interpretations', 'interpretations expressed', 'expressed MRL', 'MRL calls', 'calls application', 'application systems', 'systems (', '( databases', 'databases ,', ', summarizing', 'summarizing algorithms', 'algorithms ,', ', etc', 'etc .', '. )'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['problem relate interpretations', 'relate interpretations expressed', 'interpretations expressed MRL', 'expressed MRL calls', 'MRL calls application', 'calls application systems', 'application systems (', 'systems ( databases', '( databases ,', 'databases , summarizing', ', summarizing algorithms', 'summarizing algorithms ,', 'algorithms , etc', ', etc .', 'etc . )'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['problem', 'relate', 'application'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['MRL']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['problem', 'relat', 'interpret', 'express', 'mrl', 'call', 'applic', 'system', '(', 'databas', ',', 'summar', 'algorithm', ',', 'etc', '.', ')']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['problem', 'relat', 'interpret', 'express', 'mrl', 'call', 'applic', 'system', '(', 'databas', ',', 'summar', 'algorithm', ',', 'etc', '.', ')']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['problem', 'relate', 'interpretation', 'expressed', 'MRL', 'call', 'application', 'system', '(', 'database', ',', 'summarizing', 'algorithm', ',', 'etc', '.', ')']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

189 --> has not been fully resolved, or in fact  precisely stated. 


 ---- TOKENS ----

 ['has', 'not', 'been', 'fully', 'resolved', ',', 'or', 'in', 'fact', 'precisely', 'stated', '.'] 

 TOTAL TOKENS ==> 12

 ---- POST ----

 [('has', 'VBZ'), ('not', 'RB'), ('been', 'VBN'), ('fully', 'RB'), ('resolved', 'VBN'), (',', ','), ('or', 'CC'), ('in', 'IN'), ('fact', 'NN'), ('precisely', 'RB'), ('stated', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['fully', 'resolved', ',', 'fact', 'precisely', 'stated', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('fully', 'RB'), ('resolved', 'VBN'), (',', ','), ('fact', 'NN'), ('precisely', 'RB'), ('stated', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['fully resolved', 'resolved ,', ', fact', 'fact precisely', 'precisely stated', 'stated .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['fully resolved ,', 'resolved , fact', ', fact precisely', 'fact precisely stated', 'precisely stated .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['fact'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['fulli', 'resolv', ',', 'fact', 'precis', 'state', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['fulli', 'resolv', ',', 'fact', 'precis', 'state', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['fully', 'resolved', ',', 'fact', 'precisely', 'stated', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

190 --> Resolving this relationship is crucial to the systematic separation of the natural language part of the  system from the application part. 


 ---- TOKENS ----

 ['Resolving', 'this', 'relationship', 'is', 'crucial', 'to', 'the', 'systematic', 'separation', 'of', 'the', 'natural', 'language', 'part', 'of', 'the', 'system', 'from', 'the', 'application', 'part', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Resolving', 'VBG'), ('this', 'DT'), ('relationship', 'NN'), ('is', 'VBZ'), ('crucial', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('systematic', 'JJ'), ('separation', 'NN'), ('of', 'IN'), ('the', 'DT'), ('natural', 'JJ'), ('language', 'NN'), ('part', 'NN'), ('of', 'IN'), ('the', 'DT'), ('system', 'NN'), ('from', 'IN'), ('the', 'DT'), ('application', 'NN'), ('part', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Resolving', 'relationship', 'crucial', 'systematic', 'separation', 'natural', 'language', 'part', 'system', 'application', 'part', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Resolving', 'VBG'), ('relationship', 'NN'), ('crucial', 'JJ'), ('systematic', 'JJ'), ('separation', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('part', 'NN'), ('system', 'NN'), ('application', 'NN'), ('part', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Resolving relationship', 'relationship crucial', 'crucial systematic', 'systematic separation', 'separation natural', 'natural language', 'language part', 'part system', 'system application', 'application part', 'part .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Resolving relationship crucial', 'relationship crucial systematic', 'crucial systematic separation', 'systematic separation natural', 'separation natural language', 'natural language part', 'language part system', 'part system application', 'system application part', 'application part .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['relationship', 'crucial systematic separation', 'natural language', 'part', 'system', 'application', 'part'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['resolv', 'relationship', 'crucial', 'systemat', 'separ', 'natur', 'languag', 'part', 'system', 'applic', 'part', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['resolv', 'relationship', 'crucial', 'systemat', 'separ', 'natur', 'languag', 'part', 'system', 'applic', 'part', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Resolving', 'relationship', 'crucial', 'systematic', 'separation', 'natural', 'language', 'part', 'system', 'application', 'part', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

191 --> Any approach should deal with applications beyond databases (beyond the  semantics of tables) and should avoid the challenges of automatic programming. 


 ---- TOKENS ----

 ['Any', 'approach', 'should', 'deal', 'with', 'applications', 'beyond', 'databases', '(', 'beyond', 'the', 'semantics', 'of', 'tables', ')', 'and', 'should', 'avoid', 'the', 'challenges', 'of', 'automatic', 'programming', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Any', 'DT'), ('approach', 'NN'), ('should', 'MD'), ('deal', 'VB'), ('with', 'IN'), ('applications', 'NNS'), ('beyond', 'IN'), ('databases', 'NNS'), ('(', '('), ('beyond', 'IN'), ('the', 'DT'), ('semantics', 'NNS'), ('of', 'IN'), ('tables', 'NNS'), (')', ')'), ('and', 'CC'), ('should', 'MD'), ('avoid', 'VB'), ('the', 'DT'), ('challenges', 'NNS'), ('of', 'IN'), ('automatic', 'JJ'), ('programming', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['approach', 'deal', 'applications', 'beyond', 'databases', '(', 'beyond', 'semantics', 'tables', ')', 'avoid', 'challenges', 'automatic', 'programming', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('approach', 'NN'), ('deal', 'NN'), ('applications', 'NNS'), ('beyond', 'IN'), ('databases', 'NNS'), ('(', '('), ('beyond', 'IN'), ('semantics', 'NNS'), ('tables', 'NNS'), (')', ')'), ('avoid', 'VBP'), ('challenges', 'VBZ'), ('automatic', 'JJ'), ('programming', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['approach deal', 'deal applications', 'applications beyond', 'beyond databases', 'databases (', '( beyond', 'beyond semantics', 'semantics tables', 'tables )', ') avoid', 'avoid challenges', 'challenges automatic', 'automatic programming', 'programming .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['approach deal applications', 'deal applications beyond', 'applications beyond databases', 'beyond databases (', 'databases ( beyond', '( beyond semantics', 'beyond semantics tables', 'semantics tables )', 'tables ) avoid', ') avoid challenges', 'avoid challenges automatic', 'challenges automatic programming', 'automatic programming .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['approach', 'deal', 'automatic programming'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['approach', 'deal', 'applic', 'beyond', 'databas', '(', 'beyond', 'semant', 'tabl', ')', 'avoid', 'challeng', 'automat', 'program', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['approach', 'deal', 'applic', 'beyond', 'databas', '(', 'beyond', 'semant', 'tabl', ')', 'avoid', 'challeng', 'automat', 'program', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['approach', 'deal', 'application', 'beyond', 'database', '(', 'beyond', 'semantics', 'table', ')', 'avoid', 'challenge', 'automatic', 'programming', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

192 --> Finding the relationship between prosody, syntactic ambiguity, and discourse structure. 


 ---- TOKENS ----

 ['Finding', 'the', 'relationship', 'between', 'prosody', ',', 'syntactic', 'ambiguity', ',', 'and', 'discourse', 'structure', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Finding', 'VBG'), ('the', 'DT'), ('relationship', 'NN'), ('between', 'IN'), ('prosody', 'NN'), (',', ','), ('syntactic', 'JJ'), ('ambiguity', 'NN'), (',', ','), ('and', 'CC'), ('discourse', 'JJ'), ('structure', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Finding', 'relationship', 'prosody', ',', 'syntactic', 'ambiguity', ',', 'discourse', 'structure', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Finding', 'VBG'), ('relationship', 'NN'), ('prosody', 'NN'), (',', ','), ('syntactic', 'JJ'), ('ambiguity', 'NN'), (',', ','), ('discourse', 'JJ'), ('structure', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Finding relationship', 'relationship prosody', 'prosody ,', ', syntactic', 'syntactic ambiguity', 'ambiguity ,', ', discourse', 'discourse structure', 'structure .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Finding relationship prosody', 'relationship prosody ,', 'prosody , syntactic', ', syntactic ambiguity', 'syntactic ambiguity ,', 'ambiguity , discourse', ', discourse structure', 'discourse structure .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['relationship', 'prosody', 'syntactic ambiguity', 'discourse structure'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['find', 'relationship', 'prosodi', ',', 'syntact', 'ambigu', ',', 'discours', 'structur', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['find', 'relationship', 'prosodi', ',', 'syntact', 'ambigu', ',', 'discours', 'structur', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Finding', 'relationship', 'prosody', ',', 'syntactic', 'ambiguity', ',', 'discourse', 'structure', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

193 --> Syntactic and  discourse boundaries are one of the main sources of interpretation ambiguity. 


 ---- TOKENS ----

 ['Syntactic', 'and', 'discourse', 'boundaries', 'are', 'one', 'of', 'the', 'main', 'sources', 'of', 'interpretation', 'ambiguity', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Syntactic', 'JJ'), ('and', 'CC'), ('discourse', 'JJ'), ('boundaries', 'NNS'), ('are', 'VBP'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('main', 'JJ'), ('sources', 'NNS'), ('of', 'IN'), ('interpretation', 'NN'), ('ambiguity', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Syntactic', 'discourse', 'boundaries', 'one', 'main', 'sources', 'interpretation', 'ambiguity', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Syntactic', 'JJ'), ('discourse', 'NN'), ('boundaries', 'NNS'), ('one', 'CD'), ('main', 'JJ'), ('sources', 'NNS'), ('interpretation', 'NN'), ('ambiguity', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Syntactic discourse', 'discourse boundaries', 'boundaries one', 'one main', 'main sources', 'sources interpretation', 'interpretation ambiguity', 'ambiguity .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Syntactic discourse boundaries', 'discourse boundaries one', 'boundaries one main', 'one main sources', 'main sources interpretation', 'sources interpretation ambiguity', 'interpretation ambiguity .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['Syntactic discourse', 'interpretation', 'ambiguity'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Syntactic']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['syntact', 'discours', 'boundari', 'one', 'main', 'sourc', 'interpret', 'ambigu', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['syntact', 'discours', 'boundari', 'one', 'main', 'sourc', 'interpret', 'ambigu', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Syntactic', 'discourse', 'boundary', 'one', 'main', 'source', 'interpretation', 'ambiguity', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

194 --> Recently discovered evidence shows  that prosodic information is a good indicator of these boundaries. 


 ---- TOKENS ----

 ['Recently', 'discovered', 'evidence', 'shows', 'that', 'prosodic', 'information', 'is', 'a', 'good', 'indicator', 'of', 'these', 'boundaries', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('Recently', 'RB'), ('discovered', 'VBD'), ('evidence', 'NN'), ('shows', 'NNS'), ('that', 'WDT'), ('prosodic', 'VBP'), ('information', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('indicator', 'NN'), ('of', 'IN'), ('these', 'DT'), ('boundaries', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Recently', 'discovered', 'evidence', 'shows', 'prosodic', 'information', 'good', 'indicator', 'boundaries', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Recently', 'RB'), ('discovered', 'VBD'), ('evidence', 'NN'), ('shows', 'NNS'), ('prosodic', 'JJ'), ('information', 'NN'), ('good', 'JJ'), ('indicator', 'NN'), ('boundaries', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Recently discovered', 'discovered evidence', 'evidence shows', 'shows prosodic', 'prosodic information', 'information good', 'good indicator', 'indicator boundaries', 'boundaries .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Recently discovered evidence', 'discovered evidence shows', 'evidence shows prosodic', 'shows prosodic information', 'prosodic information good', 'information good indicator', 'good indicator boundaries', 'indicator boundaries .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['evidence', 'prosodic information', 'good indicator'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['recent', 'discov', 'evid', 'show', 'prosod', 'inform', 'good', 'indic', 'boundari', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['recent', 'discov', 'evid', 'show', 'prosod', 'inform', 'good', 'indic', 'boundari', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Recently', 'discovered', 'evidence', 'show', 'prosodic', 'information', 'good', 'indicator', 'boundary', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

195 --> Automatic extraction of prosodic information  would revolutionize the interpretation of spoken language. 


 ---- TOKENS ----

 ['Automatic', 'extraction', 'of', 'prosodic', 'information', 'would', 'revolutionize', 'the', 'interpretation', 'of', 'spoken', 'language', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Automatic', 'JJ'), ('extraction', 'NN'), ('of', 'IN'), ('prosodic', 'JJ'), ('information', 'NN'), ('would', 'MD'), ('revolutionize', 'VB'), ('the', 'DT'), ('interpretation', 'NN'), ('of', 'IN'), ('spoken', 'JJ'), ('language', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Automatic', 'extraction', 'prosodic', 'information', 'would', 'revolutionize', 'interpretation', 'spoken', 'language', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Automatic', 'JJ'), ('extraction', 'NN'), ('prosodic', 'JJ'), ('information', 'NN'), ('would', 'MD'), ('revolutionize', 'VB'), ('interpretation', 'NN'), ('spoken', 'VBN'), ('language', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Automatic extraction', 'extraction prosodic', 'prosodic information', 'information would', 'would revolutionize', 'revolutionize interpretation', 'interpretation spoken', 'spoken language', 'language .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Automatic extraction prosodic', 'extraction prosodic information', 'prosodic information would', 'information would revolutionize', 'would revolutionize interpretation', 'revolutionize interpretation spoken', 'interpretation spoken language', 'spoken language .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['Automatic extraction', 'prosodic information', 'interpretation', 'language'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Automatic']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['automat', 'extract', 'prosod', 'inform', 'would', 'revolution', 'interpret', 'spoken', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['automat', 'extract', 'prosod', 'inform', 'would', 'revolution', 'interpret', 'spoken', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Automatic', 'extraction', 'prosodic', 'information', 'would', 'revolutionize', 'interpretation', 'spoken', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

196 --> Further, generation systems could add prosodic  information to signal syntactic structure and discourse structure,  Facilitating leverage tltrough shared resources. 


 ---- TOKENS ----

 ['Further', ',', 'generation', 'systems', 'could', 'add', 'prosodic', 'information', 'to', 'signal', 'syntactic', 'structure', 'and', 'discourse', 'structure', ',', 'Facilitating', 'leverage', 'tltrough', 'shared', 'resources', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Further', 'RB'), (',', ','), ('generation', 'NN'), ('systems', 'NNS'), ('could', 'MD'), ('add', 'VB'), ('prosodic', 'JJ'), ('information', 'NN'), ('to', 'TO'), ('signal', 'VB'), ('syntactic', 'JJ'), ('structure', 'NN'), ('and', 'CC'), ('discourse', 'NN'), ('structure', 'NN'), (',', ','), ('Facilitating', 'NNP'), ('leverage', 'NN'), ('tltrough', 'RB'), ('shared', 'VBD'), ('resources', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 [',', 'generation', 'systems', 'could', 'add', 'prosodic', 'information', 'signal', 'syntactic', 'structure', 'discourse', 'structure', ',', 'Facilitating', 'leverage', 'tltrough', 'shared', 'resources', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [(',', ','), ('generation', 'NN'), ('systems', 'NNS'), ('could', 'MD'), ('add', 'VB'), ('prosodic', 'JJ'), ('information', 'NN'), ('signal', 'JJ'), ('syntactic', 'JJ'), ('structure', 'NN'), ('discourse', 'NN'), ('structure', 'NN'), (',', ','), ('Facilitating', 'NNP'), ('leverage', 'NN'), ('tltrough', 'RB'), ('shared', 'VBD'), ('resources', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 [', generation', 'generation systems', 'systems could', 'could add', 'add prosodic', 'prosodic information', 'information signal', 'signal syntactic', 'syntactic structure', 'structure discourse', 'discourse structure', 'structure ,', ', Facilitating', 'Facilitating leverage', 'leverage tltrough', 'tltrough shared', 'shared resources', 'resources .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 [', generation systems', 'generation systems could', 'systems could add', 'could add prosodic', 'add prosodic information', 'prosodic information signal', 'information signal syntactic', 'signal syntactic structure', 'syntactic structure discourse', 'structure discourse structure', 'discourse structure ,', 'structure , Facilitating', ', Facilitating leverage', 'Facilitating leverage tltrough', 'leverage tltrough shared', 'tltrough shared resources', 'shared resources .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['generation', 'prosodic information', 'signal syntactic structure', 'discourse', 'structure', 'leverage'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

[',', 'gener', 'system', 'could', 'add', 'prosod', 'inform', 'signal', 'syntact', 'structur', 'discours', 'structur', ',', 'facilit', 'leverag', 'tltrough', 'share', 'resourc', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

[',', 'generat', 'system', 'could', 'add', 'prosod', 'inform', 'signal', 'syntact', 'structur', 'discours', 'structur', ',', 'facilit', 'leverag', 'tltrough', 'share', 'resourc', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

[',', 'generation', 'system', 'could', 'add', 'prosodic', 'information', 'signal', 'syntactic', 'structure', 'discourse', 'structure', ',', 'Facilitating', 'leverage', 'tltrough', 'shared', 'resource', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

197 --> To address the problem of lack of leverage, several  projects could be funded to support efforts throughout a significant portion of the community. 


 ---- TOKENS ----

 ['To', 'address', 'the', 'problem', 'of', 'lack', 'of', 'leverage', ',', 'several', 'projects', 'could', 'be', 'funded', 'to', 'support', 'efforts', 'throughout', 'a', 'significant', 'portion', 'of', 'the', 'community', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('To', 'TO'), ('address', 'VB'), ('the', 'DT'), ('problem', 'NN'), ('of', 'IN'), ('lack', 'NN'), ('of', 'IN'), ('leverage', 'NN'), (',', ','), ('several', 'JJ'), ('projects', 'NNS'), ('could', 'MD'), ('be', 'VB'), ('funded', 'VBN'), ('to', 'TO'), ('support', 'VB'), ('efforts', 'NNS'), ('throughout', 'IN'), ('a', 'DT'), ('significant', 'JJ'), ('portion', 'NN'), ('of', 'IN'), ('the', 'DT'), ('community', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['address', 'problem', 'lack', 'leverage', ',', 'several', 'projects', 'could', 'funded', 'support', 'efforts', 'throughout', 'significant', 'portion', 'community', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('address', 'NN'), ('problem', 'NN'), ('lack', 'NN'), ('leverage', 'NN'), (',', ','), ('several', 'JJ'), ('projects', 'NNS'), ('could', 'MD'), ('funded', 'VB'), ('support', 'NN'), ('efforts', 'NNS'), ('throughout', 'IN'), ('significant', 'JJ'), ('portion', 'NN'), ('community', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['address problem', 'problem lack', 'lack leverage', 'leverage ,', ', several', 'several projects', 'projects could', 'could funded', 'funded support', 'support efforts', 'efforts throughout', 'throughout significant', 'significant portion', 'portion community', 'community .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['address problem lack', 'problem lack leverage', 'lack leverage ,', 'leverage , several', ', several projects', 'several projects could', 'projects could funded', 'could funded support', 'funded support efforts', 'support efforts throughout', 'efforts throughout significant', 'throughout significant portion', 'significant portion community', 'portion community .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['address', 'problem', 'lack', 'leverage', 'support', 'significant portion', 'community'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['address', 'problem', 'lack', 'leverag', ',', 'sever', 'project', 'could', 'fund', 'support', 'effort', 'throughout', 'signific', 'portion', 'commun', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['address', 'problem', 'lack', 'leverag', ',', 'sever', 'project', 'could', 'fund', 'support', 'effort', 'throughout', 'signific', 'portion', 'communiti', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['address', 'problem', 'lack', 'leverage', ',', 'several', 'project', 'could', 'funded', 'support', 'effort', 'throughout', 'significant', 'portion', 'community', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

198 --> We believe that such  projects will make both the conduct and the evaluation of natural language work substantially faster and easier; that  they can significantly reduce duplication of effort; that they can help to facilitate the individual researcher's efforts  on new work rather than on infrastructure: and that they can materially increase the compatibility of research and  development activities at different sites. 


 ---- TOKENS ----

 ['We', 'believe', 'that', 'such', 'projects', 'will', 'make', 'both', 'the', 'conduct', 'and', 'the', 'evaluation', 'of', 'natural', 'language', 'work', 'substantially', 'faster', 'and', 'easier', ';', 'that', 'they', 'can', 'significantly', 'reduce', 'duplication', 'of', 'effort', ';', 'that', 'they', 'can', 'help', 'to', 'facilitate', 'the', 'individual', 'researcher', "'s", 'efforts', 'on', 'new', 'work', 'rather', 'than', 'on', 'infrastructure', ':', 'and', 'that', 'they', 'can', 'materially', 'increase', 'the', 'compatibility', 'of', 'research', 'and', 'development', 'activities', 'at', 'different', 'sites', '.'] 

 TOTAL TOKENS ==> 67

 ---- POST ----

 [('We', 'PRP'), ('believe', 'VBP'), ('that', 'IN'), ('such', 'JJ'), ('projects', 'NNS'), ('will', 'MD'), ('make', 'VB'), ('both', 'DT'), ('the', 'DT'), ('conduct', 'NN'), ('and', 'CC'), ('the', 'DT'), ('evaluation', 'NN'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('work', 'NN'), ('substantially', 'RB'), ('faster', 'RBR'), ('and', 'CC'), ('easier', 'JJR'), (';', ':'), ('that', 'IN'), ('they', 'PRP'), ('can', 'MD'), ('significantly', 'RB'), ('reduce', 'VB'), ('duplication', 'NN'), ('of', 'IN'), ('effort', 'NN'), (';', ':'), ('that', 'IN'), ('they', 'PRP'), ('can', 'MD'), ('help', 'VB'), ('to', 'TO'), ('facilitate', 'VB'), ('the', 'DT'), ('individual', 'JJ'), ('researcher', 'NN'), ("'s", 'POS'), ('efforts', 'NNS'), ('on', 'IN'), ('new', 'JJ'), ('work', 'NN'), ('rather', 'RB'), ('than', 'IN'), ('on', 'IN'), ('infrastructure', 'NN'), (':', ':'), ('and', 'CC'), ('that', 'IN'), ('they', 'PRP'), ('can', 'MD'), ('materially', 'RB'), ('increase', 'VB'), ('the', 'DT'), ('compatibility', 'NN'), ('of', 'IN'), ('research', 'NN'), ('and', 'CC'), ('development', 'NN'), ('activities', 'NNS'), ('at', 'IN'), ('different', 'JJ'), ('sites', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['believe', 'projects', 'make', 'conduct', 'evaluation', 'natural', 'language', 'work', 'substantially', 'faster', 'easier', ';', 'significantly', 'reduce', 'duplication', 'effort', ';', 'help', 'facilitate', 'individual', 'researcher', "'s", 'efforts', 'new', 'work', 'rather', 'infrastructure', ':', 'materially', 'increase', 'compatibility', 'research', 'development', 'activities', 'different', 'sites', '.']

 TOTAL FILTERED TOKENS ==>  37

 ---- POST FOR FILTERED TOKENS ----

 [('believe', 'JJ'), ('projects', 'NNS'), ('make', 'VBP'), ('conduct', 'NN'), ('evaluation', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('work', 'NN'), ('substantially', 'RB'), ('faster', 'RB'), ('easier', 'JJR'), (';', ':'), ('significantly', 'RB'), ('reduce', 'VB'), ('duplication', 'NN'), ('effort', 'NN'), (';', ':'), ('help', 'VB'), ('facilitate', 'VB'), ('individual', 'JJ'), ('researcher', 'NN'), ("'s", 'POS'), ('efforts', 'NNS'), ('new', 'JJ'), ('work', 'NN'), ('rather', 'RB'), ('infrastructure', 'NN'), (':', ':'), ('materially', 'RB'), ('increase', 'VB'), ('compatibility', 'NN'), ('research', 'NN'), ('development', 'NN'), ('activities', 'NNS'), ('different', 'JJ'), ('sites', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['believe projects', 'projects make', 'make conduct', 'conduct evaluation', 'evaluation natural', 'natural language', 'language work', 'work substantially', 'substantially faster', 'faster easier', 'easier ;', '; significantly', 'significantly reduce', 'reduce duplication', 'duplication effort', 'effort ;', '; help', 'help facilitate', 'facilitate individual', 'individual researcher', "researcher 's", "'s efforts", 'efforts new', 'new work', 'work rather', 'rather infrastructure', 'infrastructure :', ': materially', 'materially increase', 'increase compatibility', 'compatibility research', 'research development', 'development activities', 'activities different', 'different sites', 'sites .'] 

 TOTAL BIGRAMS --> 36 



 ---- TRI-GRAMS ---- 

 ['believe projects make', 'projects make conduct', 'make conduct evaluation', 'conduct evaluation natural', 'evaluation natural language', 'natural language work', 'language work substantially', 'work substantially faster', 'substantially faster easier', 'faster easier ;', 'easier ; significantly', '; significantly reduce', 'significantly reduce duplication', 'reduce duplication effort', 'duplication effort ;', 'effort ; help', '; help facilitate', 'help facilitate individual', 'facilitate individual researcher', "individual researcher 's", "researcher 's efforts", "'s efforts new", 'efforts new work', 'new work rather', 'work rather infrastructure', 'rather infrastructure :', 'infrastructure : materially', ': materially increase', 'materially increase compatibility', 'increase compatibility research', 'compatibility research development', 'research development activities', 'development activities different', 'activities different sites', 'different sites .'] 

 TOTAL TRIGRAMS --> 35 



 ---- NOUN PHRASES ---- 

 ['conduct', 'evaluation', 'natural language', 'work', 'duplication', 'effort', 'individual researcher', 'new work', 'infrastructure', 'compatibility', 'research', 'development'] 

 TOTAL NOUN PHRASES --> 12 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['believ', 'project', 'make', 'conduct', 'evalu', 'natur', 'languag', 'work', 'substanti', 'faster', 'easier', ';', 'significantli', 'reduc', 'duplic', 'effort', ';', 'help', 'facilit', 'individu', 'research', "'s", 'effort', 'new', 'work', 'rather', 'infrastructur', ':', 'materi', 'increas', 'compat', 'research', 'develop', 'activ', 'differ', 'site', '.']

 TOTAL PORTER STEM WORDS ==> 37



 ---- SNOWBALL STEMMING ----

['believ', 'project', 'make', 'conduct', 'evalu', 'natur', 'languag', 'work', 'substanti', 'faster', 'easier', ';', 'signific', 'reduc', 'duplic', 'effort', ';', 'help', 'facilit', 'individu', 'research', "'s", 'effort', 'new', 'work', 'rather', 'infrastructur', ':', 'materi', 'increas', 'compat', 'research', 'develop', 'activ', 'differ', 'site', '.']

 TOTAL SNOWBALL STEM WORDS ==> 37



 ---- LEMMATIZATION ----

['believe', 'project', 'make', 'conduct', 'evaluation', 'natural', 'language', 'work', 'substantially', 'faster', 'easier', ';', 'significantly', 'reduce', 'duplication', 'effort', ';', 'help', 'facilitate', 'individual', 'researcher', "'s", 'effort', 'new', 'work', 'rather', 'infrastructure', ':', 'materially', 'increase', 'compatibility', 'research', 'development', 'activity', 'different', 'site', '.']

 TOTAL LEMMATIZE WORDS ==> 37

************************************************************************************************************************

199 --> Examples of infrastructure include:  1. 


 ---- TOKENS ----

 ['Examples', 'of', 'infrastructure', 'include', ':', '1', '.'] 

 TOTAL TOKENS ==> 7

 ---- POST ----

 [('Examples', 'NNS'), ('of', 'IN'), ('infrastructure', 'NN'), ('include', 'VBP'), (':', ':'), ('1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Examples', 'infrastructure', 'include', ':', '1', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('Examples', 'NNS'), ('infrastructure', 'NN'), ('include', 'VBP'), (':', ':'), ('1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Examples infrastructure', 'infrastructure include', 'include :', ': 1', '1 .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['Examples infrastructure include', 'infrastructure include :', 'include : 1', ': 1 .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 ['infrastructure'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['exampl', 'infrastructur', 'includ', ':', '1', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['exampl', 'infrastructur', 'includ', ':', '1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['Examples', 'infrastructure', 'include', ':', '1', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

200 --> Collection and labeling of several corpora of various genres (dialogues, essays, narratives, etc.). 


 ---- TOKENS ----

 ['Collection', 'and', 'labeling', 'of', 'several', 'corpora', 'of', 'various', 'genres', '(', 'dialogues', ',', 'essays', ',', 'narratives', ',', 'etc', '.', ')', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('Collection', 'NN'), ('and', 'CC'), ('labeling', 'NN'), ('of', 'IN'), ('several', 'JJ'), ('corpora', 'NNS'), ('of', 'IN'), ('various', 'JJ'), ('genres', 'NNS'), ('(', '('), ('dialogues', 'NNS'), (',', ','), ('essays', 'NNS'), (',', ','), ('narratives', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Collection', 'labeling', 'several', 'corpora', 'various', 'genres', '(', 'dialogues', ',', 'essays', ',', 'narratives', ',', 'etc', '.', ')', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Collection', 'NNP'), ('labeling', 'VBG'), ('several', 'JJ'), ('corpora', 'NNS'), ('various', 'JJ'), ('genres', 'NNS'), ('(', '('), ('dialogues', 'NNS'), (',', ','), ('essays', 'NNS'), (',', ','), ('narratives', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Collection labeling', 'labeling several', 'several corpora', 'corpora various', 'various genres', 'genres (', '( dialogues', 'dialogues ,', ', essays', 'essays ,', ', narratives', 'narratives ,', ', etc', 'etc .', '. )', ') .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Collection labeling several', 'labeling several corpora', 'several corpora various', 'corpora various genres', 'various genres (', 'genres ( dialogues', '( dialogues ,', 'dialogues , essays', ', essays ,', 'essays , narratives', ', narratives ,', 'narratives , etc', ', etc .', 'etc . )', '. ) .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['collect', 'label', 'sever', 'corpora', 'variou', 'genr', '(', 'dialogu', ',', 'essay', ',', 'narr', ',', 'etc', '.', ')', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['collect', 'label', 'sever', 'corpora', 'various', 'genr', '(', 'dialogu', ',', 'essay', ',', 'narrat', ',', 'etc', '.', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Collection', 'labeling', 'several', 'corpus', 'various', 'genre', '(', 'dialogue', ',', 'essay', ',', 'narrative', ',', 'etc', '.', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

201 --> Some  experts believe a corpus of 100,000,000 words is required. 


 ---- TOKENS ----

 ['Some', 'experts', 'believe', 'a', 'corpus', 'of', '100,000,000', 'words', 'is', 'required', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Some', 'DT'), ('experts', 'NNS'), ('believe', 'VBP'), ('a', 'DT'), ('corpus', 'NN'), ('of', 'IN'), ('100,000,000', 'CD'), ('words', 'NNS'), ('is', 'VBZ'), ('required', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['experts', 'believe', 'corpus', '100,000,000', 'words', 'required', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('experts', 'NNS'), ('believe', 'VBP'), ('corpus', 'NN'), ('100,000,000', 'CD'), ('words', 'NNS'), ('required', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['experts believe', 'believe corpus', 'corpus 100,000,000', '100,000,000 words', 'words required', 'required .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['experts believe corpus', 'believe corpus 100,000,000', 'corpus 100,000,000 words', '100,000,000 words required', 'words required .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['corpus'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['expert', 'believ', 'corpu', '100,000,000', 'word', 'requir', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['expert', 'believ', 'corpus', '100,000,000', 'word', 'requir', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['expert', 'believe', 'corpus', '100,000,000', 'word', 'required', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

202 --> The labeling should include part of speech,  488   syntactic structure reformation, co-reference, and any semantic/pragmatic information that can be  reliably added. 


 ---- TOKENS ----

 ['The', 'labeling', 'should', 'include', 'part', 'of', 'speech', ',', '488', 'syntactic', 'structure', 'reformation', ',', 'co-reference', ',', 'and', 'any', 'semantic/pragmatic', 'information', 'that', 'can', 'be', 'reliably', 'added', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('The', 'DT'), ('labeling', 'NN'), ('should', 'MD'), ('include', 'VB'), ('part', 'NN'), ('of', 'IN'), ('speech', 'NN'), (',', ','), ('488', 'CD'), ('syntactic', 'JJ'), ('structure', 'NN'), ('reformation', 'NN'), (',', ','), ('co-reference', 'NN'), (',', ','), ('and', 'CC'), ('any', 'DT'), ('semantic/pragmatic', 'JJ'), ('information', 'NN'), ('that', 'WDT'), ('can', 'MD'), ('be', 'VB'), ('reliably', 'RB'), ('added', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['labeling', 'include', 'part', 'speech', ',', '488', 'syntactic', 'structure', 'reformation', ',', 'co-reference', ',', 'semantic/pragmatic', 'information', 'reliably', 'added', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('labeling', 'VBG'), ('include', 'VBP'), ('part', 'NN'), ('speech', 'NN'), (',', ','), ('488', 'CD'), ('syntactic', 'JJ'), ('structure', 'NN'), ('reformation', 'NN'), (',', ','), ('co-reference', 'NN'), (',', ','), ('semantic/pragmatic', 'JJ'), ('information', 'NN'), ('reliably', 'RB'), ('added', 'VBD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['labeling include', 'include part', 'part speech', 'speech ,', ', 488', '488 syntactic', 'syntactic structure', 'structure reformation', 'reformation ,', ', co-reference', 'co-reference ,', ', semantic/pragmatic', 'semantic/pragmatic information', 'information reliably', 'reliably added', 'added .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['labeling include part', 'include part speech', 'part speech ,', 'speech , 488', ', 488 syntactic', '488 syntactic structure', 'syntactic structure reformation', 'structure reformation ,', 'reformation , co-reference', ', co-reference ,', 'co-reference , semantic/pragmatic', ', semantic/pragmatic information', 'semantic/pragmatic information reliably', 'information reliably added', 'reliably added .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['part', 'speech', 'syntactic structure', 'reformation', 'co-reference', 'semantic information'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['label', 'includ', 'part', 'speech', ',', '488', 'syntact', 'structur', 'reform', ',', 'co-refer', ',', 'semantic/pragmat', 'inform', 'reliabl', 'ad', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['label', 'includ', 'part', 'speech', ',', '488', 'syntact', 'structur', 'reform', ',', 'co-refer', ',', 'semantic/pragmat', 'inform', 'reliabl', 'ad', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['labeling', 'include', 'part', 'speech', ',', '488', 'syntactic', 'structure', 'reformation', ',', 'co-reference', ',', 'semantic/pragmatic', 'information', 'reliably', 'added', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

203 --> 2. 


 ---- TOKENS ----

 ['2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

204 --> Distribution and maintenance of  two or more of the most extensive grammars and parsers of  English. 


 ---- TOKENS ----

 ['Distribution', 'and', 'maintenance', 'of', 'two', 'or', 'more', 'of', 'the', 'most', 'extensive', 'grammars', 'and', 'parsers', 'of', 'English', '.'] 

 TOTAL TOKENS ==> 17

 ---- POST ----

 [('Distribution', 'NN'), ('and', 'CC'), ('maintenance', 'NN'), ('of', 'IN'), ('two', 'CD'), ('or', 'CC'), ('more', 'JJR'), ('of', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('extensive', 'JJ'), ('grammars', 'NNS'), ('and', 'CC'), ('parsers', 'NNS'), ('of', 'IN'), ('English', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Distribution', 'maintenance', 'two', 'extensive', 'grammars', 'parsers', 'English', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Distribution', 'NNP'), ('maintenance', 'NN'), ('two', 'CD'), ('extensive', 'JJ'), ('grammars', 'NNS'), ('parsers', 'NNS'), ('English', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Distribution maintenance', 'maintenance two', 'two extensive', 'extensive grammars', 'grammars parsers', 'parsers English', 'English .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Distribution maintenance two', 'maintenance two extensive', 'two extensive grammars', 'extensive grammars parsers', 'grammars parsers English', 'parsers English .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['maintenance'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Distribution', 'English']
 TOTAL GPE ENTITY --> 2 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['distribut', 'mainten', 'two', 'extens', 'grammar', 'parser', 'english', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['distribut', 'mainten', 'two', 'extens', 'grammar', 'parser', 'english', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Distribution', 'maintenance', 'two', 'extensive', 'grammar', 'parser', 'English', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

205 --> 3. 


 ---- TOKENS ----

 ['3', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['3', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

206 --> Collection o f  a substantial lexicon with feature information that is uncontroversial. 


 ---- TOKENS ----

 ['Collection', 'o', 'f', 'a', 'substantial', 'lexicon', 'with', 'feature', 'information', 'that', 'is', 'uncontroversial', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Collection', 'NNP'), ('o', 'PRP'), ('f', 'VBD'), ('a', 'DT'), ('substantial', 'JJ'), ('lexicon', 'NN'), ('with', 'IN'), ('feature', 'NN'), ('information', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('uncontroversial', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Collection', 'f', 'substantial', 'lexicon', 'feature', 'information', 'uncontroversial', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Collection', 'NNP'), ('f', 'VBZ'), ('substantial', 'JJ'), ('lexicon', 'JJ'), ('feature', 'NN'), ('information', 'NN'), ('uncontroversial', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Collection f', 'f substantial', 'substantial lexicon', 'lexicon feature', 'feature information', 'information uncontroversial', 'uncontroversial .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Collection f substantial', 'f substantial lexicon', 'substantial lexicon feature', 'lexicon feature information', 'feature information uncontroversial', 'information uncontroversial .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['substantial lexicon feature', 'information'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Collection']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['collect', 'f', 'substanti', 'lexicon', 'featur', 'inform', 'uncontroversi', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['collect', 'f', 'substanti', 'lexicon', 'featur', 'inform', 'uncontroversi', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Collection', 'f', 'substantial', 'lexicon', 'feature', 'information', 'uncontroversial', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

207 --> (Since the largest  lexicons thus far have been about 10,000 words, the size should be at least 20,000.) 


 ---- TOKENS ----

 ['(', 'Since', 'the', 'largest', 'lexicons', 'thus', 'far', 'have', 'been', 'about', '10,000', 'words', ',', 'the', 'size', 'should', 'be', 'at', 'least', '20,000', '.', ')'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('(', '('), ('Since', 'IN'), ('the', 'DT'), ('largest', 'JJS'), ('lexicons', 'NNS'), ('thus', 'RB'), ('far', 'RB'), ('have', 'VBP'), ('been', 'VBN'), ('about', 'IN'), ('10,000', 'CD'), ('words', 'NNS'), (',', ','), ('the', 'DT'), ('size', 'NN'), ('should', 'MD'), ('be', 'VB'), ('at', 'IN'), ('least', 'JJS'), ('20,000', 'CD'), ('.', '.'), (')', ')')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['(', 'Since', 'largest', 'lexicons', 'thus', 'far', '10,000', 'words', ',', 'size', 'least', '20,000', '.', ')']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('(', '('), ('Since', 'IN'), ('largest', 'JJS'), ('lexicons', 'NNS'), ('thus', 'RB'), ('far', 'RB'), ('10,000', 'CD'), ('words', 'NNS'), (',', ','), ('size', 'NN'), ('least', 'JJS'), ('20,000', 'CD'), ('.', '.'), (')', ')')] 



 ---- BI-GRAMS ---- 

 ['( Since', 'Since largest', 'largest lexicons', 'lexicons thus', 'thus far', 'far 10,000', '10,000 words', 'words ,', ', size', 'size least', 'least 20,000', '20,000 .', '. )'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['( Since largest', 'Since largest lexicons', 'largest lexicons thus', 'lexicons thus far', 'thus far 10,000', 'far 10,000 words', '10,000 words ,', 'words , size', ', size least', 'size least 20,000', 'least 20,000 .', '20,000 . )'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['(', 'sinc', 'largest', 'lexicon', 'thu', 'far', '10,000', 'word', ',', 'size', 'least', '20,000', '.', ')']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['(', 'sinc', 'largest', 'lexicon', 'thus', 'far', '10,000', 'word', ',', 'size', 'least', '20,000', '.', ')']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['(', 'Since', 'largest', 'lexicon', 'thus', 'far', '10,000', 'word', ',', 'size', 'least', '20,000', '.', ')']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

208 --> 4. 


 ---- TOKENS ----

 ['4', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['4', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

209 --> Maintenance of  two or more knowledge representation and reasoning systems. 


 ---- TOKENS ----

 ['Maintenance', 'of', 'two', 'or', 'more', 'knowledge', 'representation', 'and', 'reasoning', 'systems', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Maintenance', 'NN'), ('of', 'IN'), ('two', 'CD'), ('or', 'CC'), ('more', 'JJR'), ('knowledge', 'JJ'), ('representation', 'NN'), ('and', 'CC'), ('reasoning', 'VBG'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Maintenance', 'two', 'knowledge', 'representation', 'reasoning', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('Maintenance', 'NNP'), ('two', 'CD'), ('knowledge', 'NN'), ('representation', 'NN'), ('reasoning', 'VBG'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Maintenance two', 'two knowledge', 'knowledge representation', 'representation reasoning', 'reasoning systems', 'systems .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['Maintenance two knowledge', 'two knowledge representation', 'knowledge representation reasoning', 'representation reasoning systems', 'reasoning systems .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['knowledge', 'representation'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['mainten', 'two', 'knowledg', 'represent', 'reason', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['mainten', 'two', 'knowledg', 'represent', 'reason', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['Maintenance', 'two', 'knowledge', 'representation', 'reasoning', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

210 --> 5. 


 ---- TOKENS ----

 ['5', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('5', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['5', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('5', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['5 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['5', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['5', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['5', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

211 --> Distribution and maintenance of  two or three natural language interfaces. 


 ---- TOKENS ----

 ['Distribution', 'and', 'maintenance', 'of', 'two', 'or', 'three', 'natural', 'language', 'interfaces', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Distribution', 'NN'), ('and', 'CC'), ('maintenance', 'NN'), ('of', 'IN'), ('two', 'CD'), ('or', 'CC'), ('three', 'CD'), ('natural', 'JJ'), ('language', 'NN'), ('interfaces', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Distribution', 'maintenance', 'two', 'three', 'natural', 'language', 'interfaces', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Distribution', 'NNP'), ('maintenance', 'NN'), ('two', 'CD'), ('three', 'CD'), ('natural', 'JJ'), ('language', 'NN'), ('interfaces', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Distribution maintenance', 'maintenance two', 'two three', 'three natural', 'natural language', 'language interfaces', 'interfaces .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Distribution maintenance two', 'maintenance two three', 'two three natural', 'three natural language', 'natural language interfaces', 'language interfaces .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['maintenance', 'natural language'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Distribution']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['distribut', 'mainten', 'two', 'three', 'natur', 'languag', 'interfac', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['distribut', 'mainten', 'two', 'three', 'natur', 'languag', 'interfac', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Distribution', 'maintenance', 'two', 'three', 'natural', 'language', 'interface', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

212 --> 6. 


 ---- TOKENS ----

 ['6', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('6', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['6', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('6', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['6 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['6', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['6', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['6', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

213 --> Distribution of  one or more "backend"  systems to serve as the target o f  an interface. 


 ---- TOKENS ----

 ['Distribution', 'of', 'one', 'or', 'more', '``', 'backend', "''", 'systems', 'to', 'serve', 'as', 'the', 'target', 'o', 'f', 'an', 'interface', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Distribution', 'NN'), ('of', 'IN'), ('one', 'CD'), ('or', 'CC'), ('more', 'JJR'), ('``', '``'), ('backend', 'NN'), ("''", "''"), ('systems', 'NNS'), ('to', 'TO'), ('serve', 'VB'), ('as', 'IN'), ('the', 'DT'), ('target', 'NN'), ('o', 'NN'), ('f', 'VBD'), ('an', 'DT'), ('interface', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Distribution', 'one', '``', 'backend', "''", 'systems', 'serve', 'target', 'f', 'interface', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Distribution', 'NNP'), ('one', 'CD'), ('``', '``'), ('backend', 'NN'), ("''", "''"), ('systems', 'NNS'), ('serve', 'VBP'), ('target', 'NN'), ('f', 'JJ'), ('interface', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Distribution one', 'one ``', '`` backend', "backend ''", "'' systems", 'systems serve', 'serve target', 'target f', 'f interface', 'interface .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Distribution one ``', 'one `` backend', "`` backend ''", "backend '' systems", "'' systems serve", 'systems serve target', 'serve target f', 'target f interface', 'f interface .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['backend', 'target', 'f interface'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['distribut', 'one', '``', 'backend', "''", 'system', 'serv', 'target', 'f', 'interfac', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['distribut', 'one', '``', 'backend', "''", 'system', 'serv', 'target', 'f', 'interfac', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Distribution', 'one', '``', 'backend', "''", 'system', 'serve', 'target', 'f', 'interface', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

214 --> 3.2. 


 ---- TOKENS ----

 ['3.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('3.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('3.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['3.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['3.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

215 --> Measures of Progress  The means o f  measunng progress is still an active area of  discussion among NL scientists, as evidenced by  the Workshop on Natural Language Evaluation held outside Philadelphia in December 1988. 


 ---- TOKENS ----

 ['Measures', 'of', 'Progress', 'The', 'means', 'o', 'f', 'measunng', 'progress', 'is', 'still', 'an', 'active', 'area', 'of', 'discussion', 'among', 'NL', 'scientists', ',', 'as', 'evidenced', 'by', 'the', 'Workshop', 'on', 'Natural', 'Language', 'Evaluation', 'held', 'outside', 'Philadelphia', 'in', 'December', '1988', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('Measures', 'NNS'), ('of', 'IN'), ('Progress', 'NNP'), ('The', 'DT'), ('means', 'NNS'), ('o', 'VBP'), ('f', 'JJ'), ('measunng', 'NN'), ('progress', 'NN'), ('is', 'VBZ'), ('still', 'RB'), ('an', 'DT'), ('active', 'JJ'), ('area', 'NN'), ('of', 'IN'), ('discussion', 'NN'), ('among', 'IN'), ('NL', 'NNP'), ('scientists', 'NNS'), (',', ','), ('as', 'IN'), ('evidenced', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Workshop', 'NNP'), ('on', 'IN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Evaluation', 'NNP'), ('held', 'VBD'), ('outside', 'JJ'), ('Philadelphia', 'NNP'), ('in', 'IN'), ('December', 'NNP'), ('1988', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Measures', 'Progress', 'means', 'f', 'measunng', 'progress', 'still', 'active', 'area', 'discussion', 'among', 'NL', 'scientists', ',', 'evidenced', 'Workshop', 'Natural', 'Language', 'Evaluation', 'held', 'outside', 'Philadelphia', 'December', '1988', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('Measures', 'NNS'), ('Progress', 'NNP'), ('means', 'VBZ'), ('f', 'JJ'), ('measunng', 'NN'), ('progress', 'NN'), ('still', 'RB'), ('active', 'JJ'), ('area', 'NN'), ('discussion', 'NN'), ('among', 'IN'), ('NL', 'NNP'), ('scientists', 'NNS'), (',', ','), ('evidenced', 'VBD'), ('Workshop', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Evaluation', 'NNP'), ('held', 'VBD'), ('outside', 'JJ'), ('Philadelphia', 'NNP'), ('December', 'NNP'), ('1988', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Measures Progress', 'Progress means', 'means f', 'f measunng', 'measunng progress', 'progress still', 'still active', 'active area', 'area discussion', 'discussion among', 'among NL', 'NL scientists', 'scientists ,', ', evidenced', 'evidenced Workshop', 'Workshop Natural', 'Natural Language', 'Language Evaluation', 'Evaluation held', 'held outside', 'outside Philadelphia', 'Philadelphia December', 'December 1988', '1988 .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['Measures Progress means', 'Progress means f', 'means f measunng', 'f measunng progress', 'measunng progress still', 'progress still active', 'still active area', 'active area discussion', 'area discussion among', 'discussion among NL', 'among NL scientists', 'NL scientists ,', 'scientists , evidenced', ', evidenced Workshop', 'evidenced Workshop Natural', 'Workshop Natural Language', 'Natural Language Evaluation', 'Language Evaluation held', 'Evaluation held outside', 'held outside Philadelphia', 'outside Philadelphia December', 'Philadelphia December 1988', 'December 1988 .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['f measunng', 'progress', 'active area', 'discussion'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['Progress', 'Philadelphia']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> ['Workshop Natural Language Evaluation']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['measur', 'progress', 'mean', 'f', 'measunng', 'progress', 'still', 'activ', 'area', 'discuss', 'among', 'nl', 'scientist', ',', 'evidenc', 'workshop', 'natur', 'languag', 'evalu', 'held', 'outsid', 'philadelphia', 'decemb', '1988', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['measur', 'progress', 'mean', 'f', 'measunng', 'progress', 'still', 'activ', 'area', 'discuss', 'among', 'nl', 'scientist', ',', 'evidenc', 'workshop', 'natur', 'languag', 'evalu', 'held', 'outsid', 'philadelphia', 'decemb', '1988', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['Measures', 'Progress', 'mean', 'f', 'measunng', 'progress', 'still', 'active', 'area', 'discussion', 'among', 'NL', 'scientist', ',', 'evidenced', 'Workshop', 'Natural', 'Language', 'Evaluation', 'held', 'outside', 'Philadelphia', 'December', '1988', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

216 --> Measures of   correctness can be relatively simply stated for database query systems without dialogue capabilities (e.g., without  sequence-related queries or clarifications), or for text analysis systems for database entry. 


 ---- TOKENS ----

 ['Measures', 'of', 'correctness', 'can', 'be', 'relatively', 'simply', 'stated', 'for', 'database', 'query', 'systems', 'without', 'dialogue', 'capabilities', '(', 'e.g.', ',', 'without', 'sequence-related', 'queries', 'or', 'clarifications', ')', ',', 'or', 'for', 'text', 'analysis', 'systems', 'for', 'database', 'entry', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('Measures', 'NNS'), ('of', 'IN'), ('correctness', 'NN'), ('can', 'MD'), ('be', 'VB'), ('relatively', 'RB'), ('simply', 'RB'), ('stated', 'VBN'), ('for', 'IN'), ('database', 'NN'), ('query', 'NN'), ('systems', 'NNS'), ('without', 'IN'), ('dialogue', 'NN'), ('capabilities', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('without', 'IN'), ('sequence-related', 'JJ'), ('queries', 'NNS'), ('or', 'CC'), ('clarifications', 'NNS'), (')', ')'), (',', ','), ('or', 'CC'), ('for', 'IN'), ('text', 'JJ'), ('analysis', 'NN'), ('systems', 'NNS'), ('for', 'IN'), ('database', 'NN'), ('entry', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Measures', 'correctness', 'relatively', 'simply', 'stated', 'database', 'query', 'systems', 'without', 'dialogue', 'capabilities', '(', 'e.g.', ',', 'without', 'sequence-related', 'queries', 'clarifications', ')', ',', 'text', 'analysis', 'systems', 'database', 'entry', '.']

 TOTAL FILTERED TOKENS ==>  26

 ---- POST FOR FILTERED TOKENS ----

 [('Measures', 'NNS'), ('correctness', 'VBP'), ('relatively', 'RB'), ('simply', 'RB'), ('stated', 'JJ'), ('database', 'NN'), ('query', 'NN'), ('systems', 'NNS'), ('without', 'IN'), ('dialogue', 'NN'), ('capabilities', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('without', 'IN'), ('sequence-related', 'JJ'), ('queries', 'NNS'), ('clarifications', 'NNS'), (')', ')'), (',', ','), ('text', 'JJ'), ('analysis', 'NN'), ('systems', 'NNS'), ('database', 'JJ'), ('entry', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Measures correctness', 'correctness relatively', 'relatively simply', 'simply stated', 'stated database', 'database query', 'query systems', 'systems without', 'without dialogue', 'dialogue capabilities', 'capabilities (', '( e.g.', 'e.g. ,', ', without', 'without sequence-related', 'sequence-related queries', 'queries clarifications', 'clarifications )', ') ,', ', text', 'text analysis', 'analysis systems', 'systems database', 'database entry', 'entry .'] 

 TOTAL BIGRAMS --> 25 



 ---- TRI-GRAMS ---- 

 ['Measures correctness relatively', 'correctness relatively simply', 'relatively simply stated', 'simply stated database', 'stated database query', 'database query systems', 'query systems without', 'systems without dialogue', 'without dialogue capabilities', 'dialogue capabilities (', 'capabilities ( e.g.', '( e.g. ,', 'e.g. , without', ', without sequence-related', 'without sequence-related queries', 'sequence-related queries clarifications', 'queries clarifications )', 'clarifications ) ,', ') , text', ', text analysis', 'text analysis systems', 'analysis systems database', 'systems database entry', 'database entry .'] 

 TOTAL TRIGRAMS --> 24 



 ---- NOUN PHRASES ---- 

 ['stated database', 'query', 'dialogue', 'text analysis', 'database entry'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['measur', 'correct', 'rel', 'simpli', 'state', 'databas', 'queri', 'system', 'without', 'dialogu', 'capabl', '(', 'e.g.', ',', 'without', 'sequence-rel', 'queri', 'clarif', ')', ',', 'text', 'analysi', 'system', 'databas', 'entri', '.']

 TOTAL PORTER STEM WORDS ==> 26



 ---- SNOWBALL STEMMING ----

['measur', 'correct', 'relat', 'simpli', 'state', 'databas', 'queri', 'system', 'without', 'dialogu', 'capabl', '(', 'e.g.', ',', 'without', 'sequence-rel', 'queri', 'clarif', ')', ',', 'text', 'analysi', 'system', 'databas', 'entri', '.']

 TOTAL SNOWBALL STEM WORDS ==> 26



 ---- LEMMATIZATION ----

['Measures', 'correctness', 'relatively', 'simply', 'stated', 'database', 'query', 'system', 'without', 'dialogue', 'capability', '(', 'e.g.', ',', 'without', 'sequence-related', 'query', 'clarification', ')', ',', 'text', 'analysis', 'system', 'database', 'entry', '.']

 TOTAL LEMMATIZE WORDS ==> 26

************************************************************************************************************************

217 --> They are much more  difficult to state when stylistic matters need to be considered (as in MT systems) or when system responses affect  subsequent user utterances. 


 ---- TOKENS ----

 ['They', 'are', 'much', 'more', 'difficult', 'to', 'state', 'when', 'stylistic', 'matters', 'need', 'to', 'be', 'considered', '(', 'as', 'in', 'MT', 'systems', ')', 'or', 'when', 'system', 'responses', 'affect', 'subsequent', 'user', 'utterances', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('They', 'PRP'), ('are', 'VBP'), ('much', 'RB'), ('more', 'RBR'), ('difficult', 'JJ'), ('to', 'TO'), ('state', 'NN'), ('when', 'WRB'), ('stylistic', 'JJ'), ('matters', 'NNS'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('considered', 'VBN'), ('(', '('), ('as', 'IN'), ('in', 'IN'), ('MT', 'NNP'), ('systems', 'NNS'), (')', ')'), ('or', 'CC'), ('when', 'WRB'), ('system', 'NN'), ('responses', 'VBZ'), ('affect', 'JJ'), ('subsequent', 'JJ'), ('user', 'NN'), ('utterances', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['much', 'difficult', 'state', 'stylistic', 'matters', 'need', 'considered', '(', 'MT', 'systems', ')', 'system', 'responses', 'affect', 'subsequent', 'user', 'utterances', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('much', 'JJ'), ('difficult', 'JJ'), ('state', 'NN'), ('stylistic', 'JJ'), ('matters', 'NNS'), ('need', 'VBP'), ('considered', 'VBN'), ('(', '('), ('MT', 'NNP'), ('systems', 'NNS'), (')', ')'), ('system', 'NN'), ('responses', 'NNS'), ('affect', 'VBP'), ('subsequent', 'JJ'), ('user', 'NN'), ('utterances', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['much difficult', 'difficult state', 'state stylistic', 'stylistic matters', 'matters need', 'need considered', 'considered (', '( MT', 'MT systems', 'systems )', ') system', 'system responses', 'responses affect', 'affect subsequent', 'subsequent user', 'user utterances', 'utterances .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['much difficult state', 'difficult state stylistic', 'state stylistic matters', 'stylistic matters need', 'matters need considered', 'need considered (', 'considered ( MT', '( MT systems', 'MT systems )', 'systems ) system', ') system responses', 'system responses affect', 'responses affect subsequent', 'affect subsequent user', 'subsequent user utterances', 'user utterances .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['much difficult state', 'system', 'subsequent user'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['much', 'difficult', 'state', 'stylist', 'matter', 'need', 'consid', '(', 'mt', 'system', ')', 'system', 'respons', 'affect', 'subsequ', 'user', 'utter', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['much', 'difficult', 'state', 'stylist', 'matter', 'need', 'consid', '(', 'mt', 'system', ')', 'system', 'respons', 'affect', 'subsequ', 'user', 'utter', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['much', 'difficult', 'state', 'stylistic', 'matter', 'need', 'considered', '(', 'MT', 'system', ')', 'system', 'response', 'affect', 'subsequent', 'user', 'utterance', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

218 --> They probably can' t  be usefully stated in a domain- or task-independent way. 


 ---- TOKENS ----

 ['They', 'probably', 'can', "'", 't', 'be', 'usefully', 'stated', 'in', 'a', 'domain-', 'or', 'task-independent', 'way', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('They', 'PRP'), ('probably', 'RB'), ('can', 'MD'), ("'", 'VB'), ('t', 'JJ'), ('be', 'VB'), ('usefully', 'RB'), ('stated', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('domain-', 'JJ'), ('or', 'CC'), ('task-independent', 'JJ'), ('way', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['probably', "'", 'usefully', 'stated', 'domain-', 'task-independent', 'way', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('probably', 'RB'), ("'", "''"), ('usefully', 'RB'), ('stated', 'VBN'), ('domain-', 'JJ'), ('task-independent', 'JJ'), ('way', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ["probably '", "' usefully", 'usefully stated', 'stated domain-', 'domain- task-independent', 'task-independent way', 'way .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ["probably ' usefully", "' usefully stated", 'usefully stated domain-', 'stated domain- task-independent', 'domain- task-independent way', 'task-independent way .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['domain- task-independent way'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['probabl', "'", 'use', 'state', 'domain-', 'task-independ', 'way', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['probabl', "'", 'use', 'state', 'domain-', 'task-independ', 'way', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['probably', "'", 'usefully', 'stated', 'domain-', 'task-independent', 'way', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

219 --> Measures  of  task difficulty, or o f  ambiguity o f  the language model, analogous to speech recogmtion's perplexity, are much  more difficult to state. 


 ---- TOKENS ----

 ['Measures', 'of', 'task', 'difficulty', ',', 'or', 'o', 'f', 'ambiguity', 'o', 'f', 'the', 'language', 'model', ',', 'analogous', 'to', 'speech', 'recogmtion', "'s", 'perplexity', ',', 'are', 'much', 'more', 'difficult', 'to', 'state', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('Measures', 'NNS'), ('of', 'IN'), ('task', 'NN'), ('difficulty', 'NN'), (',', ','), ('or', 'CC'), ('o', 'JJ'), ('f', 'JJ'), ('ambiguity', 'NN'), ('o', 'NN'), ('f', 'VBD'), ('the', 'DT'), ('language', 'NN'), ('model', 'NN'), (',', ','), ('analogous', 'JJ'), ('to', 'TO'), ('speech', 'VB'), ('recogmtion', 'NN'), ("'s", 'POS'), ('perplexity', 'NN'), (',', ','), ('are', 'VBP'), ('much', 'RB'), ('more', 'RBR'), ('difficult', 'JJ'), ('to', 'TO'), ('state', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Measures', 'task', 'difficulty', ',', 'f', 'ambiguity', 'f', 'language', 'model', ',', 'analogous', 'speech', 'recogmtion', "'s", 'perplexity', ',', 'much', 'difficult', 'state', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('Measures', 'NNS'), ('task', 'VBP'), ('difficulty', 'NN'), (',', ','), ('f', 'JJ'), ('ambiguity', 'NN'), ('f', 'JJ'), ('language', 'NN'), ('model', 'NN'), (',', ','), ('analogous', 'JJ'), ('speech', 'NN'), ('recogmtion', 'NN'), ("'s", 'POS'), ('perplexity', 'NN'), (',', ','), ('much', 'JJ'), ('difficult', 'JJ'), ('state', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Measures task', 'task difficulty', 'difficulty ,', ', f', 'f ambiguity', 'ambiguity f', 'f language', 'language model', 'model ,', ', analogous', 'analogous speech', 'speech recogmtion', "recogmtion 's", "'s perplexity", 'perplexity ,', ', much', 'much difficult', 'difficult state', 'state .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['Measures task difficulty', 'task difficulty ,', 'difficulty , f', ', f ambiguity', 'f ambiguity f', 'ambiguity f language', 'f language model', 'language model ,', 'model , analogous', ', analogous speech', 'analogous speech recogmtion', "speech recogmtion 's", "recogmtion 's perplexity", "'s perplexity ,", 'perplexity , much', ', much difficult', 'much difficult state', 'difficult state .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['difficulty', 'f ambiguity', 'f language', 'model', 'analogous speech', 'recogmtion', 'perplexity', 'much difficult state'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['measur', 'task', 'difficulti', ',', 'f', 'ambigu', 'f', 'languag', 'model', ',', 'analog', 'speech', 'recogmt', "'s", 'perplex', ',', 'much', 'difficult', 'state', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['measur', 'task', 'difficulti', ',', 'f', 'ambigu', 'f', 'languag', 'model', ',', 'analog', 'speech', 'recogmt', "'s", 'perplex', ',', 'much', 'difficult', 'state', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['Measures', 'task', 'difficulty', ',', 'f', 'ambiguity', 'f', 'language', 'model', ',', 'analogous', 'speech', 'recogmtion', "'s", 'perplexity', ',', 'much', 'difficult', 'state', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

220 --> Measurement of  NL systems requires three distinct types of  comparisons:  1. 


 ---- TOKENS ----

 ['Measurement', 'of', 'NL', 'systems', 'requires', 'three', 'distinct', 'types', 'of', 'comparisons', ':', '1', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Measurement', 'NN'), ('of', 'IN'), ('NL', 'NNP'), ('systems', 'NNS'), ('requires', 'VBZ'), ('three', 'CD'), ('distinct', 'JJ'), ('types', 'NNS'), ('of', 'IN'), ('comparisons', 'NNS'), (':', ':'), ('1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Measurement', 'NL', 'systems', 'requires', 'three', 'distinct', 'types', 'comparisons', ':', '1', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Measurement', 'NNP'), ('NL', 'NNP'), ('systems', 'NNS'), ('requires', 'VBZ'), ('three', 'CD'), ('distinct', 'JJ'), ('types', 'NNS'), ('comparisons', 'NNS'), (':', ':'), ('1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Measurement NL', 'NL systems', 'systems requires', 'requires three', 'three distinct', 'distinct types', 'types comparisons', 'comparisons :', ': 1', '1 .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Measurement NL systems', 'NL systems requires', 'systems requires three', 'requires three distinct', 'three distinct types', 'distinct types comparisons', 'types comparisons :', 'comparisons : 1', ': 1 .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['measur', 'nl', 'system', 'requir', 'three', 'distinct', 'type', 'comparison', ':', '1', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['measur', 'nl', 'system', 'requir', 'three', 'distinct', 'type', 'comparison', ':', '1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Measurement', 'NL', 'system', 'requires', 'three', 'distinct', 'type', 'comparison', ':', '1', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

221 --> Longitudinal: It is critical to be able to measure the performance of  a system over time, so that  progress can be tracked. 


 ---- TOKENS ----

 ['Longitudinal', ':', 'It', 'is', 'critical', 'to', 'be', 'able', 'to', 'measure', 'the', 'performance', 'of', 'a', 'system', 'over', 'time', ',', 'so', 'that', 'progress', 'can', 'be', 'tracked', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Longitudinal', 'JJ'), (':', ':'), ('It', 'PRP'), ('is', 'VBZ'), ('critical', 'JJ'), ('to', 'TO'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('measure', 'VB'), ('the', 'DT'), ('performance', 'NN'), ('of', 'IN'), ('a', 'DT'), ('system', 'NN'), ('over', 'IN'), ('time', 'NN'), (',', ','), ('so', 'IN'), ('that', 'IN'), ('progress', 'NN'), ('can', 'MD'), ('be', 'VB'), ('tracked', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Longitudinal', ':', 'critical', 'able', 'measure', 'performance', 'system', 'time', ',', 'progress', 'tracked', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Longitudinal', 'JJ'), (':', ':'), ('critical', 'JJ'), ('able', 'JJ'), ('measure', 'NN'), ('performance', 'NN'), ('system', 'NN'), ('time', 'NN'), (',', ','), ('progress', 'NN'), ('tracked', 'VBD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Longitudinal :', ': critical', 'critical able', 'able measure', 'measure performance', 'performance system', 'system time', 'time ,', ', progress', 'progress tracked', 'tracked .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Longitudinal : critical', ': critical able', 'critical able measure', 'able measure performance', 'measure performance system', 'performance system time', 'system time ,', 'time , progress', ', progress tracked', 'progress tracked .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['critical able measure', 'performance', 'system', 'time', 'progress'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['longitudin', ':', 'critic', 'abl', 'measur', 'perform', 'system', 'time', ',', 'progress', 'track', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['longitudin', ':', 'critic', 'abl', 'measur', 'perform', 'system', 'time', ',', 'progress', 'track', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Longitudinal', ':', 'critical', 'able', 'measure', 'performance', 'system', 'time', ',', 'progress', 'tracked', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

222 --> 2. 


 ---- TOKENS ----

 ['2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

223 --> Cross-System: It should be possible to compare the overall performance of  two systems in explicit  terms. 


 ---- TOKENS ----

 ['Cross-System', ':', 'It', 'should', 'be', 'possible', 'to', 'compare', 'the', 'overall', 'performance', 'of', 'two', 'systems', 'in', 'explicit', 'terms', '.'] 

 TOTAL TOKENS ==> 18

 ---- POST ----

 [('Cross-System', 'NN'), (':', ':'), ('It', 'PRP'), ('should', 'MD'), ('be', 'VB'), ('possible', 'JJ'), ('to', 'TO'), ('compare', 'VB'), ('the', 'DT'), ('overall', 'JJ'), ('performance', 'NN'), ('of', 'IN'), ('two', 'CD'), ('systems', 'NNS'), ('in', 'IN'), ('explicit', 'JJ'), ('terms', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Cross-System', ':', 'possible', 'compare', 'overall', 'performance', 'two', 'systems', 'explicit', 'terms', '.']

 TOTAL FILTERED TOKENS ==>  11

 ---- POST FOR FILTERED TOKENS ----

 [('Cross-System', 'NN'), (':', ':'), ('possible', 'JJ'), ('compare', 'NN'), ('overall', 'JJ'), ('performance', 'NN'), ('two', 'CD'), ('systems', 'NNS'), ('explicit', 'JJ'), ('terms', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Cross-System :', ': possible', 'possible compare', 'compare overall', 'overall performance', 'performance two', 'two systems', 'systems explicit', 'explicit terms', 'terms .'] 

 TOTAL BIGRAMS --> 10 



 ---- TRI-GRAMS ---- 

 ['Cross-System : possible', ': possible compare', 'possible compare overall', 'compare overall performance', 'overall performance two', 'performance two systems', 'two systems explicit', 'systems explicit terms', 'explicit terms .'] 

 TOTAL TRIGRAMS --> 9 



 ---- NOUN PHRASES ---- 

 ['Cross-System', 'possible compare', 'overall performance'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['cross-system', ':', 'possibl', 'compar', 'overal', 'perform', 'two', 'system', 'explicit', 'term', '.']

 TOTAL PORTER STEM WORDS ==> 11



 ---- SNOWBALL STEMMING ----

['cross-system', ':', 'possibl', 'compar', 'overal', 'perform', 'two', 'system', 'explicit', 'term', '.']

 TOTAL SNOWBALL STEM WORDS ==> 11



 ---- LEMMATIZATION ----

['Cross-System', ':', 'possible', 'compare', 'overall', 'performance', 'two', 'system', 'explicit', 'term', '.']

 TOTAL LEMMATIZE WORDS ==> 11

************************************************************************************************************************

224 --> This focus on whole-system performance will help localize the strengths and weaknesses of   complete systems and will identify topics for research and development efforts. 


 ---- TOKENS ----

 ['This', 'focus', 'on', 'whole-system', 'performance', 'will', 'help', 'localize', 'the', 'strengths', 'and', 'weaknesses', 'of', 'complete', 'systems', 'and', 'will', 'identify', 'topics', 'for', 'research', 'and', 'development', 'efforts', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('This', 'DT'), ('focus', 'NN'), ('on', 'IN'), ('whole-system', 'JJ'), ('performance', 'NN'), ('will', 'MD'), ('help', 'VB'), ('localize', 'VB'), ('the', 'DT'), ('strengths', 'NNS'), ('and', 'CC'), ('weaknesses', 'NNS'), ('of', 'IN'), ('complete', 'JJ'), ('systems', 'NNS'), ('and', 'CC'), ('will', 'MD'), ('identify', 'VB'), ('topics', 'NNS'), ('for', 'IN'), ('research', 'NN'), ('and', 'CC'), ('development', 'NN'), ('efforts', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['focus', 'whole-system', 'performance', 'help', 'localize', 'strengths', 'weaknesses', 'complete', 'systems', 'identify', 'topics', 'research', 'development', 'efforts', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('focus', 'VB'), ('whole-system', 'JJ'), ('performance', 'NN'), ('help', 'NN'), ('localize', 'VB'), ('strengths', 'JJ'), ('weaknesses', 'NNS'), ('complete', 'JJ'), ('systems', 'NNS'), ('identify', 'VBP'), ('topics', 'NNS'), ('research', 'NN'), ('development', 'NN'), ('efforts', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['focus whole-system', 'whole-system performance', 'performance help', 'help localize', 'localize strengths', 'strengths weaknesses', 'weaknesses complete', 'complete systems', 'systems identify', 'identify topics', 'topics research', 'research development', 'development efforts', 'efforts .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['focus whole-system performance', 'whole-system performance help', 'performance help localize', 'help localize strengths', 'localize strengths weaknesses', 'strengths weaknesses complete', 'weaknesses complete systems', 'complete systems identify', 'systems identify topics', 'identify topics research', 'topics research development', 'research development efforts', 'development efforts .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['whole-system performance', 'help', 'research', 'development'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['focu', 'whole-system', 'perform', 'help', 'local', 'strength', 'weak', 'complet', 'system', 'identifi', 'topic', 'research', 'develop', 'effort', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['focus', 'whole-system', 'perform', 'help', 'local', 'strength', 'weak', 'complet', 'system', 'identifi', 'topic', 'research', 'develop', 'effort', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['focus', 'whole-system', 'performance', 'help', 'localize', 'strength', 'weakness', 'complete', 'system', 'identify', 'topic', 'research', 'development', 'effort', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

225 --> 3. 


 ---- TOKENS ----

 ['3', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['3', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

226 --> Component: It should be possible to evaluate and compare parts o f  systems and evaluate coverage of   unknown phenomena. 


 ---- TOKENS ----

 ['Component', ':', 'It', 'should', 'be', 'possible', 'to', 'evaluate', 'and', 'compare', 'parts', 'o', 'f', 'systems', 'and', 'evaluate', 'coverage', 'of', 'unknown', 'phenomena', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Component', 'NN'), (':', ':'), ('It', 'PRP'), ('should', 'MD'), ('be', 'VB'), ('possible', 'JJ'), ('to', 'TO'), ('evaluate', 'VB'), ('and', 'CC'), ('compare', 'VB'), ('parts', 'NNS'), ('o', 'JJ'), ('f', 'JJ'), ('systems', 'NNS'), ('and', 'CC'), ('evaluate', 'JJ'), ('coverage', 'NN'), ('of', 'IN'), ('unknown', 'JJ'), ('phenomena', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Component', ':', 'possible', 'evaluate', 'compare', 'parts', 'f', 'systems', 'evaluate', 'coverage', 'unknown', 'phenomena', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('Component', 'NN'), (':', ':'), ('possible', 'JJ'), ('evaluate', 'NN'), ('compare', 'NN'), ('parts', 'NNS'), ('f', 'VBP'), ('systems', 'NNS'), ('evaluate', 'JJ'), ('coverage', 'NN'), ('unknown', 'JJ'), ('phenomena', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Component :', ': possible', 'possible evaluate', 'evaluate compare', 'compare parts', 'parts f', 'f systems', 'systems evaluate', 'evaluate coverage', 'coverage unknown', 'unknown phenomena', 'phenomena .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['Component : possible', ': possible evaluate', 'possible evaluate compare', 'evaluate compare parts', 'compare parts f', 'parts f systems', 'f systems evaluate', 'systems evaluate coverage', 'evaluate coverage unknown', 'coverage unknown phenomena', 'unknown phenomena .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['Component', 'possible evaluate', 'compare', 'evaluate coverage', 'unknown phenomena'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['compon', ':', 'possibl', 'evalu', 'compar', 'part', 'f', 'system', 'evalu', 'coverag', 'unknown', 'phenomena', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['compon', ':', 'possibl', 'evalu', 'compar', 'part', 'f', 'system', 'evalu', 'coverag', 'unknown', 'phenomena', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['Component', ':', 'possible', 'evaluate', 'compare', 'part', 'f', 'system', 'evaluate', 'coverage', 'unknown', 'phenomenon', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

227 --> This focus on components will help point out areas of  relative strength in  different systems and will provide priorities and goals for specific research. 


 ---- TOKENS ----

 ['This', 'focus', 'on', 'components', 'will', 'help', 'point', 'out', 'areas', 'of', 'relative', 'strength', 'in', 'different', 'systems', 'and', 'will', 'provide', 'priorities', 'and', 'goals', 'for', 'specific', 'research', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('This', 'DT'), ('focus', 'NN'), ('on', 'IN'), ('components', 'NNS'), ('will', 'MD'), ('help', 'VB'), ('point', 'VB'), ('out', 'RP'), ('areas', 'NNS'), ('of', 'IN'), ('relative', 'JJ'), ('strength', 'NN'), ('in', 'IN'), ('different', 'JJ'), ('systems', 'NNS'), ('and', 'CC'), ('will', 'MD'), ('provide', 'VB'), ('priorities', 'NNS'), ('and', 'CC'), ('goals', 'NNS'), ('for', 'IN'), ('specific', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['focus', 'components', 'help', 'point', 'areas', 'relative', 'strength', 'different', 'systems', 'provide', 'priorities', 'goals', 'specific', 'research', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('focus', 'NN'), ('components', 'NNS'), ('help', 'VBP'), ('point', 'VB'), ('areas', 'NNS'), ('relative', 'JJ'), ('strength', 'NN'), ('different', 'JJ'), ('systems', 'NNS'), ('provide', 'VBP'), ('priorities', 'NNS'), ('goals', 'NNS'), ('specific', 'JJ'), ('research', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['focus components', 'components help', 'help point', 'point areas', 'areas relative', 'relative strength', 'strength different', 'different systems', 'systems provide', 'provide priorities', 'priorities goals', 'goals specific', 'specific research', 'research .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['focus components help', 'components help point', 'help point areas', 'point areas relative', 'areas relative strength', 'relative strength different', 'strength different systems', 'different systems provide', 'systems provide priorities', 'provide priorities goals', 'priorities goals specific', 'goals specific research', 'specific research .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['focus', 'relative strength', 'specific research'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['focu', 'compon', 'help', 'point', 'area', 'rel', 'strength', 'differ', 'system', 'provid', 'prioriti', 'goal', 'specif', 'research', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['focus', 'compon', 'help', 'point', 'area', 'relat', 'strength', 'differ', 'system', 'provid', 'prioriti', 'goal', 'specif', 'research', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['focus', 'component', 'help', 'point', 'area', 'relative', 'strength', 'different', 'system', 'provide', 'priority', 'goal', 'specific', 'research', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

228 --> 4. 


 ---- TOKENS ----

 ['4', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['4', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

229 --> I m p a c t   4.1. 


 ---- TOKENS ----

 ['I', 'm', 'p', 'a', 'c', 't', '4.1', '.'] 

 TOTAL TOKENS ==> 8

 ---- POST ----

 [('I', 'PRP'), ('m', 'VBP'), ('p', 'VB'), ('a', 'DT'), ('c', 'NN'), ('t', 'NN'), ('4.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['p', 'c', '4.1', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('p', 'NN'), ('c', 'VBZ'), ('4.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['p c', 'c 4.1', '4.1 .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['p c 4.1', 'c 4.1 .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 ['p'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['p', 'c', '4.1', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['p', 'c', '4.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['p', 'c', '4.1', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

230 --> P o t e n t i a l  I m p a c t   One way to assess potential impact is via a holistic, subjective view. 


 ---- TOKENS ----

 ['P', 'o', 't', 'e', 'n', 't', 'i', 'a', 'l', 'I', 'm', 'p', 'a', 'c', 't', 'One', 'way', 'to', 'assess', 'potential', 'impact', 'is', 'via', 'a', 'holistic', ',', 'subjective', 'view', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('P', 'NNP'), ('o', 'MD'), ('t', 'VB'), ('e', 'NN'), ('n', 'IN'), ('t', 'NN'), ('i', 'VBP'), ('a', 'DT'), ('l', 'NN'), ('I', 'PRP'), ('m', 'VBP'), ('p', 'VB'), ('a', 'DT'), ('c', 'NN'), ('t', 'NN'), ('One', 'CD'), ('way', 'NN'), ('to', 'TO'), ('assess', 'VB'), ('potential', 'JJ'), ('impact', 'NN'), ('is', 'VBZ'), ('via', 'IN'), ('a', 'DT'), ('holistic', 'JJ'), (',', ','), ('subjective', 'JJ'), ('view', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['P', 'e', 'n', 'l', 'p', 'c', 'One', 'way', 'assess', 'potential', 'impact', 'via', 'holistic', ',', 'subjective', 'view', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('P', 'NNP'), ('e', 'NN'), ('n', 'RB'), ('l', 'JJ'), ('p', 'NN'), ('c', 'VBD'), ('One', 'CD'), ('way', 'NN'), ('assess', 'JJ'), ('potential', 'JJ'), ('impact', 'NN'), ('via', 'IN'), ('holistic', 'JJ'), (',', ','), ('subjective', 'JJ'), ('view', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['P e', 'e n', 'n l', 'l p', 'p c', 'c One', 'One way', 'way assess', 'assess potential', 'potential impact', 'impact via', 'via holistic', 'holistic ,', ', subjective', 'subjective view', 'view .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['P e n', 'e n l', 'n l p', 'l p c', 'p c One', 'c One way', 'One way assess', 'way assess potential', 'assess potential impact', 'potential impact via', 'impact via holistic', 'via holistic ,', 'holistic , subjective', ', subjective view', 'subjective view .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['e', 'l p', 'way', 'assess potential impact', 'subjective view'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['p', 'e', 'n', 'l', 'p', 'c', 'one', 'way', 'assess', 'potenti', 'impact', 'via', 'holist', ',', 'subject', 'view', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['p', 'e', 'n', 'l', 'p', 'c', 'one', 'way', 'assess', 'potenti', 'impact', 'via', 'holist', ',', 'subject', 'view', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['P', 'e', 'n', 'l', 'p', 'c', 'One', 'way', 'ass', 'potential', 'impact', 'via', 'holistic', ',', 'subjective', 'view', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

231 --> The following is a summary of  a  market survey that uses this approach: 1  Considering the question of feasibility (on NLP systems) first, the answer must be "yes"  ... 


 ---- TOKENS ----

 ['The', 'following', 'is', 'a', 'summary', 'of', 'a', 'market', 'survey', 'that', 'uses', 'this', 'approach', ':', '1', 'Considering', 'the', 'question', 'of', 'feasibility', '(', 'on', 'NLP', 'systems', ')', 'first', ',', 'the', 'answer', 'must', 'be', '``', 'yes', "''", '...'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('The', 'DT'), ('following', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('summary', 'NN'), ('of', 'IN'), ('a', 'DT'), ('market', 'NN'), ('survey', 'NN'), ('that', 'WDT'), ('uses', 'VBZ'), ('this', 'DT'), ('approach', 'NN'), (':', ':'), ('1', 'CD'), ('Considering', 'VBG'), ('the', 'DT'), ('question', 'NN'), ('of', 'IN'), ('feasibility', 'NN'), ('(', '('), ('on', 'IN'), ('NLP', 'NNP'), ('systems', 'NNS'), (')', ')'), ('first', 'RB'), (',', ','), ('the', 'DT'), ('answer', 'NN'), ('must', 'MD'), ('be', 'VB'), ('``', '``'), ('yes', 'UH'), ("''", "''"), ('...', ':')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['following', 'summary', 'market', 'survey', 'uses', 'approach', ':', '1', 'Considering', 'question', 'feasibility', '(', 'NLP', 'systems', ')', 'first', ',', 'answer', 'must', '``', 'yes', "''", '...']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('following', 'VBG'), ('summary', 'JJ'), ('market', 'NN'), ('survey', 'NN'), ('uses', 'VBZ'), ('approach', 'NN'), (':', ':'), ('1', 'CD'), ('Considering', 'VBG'), ('question', 'NN'), ('feasibility', 'NN'), ('(', '('), ('NLP', 'NNP'), ('systems', 'NNS'), (')', ')'), ('first', 'RB'), (',', ','), ('answer', 'VB'), ('must', 'MD'), ('``', '``'), ('yes', 'VB'), ("''", "''"), ('...', ':')] 



 ---- BI-GRAMS ---- 

 ['following summary', 'summary market', 'market survey', 'survey uses', 'uses approach', 'approach :', ': 1', '1 Considering', 'Considering question', 'question feasibility', 'feasibility (', '( NLP', 'NLP systems', 'systems )', ') first', 'first ,', ', answer', 'answer must', 'must ``', '`` yes', "yes ''", "'' ..."] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['following summary market', 'summary market survey', 'market survey uses', 'survey uses approach', 'uses approach :', 'approach : 1', ': 1 Considering', '1 Considering question', 'Considering question feasibility', 'question feasibility (', 'feasibility ( NLP', '( NLP systems', 'NLP systems )', 'systems ) first', ') first ,', 'first , answer', ', answer must', 'answer must ``', 'must `` yes', "`` yes ''", "yes '' ..."] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['summary market', 'survey', 'approach', 'question', 'feasibility'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['follow', 'summari', 'market', 'survey', 'use', 'approach', ':', '1', 'consid', 'question', 'feasibl', '(', 'nlp', 'system', ')', 'first', ',', 'answer', 'must', '``', 'ye', "''", '...']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['follow', 'summari', 'market', 'survey', 'use', 'approach', ':', '1', 'consid', 'question', 'feasibl', '(', 'nlp', 'system', ')', 'first', ',', 'answer', 'must', '``', 'yes', "''", '...']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['following', 'summary', 'market', 'survey', 'us', 'approach', ':', '1', 'Considering', 'question', 'feasibility', '(', 'NLP', 'system', ')', 'first', ',', 'answer', 'must', '``', 'yes', "''", '...']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

232 --> The second - easier - issue, is whether people will really want computer NLP. 


 ---- TOKENS ----

 ['The', 'second', '-', 'easier', '-', 'issue', ',', 'is', 'whether', 'people', 'will', 'really', 'want', 'computer', 'NLP', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('The', 'DT'), ('second', 'JJ'), ('-', ':'), ('easier', 'JJR'), ('-', ':'), ('issue', 'NN'), (',', ','), ('is', 'VBZ'), ('whether', 'IN'), ('people', 'NNS'), ('will', 'MD'), ('really', 'RB'), ('want', 'VB'), ('computer', 'NN'), ('NLP', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['second', '-', 'easier', '-', 'issue', ',', 'whether', 'people', 'really', 'want', 'computer', 'NLP', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('second', 'JJ'), ('-', ':'), ('easier', 'JJR'), ('-', ':'), ('issue', 'NN'), (',', ','), ('whether', 'IN'), ('people', 'NNS'), ('really', 'RB'), ('want', 'VBP'), ('computer', 'NN'), ('NLP', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['second -', '- easier', 'easier -', '- issue', 'issue ,', ', whether', 'whether people', 'people really', 'really want', 'want computer', 'computer NLP', 'NLP .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['second - easier', '- easier -', 'easier - issue', '- issue ,', 'issue , whether', ', whether people', 'whether people really', 'people really want', 'really want computer', 'want computer NLP', 'computer NLP .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['issue', 'computer'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['second', '-', 'easier', '-', 'issu', ',', 'whether', 'peopl', 'realli', 'want', 'comput', 'nlp', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['second', '-', 'easier', '-', 'issu', ',', 'whether', 'peopl', 'realli', 'want', 'comput', 'nlp', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['second', '-', 'easier', '-', 'issue', ',', 'whether', 'people', 'really', 'want', 'computer', 'NLP', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

233 --> In the style of some systems of logic, it  can be resolved by testing for the negative: under what circumstances would people not want computers to handle  natural language, given that they can satisfy price and performance requirements? 


 ---- TOKENS ----

 ['In', 'the', 'style', 'of', 'some', 'systems', 'of', 'logic', ',', 'it', 'can', 'be', 'resolved', 'by', 'testing', 'for', 'the', 'negative', ':', 'under', 'what', 'circumstances', 'would', 'people', 'not', 'want', 'computers', 'to', 'handle', 'natural', 'language', ',', 'given', 'that', 'they', 'can', 'satisfy', 'price', 'and', 'performance', 'requirements', '?'] 

 TOTAL TOKENS ==> 42

 ---- POST ----

 [('In', 'IN'), ('the', 'DT'), ('style', 'NN'), ('of', 'IN'), ('some', 'DT'), ('systems', 'NNS'), ('of', 'IN'), ('logic', 'NN'), (',', ','), ('it', 'PRP'), ('can', 'MD'), ('be', 'VB'), ('resolved', 'VBN'), ('by', 'IN'), ('testing', 'VBG'), ('for', 'IN'), ('the', 'DT'), ('negative', 'JJ'), (':', ':'), ('under', 'IN'), ('what', 'WP'), ('circumstances', 'NNS'), ('would', 'MD'), ('people', 'NNS'), ('not', 'RB'), ('want', 'VB'), ('computers', 'NNS'), ('to', 'TO'), ('handle', 'VB'), ('natural', 'JJ'), ('language', 'NN'), (',', ','), ('given', 'VBN'), ('that', 'IN'), ('they', 'PRP'), ('can', 'MD'), ('satisfy', 'VB'), ('price', 'NN'), ('and', 'CC'), ('performance', 'NN'), ('requirements', 'NNS'), ('?', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['style', 'systems', 'logic', ',', 'resolved', 'testing', 'negative', ':', 'circumstances', 'would', 'people', 'want', 'computers', 'handle', 'natural', 'language', ',', 'given', 'satisfy', 'price', 'performance', 'requirements', '?']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('style', 'NN'), ('systems', 'NNS'), ('logic', 'NN'), (',', ','), ('resolved', 'VBD'), ('testing', 'VBG'), ('negative', 'JJ'), (':', ':'), ('circumstances', 'NNS'), ('would', 'MD'), ('people', 'NNS'), ('want', 'VBP'), ('computers', 'NNS'), ('handle', 'VB'), ('natural', 'JJ'), ('language', 'NN'), (',', ','), ('given', 'VBN'), ('satisfy', 'JJ'), ('price', 'NN'), ('performance', 'NN'), ('requirements', 'NNS'), ('?', '.')] 



 ---- BI-GRAMS ---- 

 ['style systems', 'systems logic', 'logic ,', ', resolved', 'resolved testing', 'testing negative', 'negative :', ': circumstances', 'circumstances would', 'would people', 'people want', 'want computers', 'computers handle', 'handle natural', 'natural language', 'language ,', ', given', 'given satisfy', 'satisfy price', 'price performance', 'performance requirements', 'requirements ?'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['style systems logic', 'systems logic ,', 'logic , resolved', ', resolved testing', 'resolved testing negative', 'testing negative :', 'negative : circumstances', ': circumstances would', 'circumstances would people', 'would people want', 'people want computers', 'want computers handle', 'computers handle natural', 'handle natural language', 'natural language ,', 'language , given', ', given satisfy', 'given satisfy price', 'satisfy price performance', 'price performance requirements', 'performance requirements ?'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['style', 'logic', 'natural language', 'satisfy price', 'performance'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['style', 'system', 'logic', ',', 'resolv', 'test', 'neg', ':', 'circumst', 'would', 'peopl', 'want', 'comput', 'handl', 'natur', 'languag', ',', 'given', 'satisfi', 'price', 'perform', 'requir', '?']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['style', 'system', 'logic', ',', 'resolv', 'test', 'negat', ':', 'circumst', 'would', 'peopl', 'want', 'comput', 'handl', 'natur', 'languag', ',', 'given', 'satisfi', 'price', 'perform', 'requir', '?']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['style', 'system', 'logic', ',', 'resolved', 'testing', 'negative', ':', 'circumstance', 'would', 'people', 'want', 'computer', 'handle', 'natural', 'language', ',', 'given', 'satisfy', 'price', 'performance', 'requirement', '?']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

234 --> The only obvious answers are:  where a routine action (such as pressing a button or keying in a standard command) is quicker or more convenient:  where communication in a strictly formalized language is more reliable, precise, or subtle: and where there are  ovemding requirements for human involvement, ranging from legal obligations to job preservation. 


 ---- TOKENS ----

 ['The', 'only', 'obvious', 'answers', 'are', ':', 'where', 'a', 'routine', 'action', '(', 'such', 'as', 'pressing', 'a', 'button', 'or', 'keying', 'in', 'a', 'standard', 'command', ')', 'is', 'quicker', 'or', 'more', 'convenient', ':', 'where', 'communication', 'in', 'a', 'strictly', 'formalized', 'language', 'is', 'more', 'reliable', ',', 'precise', ',', 'or', 'subtle', ':', 'and', 'where', 'there', 'are', 'ovemding', 'requirements', 'for', 'human', 'involvement', ',', 'ranging', 'from', 'legal', 'obligations', 'to', 'job', 'preservation', '.'] 

 TOTAL TOKENS ==> 63

 ---- POST ----

 [('The', 'DT'), ('only', 'JJ'), ('obvious', 'JJ'), ('answers', 'NNS'), ('are', 'VBP'), (':', ':'), ('where', 'WRB'), ('a', 'DT'), ('routine', 'JJ'), ('action', 'NN'), ('(', '('), ('such', 'JJ'), ('as', 'IN'), ('pressing', 'VBG'), ('a', 'DT'), ('button', 'NN'), ('or', 'CC'), ('keying', 'NN'), ('in', 'IN'), ('a', 'DT'), ('standard', 'JJ'), ('command', 'NN'), (')', ')'), ('is', 'VBZ'), ('quicker', 'JJR'), ('or', 'CC'), ('more', 'RBR'), ('convenient', 'NN'), (':', ':'), ('where', 'WRB'), ('communication', 'NN'), ('in', 'IN'), ('a', 'DT'), ('strictly', 'RB'), ('formalized', 'VBN'), ('language', 'NN'), ('is', 'VBZ'), ('more', 'RBR'), ('reliable', 'JJ'), (',', ','), ('precise', 'JJ'), (',', ','), ('or', 'CC'), ('subtle', 'NN'), (':', ':'), ('and', 'CC'), ('where', 'WRB'), ('there', 'EX'), ('are', 'VBP'), ('ovemding', 'VBG'), ('requirements', 'NNS'), ('for', 'IN'), ('human', 'JJ'), ('involvement', 'NN'), (',', ','), ('ranging', 'VBG'), ('from', 'IN'), ('legal', 'JJ'), ('obligations', 'NNS'), ('to', 'TO'), ('job', 'NN'), ('preservation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['obvious', 'answers', ':', 'routine', 'action', '(', 'pressing', 'button', 'keying', 'standard', 'command', ')', 'quicker', 'convenient', ':', 'communication', 'strictly', 'formalized', 'language', 'reliable', ',', 'precise', ',', 'subtle', ':', 'ovemding', 'requirements', 'human', 'involvement', ',', 'ranging', 'legal', 'obligations', 'job', 'preservation', '.']

 TOTAL FILTERED TOKENS ==>  36

 ---- POST FOR FILTERED TOKENS ----

 [('obvious', 'JJ'), ('answers', 'NNS'), (':', ':'), ('routine', 'JJ'), ('action', 'NN'), ('(', '('), ('pressing', 'VBG'), ('button', 'NN'), ('keying', 'VBG'), ('standard', 'JJ'), ('command', 'NN'), (')', ')'), ('quicker', 'NN'), ('convenient', 'NN'), (':', ':'), ('communication', 'NN'), ('strictly', 'RB'), ('formalized', 'VBN'), ('language', 'NN'), ('reliable', 'JJ'), (',', ','), ('precise', 'JJ'), (',', ','), ('subtle', 'JJ'), (':', ':'), ('ovemding', 'NN'), ('requirements', 'NNS'), ('human', 'JJ'), ('involvement', 'NN'), (',', ','), ('ranging', 'VBG'), ('legal', 'JJ'), ('obligations', 'NNS'), ('job', 'NN'), ('preservation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['obvious answers', 'answers :', ': routine', 'routine action', 'action (', '( pressing', 'pressing button', 'button keying', 'keying standard', 'standard command', 'command )', ') quicker', 'quicker convenient', 'convenient :', ': communication', 'communication strictly', 'strictly formalized', 'formalized language', 'language reliable', 'reliable ,', ', precise', 'precise ,', ', subtle', 'subtle :', ': ovemding', 'ovemding requirements', 'requirements human', 'human involvement', 'involvement ,', ', ranging', 'ranging legal', 'legal obligations', 'obligations job', 'job preservation', 'preservation .'] 

 TOTAL BIGRAMS --> 35 



 ---- TRI-GRAMS ---- 

 ['obvious answers :', 'answers : routine', ': routine action', 'routine action (', 'action ( pressing', '( pressing button', 'pressing button keying', 'button keying standard', 'keying standard command', 'standard command )', 'command ) quicker', ') quicker convenient', 'quicker convenient :', 'convenient : communication', ': communication strictly', 'communication strictly formalized', 'strictly formalized language', 'formalized language reliable', 'language reliable ,', 'reliable , precise', ', precise ,', 'precise , subtle', ', subtle :', 'subtle : ovemding', ': ovemding requirements', 'ovemding requirements human', 'requirements human involvement', 'human involvement ,', 'involvement , ranging', ', ranging legal', 'ranging legal obligations', 'legal obligations job', 'obligations job preservation', 'job preservation .'] 

 TOTAL TRIGRAMS --> 34 



 ---- NOUN PHRASES ---- 

 ['routine action', 'quicker', 'convenient', 'communication', 'language', 'ovemding', 'human involvement', 'job', 'preservation'] 

 TOTAL NOUN PHRASES --> 9 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['obviou', 'answer', ':', 'routin', 'action', '(', 'press', 'button', 'key', 'standard', 'command', ')', 'quicker', 'conveni', ':', 'commun', 'strictli', 'formal', 'languag', 'reliabl', ',', 'precis', ',', 'subtl', ':', 'ovemd', 'requir', 'human', 'involv', ',', 'rang', 'legal', 'oblig', 'job', 'preserv', '.']

 TOTAL PORTER STEM WORDS ==> 36



 ---- SNOWBALL STEMMING ----

['obvious', 'answer', ':', 'routin', 'action', '(', 'press', 'button', 'key', 'standard', 'command', ')', 'quicker', 'conveni', ':', 'communic', 'strict', 'formal', 'languag', 'reliabl', ',', 'precis', ',', 'subtl', ':', 'ovemd', 'requir', 'human', 'involv', ',', 'rang', 'legal', 'oblig', 'job', 'preserv', '.']

 TOTAL SNOWBALL STEM WORDS ==> 36



 ---- LEMMATIZATION ----

['obvious', 'answer', ':', 'routine', 'action', '(', 'pressing', 'button', 'keying', 'standard', 'command', ')', 'quicker', 'convenient', ':', 'communication', 'strictly', 'formalized', 'language', 'reliable', ',', 'precise', ',', 'subtle', ':', 'ovemding', 'requirement', 'human', 'involvement', ',', 'ranging', 'legal', 'obligation', 'job', 'preservation', '.']

 TOTAL LEMMATIZE WORDS ==> 36

************************************************************************************************************************

235 --> These  tTim Johnson, Natural language computing: the commercial applications, Ovum LTD, London, 1985, pp. 


 ---- TOKENS ----

 ['These', 'tTim', 'Johnson', ',', 'Natural', 'language', 'computing', ':', 'the', 'commercial', 'applications', ',', 'Ovum', 'LTD', ',', 'London', ',', '1985', ',', 'pp', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('These', 'DT'), ('tTim', 'NNS'), ('Johnson', 'NNP'), (',', ','), ('Natural', 'NNP'), ('language', 'NN'), ('computing', 'NN'), (':', ':'), ('the', 'DT'), ('commercial', 'JJ'), ('applications', 'NNS'), (',', ','), ('Ovum', 'NNP'), ('LTD', 'NNP'), (',', ','), ('London', 'NNP'), (',', ','), ('1985', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['tTim', 'Johnson', ',', 'Natural', 'language', 'computing', ':', 'commercial', 'applications', ',', 'Ovum', 'LTD', ',', 'London', ',', '1985', ',', 'pp', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('tTim', 'NN'), ('Johnson', 'NNP'), (',', ','), ('Natural', 'NNP'), ('language', 'NN'), ('computing', 'NN'), (':', ':'), ('commercial', 'JJ'), ('applications', 'NNS'), (',', ','), ('Ovum', 'NNP'), ('LTD', 'NNP'), (',', ','), ('London', 'NNP'), (',', ','), ('1985', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['tTim Johnson', 'Johnson ,', ', Natural', 'Natural language', 'language computing', 'computing :', ': commercial', 'commercial applications', 'applications ,', ', Ovum', 'Ovum LTD', 'LTD ,', ', London', 'London ,', ', 1985', '1985 ,', ', pp', 'pp .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['tTim Johnson ,', 'Johnson , Natural', ', Natural language', 'Natural language computing', 'language computing :', 'computing : commercial', ': commercial applications', 'commercial applications ,', 'applications , Ovum', ', Ovum LTD', 'Ovum LTD ,', 'LTD , London', ', London ,', 'London , 1985', ', 1985 ,', '1985 , pp', ', pp .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['tTim', 'language', 'computing', 'pp'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['tTim', 'Natural']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> ['Johnson', 'Ovum LTD']
 TOTAL PERSON ENTITY --> 2 


 GPE ---> ['London']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['ttim', 'johnson', ',', 'natur', 'languag', 'comput', ':', 'commerci', 'applic', ',', 'ovum', 'ltd', ',', 'london', ',', '1985', ',', 'pp', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['ttim', 'johnson', ',', 'natur', 'languag', 'comput', ':', 'commerci', 'applic', ',', 'ovum', 'ltd', ',', 'london', ',', '1985', ',', 'pp', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['tTim', 'Johnson', ',', 'Natural', 'language', 'computing', ':', 'commercial', 'application', ',', 'Ovum', 'LTD', ',', 'London', ',', '1985', ',', 'pp', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

236 --> 45-46  489   considerations will rule out quite a number of possible applications, but the broad conclusion must be that ff the  technology is available, then it will be widely used. 


 ---- TOKENS ----

 ['45-46', '489', 'considerations', 'will', 'rule', 'out', 'quite', 'a', 'number', 'of', 'possible', 'applications', ',', 'but', 'the', 'broad', 'conclusion', 'must', 'be', 'that', 'ff', 'the', 'technology', 'is', 'available', ',', 'then', 'it', 'will', 'be', 'widely', 'used', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('45-46', 'JJ'), ('489', 'CD'), ('considerations', 'NNS'), ('will', 'MD'), ('rule', 'VB'), ('out', 'IN'), ('quite', 'RB'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('possible', 'JJ'), ('applications', 'NNS'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('broad', 'JJ'), ('conclusion', 'NN'), ('must', 'MD'), ('be', 'VB'), ('that', 'IN'), ('ff', 'VBZ'), ('the', 'DT'), ('technology', 'NN'), ('is', 'VBZ'), ('available', 'JJ'), (',', ','), ('then', 'RB'), ('it', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('widely', 'RB'), ('used', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['45-46', '489', 'considerations', 'rule', 'quite', 'number', 'possible', 'applications', ',', 'broad', 'conclusion', 'must', 'ff', 'technology', 'available', ',', 'widely', 'used', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('45-46', 'JJ'), ('489', 'CD'), ('considerations', 'NNS'), ('rule', 'NN'), ('quite', 'RB'), ('number', 'NN'), ('possible', 'JJ'), ('applications', 'NNS'), (',', ','), ('broad', 'JJ'), ('conclusion', 'NN'), ('must', 'MD'), ('ff', 'VB'), ('technology', 'NN'), ('available', 'JJ'), (',', ','), ('widely', 'RB'), ('used', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['45-46 489', '489 considerations', 'considerations rule', 'rule quite', 'quite number', 'number possible', 'possible applications', 'applications ,', ', broad', 'broad conclusion', 'conclusion must', 'must ff', 'ff technology', 'technology available', 'available ,', ', widely', 'widely used', 'used .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['45-46 489 considerations', '489 considerations rule', 'considerations rule quite', 'rule quite number', 'quite number possible', 'number possible applications', 'possible applications ,', 'applications , broad', ', broad conclusion', 'broad conclusion must', 'conclusion must ff', 'must ff technology', 'ff technology available', 'technology available ,', 'available , widely', ', widely used', 'widely used .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['rule', 'number', 'broad conclusion', 'technology'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['45-46', '489', 'consider', 'rule', 'quit', 'number', 'possibl', 'applic', ',', 'broad', 'conclus', 'must', 'ff', 'technolog', 'avail', ',', 'wide', 'use', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['45-46', '489', 'consider', 'rule', 'quit', 'number', 'possibl', 'applic', ',', 'broad', 'conclus', 'must', 'ff', 'technolog', 'avail', ',', 'wide', 'use', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['45-46', '489', 'consideration', 'rule', 'quite', 'number', 'possible', 'application', ',', 'broad', 'conclusion', 'must', 'ff', 'technology', 'available', ',', 'widely', 'used', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

237 --> We illustrate the conclusion above in the following three subsections. 


 ---- TOKENS ----

 ['We', 'illustrate', 'the', 'conclusion', 'above', 'in', 'the', 'following', 'three', 'subsections', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('We', 'PRP'), ('illustrate', 'VBP'), ('the', 'DT'), ('conclusion', 'NN'), ('above', 'IN'), ('in', 'IN'), ('the', 'DT'), ('following', 'JJ'), ('three', 'CD'), ('subsections', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['illustrate', 'conclusion', 'following', 'three', 'subsections', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('illustrate', 'JJ'), ('conclusion', 'NN'), ('following', 'VBG'), ('three', 'CD'), ('subsections', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['illustrate conclusion', 'conclusion following', 'following three', 'three subsections', 'subsections .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['illustrate conclusion following', 'conclusion following three', 'following three subsections', 'three subsections .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 ['illustrate conclusion'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['illustr', 'conclus', 'follow', 'three', 'subsect', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['illustr', 'conclus', 'follow', 'three', 'subsect', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['illustrate', 'conclusion', 'following', 'three', 'subsection', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

238 --> A second way to view impact is to  quantify the potential marketplace. 


 ---- TOKENS ----

 ['A', 'second', 'way', 'to', 'view', 'impact', 'is', 'to', 'quantify', 'the', 'potential', 'marketplace', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('A', 'DT'), ('second', 'JJ'), ('way', 'NN'), ('to', 'TO'), ('view', 'VB'), ('impact', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('quantify', 'VB'), ('the', 'DT'), ('potential', 'JJ'), ('marketplace', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['second', 'way', 'view', 'impact', 'quantify', 'potential', 'marketplace', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('second', 'JJ'), ('way', 'NN'), ('view', 'NN'), ('impact', 'NN'), ('quantify', 'VB'), ('potential', 'JJ'), ('marketplace', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['second way', 'way view', 'view impact', 'impact quantify', 'quantify potential', 'potential marketplace', 'marketplace .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['second way view', 'way view impact', 'view impact quantify', 'impact quantify potential', 'quantify potential marketplace', 'potential marketplace .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['second way', 'view', 'impact', 'potential marketplace'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['second', 'way', 'view', 'impact', 'quantifi', 'potenti', 'marketplac', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['second', 'way', 'view', 'impact', 'quantifi', 'potenti', 'marketplac', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['second', 'way', 'view', 'impact', 'quantify', 'potential', 'marketplace', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

239 --> We report on this approach in Section 4.1.6. 


 ---- TOKENS ----

 ['We', 'report', 'on', 'this', 'approach', 'in', 'Section', '4.1.6', '.'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('We', 'PRP'), ('report', 'VBP'), ('on', 'IN'), ('this', 'DT'), ('approach', 'NN'), ('in', 'IN'), ('Section', 'NNP'), ('4.1.6', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['report', 'approach', 'Section', '4.1.6', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('report', 'NN'), ('approach', 'NN'), ('Section', 'NN'), ('4.1.6', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['report approach', 'approach Section', 'Section 4.1.6', '4.1.6 .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['report approach Section', 'approach Section 4.1.6', 'Section 4.1.6 .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 ['report', 'approach', 'Section'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['report', 'approach', 'section', '4.1.6', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['report', 'approach', 'section', '4.1.6', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['report', 'approach', 'Section', '4.1.6', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

240 --> 4.1.1. 


 ---- TOKENS ----

 ['4.1.1', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('4.1.1', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4.1.1', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('4.1.1', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4.1.1 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4.1.1', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['4.1.1', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['4.1.1', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

241 --> Human.machine  Interaction Systems  It is difficult to overestimate or overstate the technical, scientific, and socio-economic value of an effective  and efficient means of human-machine interaction. 


 ---- TOKENS ----

 ['Human.machine', 'Interaction', 'Systems', 'It', 'is', 'difficult', 'to', 'overestimate', 'or', 'overstate', 'the', 'technical', ',', 'scientific', ',', 'and', 'socio-economic', 'value', 'of', 'an', 'effective', 'and', 'efficient', 'means', 'of', 'human-machine', 'interaction', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('Human.machine', 'NNP'), ('Interaction', 'NNP'), ('Systems', 'NNPS'), ('It', 'PRP'), ('is', 'VBZ'), ('difficult', 'JJ'), ('to', 'TO'), ('overestimate', 'VB'), ('or', 'CC'), ('overstate', 'VB'), ('the', 'DT'), ('technical', 'JJ'), (',', ','), ('scientific', 'JJ'), (',', ','), ('and', 'CC'), ('socio-economic', 'JJ'), ('value', 'NN'), ('of', 'IN'), ('an', 'DT'), ('effective', 'JJ'), ('and', 'CC'), ('efficient', 'JJ'), ('means', 'NNS'), ('of', 'IN'), ('human-machine', 'JJ'), ('interaction', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Human.machine', 'Interaction', 'Systems', 'difficult', 'overestimate', 'overstate', 'technical', ',', 'scientific', ',', 'socio-economic', 'value', 'effective', 'efficient', 'means', 'human-machine', 'interaction', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Human.machine', 'NNP'), ('Interaction', 'NNP'), ('Systems', 'NNP'), ('difficult', 'JJ'), ('overestimate', 'JJ'), ('overstate', 'NN'), ('technical', 'JJ'), (',', ','), ('scientific', 'JJ'), (',', ','), ('socio-economic', 'JJ'), ('value', 'NN'), ('effective', 'JJ'), ('efficient', 'JJ'), ('means', 'VBZ'), ('human-machine', 'JJ'), ('interaction', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Human.machine Interaction', 'Interaction Systems', 'Systems difficult', 'difficult overestimate', 'overestimate overstate', 'overstate technical', 'technical ,', ', scientific', 'scientific ,', ', socio-economic', 'socio-economic value', 'value effective', 'effective efficient', 'efficient means', 'means human-machine', 'human-machine interaction', 'interaction .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Human.machine Interaction Systems', 'Interaction Systems difficult', 'Systems difficult overestimate', 'difficult overestimate overstate', 'overestimate overstate technical', 'overstate technical ,', 'technical , scientific', ', scientific ,', 'scientific , socio-economic', ', socio-economic value', 'socio-economic value effective', 'value effective efficient', 'effective efficient means', 'efficient means human-machine', 'means human-machine interaction', 'human-machine interaction .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['difficult overestimate overstate', 'socio-economic value', 'human-machine interaction'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['human.machin', 'interact', 'system', 'difficult', 'overestim', 'overst', 'technic', ',', 'scientif', ',', 'socio-econom', 'valu', 'effect', 'effici', 'mean', 'human-machin', 'interact', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['human.machin', 'interact', 'system', 'difficult', 'overestim', 'overst', 'technic', ',', 'scientif', ',', 'socio-econom', 'valu', 'effect', 'effici', 'mean', 'human-machin', 'interact', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Human.machine', 'Interaction', 'Systems', 'difficult', 'overestimate', 'overstate', 'technical', ',', 'scientific', ',', 'socio-economic', 'value', 'effective', 'efficient', 'mean', 'human-machine', 'interaction', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

242 --> Even so, it is easy to lose sight of the importance of the interface  in the effort to develop some underlying functionality. 


 ---- TOKENS ----

 ['Even', 'so', ',', 'it', 'is', 'easy', 'to', 'lose', 'sight', 'of', 'the', 'importance', 'of', 'the', 'interface', 'in', 'the', 'effort', 'to', 'develop', 'some', 'underlying', 'functionality', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('Even', 'RB'), ('so', 'RB'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('easy', 'JJ'), ('to', 'TO'), ('lose', 'VB'), ('sight', 'NN'), ('of', 'IN'), ('the', 'DT'), ('importance', 'NN'), ('of', 'IN'), ('the', 'DT'), ('interface', 'NN'), ('in', 'IN'), ('the', 'DT'), ('effort', 'NN'), ('to', 'TO'), ('develop', 'VB'), ('some', 'DT'), ('underlying', 'JJ'), ('functionality', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Even', ',', 'easy', 'lose', 'sight', 'importance', 'interface', 'effort', 'develop', 'underlying', 'functionality', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Even', 'RB'), (',', ','), ('easy', 'JJ'), ('lose', 'JJ'), ('sight', 'NN'), ('importance', 'NN'), ('interface', 'NN'), ('effort', 'NN'), ('develop', 'VB'), ('underlying', 'JJ'), ('functionality', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Even ,', ', easy', 'easy lose', 'lose sight', 'sight importance', 'importance interface', 'interface effort', 'effort develop', 'develop underlying', 'underlying functionality', 'functionality .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Even , easy', ', easy lose', 'easy lose sight', 'lose sight importance', 'sight importance interface', 'importance interface effort', 'interface effort develop', 'effort develop underlying', 'develop underlying functionality', 'underlying functionality .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['easy lose sight', 'importance', 'interface', 'effort', 'underlying functionality'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['even', ',', 'easi', 'lose', 'sight', 'import', 'interfac', 'effort', 'develop', 'underli', 'function', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['even', ',', 'easi', 'lose', 'sight', 'import', 'interfac', 'effort', 'develop', 'under', 'function', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Even', ',', 'easy', 'lose', 'sight', 'importance', 'interface', 'effort', 'develop', 'underlying', 'functionality', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

243 --> Indeed, it is worth pointing out that the ideal interface is  "invisible," in the sense that users find it so natural and easy to use that they are never aware of the interface itself. 


 ---- TOKENS ----

 ['Indeed', ',', 'it', 'is', 'worth', 'pointing', 'out', 'that', 'the', 'ideal', 'interface', 'is', '``', 'invisible', ',', "''", 'in', 'the', 'sense', 'that', 'users', 'find', 'it', 'so', 'natural', 'and', 'easy', 'to', 'use', 'that', 'they', 'are', 'never', 'aware', 'of', 'the', 'interface', 'itself', '.'] 

 TOTAL TOKENS ==> 39

 ---- POST ----

 [('Indeed', 'RB'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('worth', 'JJ'), ('pointing', 'VBG'), ('out', 'RP'), ('that', 'IN'), ('the', 'DT'), ('ideal', 'JJ'), ('interface', 'NN'), ('is', 'VBZ'), ('``', '``'), ('invisible', 'JJ'), (',', ','), ("''", "''"), ('in', 'IN'), ('the', 'DT'), ('sense', 'NN'), ('that', 'IN'), ('users', 'NNS'), ('find', 'VBP'), ('it', 'PRP'), ('so', 'RB'), ('natural', 'JJ'), ('and', 'CC'), ('easy', 'JJ'), ('to', 'TO'), ('use', 'VB'), ('that', 'IN'), ('they', 'PRP'), ('are', 'VBP'), ('never', 'RB'), ('aware', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('interface', 'NN'), ('itself', 'PRP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Indeed', ',', 'worth', 'pointing', 'ideal', 'interface', '``', 'invisible', ',', "''", 'sense', 'users', 'find', 'natural', 'easy', 'use', 'never', 'aware', 'interface', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('Indeed', 'RB'), (',', ','), ('worth', 'JJ'), ('pointing', 'VBG'), ('ideal', 'JJ'), ('interface', 'NN'), ('``', '``'), ('invisible', 'JJ'), (',', ','), ("''", "''"), ('sense', 'NN'), ('users', 'NNS'), ('find', 'VBP'), ('natural', 'JJ'), ('easy', 'JJ'), ('use', 'NN'), ('never', 'RB'), ('aware', 'JJ'), ('interface', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Indeed ,', ', worth', 'worth pointing', 'pointing ideal', 'ideal interface', 'interface ``', '`` invisible', 'invisible ,', ", ''", "'' sense", 'sense users', 'users find', 'find natural', 'natural easy', 'easy use', 'use never', 'never aware', 'aware interface', 'interface .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['Indeed , worth', ', worth pointing', 'worth pointing ideal', 'pointing ideal interface', 'ideal interface ``', 'interface `` invisible', '`` invisible ,', "invisible , ''", ", '' sense", "'' sense users", 'sense users find', 'users find natural', 'find natural easy', 'natural easy use', 'easy use never', 'use never aware', 'never aware interface', 'aware interface .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['ideal interface', 'sense', 'natural easy use', 'aware interface'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['inde', ',', 'worth', 'point', 'ideal', 'interfac', '``', 'invis', ',', "''", 'sens', 'user', 'find', 'natur', 'easi', 'use', 'never', 'awar', 'interfac', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['inde', ',', 'worth', 'point', 'ideal', 'interfac', '``', 'invis', ',', "''", 'sens', 'user', 'find', 'natur', 'easi', 'use', 'never', 'awar', 'interfac', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['Indeed', ',', 'worth', 'pointing', 'ideal', 'interface', '``', 'invisible', ',', "''", 'sense', 'user', 'find', 'natural', 'easy', 'use', 'never', 'aware', 'interface', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

244 --> Such interfaces will make computers usable by everyone, without special training. 


 ---- TOKENS ----

 ['Such', 'interfaces', 'will', 'make', 'computers', 'usable', 'by', 'everyone', ',', 'without', 'special', 'training', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Such', 'JJ'), ('interfaces', 'NNS'), ('will', 'MD'), ('make', 'VB'), ('computers', 'NNS'), ('usable', 'JJ'), ('by', 'IN'), ('everyone', 'NN'), (',', ','), ('without', 'IN'), ('special', 'JJ'), ('training', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['interfaces', 'make', 'computers', 'usable', 'everyone', ',', 'without', 'special', 'training', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('interfaces', 'NNS'), ('make', 'VBP'), ('computers', 'NNS'), ('usable', 'JJ'), ('everyone', 'NN'), (',', ','), ('without', 'IN'), ('special', 'JJ'), ('training', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['interfaces make', 'make computers', 'computers usable', 'usable everyone', 'everyone ,', ', without', 'without special', 'special training', 'training .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['interfaces make computers', 'make computers usable', 'computers usable everyone', 'usable everyone ,', 'everyone , without', ', without special', 'without special training', 'special training .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['usable everyone', 'special training'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['interfac', 'make', 'comput', 'usabl', 'everyon', ',', 'without', 'special', 'train', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['interfac', 'make', 'comput', 'usabl', 'everyon', ',', 'without', 'special', 'train', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['interface', 'make', 'computer', 'usable', 'everyone', ',', 'without', 'special', 'training', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

245 --> Components of this work could  be incorporated into virtually every human-machine system developed or supported by the government. 


 ---- TOKENS ----

 ['Components', 'of', 'this', 'work', 'could', 'be', 'incorporated', 'into', 'virtually', 'every', 'human-machine', 'system', 'developed', 'or', 'supported', 'by', 'the', 'government', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Components', 'NNS'), ('of', 'IN'), ('this', 'DT'), ('work', 'NN'), ('could', 'MD'), ('be', 'VB'), ('incorporated', 'VBN'), ('into', 'IN'), ('virtually', 'RB'), ('every', 'DT'), ('human-machine', 'NN'), ('system', 'NN'), ('developed', 'VBD'), ('or', 'CC'), ('supported', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('government', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Components', 'work', 'could', 'incorporated', 'virtually', 'every', 'human-machine', 'system', 'developed', 'supported', 'government', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Components', 'NNS'), ('work', 'NN'), ('could', 'MD'), ('incorporated', 'VB'), ('virtually', 'RB'), ('every', 'DT'), ('human-machine', 'NN'), ('system', 'NN'), ('developed', 'VBD'), ('supported', 'JJ'), ('government', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Components work', 'work could', 'could incorporated', 'incorporated virtually', 'virtually every', 'every human-machine', 'human-machine system', 'system developed', 'developed supported', 'supported government', 'government .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Components work could', 'work could incorporated', 'could incorporated virtually', 'incorporated virtually every', 'virtually every human-machine', 'every human-machine system', 'human-machine system developed', 'system developed supported', 'developed supported government', 'supported government .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['work', 'every human-machine', 'system', 'supported government'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['compon', 'work', 'could', 'incorpor', 'virtual', 'everi', 'human-machin', 'system', 'develop', 'support', 'govern', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['compon', 'work', 'could', 'incorpor', 'virtual', 'everi', 'human-machin', 'system', 'develop', 'support', 'govern', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Components', 'work', 'could', 'incorporated', 'virtually', 'every', 'human-machine', 'system', 'developed', 'supported', 'government', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

246 --> Just as  independent menu, graphic, text, and speech I/0 capabilities have evolved from DARPA-supported work, so wLll the  integrated, multimodal problem-solving environments made possible by work on interfaces become commonplace. 


 ---- TOKENS ----

 ['Just', 'as', 'independent', 'menu', ',', 'graphic', ',', 'text', ',', 'and', 'speech', 'I/0', 'capabilities', 'have', 'evolved', 'from', 'DARPA-supported', 'work', ',', 'so', 'wLll', 'the', 'integrated', ',', 'multimodal', 'problem-solving', 'environments', 'made', 'possible', 'by', 'work', 'on', 'interfaces', 'become', 'commonplace', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('Just', 'RB'), ('as', 'IN'), ('independent', 'JJ'), ('menu', 'NN'), (',', ','), ('graphic', 'JJ'), (',', ','), ('text', 'JJ'), (',', ','), ('and', 'CC'), ('speech', 'NN'), ('I/0', 'NNP'), ('capabilities', 'NNS'), ('have', 'VBP'), ('evolved', 'VBN'), ('from', 'IN'), ('DARPA-supported', 'NNP'), ('work', 'NN'), (',', ','), ('so', 'RB'), ('wLll', 'IN'), ('the', 'DT'), ('integrated', 'VBN'), (',', ','), ('multimodal', 'JJ'), ('problem-solving', 'NN'), ('environments', 'NNS'), ('made', 'VBN'), ('possible', 'JJ'), ('by', 'IN'), ('work', 'NN'), ('on', 'IN'), ('interfaces', 'NNS'), ('become', 'VBN'), ('commonplace', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['independent', 'menu', ',', 'graphic', ',', 'text', ',', 'speech', 'I/0', 'capabilities', 'evolved', 'DARPA-supported', 'work', ',', 'wLll', 'integrated', ',', 'multimodal', 'problem-solving', 'environments', 'made', 'possible', 'work', 'interfaces', 'become', 'commonplace', '.']

 TOTAL FILTERED TOKENS ==>  27

 ---- POST FOR FILTERED TOKENS ----

 [('independent', 'JJ'), ('menu', 'NN'), (',', ','), ('graphic', 'JJ'), (',', ','), ('text', 'JJ'), (',', ','), ('speech', 'JJ'), ('I/0', 'NNP'), ('capabilities', 'NNS'), ('evolved', 'VBD'), ('DARPA-supported', 'JJ'), ('work', 'NN'), (',', ','), ('wLll', 'RB'), ('integrated', 'VBN'), (',', ','), ('multimodal', 'JJ'), ('problem-solving', 'NN'), ('environments', 'NNS'), ('made', 'VBD'), ('possible', 'JJ'), ('work', 'NN'), ('interfaces', 'NNS'), ('become', 'VBP'), ('commonplace', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['independent menu', 'menu ,', ', graphic', 'graphic ,', ', text', 'text ,', ', speech', 'speech I/0', 'I/0 capabilities', 'capabilities evolved', 'evolved DARPA-supported', 'DARPA-supported work', 'work ,', ', wLll', 'wLll integrated', 'integrated ,', ', multimodal', 'multimodal problem-solving', 'problem-solving environments', 'environments made', 'made possible', 'possible work', 'work interfaces', 'interfaces become', 'become commonplace', 'commonplace .'] 

 TOTAL BIGRAMS --> 26 



 ---- TRI-GRAMS ---- 

 ['independent menu ,', 'menu , graphic', ', graphic ,', 'graphic , text', ', text ,', 'text , speech', ', speech I/0', 'speech I/0 capabilities', 'I/0 capabilities evolved', 'capabilities evolved DARPA-supported', 'evolved DARPA-supported work', 'DARPA-supported work ,', 'work , wLll', ', wLll integrated', 'wLll integrated ,', 'integrated , multimodal', ', multimodal problem-solving', 'multimodal problem-solving environments', 'problem-solving environments made', 'environments made possible', 'made possible work', 'possible work interfaces', 'work interfaces become', 'interfaces become commonplace', 'become commonplace .'] 

 TOTAL TRIGRAMS --> 25 



 ---- NOUN PHRASES ---- 

 ['independent menu', 'DARPA-supported work', 'multimodal problem-solving', 'possible work', 'commonplace'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['independ', 'menu', ',', 'graphic', ',', 'text', ',', 'speech', 'i/0', 'capabl', 'evolv', 'darpa-support', 'work', ',', 'wlll', 'integr', ',', 'multimod', 'problem-solv', 'environ', 'made', 'possibl', 'work', 'interfac', 'becom', 'commonplac', '.']

 TOTAL PORTER STEM WORDS ==> 27



 ---- SNOWBALL STEMMING ----

['independ', 'menu', ',', 'graphic', ',', 'text', ',', 'speech', 'i/0', 'capabl', 'evolv', 'darpa-support', 'work', ',', 'wlll', 'integr', ',', 'multimod', 'problem-solv', 'environ', 'made', 'possibl', 'work', 'interfac', 'becom', 'commonplac', '.']

 TOTAL SNOWBALL STEM WORDS ==> 27



 ---- LEMMATIZATION ----

['independent', 'menu', ',', 'graphic', ',', 'text', ',', 'speech', 'I/0', 'capability', 'evolved', 'DARPA-supported', 'work', ',', 'wLll', 'integrated', ',', 'multimodal', 'problem-solving', 'environment', 'made', 'possible', 'work', 'interface', 'become', 'commonplace', '.']

 TOTAL LEMMATIZE WORDS ==> 27

************************************************************************************************************************

247 --> 4.1.2. 


 ---- TOKENS ----

 ['4.1.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('4.1.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4.1.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('4.1.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4.1.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4.1.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['4.1.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['4.1.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

248 --> Reading And Writing Text  Virtually all workplaces are inundated by documents, forms, messages, memos, and reference archives. 


 ---- TOKENS ----

 ['Reading', 'And', 'Writing', 'Text', 'Virtually', 'all', 'workplaces', 'are', 'inundated', 'by', 'documents', ',', 'forms', ',', 'messages', ',', 'memos', ',', 'and', 'reference', 'archives', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Reading', 'VBG'), ('And', 'CC'), ('Writing', 'VBG'), ('Text', 'NNP'), ('Virtually', 'NNP'), ('all', 'DT'), ('workplaces', 'NNS'), ('are', 'VBP'), ('inundated', 'VBN'), ('by', 'IN'), ('documents', 'NNS'), (',', ','), ('forms', 'NNS'), (',', ','), ('messages', 'NNS'), (',', ','), ('memos', 'NNS'), (',', ','), ('and', 'CC'), ('reference', 'NN'), ('archives', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Reading', 'Writing', 'Text', 'Virtually', 'workplaces', 'inundated', 'documents', ',', 'forms', ',', 'messages', ',', 'memos', ',', 'reference', 'archives', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Reading', 'VBG'), ('Writing', 'VBG'), ('Text', 'NNP'), ('Virtually', 'NNP'), ('workplaces', 'NNS'), ('inundated', 'VBD'), ('documents', 'NNS'), (',', ','), ('forms', 'NNS'), (',', ','), ('messages', 'NNS'), (',', ','), ('memos', 'NNS'), (',', ','), ('reference', 'NN'), ('archives', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Reading Writing', 'Writing Text', 'Text Virtually', 'Virtually workplaces', 'workplaces inundated', 'inundated documents', 'documents ,', ', forms', 'forms ,', ', messages', 'messages ,', ', memos', 'memos ,', ', reference', 'reference archives', 'archives .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Reading Writing Text', 'Writing Text Virtually', 'Text Virtually workplaces', 'Virtually workplaces inundated', 'workplaces inundated documents', 'inundated documents ,', 'documents , forms', ', forms ,', 'forms , messages', ', messages ,', 'messages , memos', ', memos ,', 'memos , reference', ', reference archives', 'reference archives .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['reference'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Text Virtually']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['read', 'write', 'text', 'virtual', 'workplac', 'inund', 'document', ',', 'form', ',', 'messag', ',', 'memo', ',', 'refer', 'archiv', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['read', 'write', 'text', 'virtual', 'workplac', 'inund', 'document', ',', 'form', ',', 'messag', ',', 'memo', ',', 'refer', 'archiv', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Reading', 'Writing', 'Text', 'Virtually', 'workplace', 'inundated', 'document', ',', 'form', ',', 'message', ',', 'memo', ',', 'reference', 'archive', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

249 --> With far more computing power and memory at the fingertips of office staff, with the rapid growth in networks, and  with the demand for timely information, it is not wild speculation to foresee a crisis of information gridlock in whole  organizations. 


 ---- TOKENS ----

 ['With', 'far', 'more', 'computing', 'power', 'and', 'memory', 'at', 'the', 'fingertips', 'of', 'office', 'staff', ',', 'with', 'the', 'rapid', 'growth', 'in', 'networks', ',', 'and', 'with', 'the', 'demand', 'for', 'timely', 'information', ',', 'it', 'is', 'not', 'wild', 'speculation', 'to', 'foresee', 'a', 'crisis', 'of', 'information', 'gridlock', 'in', 'whole', 'organizations', '.'] 

 TOTAL TOKENS ==> 45

 ---- POST ----

 [('With', 'IN'), ('far', 'RB'), ('more', 'RBR'), ('computing', 'JJ'), ('power', 'NN'), ('and', 'CC'), ('memory', 'NN'), ('at', 'IN'), ('the', 'DT'), ('fingertips', 'NNS'), ('of', 'IN'), ('office', 'NN'), ('staff', 'NN'), (',', ','), ('with', 'IN'), ('the', 'DT'), ('rapid', 'JJ'), ('growth', 'NN'), ('in', 'IN'), ('networks', 'NNS'), (',', ','), ('and', 'CC'), ('with', 'IN'), ('the', 'DT'), ('demand', 'NN'), ('for', 'IN'), ('timely', 'JJ'), ('information', 'NN'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('not', 'RB'), ('wild', 'JJ'), ('speculation', 'NN'), ('to', 'TO'), ('foresee', 'VB'), ('a', 'DT'), ('crisis', 'NN'), ('of', 'IN'), ('information', 'NN'), ('gridlock', 'NN'), ('in', 'IN'), ('whole', 'JJ'), ('organizations', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['far', 'computing', 'power', 'memory', 'fingertips', 'office', 'staff', ',', 'rapid', 'growth', 'networks', ',', 'demand', 'timely', 'information', ',', 'wild', 'speculation', 'foresee', 'crisis', 'information', 'gridlock', 'whole', 'organizations', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('far', 'RB'), ('computing', 'VBG'), ('power', 'NN'), ('memory', 'NN'), ('fingertips', 'NNS'), ('office', 'NN'), ('staff', 'NN'), (',', ','), ('rapid', 'JJ'), ('growth', 'NN'), ('networks', 'NNS'), (',', ','), ('demand', 'NN'), ('timely', 'JJ'), ('information', 'NN'), (',', ','), ('wild', 'JJ'), ('speculation', 'NN'), ('foresee', 'NN'), ('crisis', 'NN'), ('information', 'NN'), ('gridlock', 'NN'), ('whole', 'JJ'), ('organizations', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['far computing', 'computing power', 'power memory', 'memory fingertips', 'fingertips office', 'office staff', 'staff ,', ', rapid', 'rapid growth', 'growth networks', 'networks ,', ', demand', 'demand timely', 'timely information', 'information ,', ', wild', 'wild speculation', 'speculation foresee', 'foresee crisis', 'crisis information', 'information gridlock', 'gridlock whole', 'whole organizations', 'organizations .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['far computing power', 'computing power memory', 'power memory fingertips', 'memory fingertips office', 'fingertips office staff', 'office staff ,', 'staff , rapid', ', rapid growth', 'rapid growth networks', 'growth networks ,', 'networks , demand', ', demand timely', 'demand timely information', 'timely information ,', 'information , wild', ', wild speculation', 'wild speculation foresee', 'speculation foresee crisis', 'foresee crisis information', 'crisis information gridlock', 'information gridlock whole', 'gridlock whole organizations', 'whole organizations .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['power', 'memory', 'office', 'staff', 'rapid growth', 'demand', 'timely information', 'wild speculation', 'foresee', 'crisis', 'information', 'gridlock'] 

 TOTAL NOUN PHRASES --> 12 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['far', 'comput', 'power', 'memori', 'fingertip', 'offic', 'staff', ',', 'rapid', 'growth', 'network', ',', 'demand', 'time', 'inform', ',', 'wild', 'specul', 'forese', 'crisi', 'inform', 'gridlock', 'whole', 'organ', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['far', 'comput', 'power', 'memori', 'fingertip', 'offic', 'staff', ',', 'rapid', 'growth', 'network', ',', 'demand', 'time', 'inform', ',', 'wild', 'specul', 'forese', 'crisi', 'inform', 'gridlock', 'whole', 'organ', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['far', 'computing', 'power', 'memory', 'fingertip', 'office', 'staff', ',', 'rapid', 'growth', 'network', ',', 'demand', 'timely', 'information', ',', 'wild', 'speculation', 'foresee', 'crisis', 'information', 'gridlock', 'whole', 'organization', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

250 --> Those who can digest the necessary information first will have the advantage in the economic,  political, and military battles of the future. 


 ---- TOKENS ----

 ['Those', 'who', 'can', 'digest', 'the', 'necessary', 'information', 'first', 'will', 'have', 'the', 'advantage', 'in', 'the', 'economic', ',', 'political', ',', 'and', 'military', 'battles', 'of', 'the', 'future', '.'] 

 TOTAL TOKENS ==> 25

 ---- POST ----

 [('Those', 'DT'), ('who', 'WP'), ('can', 'MD'), ('digest', 'VB'), ('the', 'DT'), ('necessary', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('will', 'MD'), ('have', 'VB'), ('the', 'DT'), ('advantage', 'NN'), ('in', 'IN'), ('the', 'DT'), ('economic', 'JJ'), (',', ','), ('political', 'JJ'), (',', ','), ('and', 'CC'), ('military', 'JJ'), ('battles', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('future', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['digest', 'necessary', 'information', 'first', 'advantage', 'economic', ',', 'political', ',', 'military', 'battles', 'future', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('digest', 'RB'), ('necessary', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('advantage', 'JJ'), ('economic', 'JJ'), (',', ','), ('political', 'JJ'), (',', ','), ('military', 'JJ'), ('battles', 'NNS'), ('future', 'VBP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['digest necessary', 'necessary information', 'information first', 'first advantage', 'advantage economic', 'economic ,', ', political', 'political ,', ', military', 'military battles', 'battles future', 'future .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['digest necessary information', 'necessary information first', 'information first advantage', 'first advantage economic', 'advantage economic ,', 'economic , political', ', political ,', 'political , military', ', military battles', 'military battles future', 'battles future .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['necessary information'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['digest', 'necessari', 'inform', 'first', 'advantag', 'econom', ',', 'polit', ',', 'militari', 'battl', 'futur', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['digest', 'necessari', 'inform', 'first', 'advantag', 'econom', ',', 'polit', ',', 'militari', 'battl', 'futur', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['digest', 'necessary', 'information', 'first', 'advantage', 'economic', ',', 'political', ',', 'military', 'battle', 'future', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

251 --> The problem is not merely one of ingesting new information, though;  productivity in retrieving, editing, maintaining, and mat ing  information is also critical. 


 ---- TOKENS ----

 ['The', 'problem', 'is', 'not', 'merely', 'one', 'of', 'ingesting', 'new', 'information', ',', 'though', ';', 'productivity', 'in', 'retrieving', ',', 'editing', ',', 'maintaining', ',', 'and', 'mat', 'ing', 'information', 'is', 'also', 'critical', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('The', 'DT'), ('problem', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('merely', 'RB'), ('one', 'CD'), ('of', 'IN'), ('ingesting', 'VBG'), ('new', 'JJ'), ('information', 'NN'), (',', ','), ('though', 'RB'), (';', ':'), ('productivity', 'NN'), ('in', 'IN'), ('retrieving', 'NN'), (',', ','), ('editing', 'VBG'), (',', ','), ('maintaining', 'VBG'), (',', ','), ('and', 'CC'), ('mat', 'VB'), ('ing', 'VBG'), ('information', 'NN'), ('is', 'VBZ'), ('also', 'RB'), ('critical', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['problem', 'merely', 'one', 'ingesting', 'new', 'information', ',', 'though', ';', 'productivity', 'retrieving', ',', 'editing', ',', 'maintaining', ',', 'mat', 'ing', 'information', 'also', 'critical', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('problem', 'NN'), ('merely', 'RB'), ('one', 'CD'), ('ingesting', 'VBG'), ('new', 'JJ'), ('information', 'NN'), (',', ','), ('though', 'RB'), (';', ':'), ('productivity', 'NN'), ('retrieving', 'NN'), (',', ','), ('editing', 'VBG'), (',', ','), ('maintaining', 'VBG'), (',', ','), ('mat', 'FW'), ('ing', 'VBG'), ('information', 'NN'), ('also', 'RB'), ('critical', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['problem merely', 'merely one', 'one ingesting', 'ingesting new', 'new information', 'information ,', ', though', 'though ;', '; productivity', 'productivity retrieving', 'retrieving ,', ', editing', 'editing ,', ', maintaining', 'maintaining ,', ', mat', 'mat ing', 'ing information', 'information also', 'also critical', 'critical .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['problem merely one', 'merely one ingesting', 'one ingesting new', 'ingesting new information', 'new information ,', 'information , though', ', though ;', 'though ; productivity', '; productivity retrieving', 'productivity retrieving ,', 'retrieving , editing', ', editing ,', 'editing , maintaining', ', maintaining ,', 'maintaining , mat', ', mat ing', 'mat ing information', 'ing information also', 'information also critical', 'also critical .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['problem', 'new information', 'productivity', 'retrieving', 'information'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['problem', 'mere', 'one', 'ingest', 'new', 'inform', ',', 'though', ';', 'product', 'retriev', ',', 'edit', ',', 'maintain', ',', 'mat', 'ing', 'inform', 'also', 'critic', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['problem', 'mere', 'one', 'ingest', 'new', 'inform', ',', 'though', ';', 'product', 'retriev', ',', 'edit', ',', 'maintain', ',', 'mat', 'ing', 'inform', 'also', 'critic', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['problem', 'merely', 'one', 'ingesting', 'new', 'information', ',', 'though', ';', 'productivity', 'retrieving', ',', 'editing', ',', 'maintaining', ',', 'mat', 'ing', 'information', 'also', 'critical', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

252 --> Consider the potential in the area of intelligence analysis. 


 ---- TOKENS ----

 ['Consider', 'the', 'potential', 'in', 'the', 'area', 'of', 'intelligence', 'analysis', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('Consider', 'VB'), ('the', 'DT'), ('potential', 'NN'), ('in', 'IN'), ('the', 'DT'), ('area', 'NN'), ('of', 'IN'), ('intelligence', 'NN'), ('analysis', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Consider', 'potential', 'area', 'intelligence', 'analysis', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('Consider', 'VB'), ('potential', 'JJ'), ('area', 'NN'), ('intelligence', 'NN'), ('analysis', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Consider potential', 'potential area', 'area intelligence', 'intelligence analysis', 'analysis .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['Consider potential area', 'potential area intelligence', 'area intelligence analysis', 'intelligence analysis .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 ['potential area', 'intelligence', 'analysis'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['consid', 'potenti', 'area', 'intellig', 'analysi', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['consid', 'potenti', 'area', 'intellig', 'analysi', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['Consider', 'potential', 'area', 'intelligence', 'analysis', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

253 --> Impressive improvements in the means of  collecting data for intelligence analysis have far outstripped advances in technology to help the intelligence analyst  use the data collected. 


 ---- TOKENS ----

 ['Impressive', 'improvements', 'in', 'the', 'means', 'of', 'collecting', 'data', 'for', 'intelligence', 'analysis', 'have', 'far', 'outstripped', 'advances', 'in', 'technology', 'to', 'help', 'the', 'intelligence', 'analyst', 'use', 'the', 'data', 'collected', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('Impressive', 'JJ'), ('improvements', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('means', 'NNS'), ('of', 'IN'), ('collecting', 'VBG'), ('data', 'NNS'), ('for', 'IN'), ('intelligence', 'NN'), ('analysis', 'NN'), ('have', 'VBP'), ('far', 'RB'), ('outstripped', 'VBN'), ('advances', 'NNS'), ('in', 'IN'), ('technology', 'NN'), ('to', 'TO'), ('help', 'VB'), ('the', 'DT'), ('intelligence', 'NN'), ('analyst', 'NN'), ('use', 'VBP'), ('the', 'DT'), ('data', 'NNS'), ('collected', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Impressive', 'improvements', 'means', 'collecting', 'data', 'intelligence', 'analysis', 'far', 'outstripped', 'advances', 'technology', 'help', 'intelligence', 'analyst', 'use', 'data', 'collected', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Impressive', 'JJ'), ('improvements', 'NNS'), ('means', 'VBZ'), ('collecting', 'VBG'), ('data', 'NNS'), ('intelligence', 'NN'), ('analysis', 'NN'), ('far', 'RB'), ('outstripped', 'VBD'), ('advances', 'NNS'), ('technology', 'NN'), ('help', 'NN'), ('intelligence', 'VB'), ('analyst', 'NN'), ('use', 'NN'), ('data', 'NNS'), ('collected', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Impressive improvements', 'improvements means', 'means collecting', 'collecting data', 'data intelligence', 'intelligence analysis', 'analysis far', 'far outstripped', 'outstripped advances', 'advances technology', 'technology help', 'help intelligence', 'intelligence analyst', 'analyst use', 'use data', 'data collected', 'collected .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Impressive improvements means', 'improvements means collecting', 'means collecting data', 'collecting data intelligence', 'data intelligence analysis', 'intelligence analysis far', 'analysis far outstripped', 'far outstripped advances', 'outstripped advances technology', 'advances technology help', 'technology help intelligence', 'help intelligence analyst', 'intelligence analyst use', 'analyst use data', 'use data collected', 'data collected .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 ['intelligence', 'analysis', 'technology', 'help', 'analyst', 'use'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['impress', 'improv', 'mean', 'collect', 'data', 'intellig', 'analysi', 'far', 'outstrip', 'advanc', 'technolog', 'help', 'intellig', 'analyst', 'use', 'data', 'collect', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['impress', 'improv', 'mean', 'collect', 'data', 'intellig', 'analysi', 'far', 'outstrip', 'advanc', 'technolog', 'help', 'intellig', 'analyst', 'use', 'data', 'collect', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Impressive', 'improvement', 'mean', 'collecting', 'data', 'intelligence', 'analysis', 'far', 'outstripped', 'advance', 'technology', 'help', 'intelligence', 'analyst', 'use', 'data', 'collected', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

254 --> It is now possible to collect more free text reports than can possibly be digested. 


 ---- TOKENS ----

 ['It', 'is', 'now', 'possible', 'to', 'collect', 'more', 'free', 'text', 'reports', 'than', 'can', 'possibly', 'be', 'digested', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('It', 'PRP'), ('is', 'VBZ'), ('now', 'RB'), ('possible', 'JJ'), ('to', 'TO'), ('collect', 'VB'), ('more', 'JJR'), ('free', 'JJ'), ('text', 'NN'), ('reports', 'NNS'), ('than', 'IN'), ('can', 'MD'), ('possibly', 'RB'), ('be', 'VB'), ('digested', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['possible', 'collect', 'free', 'text', 'reports', 'possibly', 'digested', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('possible', 'JJ'), ('collect', 'JJ'), ('free', 'JJ'), ('text', 'NN'), ('reports', 'NNS'), ('possibly', 'RB'), ('digested', 'VBD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['possible collect', 'collect free', 'free text', 'text reports', 'reports possibly', 'possibly digested', 'digested .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['possible collect free', 'collect free text', 'free text reports', 'text reports possibly', 'reports possibly digested', 'possibly digested .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['possible collect free text'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['possibl', 'collect', 'free', 'text', 'report', 'possibl', 'digest', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['possibl', 'collect', 'free', 'text', 'report', 'possibl', 'digest', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['possible', 'collect', 'free', 'text', 'report', 'possibly', 'digested', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

255 --> The reports  come in many languages, not just English. 


 ---- TOKENS ----

 ['The', 'reports', 'come', 'in', 'many', 'languages', ',', 'not', 'just', 'English', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('The', 'DT'), ('reports', 'NNS'), ('come', 'VBP'), ('in', 'IN'), ('many', 'JJ'), ('languages', 'NNS'), (',', ','), ('not', 'RB'), ('just', 'RB'), ('English', 'VB'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['reports', 'come', 'many', 'languages', ',', 'English', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('reports', 'NNS'), ('come', 'VBD'), ('many', 'JJ'), ('languages', 'NNS'), (',', ','), ('English', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['reports come', 'come many', 'many languages', 'languages ,', ', English', 'English .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['reports come many', 'come many languages', 'many languages ,', 'languages , English', ', English .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['English']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['report', 'come', 'mani', 'languag', ',', 'english', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['report', 'come', 'mani', 'languag', ',', 'english', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['report', 'come', 'many', 'language', ',', 'English', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

256 --> The availability of reports is going to grow further in the 1990s, but there  is no hope for commensurate personnel increases to deal with the availability of data. 


 ---- TOKENS ----

 ['The', 'availability', 'of', 'reports', 'is', 'going', 'to', 'grow', 'further', 'in', 'the', '1990s', ',', 'but', 'there', 'is', 'no', 'hope', 'for', 'commensurate', 'personnel', 'increases', 'to', 'deal', 'with', 'the', 'availability', 'of', 'data', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('The', 'DT'), ('availability', 'NN'), ('of', 'IN'), ('reports', 'NNS'), ('is', 'VBZ'), ('going', 'VBG'), ('to', 'TO'), ('grow', 'VB'), ('further', 'RBR'), ('in', 'IN'), ('the', 'DT'), ('1990s', 'CD'), (',', ','), ('but', 'CC'), ('there', 'EX'), ('is', 'VBZ'), ('no', 'DT'), ('hope', 'NN'), ('for', 'IN'), ('commensurate', 'NN'), ('personnel', 'NNS'), ('increases', 'VBZ'), ('to', 'TO'), ('deal', 'VB'), ('with', 'IN'), ('the', 'DT'), ('availability', 'NN'), ('of', 'IN'), ('data', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['availability', 'reports', 'going', 'grow', '1990s', ',', 'hope', 'commensurate', 'personnel', 'increases', 'deal', 'availability', 'data', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('availability', 'NN'), ('reports', 'NNS'), ('going', 'VBG'), ('grow', 'JJ'), ('1990s', 'CD'), (',', ','), ('hope', 'VBP'), ('commensurate', 'JJ'), ('personnel', 'NNS'), ('increases', 'VBZ'), ('deal', 'JJ'), ('availability', 'NN'), ('data', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['availability reports', 'reports going', 'going grow', 'grow 1990s', '1990s ,', ', hope', 'hope commensurate', 'commensurate personnel', 'personnel increases', 'increases deal', 'deal availability', 'availability data', 'data .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['availability reports going', 'reports going grow', 'going grow 1990s', 'grow 1990s ,', '1990s , hope', ', hope commensurate', 'hope commensurate personnel', 'commensurate personnel increases', 'personnel increases deal', 'increases deal availability', 'deal availability data', 'availability data .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['availability', 'deal availability'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['avail', 'report', 'go', 'grow', '1990', ',', 'hope', 'commensur', 'personnel', 'increas', 'deal', 'avail', 'data', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['avail', 'report', 'go', 'grow', '1990s', ',', 'hope', 'commensur', 'personnel', 'increas', 'deal', 'avail', 'data', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['availability', 'report', 'going', 'grow', '1990s', ',', 'hope', 'commensurate', 'personnel', 'increase', 'deal', 'availability', 'data', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

257 --> Natural language processing  seems the only hope for aiding in the selection, prioritization, filtering, and analysis of data. 


 ---- TOKENS ----

 ['Natural', 'language', 'processing', 'seems', 'the', 'only', 'hope', 'for', 'aiding', 'in', 'the', 'selection', ',', 'prioritization', ',', 'filtering', ',', 'and', 'analysis', 'of', 'data', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('seems', 'VBZ'), ('the', 'DT'), ('only', 'JJ'), ('hope', 'NN'), ('for', 'IN'), ('aiding', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('selection', 'NN'), (',', ','), ('prioritization', 'NN'), (',', ','), ('filtering', 'NN'), (',', ','), ('and', 'CC'), ('analysis', 'NN'), ('of', 'IN'), ('data', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Natural', 'language', 'processing', 'seems', 'hope', 'aiding', 'selection', ',', 'prioritization', ',', 'filtering', ',', 'analysis', 'data', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('seems', 'VBZ'), ('hope', 'VBP'), ('aiding', 'VBG'), ('selection', 'NN'), (',', ','), ('prioritization', 'NN'), (',', ','), ('filtering', 'NN'), (',', ','), ('analysis', 'NN'), ('data', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Natural language', 'language processing', 'processing seems', 'seems hope', 'hope aiding', 'aiding selection', 'selection ,', ', prioritization', 'prioritization ,', ', filtering', 'filtering ,', ', analysis', 'analysis data', 'data .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Natural language processing', 'language processing seems', 'processing seems hope', 'seems hope aiding', 'hope aiding selection', 'aiding selection ,', 'selection , prioritization', ', prioritization ,', 'prioritization , filtering', ', filtering ,', 'filtering , analysis', ', analysis data', 'analysis data .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['Natural language', 'processing', 'selection', 'prioritization', 'filtering', 'analysis'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['natur', 'languag', 'process', 'seem', 'hope', 'aid', 'select', ',', 'priorit', ',', 'filter', ',', 'analysi', 'data', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['natur', 'languag', 'process', 'seem', 'hope', 'aid', 'select', ',', 'priorit', ',', 'filter', ',', 'analysi', 'data', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Natural', 'language', 'processing', 'seems', 'hope', 'aiding', 'selection', ',', 'prioritization', ',', 'filtering', ',', 'analysis', 'data', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

258 --> The kinds of aids or utilities that would provide help are broad in scope:  • L a n g u a g e  ident i f icat ion . 


 ---- TOKENS ----

 ['The', 'kinds', 'of', 'aids', 'or', 'utilities', 'that', 'would', 'provide', 'help', 'are', 'broad', 'in', 'scope', ':', '•', 'L', 'a', 'n', 'g', 'u', 'a', 'g', 'e', 'ident', 'i', 'f', 'icat', 'ion', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('The', 'DT'), ('kinds', 'NNS'), ('of', 'IN'), ('aids', 'NNS'), ('or', 'CC'), ('utilities', 'NNS'), ('that', 'WDT'), ('would', 'MD'), ('provide', 'VB'), ('help', 'NN'), ('are', 'VBP'), ('broad', 'JJ'), ('in', 'IN'), ('scope', 'NN'), (':', ':'), ('•', 'NN'), ('L', 'VBZ'), ('a', 'DT'), ('n', 'JJ'), ('g', 'NN'), ('u', 'IN'), ('a', 'DT'), ('g', 'NN'), ('e', 'NN'), ('ident', 'NN'), ('i', 'NN'), ('f', 'VBP'), ('icat', 'JJ'), ('ion', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['kinds', 'aids', 'utilities', 'would', 'provide', 'help', 'broad', 'scope', ':', '•', 'L', 'n', 'g', 'u', 'g', 'e', 'ident', 'f', 'icat', 'ion', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('kinds', 'NNS'), ('aids', 'NNS'), ('utilities', 'NNS'), ('would', 'MD'), ('provide', 'VB'), ('help', 'NN'), ('broad', 'JJ'), ('scope', 'NN'), (':', ':'), ('•', 'JJ'), ('L', 'NNP'), ('n', 'NN'), ('g', 'NN'), ('u', 'JJ'), ('g', 'NN'), ('e', 'NN'), ('ident', 'NN'), ('f', 'NN'), ('icat', 'NN'), ('ion', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['kinds aids', 'aids utilities', 'utilities would', 'would provide', 'provide help', 'help broad', 'broad scope', 'scope :', ': •', '• L', 'L n', 'n g', 'g u', 'u g', 'g e', 'e ident', 'ident f', 'f icat', 'icat ion', 'ion .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['kinds aids utilities', 'aids utilities would', 'utilities would provide', 'would provide help', 'provide help broad', 'help broad scope', 'broad scope :', 'scope : •', ': • L', '• L n', 'L n g', 'n g u', 'g u g', 'u g e', 'g e ident', 'e ident f', 'ident f icat', 'f icat ion', 'icat ion .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['help', 'broad scope', 'n', 'g', 'u g', 'e', 'ident', 'f', 'icat', 'ion'] 

 TOTAL NOUN PHRASES --> 10 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['kind', 'aid', 'util', 'would', 'provid', 'help', 'broad', 'scope', ':', '•', 'l', 'n', 'g', 'u', 'g', 'e', 'ident', 'f', 'icat', 'ion', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['kind', 'aid', 'util', 'would', 'provid', 'help', 'broad', 'scope', ':', '•', 'l', 'n', 'g', 'u', 'g', 'e', 'ident', 'f', 'icat', 'ion', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['kind', 'aid', 'utility', 'would', 'provide', 'help', 'broad', 'scope', ':', '•', 'L', 'n', 'g', 'u', 'g', 'e', 'ident', 'f', 'icat', 'ion', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

259 --> Given a segment of free text, identifying the languages it is written in. 


 ---- TOKENS ----

 ['Given', 'a', 'segment', 'of', 'free', 'text', ',', 'identifying', 'the', 'languages', 'it', 'is', 'written', 'in', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('Given', 'VBN'), ('a', 'DT'), ('segment', 'NN'), ('of', 'IN'), ('free', 'JJ'), ('text', 'NN'), (',', ','), ('identifying', 'VBG'), ('the', 'DT'), ('languages', 'NNS'), ('it', 'PRP'), ('is', 'VBZ'), ('written', 'VBN'), ('in', 'IN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Given', 'segment', 'free', 'text', ',', 'identifying', 'languages', 'written', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Given', 'VBN'), ('segment', 'NN'), ('free', 'JJ'), ('text', 'NN'), (',', ','), ('identifying', 'VBG'), ('languages', 'NNS'), ('written', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Given segment', 'segment free', 'free text', 'text ,', ', identifying', 'identifying languages', 'languages written', 'written .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Given segment free', 'segment free text', 'free text ,', 'text , identifying', ', identifying languages', 'identifying languages written', 'languages written .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['segment', 'free text'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['given', 'segment', 'free', 'text', ',', 'identifi', 'languag', 'written', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['given', 'segment', 'free', 'text', ',', 'identifi', 'languag', 'written', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Given', 'segment', 'free', 'text', ',', 'identifying', 'language', 'written', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

260 --> • Pr ior i t i za t ion . 


 ---- TOKENS ----

 ['•', 'Pr', 'ior', 'i', 't', 'i', 'za', 't', 'ion', '.'] 

 TOTAL TOKENS ==> 10

 ---- POST ----

 [('•', 'JJ'), ('Pr', 'NNP'), ('ior', 'NN'), ('i', 'NN'), ('t', 'VBP'), ('i', 'NN'), ('za', 'VBP'), ('t', 'JJ'), ('ion', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Pr', 'ior', 'za', 'ion', '.']

 TOTAL FILTERED TOKENS ==>  6

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Pr', 'NNP'), ('ior', 'NN'), ('za', 'NN'), ('ion', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Pr', 'Pr ior', 'ior za', 'za ion', 'ion .'] 

 TOTAL BIGRAMS --> 5 



 ---- TRI-GRAMS ---- 

 ['• Pr ior', 'Pr ior za', 'ior za ion', 'za ion .'] 

 TOTAL TRIGRAMS --> 4 



 ---- NOUN PHRASES ---- 

 ['ior', 'za', 'ion'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'pr', 'ior', 'za', 'ion', '.']

 TOTAL PORTER STEM WORDS ==> 6



 ---- SNOWBALL STEMMING ----

['•', 'pr', 'ior', 'za', 'ion', '.']

 TOTAL SNOWBALL STEM WORDS ==> 6



 ---- LEMMATIZATION ----

['•', 'Pr', 'ior', 'za', 'ion', '.']

 TOTAL LEMMATIZE WORDS ==> 6

************************************************************************************************************************

261 --> Given a message (in free text), assigning a priority to it, based on message content. 


 ---- TOKENS ----

 ['Given', 'a', 'message', '(', 'in', 'free', 'text', ')', ',', 'assigning', 'a', 'priority', 'to', 'it', ',', 'based', 'on', 'message', 'content', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('Given', 'VBN'), ('a', 'DT'), ('message', 'NN'), ('(', '('), ('in', 'IN'), ('free', 'JJ'), ('text', 'NN'), (')', ')'), (',', ','), ('assigning', 'VBG'), ('a', 'DT'), ('priority', 'NN'), ('to', 'TO'), ('it', 'PRP'), (',', ','), ('based', 'VBN'), ('on', 'IN'), ('message', 'NN'), ('content', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Given', 'message', '(', 'free', 'text', ')', ',', 'assigning', 'priority', ',', 'based', 'message', 'content', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('Given', 'VBN'), ('message', 'NN'), ('(', '('), ('free', 'JJ'), ('text', 'NN'), (')', ')'), (',', ','), ('assigning', 'VBG'), ('priority', 'NN'), (',', ','), ('based', 'VBN'), ('message', 'NN'), ('content', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Given message', 'message (', '( free', 'free text', 'text )', ') ,', ', assigning', 'assigning priority', 'priority ,', ', based', 'based message', 'message content', 'content .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['Given message (', 'message ( free', '( free text', 'free text )', 'text ) ,', ') , assigning', ', assigning priority', 'assigning priority ,', 'priority , based', ', based message', 'based message content', 'message content .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['message', 'priority', 'message', 'content'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['given', 'messag', '(', 'free', 'text', ')', ',', 'assign', 'prioriti', ',', 'base', 'messag', 'content', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['given', 'messag', '(', 'free', 'text', ')', ',', 'assign', 'prioriti', ',', 'base', 'messag', 'content', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['Given', 'message', '(', 'free', 'text', ')', ',', 'assigning', 'priority', ',', 'based', 'message', 'content', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

262 --> • Rou t ing . 


 ---- TOKENS ----

 ['•', 'Rou', 't', 'ing', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('•', 'JJ'), ('Rou', 'NNP'), ('t', 'NN'), ('ing', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Rou', 'ing', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Rou', 'NNP'), ('ing', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Rou', 'Rou ing', 'ing .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['• Rou ing', 'Rou ing .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 ['ing'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'rou', 'ing', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['•', 'rou', 'ing', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['•', 'Rou', 'ing', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

263 --> Determining which offices should receive a copy of the text based on its content. 


 ---- TOKENS ----

 ['Determining', 'which', 'offices', 'should', 'receive', 'a', 'copy', 'of', 'the', 'text', 'based', 'on', 'its', 'content', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('Determining', 'VBG'), ('which', 'WDT'), ('offices', 'NNS'), ('should', 'MD'), ('receive', 'VB'), ('a', 'DT'), ('copy', 'NN'), ('of', 'IN'), ('the', 'DT'), ('text', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('its', 'PRP$'), ('content', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Determining', 'offices', 'receive', 'copy', 'text', 'based', 'content', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('Determining', 'VBG'), ('offices', 'NNS'), ('receive', 'VBP'), ('copy', 'NN'), ('text', 'NN'), ('based', 'VBN'), ('content', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Determining offices', 'offices receive', 'receive copy', 'copy text', 'text based', 'based content', 'content .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['Determining offices receive', 'offices receive copy', 'receive copy text', 'copy text based', 'text based content', 'based content .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['copy', 'text', 'content'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['determin', 'offic', 'receiv', 'copi', 'text', 'base', 'content', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['determin', 'offic', 'receiv', 'copi', 'text', 'base', 'content', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['Determining', 'office', 'receive', 'copy', 'text', 'based', 'content', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

264 --> • Gis t ing . 


 ---- TOKENS ----

 ['•', 'Gis', 't', 'ing', '.'] 

 TOTAL TOKENS ==> 5

 ---- POST ----

 [('•', 'JJ'), ('Gis', 'NNP'), ('t', 'NN'), ('ing', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Gis', 'ing', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Gis', 'NNP'), ('ing', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Gis', 'Gis ing', 'ing .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['• Gis ing', 'Gis ing .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 ['ing'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'gi', 'ing', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['•', 'gis', 'ing', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['•', 'Gis', 'ing', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

265 --> Automatically adding records to a database, given the content of free text. 


 ---- TOKENS ----

 ['Automatically', 'adding', 'records', 'to', 'a', 'database', ',', 'given', 'the', 'content', 'of', 'free', 'text', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Automatically', 'RB'), ('adding', 'VBG'), ('records', 'NNS'), ('to', 'TO'), ('a', 'DT'), ('database', 'NN'), (',', ','), ('given', 'VBN'), ('the', 'DT'), ('content', 'NN'), ('of', 'IN'), ('free', 'JJ'), ('text', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Automatically', 'adding', 'records', 'database', ',', 'given', 'content', 'free', 'text', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Automatically', 'RB'), ('adding', 'VBG'), ('records', 'NNS'), ('database', 'NN'), (',', ','), ('given', 'VBN'), ('content', 'JJ'), ('free', 'JJ'), ('text', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Automatically adding', 'adding records', 'records database', 'database ,', ', given', 'given content', 'content free', 'free text', 'text .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Automatically adding records', 'adding records database', 'records database ,', 'database , given', ', given content', 'given content free', 'content free text', 'free text .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['database', 'content free text'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['automat', 'ad', 'record', 'databas', ',', 'given', 'content', 'free', 'text', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['automat', 'ad', 'record', 'databas', ',', 'given', 'content', 'free', 'text', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Automatically', 'adding', 'record', 'database', ',', 'given', 'content', 'free', 'text', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

266 --> • Fus ion . 


 ---- TOKENS ----

 ['•', 'Fus', 'ion', '.'] 

 TOTAL TOKENS ==> 4

 ---- POST ----

 [('•', 'JJ'), ('Fus', 'NNP'), ('ion', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'Fus', 'ion', '.']

 TOTAL FILTERED TOKENS ==>  4

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('Fus', 'NNP'), ('ion', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• Fus', 'Fus ion', 'ion .'] 

 TOTAL BIGRAMS --> 3 



 ---- TRI-GRAMS ---- 

 ['• Fus ion', 'Fus ion .'] 

 TOTAL TRIGRAMS --> 2 



 ---- NOUN PHRASES ---- 

 ['ion'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'fu', 'ion', '.']

 TOTAL PORTER STEM WORDS ==> 4



 ---- SNOWBALL STEMMING ----

['•', 'fus', 'ion', '.']

 TOTAL SNOWBALL STEM WORDS ==> 4



 ---- LEMMATIZATION ----

['•', 'Fus', 'ion', '.']

 TOTAL LEMMATIZE WORDS ==> 4

************************************************************************************************************************

267 --> Recognizing that a new piece of text correlates with previously known information. 


 ---- TOKENS ----

 ['Recognizing', 'that', 'a', 'new', 'piece', 'of', 'text', 'correlates', 'with', 'previously', 'known', 'information', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('Recognizing', 'VBG'), ('that', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('piece', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('correlates', 'NNS'), ('with', 'IN'), ('previously', 'RB'), ('known', 'VBN'), ('information', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Recognizing', 'new', 'piece', 'text', 'correlates', 'previously', 'known', 'information', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Recognizing', 'VBG'), ('new', 'JJ'), ('piece', 'NN'), ('text', 'NN'), ('correlates', 'VBZ'), ('previously', 'RB'), ('known', 'VBN'), ('information', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Recognizing new', 'new piece', 'piece text', 'text correlates', 'correlates previously', 'previously known', 'known information', 'information .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Recognizing new piece', 'new piece text', 'piece text correlates', 'text correlates previously', 'correlates previously known', 'previously known information', 'known information .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['new piece', 'text', 'information'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['recogn', 'new', 'piec', 'text', 'correl', 'previous', 'known', 'inform', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['recogn', 'new', 'piec', 'text', 'correl', 'previous', 'known', 'inform', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Recognizing', 'new', 'piece', 'text', 'correlate', 'previously', 'known', 'information', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

268 --> Identification of what is new in the message, what corroborates known data, and what conflicts with  known data. 


 ---- TOKENS ----

 ['Identification', 'of', 'what', 'is', 'new', 'in', 'the', 'message', ',', 'what', 'corroborates', 'known', 'data', ',', 'and', 'what', 'conflicts', 'with', 'known', 'data', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('Identification', 'NN'), ('of', 'IN'), ('what', 'WP'), ('is', 'VBZ'), ('new', 'JJ'), ('in', 'IN'), ('the', 'DT'), ('message', 'NN'), (',', ','), ('what', 'WP'), ('corroborates', 'VBZ'), ('known', 'VBN'), ('data', 'NNS'), (',', ','), ('and', 'CC'), ('what', 'WP'), ('conflicts', 'VBZ'), ('with', 'IN'), ('known', 'VBN'), ('data', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Identification', 'new', 'message', ',', 'corroborates', 'known', 'data', ',', 'conflicts', 'known', 'data', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Identification', 'NNP'), ('new', 'JJ'), ('message', 'NN'), (',', ','), ('corroborates', 'VBZ'), ('known', 'VBN'), ('data', 'NNS'), (',', ','), ('conflicts', 'NNS'), ('known', 'VBN'), ('data', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Identification new', 'new message', 'message ,', ', corroborates', 'corroborates known', 'known data', 'data ,', ', conflicts', 'conflicts known', 'known data', 'data .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Identification new message', 'new message ,', 'message , corroborates', ', corroborates known', 'corroborates known data', 'known data ,', 'data , conflicts', ', conflicts known', 'conflicts known data', 'known data .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['new message'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['identif', 'new', 'messag', ',', 'corrobor', 'known', 'data', ',', 'conflict', 'known', 'data', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['identif', 'new', 'messag', ',', 'corrobor', 'known', 'data', ',', 'conflict', 'known', 'data', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Identification', 'new', 'message', ',', 'corroborates', 'known', 'data', ',', 'conflict', 'known', 'data', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

269 --> • R e p o r t  genera t ion . 


 ---- TOKENS ----

 ['•', 'R', 'e', 'p', 'o', 'r', 't', 'genera', 't', 'ion', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('•', 'JJ'), ('R', 'NNP'), ('e', 'NN'), ('p', 'NN'), ('o', 'NN'), ('r', 'NN'), ('t', 'NN'), ('genera', 'NN'), ('t', 'NN'), ('ion', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'R', 'e', 'p', 'r', 'genera', 'ion', '.']

 TOTAL FILTERED TOKENS ==>  8

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('R', 'NNP'), ('e', 'NN'), ('p', 'NN'), ('r', 'NN'), ('genera', 'NN'), ('ion', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• R', 'R e', 'e p', 'p r', 'r genera', 'genera ion', 'ion .'] 

 TOTAL BIGRAMS --> 7 



 ---- TRI-GRAMS ---- 

 ['• R e', 'R e p', 'e p r', 'p r genera', 'r genera ion', 'genera ion .'] 

 TOTAL TRIGRAMS --> 6 



 ---- NOUN PHRASES ---- 

 ['e', 'p', 'r', 'genera', 'ion'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'r', 'e', 'p', 'r', 'genera', 'ion', '.']

 TOTAL PORTER STEM WORDS ==> 8



 ---- SNOWBALL STEMMING ----

['•', 'r', 'e', 'p', 'r', 'genera', 'ion', '.']

 TOTAL SNOWBALL STEM WORDS ==> 8



 ---- LEMMATIZATION ----

['•', 'R', 'e', 'p', 'r', 'genus', 'ion', '.']

 TOTAL LEMMATIZE WORDS ==> 8

************************************************************************************************************************

270 --> Automatic preparation of text and tables describing a message, set of  messages, or  situation. 


 ---- TOKENS ----

 ['Automatic', 'preparation', 'of', 'text', 'and', 'tables', 'describing', 'a', 'message', ',', 'set', 'of', 'messages', ',', 'or', 'situation', '.'] 

 TOTAL TOKENS ==> 17

 ---- POST ----

 [('Automatic', 'JJ'), ('preparation', 'NN'), ('of', 'IN'), ('text', 'NN'), ('and', 'CC'), ('tables', 'NNS'), ('describing', 'VBG'), ('a', 'DT'), ('message', 'NN'), (',', ','), ('set', 'NN'), ('of', 'IN'), ('messages', 'NNS'), (',', ','), ('or', 'CC'), ('situation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Automatic', 'preparation', 'text', 'tables', 'describing', 'message', ',', 'set', 'messages', ',', 'situation', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('Automatic', 'JJ'), ('preparation', 'NN'), ('text', 'NN'), ('tables', 'NNS'), ('describing', 'VBG'), ('message', 'NN'), (',', ','), ('set', 'VBN'), ('messages', 'NNS'), (',', ','), ('situation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Automatic preparation', 'preparation text', 'text tables', 'tables describing', 'describing message', 'message ,', ', set', 'set messages', 'messages ,', ', situation', 'situation .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['Automatic preparation text', 'preparation text tables', 'text tables describing', 'tables describing message', 'describing message ,', 'message , set', ', set messages', 'set messages ,', 'messages , situation', ', situation .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['Automatic preparation', 'text', 'message', 'situation'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Automatic']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['automat', 'prepar', 'text', 'tabl', 'describ', 'messag', ',', 'set', 'messag', ',', 'situat', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['automat', 'prepar', 'text', 'tabl', 'describ', 'messag', ',', 'set', 'messag', ',', 'situat', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['Automatic', 'preparation', 'text', 'table', 'describing', 'message', ',', 'set', 'message', ',', 'situation', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

271 --> • A ler t s . 


 ---- TOKENS ----

 ['•', 'A', 'ler', 't', 's', '.'] 

 TOTAL TOKENS ==> 6

 ---- POST ----

 [('•', 'VB'), ('A', 'NNP'), ('ler', 'NN'), ('t', 'NN'), ('s', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['•', 'ler', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('•', 'JJ'), ('ler', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['• ler', 'ler .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['• ler .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 ['• ler'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['•', 'ler', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['•', 'ler', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['•', 'ler', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

272 --> Given some pre-defined criteria about the content of a knowledge base/database, sending a  message notifying that the criteria have now been met  490   4.1.3. 


 ---- TOKENS ----

 ['Given', 'some', 'pre-defined', 'criteria', 'about', 'the', 'content', 'of', 'a', 'knowledge', 'base/database', ',', 'sending', 'a', 'message', 'notifying', 'that', 'the', 'criteria', 'have', 'now', 'been', 'met', '490', '4.1.3', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Given', 'VBN'), ('some', 'DT'), ('pre-defined', 'JJ'), ('criteria', 'NNS'), ('about', 'IN'), ('the', 'DT'), ('content', 'NN'), ('of', 'IN'), ('a', 'DT'), ('knowledge', 'NN'), ('base/database', 'NN'), (',', ','), ('sending', 'VBG'), ('a', 'DT'), ('message', 'NN'), ('notifying', 'NN'), ('that', 'IN'), ('the', 'DT'), ('criteria', 'NNS'), ('have', 'VBP'), ('now', 'RB'), ('been', 'VBN'), ('met', 'VBN'), ('490', 'CD'), ('4.1.3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Given', 'pre-defined', 'criteria', 'content', 'knowledge', 'base/database', ',', 'sending', 'message', 'notifying', 'criteria', 'met', '490', '4.1.3', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('Given', 'VBN'), ('pre-defined', 'JJ'), ('criteria', 'NNS'), ('content', 'JJ'), ('knowledge', 'NN'), ('base/database', 'NN'), (',', ','), ('sending', 'VBG'), ('message', 'NN'), ('notifying', 'VBG'), ('criteria', 'NNS'), ('met', 'VBD'), ('490', 'CD'), ('4.1.3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Given pre-defined', 'pre-defined criteria', 'criteria content', 'content knowledge', 'knowledge base/database', 'base/database ,', ', sending', 'sending message', 'message notifying', 'notifying criteria', 'criteria met', 'met 490', '490 4.1.3', '4.1.3 .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['Given pre-defined criteria', 'pre-defined criteria content', 'criteria content knowledge', 'content knowledge base/database', 'knowledge base/database ,', 'base/database , sending', ', sending message', 'sending message notifying', 'message notifying criteria', 'notifying criteria met', 'criteria met 490', 'met 490 4.1.3', '490 4.1.3 .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['content knowledge', 'base', 'message'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['given', 'pre-defin', 'criteria', 'content', 'knowledg', 'base/databas', ',', 'send', 'messag', 'notifi', 'criteria', 'met', '490', '4.1.3', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['given', 'pre-defin', 'criteria', 'content', 'knowledg', 'base/databas', ',', 'send', 'messag', 'notifi', 'criteria', 'met', '490', '4.1.3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['Given', 'pre-defined', 'criterion', 'content', 'knowledge', 'base/database', ',', 'sending', 'message', 'notifying', 'criterion', 'met', '490', '4.1.3', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

273 --> Machine Translation (MT)  The need for extensive translation capabilities, whether human or machine, is becoming increasingly  important to the U.S., because of both the increasing importance of world markets to U.S. business and the  increasing role of joint military operations. 


 ---- TOKENS ----

 ['Machine', 'Translation', '(', 'MT', ')', 'The', 'need', 'for', 'extensive', 'translation', 'capabilities', ',', 'whether', 'human', 'or', 'machine', ',', 'is', 'becoming', 'increasingly', 'important', 'to', 'the', 'U.S.', ',', 'because', 'of', 'both', 'the', 'increasing', 'importance', 'of', 'world', 'markets', 'to', 'U.S.', 'business', 'and', 'the', 'increasing', 'role', 'of', 'joint', 'military', 'operations', '.'] 

 TOTAL TOKENS ==> 46

 ---- POST ----

 [('Machine', 'NN'), ('Translation', 'NNP'), ('(', '('), ('MT', 'NNP'), (')', ')'), ('The', 'DT'), ('need', 'NN'), ('for', 'IN'), ('extensive', 'JJ'), ('translation', 'NN'), ('capabilities', 'NNS'), (',', ','), ('whether', 'IN'), ('human', 'JJ'), ('or', 'CC'), ('machine', 'NN'), (',', ','), ('is', 'VBZ'), ('becoming', 'VBG'), ('increasingly', 'RB'), ('important', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('U.S.', 'NNP'), (',', ','), ('because', 'IN'), ('of', 'IN'), ('both', 'DT'), ('the', 'DT'), ('increasing', 'VBG'), ('importance', 'NN'), ('of', 'IN'), ('world', 'NN'), ('markets', 'NNS'), ('to', 'TO'), ('U.S.', 'NNP'), ('business', 'NN'), ('and', 'CC'), ('the', 'DT'), ('increasing', 'VBG'), ('role', 'NN'), ('of', 'IN'), ('joint', 'JJ'), ('military', 'JJ'), ('operations', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Machine', 'Translation', '(', 'MT', ')', 'need', 'extensive', 'translation', 'capabilities', ',', 'whether', 'human', 'machine', ',', 'becoming', 'increasingly', 'important', 'U.S.', ',', 'increasing', 'importance', 'world', 'markets', 'U.S.', 'business', 'increasing', 'role', 'joint', 'military', 'operations', '.']

 TOTAL FILTERED TOKENS ==>  31

 ---- POST FOR FILTERED TOKENS ----

 [('Machine', 'NN'), ('Translation', 'NNP'), ('(', '('), ('MT', 'NNP'), (')', ')'), ('need', 'VBP'), ('extensive', 'JJ'), ('translation', 'NN'), ('capabilities', 'NNS'), (',', ','), ('whether', 'IN'), ('human', 'JJ'), ('machine', 'NN'), (',', ','), ('becoming', 'VBG'), ('increasingly', 'RB'), ('important', 'JJ'), ('U.S.', 'NNP'), (',', ','), ('increasing', 'VBG'), ('importance', 'NN'), ('world', 'NN'), ('markets', 'NNS'), ('U.S.', 'NNP'), ('business', 'NN'), ('increasing', 'VBG'), ('role', 'NN'), ('joint', 'NN'), ('military', 'JJ'), ('operations', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Machine Translation', 'Translation (', '( MT', 'MT )', ') need', 'need extensive', 'extensive translation', 'translation capabilities', 'capabilities ,', ', whether', 'whether human', 'human machine', 'machine ,', ', becoming', 'becoming increasingly', 'increasingly important', 'important U.S.', 'U.S. ,', ', increasing', 'increasing importance', 'importance world', 'world markets', 'markets U.S.', 'U.S. business', 'business increasing', 'increasing role', 'role joint', 'joint military', 'military operations', 'operations .'] 

 TOTAL BIGRAMS --> 30 



 ---- TRI-GRAMS ---- 

 ['Machine Translation (', 'Translation ( MT', '( MT )', 'MT ) need', ') need extensive', 'need extensive translation', 'extensive translation capabilities', 'translation capabilities ,', 'capabilities , whether', ', whether human', 'whether human machine', 'human machine ,', 'machine , becoming', ', becoming increasingly', 'becoming increasingly important', 'increasingly important U.S.', 'important U.S. ,', 'U.S. , increasing', ', increasing importance', 'increasing importance world', 'importance world markets', 'world markets U.S.', 'markets U.S. business', 'U.S. business increasing', 'business increasing role', 'increasing role joint', 'role joint military', 'joint military operations', 'military operations .'] 

 TOTAL TRIGRAMS --> 29 



 ---- NOUN PHRASES ---- 

 ['Machine', 'extensive translation', 'human machine', 'importance', 'world', 'business', 'role', 'joint'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['Translation']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Machine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['U.S.', 'U.S.']
 TOTAL GPE ENTITY --> 2 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['machin', 'translat', '(', 'mt', ')', 'need', 'extens', 'translat', 'capabl', ',', 'whether', 'human', 'machin', ',', 'becom', 'increasingli', 'import', 'u.s.', ',', 'increas', 'import', 'world', 'market', 'u.s.', 'busi', 'increas', 'role', 'joint', 'militari', 'oper', '.']

 TOTAL PORTER STEM WORDS ==> 31



 ---- SNOWBALL STEMMING ----

['machin', 'translat', '(', 'mt', ')', 'need', 'extens', 'translat', 'capabl', ',', 'whether', 'human', 'machin', ',', 'becom', 'increas', 'import', 'u.s.', ',', 'increas', 'import', 'world', 'market', 'u.s.', 'busi', 'increas', 'role', 'joint', 'militari', 'oper', '.']

 TOTAL SNOWBALL STEM WORDS ==> 31



 ---- LEMMATIZATION ----

['Machine', 'Translation', '(', 'MT', ')', 'need', 'extensive', 'translation', 'capability', ',', 'whether', 'human', 'machine', ',', 'becoming', 'increasingly', 'important', 'U.S.', ',', 'increasing', 'importance', 'world', 'market', 'U.S.', 'business', 'increasing', 'role', 'joint', 'military', 'operation', '.']

 TOTAL LEMMATIZE WORDS ==> 31

************************************************************************************************************************

274 --> Aids to translation therefore can help the U.S. achieve success in an  evolving world. 


 ---- TOKENS ----

 ['Aids', 'to', 'translation', 'therefore', 'can', 'help', 'the', 'U.S.', 'achieve', 'success', 'in', 'an', 'evolving', 'world', '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('Aids', 'NNS'), ('to', 'TO'), ('translation', 'VB'), ('therefore', 'RB'), ('can', 'MD'), ('help', 'VB'), ('the', 'DT'), ('U.S.', 'NNP'), ('achieve', 'NN'), ('success', 'NN'), ('in', 'IN'), ('an', 'DT'), ('evolving', 'JJ'), ('world', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Aids', 'translation', 'therefore', 'help', 'U.S.', 'achieve', 'success', 'evolving', 'world', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('Aids', 'NNP'), ('translation', 'NN'), ('therefore', 'RB'), ('help', 'VBD'), ('U.S.', 'NNP'), ('achieve', 'VB'), ('success', 'NN'), ('evolving', 'VBG'), ('world', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Aids translation', 'translation therefore', 'therefore help', 'help U.S.', 'U.S. achieve', 'achieve success', 'success evolving', 'evolving world', 'world .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['Aids translation therefore', 'translation therefore help', 'therefore help U.S.', 'help U.S. achieve', 'U.S. achieve success', 'achieve success evolving', 'success evolving world', 'evolving world .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['translation', 'success', 'world'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Aids', 'U.S.']
 TOTAL GPE ENTITY --> 2 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['aid', 'translat', 'therefor', 'help', 'u.s.', 'achiev', 'success', 'evolv', 'world', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['aid', 'translat', 'therefor', 'help', 'u.s.', 'achiev', 'success', 'evolv', 'world', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['Aids', 'translation', 'therefore', 'help', 'U.S.', 'achieve', 'success', 'evolving', 'world', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

275 --> The potential impact of MT is indicated below by a quote: 2  Today, more than 20 years after computerized language translation was laughed out of the funding process in the  United States. 


 ---- TOKENS ----

 ['The', 'potential', 'impact', 'of', 'MT', 'is', 'indicated', 'below', 'by', 'a', 'quote', ':', '2', 'Today', ',', 'more', 'than', '20', 'years', 'after', 'computerized', 'language', 'translation', 'was', 'laughed', 'out', 'of', 'the', 'funding', 'process', 'in', 'the', 'United', 'States', '.'] 

 TOTAL TOKENS ==> 35

 ---- POST ----

 [('The', 'DT'), ('potential', 'JJ'), ('impact', 'NN'), ('of', 'IN'), ('MT', 'NNP'), ('is', 'VBZ'), ('indicated', 'VBN'), ('below', 'IN'), ('by', 'IN'), ('a', 'DT'), ('quote', 'NN'), (':', ':'), ('2', 'CD'), ('Today', 'NN'), (',', ','), ('more', 'JJR'), ('than', 'IN'), ('20', 'CD'), ('years', 'NNS'), ('after', 'IN'), ('computerized', 'JJ'), ('language', 'NN'), ('translation', 'NN'), ('was', 'VBD'), ('laughed', 'VBN'), ('out', 'IN'), ('of', 'IN'), ('the', 'DT'), ('funding', 'NN'), ('process', 'NN'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['potential', 'impact', 'MT', 'indicated', 'quote', ':', '2', 'Today', ',', '20', 'years', 'computerized', 'language', 'translation', 'laughed', 'funding', 'process', 'United', 'States', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('potential', 'JJ'), ('impact', 'NN'), ('MT', 'NNP'), ('indicated', 'VBD'), ('quote', 'NN'), (':', ':'), ('2', 'CD'), ('Today', 'NN'), (',', ','), ('20', 'CD'), ('years', 'NNS'), ('computerized', 'JJ'), ('language', 'NN'), ('translation', 'NN'), ('laughed', 'VBD'), ('funding', 'NN'), ('process', 'NN'), ('United', 'NNP'), ('States', 'NNPS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['potential impact', 'impact MT', 'MT indicated', 'indicated quote', 'quote :', ': 2', '2 Today', 'Today ,', ', 20', '20 years', 'years computerized', 'computerized language', 'language translation', 'translation laughed', 'laughed funding', 'funding process', 'process United', 'United States', 'States .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['potential impact MT', 'impact MT indicated', 'MT indicated quote', 'indicated quote :', 'quote : 2', ': 2 Today', '2 Today ,', 'Today , 20', ', 20 years', '20 years computerized', 'years computerized language', 'computerized language translation', 'language translation laughed', 'translation laughed funding', 'laughed funding process', 'funding process United', 'process United States', 'United States .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['potential impact', 'quote', 'Today', 'computerized language', 'translation', 'funding', 'process'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['United States']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['potenti', 'impact', 'mt', 'indic', 'quot', ':', '2', 'today', ',', '20', 'year', 'computer', 'languag', 'translat', 'laugh', 'fund', 'process', 'unit', 'state', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['potenti', 'impact', 'mt', 'indic', 'quot', ':', '2', 'today', ',', '20', 'year', 'computer', 'languag', 'translat', 'laugh', 'fund', 'process', 'unit', 'state', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['potential', 'impact', 'MT', 'indicated', 'quote', ':', '2', 'Today', ',', '20', 'year', 'computerized', 'language', 'translation', 'laughed', 'funding', 'process', 'United', 'States', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

276 --> several Japanese companies and industry/government collaborations are beginning to turn the once-  derided technology into a gold mine of new applications and opportunities. 


 ---- TOKENS ----

 ['several', 'Japanese', 'companies', 'and', 'industry/government', 'collaborations', 'are', 'beginning', 'to', 'turn', 'the', 'once-', 'derided', 'technology', 'into', 'a', 'gold', 'mine', 'of', 'new', 'applications', 'and', 'opportunities', '.'] 

 TOTAL TOKENS ==> 24

 ---- POST ----

 [('several', 'JJ'), ('Japanese', 'JJ'), ('companies', 'NNS'), ('and', 'CC'), ('industry/government', 'JJ'), ('collaborations', 'NNS'), ('are', 'VBP'), ('beginning', 'VBG'), ('to', 'TO'), ('turn', 'VB'), ('the', 'DT'), ('once-', 'JJ'), ('derided', 'JJ'), ('technology', 'NN'), ('into', 'IN'), ('a', 'DT'), ('gold', 'JJ'), ('mine', 'NN'), ('of', 'IN'), ('new', 'JJ'), ('applications', 'NNS'), ('and', 'CC'), ('opportunities', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['several', 'Japanese', 'companies', 'industry/government', 'collaborations', 'beginning', 'turn', 'once-', 'derided', 'technology', 'gold', 'mine', 'new', 'applications', 'opportunities', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('several', 'JJ'), ('Japanese', 'JJ'), ('companies', 'NNS'), ('industry/government', 'JJ'), ('collaborations', 'NNS'), ('beginning', 'VBG'), ('turn', 'VBP'), ('once-', 'JJ'), ('derided', 'JJ'), ('technology', 'NN'), ('gold', 'NN'), ('mine', 'VBP'), ('new', 'JJ'), ('applications', 'NNS'), ('opportunities', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['several Japanese', 'Japanese companies', 'companies industry/government', 'industry/government collaborations', 'collaborations beginning', 'beginning turn', 'turn once-', 'once- derided', 'derided technology', 'technology gold', 'gold mine', 'mine new', 'new applications', 'applications opportunities', 'opportunities .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['several Japanese companies', 'Japanese companies industry/government', 'companies industry/government collaborations', 'industry/government collaborations beginning', 'collaborations beginning turn', 'beginning turn once-', 'turn once- derided', 'once- derided technology', 'derided technology gold', 'technology gold mine', 'gold mine new', 'mine new applications', 'new applications opportunities', 'applications opportunities .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['once- derided technology', 'gold'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Japanese']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['sever', 'japanes', 'compani', 'industry/govern', 'collabor', 'begin', 'turn', 'once-', 'derid', 'technolog', 'gold', 'mine', 'new', 'applic', 'opportun', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['sever', 'japanes', 'compani', 'industry/govern', 'collabor', 'begin', 'turn', 'once-', 'derid', 'technolog', 'gold', 'mine', 'new', 'applic', 'opportun', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['several', 'Japanese', 'company', 'industry/government', 'collaboration', 'beginning', 'turn', 'once-', 'derided', 'technology', 'gold', 'mine', 'new', 'application', 'opportunity', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

277 --> The top U.S. company estimates that the  annual market for international translation is at least $10 billion, and as machine translation systems improve they will  command an increasing share of a market growing at a rate of I0 to 15 percent a year. 


 ---- TOKENS ----

 ['The', 'top', 'U.S.', 'company', 'estimates', 'that', 'the', 'annual', 'market', 'for', 'international', 'translation', 'is', 'at', 'least', '$', '10', 'billion', ',', 'and', 'as', 'machine', 'translation', 'systems', 'improve', 'they', 'will', 'command', 'an', 'increasing', 'share', 'of', 'a', 'market', 'growing', 'at', 'a', 'rate', 'of', 'I0', 'to', '15', 'percent', 'a', 'year', '.'] 

 TOTAL TOKENS ==> 46

 ---- POST ----

 [('The', 'DT'), ('top', 'JJ'), ('U.S.', 'NNP'), ('company', 'NN'), ('estimates', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('annual', 'JJ'), ('market', 'NN'), ('for', 'IN'), ('international', 'JJ'), ('translation', 'NN'), ('is', 'VBZ'), ('at', 'IN'), ('least', 'JJS'), ('$', '$'), ('10', 'CD'), ('billion', 'CD'), (',', ','), ('and', 'CC'), ('as', 'IN'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('improve', 'VBP'), ('they', 'PRP'), ('will', 'MD'), ('command', 'VB'), ('an', 'DT'), ('increasing', 'VBG'), ('share', 'NN'), ('of', 'IN'), ('a', 'DT'), ('market', 'NN'), ('growing', 'VBG'), ('at', 'IN'), ('a', 'DT'), ('rate', 'NN'), ('of', 'IN'), ('I0', 'NNP'), ('to', 'TO'), ('15', 'CD'), ('percent', 'NN'), ('a', 'DT'), ('year', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['top', 'U.S.', 'company', 'estimates', 'annual', 'market', 'international', 'translation', 'least', '$', '10', 'billion', ',', 'machine', 'translation', 'systems', 'improve', 'command', 'increasing', 'share', 'market', 'growing', 'rate', 'I0', '15', 'percent', 'year', '.']

 TOTAL FILTERED TOKENS ==>  28

 ---- POST FOR FILTERED TOKENS ----

 [('top', 'JJ'), ('U.S.', 'NNP'), ('company', 'NN'), ('estimates', 'VBZ'), ('annual', 'JJ'), ('market', 'NN'), ('international', 'JJ'), ('translation', 'NN'), ('least', 'JJS'), ('$', '$'), ('10', 'CD'), ('billion', 'CD'), (',', ','), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('improve', 'VBP'), ('command', 'NN'), ('increasing', 'VBG'), ('share', 'NN'), ('market', 'NN'), ('growing', 'VBG'), ('rate', 'NN'), ('I0', 'NNP'), ('15', 'CD'), ('percent', 'NN'), ('year', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['top U.S.', 'U.S. company', 'company estimates', 'estimates annual', 'annual market', 'market international', 'international translation', 'translation least', 'least $', '$ 10', '10 billion', 'billion ,', ', machine', 'machine translation', 'translation systems', 'systems improve', 'improve command', 'command increasing', 'increasing share', 'share market', 'market growing', 'growing rate', 'rate I0', 'I0 15', '15 percent', 'percent year', 'year .'] 

 TOTAL BIGRAMS --> 27 



 ---- TRI-GRAMS ---- 

 ['top U.S. company', 'U.S. company estimates', 'company estimates annual', 'estimates annual market', 'annual market international', 'market international translation', 'international translation least', 'translation least $', 'least $ 10', '$ 10 billion', '10 billion ,', 'billion , machine', ', machine translation', 'machine translation systems', 'translation systems improve', 'systems improve command', 'improve command increasing', 'command increasing share', 'increasing share market', 'share market growing', 'market growing rate', 'growing rate I0', 'rate I0 15', 'I0 15 percent', '15 percent year', 'percent year .'] 

 TOTAL TRIGRAMS --> 26 



 ---- NOUN PHRASES ---- 

 ['company', 'annual market', 'international translation', 'machine', 'translation', 'command', 'share', 'market', 'rate', 'percent', 'year'] 

 TOTAL NOUN PHRASES --> 11 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['U.S.']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['top', 'u.s.', 'compani', 'estim', 'annual', 'market', 'intern', 'translat', 'least', '$', '10', 'billion', ',', 'machin', 'translat', 'system', 'improv', 'command', 'increas', 'share', 'market', 'grow', 'rate', 'i0', '15', 'percent', 'year', '.']

 TOTAL PORTER STEM WORDS ==> 28



 ---- SNOWBALL STEMMING ----

['top', 'u.s.', 'compani', 'estim', 'annual', 'market', 'intern', 'translat', 'least', '$', '10', 'billion', ',', 'machin', 'translat', 'system', 'improv', 'command', 'increas', 'share', 'market', 'grow', 'rate', 'i0', '15', 'percent', 'year', '.']

 TOTAL SNOWBALL STEM WORDS ==> 28



 ---- LEMMATIZATION ----

['top', 'U.S.', 'company', 'estimate', 'annual', 'market', 'international', 'translation', 'least', '$', '10', 'billion', ',', 'machine', 'translation', 'system', 'improve', 'command', 'increasing', 'share', 'market', 'growing', 'rate', 'I0', '15', 'percent', 'year', '.']

 TOTAL LEMMATIZE WORDS ==> 28

************************************************************************************************************************

278 --> The key to why there is a market for MT today is the fact that one need not have fully automatic  high-quality translation to have a valuable product; tools that increase productivity are sufficient. 


 ---- TOKENS ----

 ['The', 'key', 'to', 'why', 'there', 'is', 'a', 'market', 'for', 'MT', 'today', 'is', 'the', 'fact', 'that', 'one', 'need', 'not', 'have', 'fully', 'automatic', 'high-quality', 'translation', 'to', 'have', 'a', 'valuable', 'product', ';', 'tools', 'that', 'increase', 'productivity', 'are', 'sufficient', '.'] 

 TOTAL TOKENS ==> 36

 ---- POST ----

 [('The', 'DT'), ('key', 'NN'), ('to', 'TO'), ('why', 'WRB'), ('there', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('market', 'NN'), ('for', 'IN'), ('MT', 'NNP'), ('today', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('fact', 'NN'), ('that', 'IN'), ('one', 'CD'), ('need', 'NN'), ('not', 'RB'), ('have', 'VB'), ('fully', 'RB'), ('automatic', 'JJ'), ('high-quality', 'NN'), ('translation', 'NN'), ('to', 'TO'), ('have', 'VB'), ('a', 'DT'), ('valuable', 'JJ'), ('product', 'NN'), (';', ':'), ('tools', 'NNS'), ('that', 'IN'), ('increase', 'NN'), ('productivity', 'NN'), ('are', 'VBP'), ('sufficient', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['key', 'market', 'MT', 'today', 'fact', 'one', 'need', 'fully', 'automatic', 'high-quality', 'translation', 'valuable', 'product', ';', 'tools', 'increase', 'productivity', 'sufficient', '.']

 TOTAL FILTERED TOKENS ==>  19

 ---- POST FOR FILTERED TOKENS ----

 [('key', 'JJ'), ('market', 'NN'), ('MT', 'NNP'), ('today', 'NN'), ('fact', 'NN'), ('one', 'CD'), ('need', 'NN'), ('fully', 'RB'), ('automatic', 'JJ'), ('high-quality', 'NN'), ('translation', 'NN'), ('valuable', 'JJ'), ('product', 'NN'), (';', ':'), ('tools', 'JJ'), ('increase', 'NN'), ('productivity', 'NN'), ('sufficient', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['key market', 'market MT', 'MT today', 'today fact', 'fact one', 'one need', 'need fully', 'fully automatic', 'automatic high-quality', 'high-quality translation', 'translation valuable', 'valuable product', 'product ;', '; tools', 'tools increase', 'increase productivity', 'productivity sufficient', 'sufficient .'] 

 TOTAL BIGRAMS --> 18 



 ---- TRI-GRAMS ---- 

 ['key market MT', 'market MT today', 'MT today fact', 'today fact one', 'fact one need', 'one need fully', 'need fully automatic', 'fully automatic high-quality', 'automatic high-quality translation', 'high-quality translation valuable', 'translation valuable product', 'valuable product ;', 'product ; tools', '; tools increase', 'tools increase productivity', 'increase productivity sufficient', 'productivity sufficient .'] 

 TOTAL TRIGRAMS --> 17 



 ---- NOUN PHRASES ---- 

 ['key market', 'today', 'fact', 'need', 'automatic high-quality', 'translation', 'valuable product', 'tools increase', 'productivity', 'sufficient'] 

 TOTAL NOUN PHRASES --> 10 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['key', 'market', 'mt', 'today', 'fact', 'one', 'need', 'fulli', 'automat', 'high-qual', 'translat', 'valuabl', 'product', ';', 'tool', 'increas', 'product', 'suffici', '.']

 TOTAL PORTER STEM WORDS ==> 19



 ---- SNOWBALL STEMMING ----

['key', 'market', 'mt', 'today', 'fact', 'one', 'need', 'fulli', 'automat', 'high-qual', 'translat', 'valuabl', 'product', ';', 'tool', 'increas', 'product', 'suffici', '.']

 TOTAL SNOWBALL STEM WORDS ==> 19



 ---- LEMMATIZATION ----

['key', 'market', 'MT', 'today', 'fact', 'one', 'need', 'fully', 'automatic', 'high-quality', 'translation', 'valuable', 'product', ';', 'tool', 'increase', 'productivity', 'sufficient', '.']

 TOTAL LEMMATIZE WORDS ==> 19

************************************************************************************************************************

279 --> If economies are  gained by editing a translation drafted using MT, that is sufficient to warrant use of MT systems. 


 ---- TOKENS ----

 ['If', 'economies', 'are', 'gained', 'by', 'editing', 'a', 'translation', 'drafted', 'using', 'MT', ',', 'that', 'is', 'sufficient', 'to', 'warrant', 'use', 'of', 'MT', 'systems', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('If', 'IN'), ('economies', 'NNS'), ('are', 'VBP'), ('gained', 'VBN'), ('by', 'IN'), ('editing', 'VBG'), ('a', 'DT'), ('translation', 'NN'), ('drafted', 'VBN'), ('using', 'VBG'), ('MT', 'NNP'), (',', ','), ('that', 'WDT'), ('is', 'VBZ'), ('sufficient', 'JJ'), ('to', 'TO'), ('warrant', 'VB'), ('use', 'NN'), ('of', 'IN'), ('MT', 'NNP'), ('systems', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['economies', 'gained', 'editing', 'translation', 'drafted', 'using', 'MT', ',', 'sufficient', 'warrant', 'use', 'MT', 'systems', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('economies', 'NNS'), ('gained', 'VBD'), ('editing', 'VBG'), ('translation', 'NN'), ('drafted', 'VBD'), ('using', 'VBG'), ('MT', 'NNP'), (',', ','), ('sufficient', 'NN'), ('warrant', 'NN'), ('use', 'NN'), ('MT', 'NNP'), ('systems', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['economies gained', 'gained editing', 'editing translation', 'translation drafted', 'drafted using', 'using MT', 'MT ,', ', sufficient', 'sufficient warrant', 'warrant use', 'use MT', 'MT systems', 'systems .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['economies gained editing', 'gained editing translation', 'editing translation drafted', 'translation drafted using', 'drafted using MT', 'using MT ,', 'MT , sufficient', ', sufficient warrant', 'sufficient warrant use', 'warrant use MT', 'use MT systems', 'MT systems .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['translation', 'sufficient', 'warrant', 'use'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['MT']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['economi', 'gain', 'edit', 'translat', 'draft', 'use', 'mt', ',', 'suffici', 'warrant', 'use', 'mt', 'system', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['economi', 'gain', 'edit', 'translat', 'draft', 'use', 'mt', ',', 'suffici', 'warrant', 'use', 'mt', 'system', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['economy', 'gained', 'editing', 'translation', 'drafted', 'using', 'MT', ',', 'sufficient', 'warrant', 'use', 'MT', 'system', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

280 --> In terms of R&D funding, MT is the application of NLP that is attracting the most funding from  government and industry in Japan and Europe. 


 ---- TOKENS ----

 ['In', 'terms', 'of', 'R', '&', 'D', 'funding', ',', 'MT', 'is', 'the', 'application', 'of', 'NLP', 'that', 'is', 'attracting', 'the', 'most', 'funding', 'from', 'government', 'and', 'industry', 'in', 'Japan', 'and', 'Europe', '.'] 

 TOTAL TOKENS ==> 29

 ---- POST ----

 [('In', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('R', 'NNP'), ('&', 'CC'), ('D', 'NNP'), ('funding', 'NN'), (',', ','), ('MT', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('application', 'NN'), ('of', 'IN'), ('NLP', 'NNP'), ('that', 'WDT'), ('is', 'VBZ'), ('attracting', 'VBG'), ('the', 'DT'), ('most', 'RBS'), ('funding', 'NN'), ('from', 'IN'), ('government', 'NN'), ('and', 'CC'), ('industry', 'NN'), ('in', 'IN'), ('Japan', 'NNP'), ('and', 'CC'), ('Europe', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['terms', 'R', '&', 'funding', ',', 'MT', 'application', 'NLP', 'attracting', 'funding', 'government', 'industry', 'Japan', 'Europe', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('terms', 'NNS'), ('R', 'NNP'), ('&', 'CC'), ('funding', 'NN'), (',', ','), ('MT', 'NNP'), ('application', 'NN'), ('NLP', 'NNP'), ('attracting', 'VBG'), ('funding', 'JJ'), ('government', 'NN'), ('industry', 'NN'), ('Japan', 'NNP'), ('Europe', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['terms R', 'R &', '& funding', 'funding ,', ', MT', 'MT application', 'application NLP', 'NLP attracting', 'attracting funding', 'funding government', 'government industry', 'industry Japan', 'Japan Europe', 'Europe .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['terms R &', 'R & funding', '& funding ,', 'funding , MT', ', MT application', 'MT application NLP', 'application NLP attracting', 'NLP attracting funding', 'attracting funding government', 'funding government industry', 'government industry Japan', 'industry Japan Europe', 'Japan Europe .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['funding', 'application', 'funding government', 'industry'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> ['MT']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Japan Europe']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['term', 'r', '&', 'fund', ',', 'mt', 'applic', 'nlp', 'attract', 'fund', 'govern', 'industri', 'japan', 'europ', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['term', 'r', '&', 'fund', ',', 'mt', 'applic', 'nlp', 'attract', 'fund', 'govern', 'industri', 'japan', 'europ', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['term', 'R', '&', 'funding', ',', 'MT', 'application', 'NLP', 'attracting', 'funding', 'government', 'industry', 'Japan', 'Europe', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

281 --> In Europe, Eurotra alone is spending $20 million in MT, with  another expected $20 million in matching funds. 


 ---- TOKENS ----

 ['In', 'Europe', ',', 'Eurotra', 'alone', 'is', 'spending', '$', '20', 'million', 'in', 'MT', ',', 'with', 'another', 'expected', '$', '20', 'million', 'in', 'matching', 'funds', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('In', 'IN'), ('Europe', 'NNP'), (',', ','), ('Eurotra', 'NNP'), ('alone', 'RB'), ('is', 'VBZ'), ('spending', 'VBG'), ('$', '$'), ('20', 'CD'), ('million', 'CD'), ('in', 'IN'), ('MT', 'NNP'), (',', ','), ('with', 'IN'), ('another', 'DT'), ('expected', 'VBN'), ('$', '$'), ('20', 'CD'), ('million', 'CD'), ('in', 'IN'), ('matching', 'VBG'), ('funds', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Europe', ',', 'Eurotra', 'alone', 'spending', '$', '20', 'million', 'MT', ',', 'another', 'expected', '$', '20', 'million', 'matching', 'funds', '.']

 TOTAL FILTERED TOKENS ==>  18

 ---- POST FOR FILTERED TOKENS ----

 [('Europe', 'NNP'), (',', ','), ('Eurotra', 'NNP'), ('alone', 'RB'), ('spending', 'VBG'), ('$', '$'), ('20', 'CD'), ('million', 'CD'), ('MT', 'NNP'), (',', ','), ('another', 'DT'), ('expected', 'VBD'), ('$', '$'), ('20', 'CD'), ('million', 'CD'), ('matching', 'JJ'), ('funds', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Europe ,', ', Eurotra', 'Eurotra alone', 'alone spending', 'spending $', '$ 20', '20 million', 'million MT', 'MT ,', ', another', 'another expected', 'expected $', '$ 20', '20 million', 'million matching', 'matching funds', 'funds .'] 

 TOTAL BIGRAMS --> 17 



 ---- TRI-GRAMS ---- 

 ['Europe , Eurotra', ', Eurotra alone', 'Eurotra alone spending', 'alone spending $', 'spending $ 20', '$ 20 million', '20 million MT', 'million MT ,', 'MT , another', ', another expected', 'another expected $', 'expected $ 20', '$ 20 million', '20 million matching', 'million matching funds', 'matching funds .'] 

 TOTAL TRIGRAMS --> 16 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Eurotra']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Europe']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['europ', ',', 'eurotra', 'alon', 'spend', '$', '20', 'million', 'mt', ',', 'anoth', 'expect', '$', '20', 'million', 'match', 'fund', '.']

 TOTAL PORTER STEM WORDS ==> 18



 ---- SNOWBALL STEMMING ----

['europ', ',', 'eurotra', 'alon', 'spend', '$', '20', 'million', 'mt', ',', 'anoth', 'expect', '$', '20', 'million', 'match', 'fund', '.']

 TOTAL SNOWBALL STEM WORDS ==> 18



 ---- LEMMATIZATION ----

['Europe', ',', 'Eurotra', 'alone', 'spending', '$', '20', 'million', 'MT', ',', 'another', 'expected', '$', '20', 'million', 'matching', 'fund', '.']

 TOTAL LEMMATIZE WORDS ==> 18

************************************************************************************************************************

282 --> The total Japanese investment is even larger (most of it industrial). 


 ---- TOKENS ----

 ['The', 'total', 'Japanese', 'investment', 'is', 'even', 'larger', '(', 'most', 'of', 'it', 'industrial', ')', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('The', 'DT'), ('total', 'JJ'), ('Japanese', 'JJ'), ('investment', 'NN'), ('is', 'VBZ'), ('even', 'RB'), ('larger', 'JJR'), ('(', '('), ('most', 'JJS'), ('of', 'IN'), ('it', 'PRP'), ('industrial', 'JJ'), (')', ')'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['total', 'Japanese', 'investment', 'even', 'larger', '(', 'industrial', ')', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('total', 'JJ'), ('Japanese', 'JJ'), ('investment', 'NN'), ('even', 'RB'), ('larger', 'JJR'), ('(', '('), ('industrial', 'JJ'), (')', ')'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['total Japanese', 'Japanese investment', 'investment even', 'even larger', 'larger (', '( industrial', 'industrial )', ') .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['total Japanese investment', 'Japanese investment even', 'investment even larger', 'even larger (', 'larger ( industrial', '( industrial )', 'industrial ) .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['total Japanese investment'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Japanese']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['total', 'japanes', 'invest', 'even', 'larger', '(', 'industri', ')', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['total', 'japanes', 'invest', 'even', 'larger', '(', 'industri', ')', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['total', 'Japanese', 'investment', 'even', 'larger', '(', 'industrial', ')', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

283 --> ATR (in Osaka, funded by the ministry of postal and telecommunication) is doing a 15-year project on simultaneous  "interpreting telephony" combining MT, dialog analysis, and speech. 


 ---- TOKENS ----

 ['ATR', '(', 'in', 'Osaka', ',', 'funded', 'by', 'the', 'ministry', 'of', 'postal', 'and', 'telecommunication', ')', 'is', 'doing', 'a', '15-year', 'project', 'on', 'simultaneous', '``', 'interpreting', 'telephony', "''", 'combining', 'MT', ',', 'dialog', 'analysis', ',', 'and', 'speech', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('ATR', 'NNP'), ('(', '('), ('in', 'IN'), ('Osaka', 'NNP'), (',', ','), ('funded', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('ministry', 'NN'), ('of', 'IN'), ('postal', 'JJ'), ('and', 'CC'), ('telecommunication', 'NN'), (')', ')'), ('is', 'VBZ'), ('doing', 'VBG'), ('a', 'DT'), ('15-year', 'JJ'), ('project', 'NN'), ('on', 'IN'), ('simultaneous', 'JJ'), ('``', '``'), ('interpreting', 'VBG'), ('telephony', 'NN'), ("''", "''"), ('combining', 'VBG'), ('MT', 'NNP'), (',', ','), ('dialog', 'NN'), ('analysis', 'NN'), (',', ','), ('and', 'CC'), ('speech', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['ATR', '(', 'Osaka', ',', 'funded', 'ministry', 'postal', 'telecommunication', ')', '15-year', 'project', 'simultaneous', '``', 'interpreting', 'telephony', "''", 'combining', 'MT', ',', 'dialog', 'analysis', ',', 'speech', '.']

 TOTAL FILTERED TOKENS ==>  24

 ---- POST FOR FILTERED TOKENS ----

 [('ATR', 'NNP'), ('(', '('), ('Osaka', 'NNP'), (',', ','), ('funded', 'VBD'), ('ministry', 'NN'), ('postal', 'JJ'), ('telecommunication', 'NN'), (')', ')'), ('15-year', 'JJ'), ('project', 'NN'), ('simultaneous', 'JJ'), ('``', '``'), ('interpreting', 'VBG'), ('telephony', 'NN'), ("''", "''"), ('combining', 'VBG'), ('MT', 'NNP'), (',', ','), ('dialog', 'NN'), ('analysis', 'NN'), (',', ','), ('speech', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['ATR (', '( Osaka', 'Osaka ,', ', funded', 'funded ministry', 'ministry postal', 'postal telecommunication', 'telecommunication )', ') 15-year', '15-year project', 'project simultaneous', 'simultaneous ``', '`` interpreting', 'interpreting telephony', "telephony ''", "'' combining", 'combining MT', 'MT ,', ', dialog', 'dialog analysis', 'analysis ,', ', speech', 'speech .'] 

 TOTAL BIGRAMS --> 23 



 ---- TRI-GRAMS ---- 

 ['ATR ( Osaka', '( Osaka ,', 'Osaka , funded', ', funded ministry', 'funded ministry postal', 'ministry postal telecommunication', 'postal telecommunication )', 'telecommunication ) 15-year', ') 15-year project', '15-year project simultaneous', 'project simultaneous ``', 'simultaneous `` interpreting', '`` interpreting telephony', "interpreting telephony ''", "telephony '' combining", "'' combining MT", 'combining MT ,', 'MT , dialog', ', dialog analysis', 'dialog analysis ,', 'analysis , speech', ', speech .'] 

 TOTAL TRIGRAMS --> 22 



 ---- NOUN PHRASES ---- 

 ['15-year project', 'telephony', 'dialog', 'analysis', 'speech'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['MT']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['ATR']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['atr', '(', 'osaka', ',', 'fund', 'ministri', 'postal', 'telecommun', ')', '15-year', 'project', 'simultan', '``', 'interpret', 'telephoni', "''", 'combin', 'mt', ',', 'dialog', 'analysi', ',', 'speech', '.']

 TOTAL PORTER STEM WORDS ==> 24



 ---- SNOWBALL STEMMING ----

['atr', '(', 'osaka', ',', 'fund', 'ministri', 'postal', 'telecommun', ')', '15-year', 'project', 'simultan', '``', 'interpret', 'telephoni', "''", 'combin', 'mt', ',', 'dialog', 'analysi', ',', 'speech', '.']

 TOTAL SNOWBALL STEM WORDS ==> 24



 ---- LEMMATIZATION ----

['ATR', '(', 'Osaka', ',', 'funded', 'ministry', 'postal', 'telecommunication', ')', '15-year', 'project', 'simultaneous', '``', 'interpreting', 'telephony', "''", 'combining', 'MT', ',', 'dialog', 'analysis', ',', 'speech', '.']

 TOTAL LEMMATIZE WORDS ==> 24

************************************************************************************************************************

284 --> 4.1.4. 


 ---- TOKENS ----

 ['4.1.4', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('4.1.4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4.1.4', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('4.1.4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4.1.4 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4.1.4', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['4.1.4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['4.1.4', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

285 --> Forecasting the Market  Though forecasting the market for a technology that is emerging from the laboratory is not a reliable  process, we cite what we feel is the most useful market survey. 


 ---- TOKENS ----

 ['Forecasting', 'the', 'Market', 'Though', 'forecasting', 'the', 'market', 'for', 'a', 'technology', 'that', 'is', 'emerging', 'from', 'the', 'laboratory', 'is', 'not', 'a', 'reliable', 'process', ',', 'we', 'cite', 'what', 'we', 'feel', 'is', 'the', 'most', 'useful', 'market', 'survey', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('Forecasting', 'VBG'), ('the', 'DT'), ('Market', 'NNP'), ('Though', 'NNP'), ('forecasting', 'VBG'), ('the', 'DT'), ('market', 'NN'), ('for', 'IN'), ('a', 'DT'), ('technology', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('emerging', 'VBG'), ('from', 'IN'), ('the', 'DT'), ('laboratory', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('a', 'DT'), ('reliable', 'JJ'), ('process', 'NN'), (',', ','), ('we', 'PRP'), ('cite', 'VBP'), ('what', 'WP'), ('we', 'PRP'), ('feel', 'VBP'), ('is', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('useful', 'JJ'), ('market', 'NN'), ('survey', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Forecasting', 'Market', 'Though', 'forecasting', 'market', 'technology', 'emerging', 'laboratory', 'reliable', 'process', ',', 'cite', 'feel', 'useful', 'market', 'survey', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('Forecasting', 'VBG'), ('Market', 'NNP'), ('Though', 'IN'), ('forecasting', 'VBG'), ('market', 'NN'), ('technology', 'NN'), ('emerging', 'VBG'), ('laboratory', 'NN'), ('reliable', 'JJ'), ('process', 'NN'), (',', ','), ('cite', 'JJ'), ('feel', 'NN'), ('useful', 'JJ'), ('market', 'NN'), ('survey', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Forecasting Market', 'Market Though', 'Though forecasting', 'forecasting market', 'market technology', 'technology emerging', 'emerging laboratory', 'laboratory reliable', 'reliable process', 'process ,', ', cite', 'cite feel', 'feel useful', 'useful market', 'market survey', 'survey .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['Forecasting Market Though', 'Market Though forecasting', 'Though forecasting market', 'forecasting market technology', 'market technology emerging', 'technology emerging laboratory', 'emerging laboratory reliable', 'laboratory reliable process', 'reliable process ,', 'process , cite', ', cite feel', 'cite feel useful', 'feel useful market', 'useful market survey', 'market survey .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['market', 'technology', 'laboratory', 'reliable process', 'cite feel', 'useful market', 'survey'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Market']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['forecast', 'market', 'though', 'forecast', 'market', 'technolog', 'emerg', 'laboratori', 'reliabl', 'process', ',', 'cite', 'feel', 'use', 'market', 'survey', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['forecast', 'market', 'though', 'forecast', 'market', 'technolog', 'emerg', 'laboratori', 'reliabl', 'process', ',', 'cite', 'feel', 'use', 'market', 'survey', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['Forecasting', 'Market', 'Though', 'forecasting', 'market', 'technology', 'emerging', 'laboratory', 'reliable', 'process', ',', 'cite', 'feel', 'useful', 'market', 'survey', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

286 --> Figure 4..1 shows estimated sales in 1987 of NLP  systems in the U.S.; Figure 4-2 shows estimated sales of NLP products in 1985 and 1987 and forecasted sales for  1989, 1991, 1993, and 1995. 


 ---- TOKENS ----

 ['Figure', '4', '..', '1', 'shows', 'estimated', 'sales', 'in', '1987', 'of', 'NLP', 'systems', 'in', 'the', 'U.S.', ';', 'Figure', '4-2', 'shows', 'estimated', 'sales', 'of', 'NLP', 'products', 'in', '1985', 'and', '1987', 'and', 'forecasted', 'sales', 'for', '1989', ',', '1991', ',', '1993', ',', 'and', '1995', '.'] 

 TOTAL TOKENS ==> 41

 ---- POST ----

 [('Figure', 'NN'), ('4', 'CD'), ('..', 'NN'), ('1', 'CD'), ('shows', 'NNS'), ('estimated', 'VBN'), ('sales', 'NNS'), ('in', 'IN'), ('1987', 'CD'), ('of', 'IN'), ('NLP', 'NNP'), ('systems', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), (';', ':'), ('Figure', 'NNP'), ('4-2', 'CD'), ('shows', 'NNS'), ('estimated', 'VBD'), ('sales', 'NNS'), ('of', 'IN'), ('NLP', 'NNP'), ('products', 'NNS'), ('in', 'IN'), ('1985', 'CD'), ('and', 'CC'), ('1987', 'CD'), ('and', 'CC'), ('forecasted', 'VBD'), ('sales', 'NNS'), ('for', 'IN'), ('1989', 'CD'), (',', ','), ('1991', 'CD'), (',', ','), ('1993', 'CD'), (',', ','), ('and', 'CC'), ('1995', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Figure', '4', '..', '1', 'shows', 'estimated', 'sales', '1987', 'NLP', 'systems', 'U.S.', ';', 'Figure', '4-2', 'shows', 'estimated', 'sales', 'NLP', 'products', '1985', '1987', 'forecasted', 'sales', '1989', ',', '1991', ',', '1993', ',', '1995', '.']

 TOTAL FILTERED TOKENS ==>  31

 ---- POST FOR FILTERED TOKENS ----

 [('Figure', 'NN'), ('4', 'CD'), ('..', 'NN'), ('1', 'CD'), ('shows', 'NNS'), ('estimated', 'VBN'), ('sales', 'NNS'), ('1987', 'CD'), ('NLP', 'NNP'), ('systems', 'NNS'), ('U.S.', 'NNP'), (';', ':'), ('Figure', 'NNP'), ('4-2', 'CD'), ('shows', 'NNS'), ('estimated', 'VBN'), ('sales', 'NNS'), ('NLP', 'NNP'), ('products', 'NNS'), ('1985', 'CD'), ('1987', 'CD'), ('forecasted', 'VBD'), ('sales', 'NNS'), ('1989', 'CD'), (',', ','), ('1991', 'CD'), (',', ','), ('1993', 'CD'), (',', ','), ('1995', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Figure 4', '4 ..', '.. 1', '1 shows', 'shows estimated', 'estimated sales', 'sales 1987', '1987 NLP', 'NLP systems', 'systems U.S.', 'U.S. ;', '; Figure', 'Figure 4-2', '4-2 shows', 'shows estimated', 'estimated sales', 'sales NLP', 'NLP products', 'products 1985', '1985 1987', '1987 forecasted', 'forecasted sales', 'sales 1989', '1989 ,', ', 1991', '1991 ,', ', 1993', '1993 ,', ', 1995', '1995 .'] 

 TOTAL BIGRAMS --> 30 



 ---- TRI-GRAMS ---- 

 ['Figure 4 ..', '4 .. 1', '.. 1 shows', '1 shows estimated', 'shows estimated sales', 'estimated sales 1987', 'sales 1987 NLP', '1987 NLP systems', 'NLP systems U.S.', 'systems U.S. ;', 'U.S. ; Figure', '; Figure 4-2', 'Figure 4-2 shows', '4-2 shows estimated', 'shows estimated sales', 'estimated sales NLP', 'sales NLP products', 'NLP products 1985', 'products 1985 1987', '1985 1987 forecasted', '1987 forecasted sales', 'forecasted sales 1989', 'sales 1989 ,', '1989 , 1991', ', 1991 ,', '1991 , 1993', ', 1993 ,', '1993 , 1995', ', 1995 .'] 

 TOTAL TRIGRAMS --> 29 



 ---- NOUN PHRASES ---- 

 ['Figure', '..'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP', 'NLP']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['U.S.']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['figur', '4', '..', '1', 'show', 'estim', 'sale', '1987', 'nlp', 'system', 'u.s.', ';', 'figur', '4-2', 'show', 'estim', 'sale', 'nlp', 'product', '1985', '1987', 'forecast', 'sale', '1989', ',', '1991', ',', '1993', ',', '1995', '.']

 TOTAL PORTER STEM WORDS ==> 31



 ---- SNOWBALL STEMMING ----

['figur', '4', '..', '1', 'show', 'estim', 'sale', '1987', 'nlp', 'system', 'u.s.', ';', 'figur', '4-2', 'show', 'estim', 'sale', 'nlp', 'product', '1985', '1987', 'forecast', 'sale', '1989', ',', '1991', ',', '1993', ',', '1995', '.']

 TOTAL SNOWBALL STEM WORDS ==> 31



 ---- LEMMATIZATION ----

['Figure', '4', '..', '1', 'show', 'estimated', 'sale', '1987', 'NLP', 'system', 'U.S.', ';', 'Figure', '4-2', 'show', 'estimated', 'sale', 'NLP', 'product', '1985', '1987', 'forecasted', 'sale', '1989', ',', '1991', ',', '1993', ',', '1995', '.']

 TOTAL LEMMATIZE WORDS ==> 31

************************************************************************************************************************

287 --> In the diagrams, "content scanning" corresponds to the ultimate goal of text reading,  and "talkwriter" corresponds to the goal of automatic speech transcription. 


 ---- TOKENS ----

 ['In', 'the', 'diagrams', ',', '``', 'content', 'scanning', "''", 'corresponds', 'to', 'the', 'ultimate', 'goal', 'of', 'text', 'reading', ',', 'and', '``', 'talkwriter', "''", 'corresponds', 'to', 'the', 'goal', 'of', 'automatic', 'speech', 'transcription', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('In', 'IN'), ('the', 'DT'), ('diagrams', 'NN'), (',', ','), ('``', '``'), ('content', 'NN'), ('scanning', 'NN'), ("''", "''"), ('corresponds', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('ultimate', 'JJ'), ('goal', 'NN'), ('of', 'IN'), ('text', 'NN'), ('reading', 'NN'), (',', ','), ('and', 'CC'), ('``', '``'), ('talkwriter', 'NN'), ("''", "''"), ('corresponds', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('goal', 'NN'), ('of', 'IN'), ('automatic', 'JJ'), ('speech', 'NN'), ('transcription', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['diagrams', ',', '``', 'content', 'scanning', "''", 'corresponds', 'ultimate', 'goal', 'text', 'reading', ',', '``', 'talkwriter', "''", 'corresponds', 'goal', 'automatic', 'speech', 'transcription', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('diagrams', 'NNS'), (',', ','), ('``', '``'), ('content', 'NN'), ('scanning', 'NN'), ("''", "''"), ('corresponds', 'NNS'), ('ultimate', 'JJ'), ('goal', 'NN'), ('text', 'NN'), ('reading', 'NN'), (',', ','), ('``', '``'), ('talkwriter', 'NN'), ("''", "''"), ('corresponds', 'NNS'), ('goal', 'NN'), ('automatic', 'JJ'), ('speech', 'NN'), ('transcription', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['diagrams ,', ', ``', '`` content', 'content scanning', "scanning ''", "'' corresponds", 'corresponds ultimate', 'ultimate goal', 'goal text', 'text reading', 'reading ,', ', ``', '`` talkwriter', "talkwriter ''", "'' corresponds", 'corresponds goal', 'goal automatic', 'automatic speech', 'speech transcription', 'transcription .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['diagrams , ``', ', `` content', '`` content scanning', "content scanning ''", "scanning '' corresponds", "'' corresponds ultimate", 'corresponds ultimate goal', 'ultimate goal text', 'goal text reading', 'text reading ,', 'reading , ``', ', `` talkwriter', "`` talkwriter ''", "talkwriter '' corresponds", "'' corresponds goal", 'corresponds goal automatic', 'goal automatic speech', 'automatic speech transcription', 'speech transcription .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['content', 'scanning', 'ultimate goal', 'text', 'reading', 'talkwriter', 'goal', 'automatic speech', 'transcription'] 

 TOTAL NOUN PHRASES --> 9 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['diagram', ',', '``', 'content', 'scan', "''", 'correspond', 'ultim', 'goal', 'text', 'read', ',', '``', 'talkwrit', "''", 'correspond', 'goal', 'automat', 'speech', 'transcript', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['diagram', ',', '``', 'content', 'scan', "''", 'correspond', 'ultim', 'goal', 'text', 'read', ',', '``', 'talkwrit', "''", 'correspond', 'goal', 'automat', 'speech', 'transcript', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['diagram', ',', '``', 'content', 'scanning', "''", 'corresponds', 'ultimate', 'goal', 'text', 'reading', ',', '``', 'talkwriter', "''", 'corresponds', 'goal', 'automatic', 'speech', 'transcription', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

288 --> 4.2. 


 ---- TOKENS ----

 ['4.2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('4.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4.2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('4.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4.2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4.2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['4.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['4.2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

289 --> Transfer to the Real World  Transfer to the real world is already occurring in three appfication areas: database retrieval, message  processing in highly constrained domains, and aids to document translation. 


 ---- TOKENS ----

 ['Transfer', 'to', 'the', 'Real', 'World', 'Transfer', 'to', 'the', 'real', 'world', 'is', 'already', 'occurring', 'in', 'three', 'appfication', 'areas', ':', 'database', 'retrieval', ',', 'message', 'processing', 'in', 'highly', 'constrained', 'domains', ',', 'and', 'aids', 'to', 'document', 'translation', '.'] 

 TOTAL TOKENS ==> 34

 ---- POST ----

 [('Transfer', 'NN'), ('to', 'TO'), ('the', 'DT'), ('Real', 'NNP'), ('World', 'NNP'), ('Transfer', 'NNP'), ('to', 'TO'), ('the', 'DT'), ('real', 'JJ'), ('world', 'NN'), ('is', 'VBZ'), ('already', 'RB'), ('occurring', 'VBG'), ('in', 'IN'), ('three', 'CD'), ('appfication', 'NN'), ('areas', 'NNS'), (':', ':'), ('database', 'NN'), ('retrieval', 'NN'), (',', ','), ('message', 'NN'), ('processing', 'NN'), ('in', 'IN'), ('highly', 'RB'), ('constrained', 'JJ'), ('domains', 'NNS'), (',', ','), ('and', 'CC'), ('aids', 'NNS'), ('to', 'TO'), ('document', 'VB'), ('translation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Transfer', 'Real', 'World', 'Transfer', 'real', 'world', 'already', 'occurring', 'three', 'appfication', 'areas', ':', 'database', 'retrieval', ',', 'message', 'processing', 'highly', 'constrained', 'domains', ',', 'aids', 'document', 'translation', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('Transfer', 'VB'), ('Real', 'JJ'), ('World', 'NNP'), ('Transfer', 'NNP'), ('real', 'JJ'), ('world', 'NN'), ('already', 'RB'), ('occurring', 'VBG'), ('three', 'CD'), ('appfication', 'NN'), ('areas', 'NNS'), (':', ':'), ('database', 'NN'), ('retrieval', 'NN'), (',', ','), ('message', 'NN'), ('processing', 'NN'), ('highly', 'RB'), ('constrained', 'VBD'), ('domains', 'NNS'), (',', ','), ('aids', 'NNS'), ('document', 'NN'), ('translation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Transfer Real', 'Real World', 'World Transfer', 'Transfer real', 'real world', 'world already', 'already occurring', 'occurring three', 'three appfication', 'appfication areas', 'areas :', ': database', 'database retrieval', 'retrieval ,', ', message', 'message processing', 'processing highly', 'highly constrained', 'constrained domains', 'domains ,', ', aids', 'aids document', 'document translation', 'translation .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['Transfer Real World', 'Real World Transfer', 'World Transfer real', 'Transfer real world', 'real world already', 'world already occurring', 'already occurring three', 'occurring three appfication', 'three appfication areas', 'appfication areas :', 'areas : database', ': database retrieval', 'database retrieval ,', 'retrieval , message', ', message processing', 'message processing highly', 'processing highly constrained', 'highly constrained domains', 'constrained domains ,', 'domains , aids', ', aids document', 'aids document translation', 'document translation .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['real world', 'appfication', 'database', 'retrieval', 'message', 'processing', 'document', 'translation'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> ['Real']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['transfer', 'real', 'world', 'transfer', 'real', 'world', 'alreadi', 'occur', 'three', 'appfic', 'area', ':', 'databas', 'retriev', ',', 'messag', 'process', 'highli', 'constrain', 'domain', ',', 'aid', 'document', 'translat', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['transfer', 'real', 'world', 'transfer', 'real', 'world', 'alreadi', 'occur', 'three', 'appfic', 'area', ':', 'databas', 'retriev', ',', 'messag', 'process', 'high', 'constrain', 'domain', ',', 'aid', 'document', 'translat', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['Transfer', 'Real', 'World', 'Transfer', 'real', 'world', 'already', 'occurring', 'three', 'appfication', 'area', ':', 'database', 'retrieval', ',', 'message', 'processing', 'highly', 'constrained', 'domain', ',', 'aid', 'document', 'translation', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

290 --> As can be seen from the forecasts in the  previous section, prospects for continued transfer of technology seem bright. 


 ---- TOKENS ----

 ['As', 'can', 'be', 'seen', 'from', 'the', 'forecasts', 'in', 'the', 'previous', 'section', ',', 'prospects', 'for', 'continued', 'transfer', 'of', 'technology', 'seem', 'bright', '.'] 

 TOTAL TOKENS ==> 21

 ---- POST ----

 [('As', 'IN'), ('can', 'MD'), ('be', 'VB'), ('seen', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('forecasts', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('previous', 'JJ'), ('section', 'NN'), (',', ','), ('prospects', 'NNS'), ('for', 'IN'), ('continued', 'JJ'), ('transfer', 'NN'), ('of', 'IN'), ('technology', 'NN'), ('seem', 'VBP'), ('bright', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['seen', 'forecasts', 'previous', 'section', ',', 'prospects', 'continued', 'transfer', 'technology', 'seem', 'bright', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('seen', 'VBN'), ('forecasts', 'NNS'), ('previous', 'JJ'), ('section', 'NN'), (',', ','), ('prospects', 'NNS'), ('continued', 'VBD'), ('transfer', 'NN'), ('technology', 'NN'), ('seem', 'VBP'), ('bright', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['seen forecasts', 'forecasts previous', 'previous section', 'section ,', ', prospects', 'prospects continued', 'continued transfer', 'transfer technology', 'technology seem', 'seem bright', 'bright .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['seen forecasts previous', 'forecasts previous section', 'previous section ,', 'section , prospects', ', prospects continued', 'prospects continued transfer', 'continued transfer technology', 'transfer technology seem', 'technology seem bright', 'seem bright .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['previous section', 'transfer', 'technology'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['seen', 'forecast', 'previou', 'section', ',', 'prospect', 'continu', 'transfer', 'technolog', 'seem', 'bright', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['seen', 'forecast', 'previous', 'section', ',', 'prospect', 'continu', 'transfer', 'technolog', 'seem', 'bright', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['seen', 'forecast', 'previous', 'section', ',', 'prospect', 'continued', 'transfer', 'technology', 'seem', 'bright', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

291 --> Nevertheless, government support for  particular aspects will be necessary to develop the technology and its commercialization in ways that might  otherwise be long delayed. 


 ---- TOKENS ----

 ['Nevertheless', ',', 'government', 'support', 'for', 'particular', 'aspects', 'will', 'be', 'necessary', 'to', 'develop', 'the', 'technology', 'and', 'its', 'commercialization', 'in', 'ways', 'that', 'might', 'otherwise', 'be', 'long', 'delayed', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('Nevertheless', 'RB'), (',', ','), ('government', 'NN'), ('support', 'NN'), ('for', 'IN'), ('particular', 'JJ'), ('aspects', 'NNS'), ('will', 'MD'), ('be', 'VB'), ('necessary', 'JJ'), ('to', 'TO'), ('develop', 'VB'), ('the', 'DT'), ('technology', 'NN'), ('and', 'CC'), ('its', 'PRP$'), ('commercialization', 'NN'), ('in', 'IN'), ('ways', 'NNS'), ('that', 'WDT'), ('might', 'MD'), ('otherwise', 'RB'), ('be', 'VB'), ('long', 'JJ'), ('delayed', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Nevertheless', ',', 'government', 'support', 'particular', 'aspects', 'necessary', 'develop', 'technology', 'commercialization', 'ways', 'might', 'otherwise', 'long', 'delayed', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Nevertheless', 'RB'), (',', ','), ('government', 'NN'), ('support', 'NN'), ('particular', 'JJ'), ('aspects', 'NNS'), ('necessary', 'JJ'), ('develop', 'VBP'), ('technology', 'NN'), ('commercialization', 'NN'), ('ways', 'NNS'), ('might', 'MD'), ('otherwise', 'RB'), ('long', 'RB'), ('delayed', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Nevertheless ,', ', government', 'government support', 'support particular', 'particular aspects', 'aspects necessary', 'necessary develop', 'develop technology', 'technology commercialization', 'commercialization ways', 'ways might', 'might otherwise', 'otherwise long', 'long delayed', 'delayed .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Nevertheless , government', ', government support', 'government support particular', 'support particular aspects', 'particular aspects necessary', 'aspects necessary develop', 'necessary develop technology', 'develop technology commercialization', 'technology commercialization ways', 'commercialization ways might', 'ways might otherwise', 'might otherwise long', 'otherwise long delayed', 'long delayed .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['government', 'support', 'technology', 'commercialization'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['nevertheless', ',', 'govern', 'support', 'particular', 'aspect', 'necessari', 'develop', 'technolog', 'commerci', 'way', 'might', 'otherwis', 'long', 'delay', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['nevertheless', ',', 'govern', 'support', 'particular', 'aspect', 'necessari', 'develop', 'technolog', 'commerci', 'way', 'might', 'otherwis', 'long', 'delay', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Nevertheless', ',', 'government', 'support', 'particular', 'aspect', 'necessary', 'develop', 'technology', 'commercialization', 'way', 'might', 'otherwise', 'long', 'delayed', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

292 --> For instance, multi-modal interfaces that include both text and speech processing are  clearly mandated in military apphcations, where high-quality audio-visual hardware is expected; on the other hand,  market forces can argue for supporting the lowest common denominator in hardware, such as, a terminal, because it  is the most dominant screen technology currently commonplace. 


 ---- TOKENS ----

 ['For', 'instance', ',', 'multi-modal', 'interfaces', 'that', 'include', 'both', 'text', 'and', 'speech', 'processing', 'are', 'clearly', 'mandated', 'in', 'military', 'apphcations', ',', 'where', 'high-quality', 'audio-visual', 'hardware', 'is', 'expected', ';', 'on', 'the', 'other', 'hand', ',', 'market', 'forces', 'can', 'argue', 'for', 'supporting', 'the', 'lowest', 'common', 'denominator', 'in', 'hardware', ',', 'such', 'as', ',', 'a', 'terminal', ',', 'because', 'it', 'is', 'the', 'most', 'dominant', 'screen', 'technology', 'currently', 'commonplace', '.'] 

 TOTAL TOKENS ==> 61

 ---- POST ----

 [('For', 'IN'), ('instance', 'NN'), (',', ','), ('multi-modal', 'JJ'), ('interfaces', 'NNS'), ('that', 'WDT'), ('include', 'VBP'), ('both', 'DT'), ('text', 'NN'), ('and', 'CC'), ('speech', 'NN'), ('processing', 'NN'), ('are', 'VBP'), ('clearly', 'RB'), ('mandated', 'VBN'), ('in', 'IN'), ('military', 'JJ'), ('apphcations', 'NNS'), (',', ','), ('where', 'WRB'), ('high-quality', 'NN'), ('audio-visual', 'JJ'), ('hardware', 'NN'), ('is', 'VBZ'), ('expected', 'VBN'), (';', ':'), ('on', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('hand', 'NN'), (',', ','), ('market', 'NN'), ('forces', 'NNS'), ('can', 'MD'), ('argue', 'VB'), ('for', 'IN'), ('supporting', 'VBG'), ('the', 'DT'), ('lowest', 'JJS'), ('common', 'JJ'), ('denominator', 'NN'), ('in', 'IN'), ('hardware', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), (',', ','), ('a', 'DT'), ('terminal', 'NN'), (',', ','), ('because', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('dominant', 'JJ'), ('screen', 'JJ'), ('technology', 'NN'), ('currently', 'RB'), ('commonplace', 'VBP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['instance', ',', 'multi-modal', 'interfaces', 'include', 'text', 'speech', 'processing', 'clearly', 'mandated', 'military', 'apphcations', ',', 'high-quality', 'audio-visual', 'hardware', 'expected', ';', 'hand', ',', 'market', 'forces', 'argue', 'supporting', 'lowest', 'common', 'denominator', 'hardware', ',', ',', 'terminal', ',', 'dominant', 'screen', 'technology', 'currently', 'commonplace', '.']

 TOTAL FILTERED TOKENS ==>  38

 ---- POST FOR FILTERED TOKENS ----

 [('instance', 'NN'), (',', ','), ('multi-modal', 'JJ'), ('interfaces', 'NNS'), ('include', 'VBP'), ('text', 'JJ'), ('speech', 'NN'), ('processing', 'NN'), ('clearly', 'RB'), ('mandated', 'VBD'), ('military', 'JJ'), ('apphcations', 'NNS'), (',', ','), ('high-quality', 'JJ'), ('audio-visual', 'JJ'), ('hardware', 'NN'), ('expected', 'VBN'), (';', ':'), ('hand', 'NN'), (',', ','), ('market', 'NN'), ('forces', 'NNS'), ('argue', 'VBP'), ('supporting', 'VBG'), ('lowest', 'JJS'), ('common', 'JJ'), ('denominator', 'NN'), ('hardware', 'NN'), (',', ','), (',', ','), ('terminal', 'JJ'), (',', ','), ('dominant', 'JJ'), ('screen', 'JJ'), ('technology', 'NN'), ('currently', 'RB'), ('commonplace', 'VBP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['instance ,', ', multi-modal', 'multi-modal interfaces', 'interfaces include', 'include text', 'text speech', 'speech processing', 'processing clearly', 'clearly mandated', 'mandated military', 'military apphcations', 'apphcations ,', ', high-quality', 'high-quality audio-visual', 'audio-visual hardware', 'hardware expected', 'expected ;', '; hand', 'hand ,', ', market', 'market forces', 'forces argue', 'argue supporting', 'supporting lowest', 'lowest common', 'common denominator', 'denominator hardware', 'hardware ,', ', ,', ', terminal', 'terminal ,', ', dominant', 'dominant screen', 'screen technology', 'technology currently', 'currently commonplace', 'commonplace .'] 

 TOTAL BIGRAMS --> 37 



 ---- TRI-GRAMS ---- 

 ['instance , multi-modal', ', multi-modal interfaces', 'multi-modal interfaces include', 'interfaces include text', 'include text speech', 'text speech processing', 'speech processing clearly', 'processing clearly mandated', 'clearly mandated military', 'mandated military apphcations', 'military apphcations ,', 'apphcations , high-quality', ', high-quality audio-visual', 'high-quality audio-visual hardware', 'audio-visual hardware expected', 'hardware expected ;', 'expected ; hand', '; hand ,', 'hand , market', ', market forces', 'market forces argue', 'forces argue supporting', 'argue supporting lowest', 'supporting lowest common', 'lowest common denominator', 'common denominator hardware', 'denominator hardware ,', 'hardware , ,', ', , terminal', ', terminal ,', 'terminal , dominant', ', dominant screen', 'dominant screen technology', 'screen technology currently', 'technology currently commonplace', 'currently commonplace .'] 

 TOTAL TRIGRAMS --> 36 



 ---- NOUN PHRASES ---- 

 ['instance', 'text speech', 'processing', 'high-quality audio-visual hardware', 'hand', 'market', 'common denominator', 'hardware', 'dominant screen technology'] 

 TOTAL NOUN PHRASES --> 9 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['instanc', ',', 'multi-mod', 'interfac', 'includ', 'text', 'speech', 'process', 'clearli', 'mandat', 'militari', 'apphcat', ',', 'high-qual', 'audio-visu', 'hardwar', 'expect', ';', 'hand', ',', 'market', 'forc', 'argu', 'support', 'lowest', 'common', 'denomin', 'hardwar', ',', ',', 'termin', ',', 'domin', 'screen', 'technolog', 'current', 'commonplac', '.']

 TOTAL PORTER STEM WORDS ==> 38



 ---- SNOWBALL STEMMING ----

['instanc', ',', 'multi-mod', 'interfac', 'includ', 'text', 'speech', 'process', 'clear', 'mandat', 'militari', 'apphcat', ',', 'high-qual', 'audio-visu', 'hardwar', 'expect', ';', 'hand', ',', 'market', 'forc', 'argu', 'support', 'lowest', 'common', 'denomin', 'hardwar', ',', ',', 'termin', ',', 'domin', 'screen', 'technolog', 'current', 'commonplac', '.']

 TOTAL SNOWBALL STEM WORDS ==> 38



 ---- LEMMATIZATION ----

['instance', ',', 'multi-modal', 'interface', 'include', 'text', 'speech', 'processing', 'clearly', 'mandated', 'military', 'apphcations', ',', 'high-quality', 'audio-visual', 'hardware', 'expected', ';', 'hand', ',', 'market', 'force', 'argue', 'supporting', 'lowest', 'common', 'denominator', 'hardware', ',', ',', 'terminal', ',', 'dominant', 'screen', 'technology', 'currently', 'commonplace', '.']

 TOTAL LEMMATIZE WORDS ==> 38

************************************************************************************************************************

293 --> Similarly, commercial sources can be expected to  fund evolutionary improvements in current technology and short-term risks likely to have high payoff. 


 ---- TOKENS ----

 ['Similarly', ',', 'commercial', 'sources', 'can', 'be', 'expected', 'to', 'fund', 'evolutionary', 'improvements', 'in', 'current', 'technology', 'and', 'short-term', 'risks', 'likely', 'to', 'have', 'high', 'payoff', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('Similarly', 'RB'), (',', ','), ('commercial', 'JJ'), ('sources', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('expected', 'VBN'), ('to', 'TO'), ('fund', 'VB'), ('evolutionary', 'JJ'), ('improvements', 'NNS'), ('in', 'IN'), ('current', 'JJ'), ('technology', 'NN'), ('and', 'CC'), ('short-term', 'JJ'), ('risks', 'NNS'), ('likely', 'JJ'), ('to', 'TO'), ('have', 'VB'), ('high', 'JJ'), ('payoff', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Similarly', ',', 'commercial', 'sources', 'expected', 'fund', 'evolutionary', 'improvements', 'current', 'technology', 'short-term', 'risks', 'likely', 'high', 'payoff', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('Similarly', 'RB'), (',', ','), ('commercial', 'JJ'), ('sources', 'NNS'), ('expected', 'VBN'), ('fund', 'NN'), ('evolutionary', 'JJ'), ('improvements', 'NNS'), ('current', 'JJ'), ('technology', 'NN'), ('short-term', 'JJ'), ('risks', 'NNS'), ('likely', 'JJ'), ('high', 'JJ'), ('payoff', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Similarly ,', ', commercial', 'commercial sources', 'sources expected', 'expected fund', 'fund evolutionary', 'evolutionary improvements', 'improvements current', 'current technology', 'technology short-term', 'short-term risks', 'risks likely', 'likely high', 'high payoff', 'payoff .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['Similarly , commercial', ', commercial sources', 'commercial sources expected', 'sources expected fund', 'expected fund evolutionary', 'fund evolutionary improvements', 'evolutionary improvements current', 'improvements current technology', 'current technology short-term', 'technology short-term risks', 'short-term risks likely', 'risks likely high', 'likely high payoff', 'high payoff .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ['fund', 'current technology', 'likely high payoff'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['similarli', ',', 'commerci', 'sourc', 'expect', 'fund', 'evolutionari', 'improv', 'current', 'technolog', 'short-term', 'risk', 'like', 'high', 'payoff', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['similar', ',', 'commerci', 'sourc', 'expect', 'fund', 'evolutionari', 'improv', 'current', 'technolog', 'short-term', 'risk', 'like', 'high', 'payoff', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['Similarly', ',', 'commercial', 'source', 'expected', 'fund', 'evolutionary', 'improvement', 'current', 'technology', 'short-term', 'risk', 'likely', 'high', 'payoff', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

294 --> However,  the next one or two generations of science and technology cannot be expected to emerge without substantial  government funding. 


 ---- TOKENS ----

 ['However', ',', 'the', 'next', 'one', 'or', 'two', 'generations', 'of', 'science', 'and', 'technology', 'can', 'not', 'be', 'expected', 'to', 'emerge', 'without', 'substantial', 'government', 'funding', '.'] 

 TOTAL TOKENS ==> 23

 ---- POST ----

 [('However', 'RB'), (',', ','), ('the', 'DT'), ('next', 'JJ'), ('one', 'CD'), ('or', 'CC'), ('two', 'CD'), ('generations', 'NNS'), ('of', 'IN'), ('science', 'NN'), ('and', 'CC'), ('technology', 'NN'), ('can', 'MD'), ('not', 'RB'), ('be', 'VB'), ('expected', 'VBN'), ('to', 'TO'), ('emerge', 'VB'), ('without', 'IN'), ('substantial', 'JJ'), ('government', 'NN'), ('funding', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['However', ',', 'next', 'one', 'two', 'generations', 'science', 'technology', 'expected', 'emerge', 'without', 'substantial', 'government', 'funding', '.']

 TOTAL FILTERED TOKENS ==>  15

 ---- POST FOR FILTERED TOKENS ----

 [('However', 'RB'), (',', ','), ('next', 'JJ'), ('one', 'CD'), ('two', 'CD'), ('generations', 'NNS'), ('science', 'NN'), ('technology', 'NN'), ('expected', 'VBN'), ('emerge', 'NN'), ('without', 'IN'), ('substantial', 'JJ'), ('government', 'NN'), ('funding', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['However ,', ', next', 'next one', 'one two', 'two generations', 'generations science', 'science technology', 'technology expected', 'expected emerge', 'emerge without', 'without substantial', 'substantial government', 'government funding', 'funding .'] 

 TOTAL BIGRAMS --> 14 



 ---- TRI-GRAMS ---- 

 ['However , next', ', next one', 'next one two', 'one two generations', 'two generations science', 'generations science technology', 'science technology expected', 'technology expected emerge', 'expected emerge without', 'emerge without substantial', 'without substantial government', 'substantial government funding', 'government funding .'] 

 TOTAL TRIGRAMS --> 13 



 ---- NOUN PHRASES ---- 

 ['science', 'technology', 'emerge', 'substantial government', 'funding'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['howev', ',', 'next', 'one', 'two', 'gener', 'scienc', 'technolog', 'expect', 'emerg', 'without', 'substanti', 'govern', 'fund', '.']

 TOTAL PORTER STEM WORDS ==> 15



 ---- SNOWBALL STEMMING ----

['howev', ',', 'next', 'one', 'two', 'generat', 'scienc', 'technolog', 'expect', 'emerg', 'without', 'substanti', 'govern', 'fund', '.']

 TOTAL SNOWBALL STEM WORDS ==> 15



 ---- LEMMATIZATION ----

['However', ',', 'next', 'one', 'two', 'generation', 'science', 'technology', 'expected', 'emerge', 'without', 'substantial', 'government', 'funding', '.']

 TOTAL LEMMATIZE WORDS ==> 15

************************************************************************************************************************

295 --> 2R. 


 ---- TOKENS ----

 ['2R', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2R', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2R', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2R', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2R .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2r', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2r', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2R', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

296 --> C. Wood, "The Language Advantage: Japan's Machine Translators Rule he Market", High Technology Business, November 1987, p.  17. 


 ---- TOKENS ----

 ['C.', 'Wood', ',', '``', 'The', 'Language', 'Advantage', ':', 'Japan', "'s", 'Machine', 'Translators', 'Rule', 'he', 'Market', "''", ',', 'High', 'Technology', 'Business', ',', 'November', '1987', ',', 'p.', '17', '.'] 

 TOTAL TOKENS ==> 27

 ---- POST ----

 [('C.', 'NNP'), ('Wood', 'NNP'), (',', ','), ('``', '``'), ('The', 'DT'), ('Language', 'NNP'), ('Advantage', 'NN'), (':', ':'), ('Japan', 'NNP'), ("'s", 'POS'), ('Machine', 'NNP'), ('Translators', 'NNPS'), ('Rule', 'NNP'), ('he', 'PRP'), ('Market', 'NNP'), ("''", "''"), (',', ','), ('High', 'NNP'), ('Technology', 'NNP'), ('Business', 'NNP'), (',', ','), ('November', 'NNP'), ('1987', 'CD'), (',', ','), ('p.', 'VBD'), ('17', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['C.', 'Wood', ',', '``', 'Language', 'Advantage', ':', 'Japan', "'s", 'Machine', 'Translators', 'Rule', 'Market', "''", ',', 'High', 'Technology', 'Business', ',', 'November', '1987', ',', 'p.', '17', '.']

 TOTAL FILTERED TOKENS ==>  25

 ---- POST FOR FILTERED TOKENS ----

 [('C.', 'NNP'), ('Wood', 'NNP'), (',', ','), ('``', '``'), ('Language', 'JJ'), ('Advantage', 'NN'), (':', ':'), ('Japan', 'NNP'), ("'s", 'POS'), ('Machine', 'NNP'), ('Translators', 'NNPS'), ('Rule', 'NNP'), ('Market', 'NNP'), ("''", "''"), (',', ','), ('High', 'NNP'), ('Technology', 'NNP'), ('Business', 'NNP'), (',', ','), ('November', 'NNP'), ('1987', 'CD'), (',', ','), ('p.', 'VBD'), ('17', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['C. Wood', 'Wood ,', ', ``', '`` Language', 'Language Advantage', 'Advantage :', ': Japan', "Japan 's", "'s Machine", 'Machine Translators', 'Translators Rule', 'Rule Market', "Market ''", "'' ,", ', High', 'High Technology', 'Technology Business', 'Business ,', ', November', 'November 1987', '1987 ,', ', p.', 'p. 17', '17 .'] 

 TOTAL BIGRAMS --> 24 



 ---- TRI-GRAMS ---- 

 ['C. Wood ,', 'Wood , ``', ', `` Language', '`` Language Advantage', 'Language Advantage :', 'Advantage : Japan', ": Japan 's", "Japan 's Machine", "'s Machine Translators", 'Machine Translators Rule', 'Translators Rule Market', "Rule Market ''", "Market '' ,", "'' , High", ', High Technology', 'High Technology Business', 'Technology Business ,', 'Business , November', ', November 1987', 'November 1987 ,', '1987 , p.', ', p. 17', 'p. 17 .'] 

 TOTAL TRIGRAMS --> 23 



 ---- NOUN PHRASES ---- 

 ['Language Advantage'] 

 TOTAL NOUN PHRASES --> 1 



 ---- NER ----

 
 ORGANIZATION ---> ['Machine Translators Rule Market']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['High Technology Business']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> ['Japan']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['c.', 'wood', ',', '``', 'languag', 'advantag', ':', 'japan', "'s", 'machin', 'translat', 'rule', 'market', "''", ',', 'high', 'technolog', 'busi', ',', 'novemb', '1987', ',', 'p.', '17', '.']

 TOTAL PORTER STEM WORDS ==> 25



 ---- SNOWBALL STEMMING ----

['c.', 'wood', ',', '``', 'languag', 'advantag', ':', 'japan', "'s", 'machin', 'translat', 'rule', 'market', "''", ',', 'high', 'technolog', 'busi', ',', 'novemb', '1987', ',', 'p.', '17', '.']

 TOTAL SNOWBALL STEM WORDS ==> 25



 ---- LEMMATIZATION ----

['C.', 'Wood', ',', '``', 'Language', 'Advantage', ':', 'Japan', "'s", 'Machine', 'Translators', 'Rule', 'Market', "''", ',', 'High', 'Technology', 'Business', ',', 'November', '1987', ',', 'p.', '17', '.']

 TOTAL LEMMATIZE WORDS ==> 25

************************************************************************************************************************

297 --> 491   SCANNING (S.H%)  MACHINE 'TRANSLATIC6 . 


 ---- TOKENS ----

 ['491', 'SCANNING', '(', 'S.H', '%', ')', 'MACHINE', "'TRANSLATIC6", '.'] 

 TOTAL TOKENS ==> 9

 ---- POST ----

 [('491', 'CD'), ('SCANNING', 'NNP'), ('(', '('), ('S.H', 'NNP'), ('%', 'NN'), (')', ')'), ('MACHINE', 'NNP'), ("'TRANSLATIC6", 'POS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['491', 'SCANNING', '(', 'S.H', '%', ')', 'MACHINE', "'TRANSLATIC6", '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('491', 'CD'), ('SCANNING', 'NNP'), ('(', '('), ('S.H', 'NNP'), ('%', 'NN'), (')', ')'), ('MACHINE', 'NNP'), ("'TRANSLATIC6", 'POS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['491 SCANNING', 'SCANNING (', '( S.H', 'S.H %', '% )', ') MACHINE', "MACHINE 'TRANSLATIC6", "'TRANSLATIC6 ."] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['491 SCANNING (', 'SCANNING ( S.H', '( S.H %', 'S.H % )', '% ) MACHINE', ") MACHINE 'TRANSLATIC6", "MACHINE 'TRANSLATIC6 ."] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> ['MACHINE']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['491', 'scan', '(', 's.h', '%', ')', 'machin', "'translatic6", '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['491', 'scan', '(', 's.h', '%', ')', 'machin', 'translatic6', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['491', 'SCANNING', '(', 'S.H', '%', ')', 'MACHINE', "'TRANSLATIC6", '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

298 --> . 


 ---- TOKENS ----

 ['.'] 

 TOTAL TOKENS ==> 1

 ---- POST ----

 [('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['.']

 TOTAL FILTERED TOKENS ==>  1

 ---- POST FOR FILTERED TOKENS ----

 [('.', '.')] 



 ---- BI-GRAMS ---- 

 [] 

 TOTAL BIGRAMS --> 0 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['.']

 TOTAL PORTER STEM WORDS ==> 1



 ---- SNOWBALL STEMMING ----

['.']

 TOTAL SNOWBALL STEM WORDS ==> 1



 ---- LEMMATIZATION ----

['.']

 TOTAL LEMMATIZE WORDS ==> 1

************************************************************************************************************************

299 --> . 


 ---- TOKENS ----

 ['.'] 

 TOTAL TOKENS ==> 1

 ---- POST ----

 [('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['.']

 TOTAL FILTERED TOKENS ==>  1

 ---- POST FOR FILTERED TOKENS ----

 [('.', '.')] 



 ---- BI-GRAMS ---- 

 [] 

 TOTAL BIGRAMS --> 0 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['.']

 TOTAL PORTER STEM WORDS ==> 1



 ---- SNOWBALL STEMMING ----

['.']

 TOTAL SNOWBALL STEM WORDS ==> 1



 ---- LEMMATIZATION ----

['.']

 TOTAL LEMMATIZE WORDS ==> 1

************************************************************************************************************************

300 --> . 


 ---- TOKENS ----

 ['.'] 

 TOTAL TOKENS ==> 1

 ---- POST ----

 [('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['.']

 TOTAL FILTERED TOKENS ==>  1

 ---- POST FOR FILTERED TOKENS ----

 [('.', '.')] 



 ---- BI-GRAMS ---- 

 [] 

 TOTAL BIGRAMS --> 0 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['.']

 TOTAL PORTER STEM WORDS ==> 1



 ---- SNOWBALL STEMMING ----

['.']

 TOTAL SNOWBALL STEM WORDS ==> 1



 ---- LEMMATIZATION ----

['.']

 TOTAL LEMMATIZE WORDS ==> 1

************************************************************************************************************************

301 --> . 


 ---- TOKENS ----

 ['.'] 

 TOTAL TOKENS ==> 1

 ---- POST ----

 [('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['.']

 TOTAL FILTERED TOKENS ==>  1

 ---- POST FOR FILTERED TOKENS ----

 [('.', '.')] 



 ---- BI-GRAMS ---- 

 [] 

 TOTAL BIGRAMS --> 0 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['.']

 TOTAL PORTER STEM WORDS ==> 1



 ---- SNOWBALL STEMMING ----

['.']

 TOTAL SNOWBALL STEM WORDS ==> 1



 ---- LEMMATIZATION ----

['.']

 TOTAL LEMMATIZE WORDS ==> 1

************************************************************************************************************************

302 --> . 


 ---- TOKENS ----

 ['.'] 

 TOTAL TOKENS ==> 1

 ---- POST ----

 [('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['.']

 TOTAL FILTERED TOKENS ==>  1

 ---- POST FOR FILTERED TOKENS ----

 [('.', '.')] 



 ---- BI-GRAMS ---- 

 [] 

 TOTAL BIGRAMS --> 0 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['.']

 TOTAL PORTER STEM WORDS ==> 1



 ---- SNOWBALL STEMMING ----

['.']

 TOTAL SNOWBALL STEM WORDS ==> 1



 ---- LEMMATIZATION ----

['.']

 TOTAL LEMMATIZE WORDS ==> 1

************************************************************************************************************************

303 --> OTHER (8.1'  TALKWRITER8 (17.4%)  INTERFACES (el.4%)  Figure 4-1: NLP Applicmtlona-Market Share, USA, 1987  Area 1985 [ 987 1989 1991 ! 


 ---- TOKENS ----

 ['OTHER', '(', '8.1', "'", 'TALKWRITER8', '(', '17.4', '%', ')', 'INTERFACES', '(', 'el.4', '%', ')', 'Figure', '4-1', ':', 'NLP', 'Applicmtlona-Market', 'Share', ',', 'USA', ',', '1987', 'Area', '1985', '[', '987', '1989', '1991', '!'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('OTHER', 'NNP'), ('(', '('), ('8.1', 'CD'), ("'", "''"), ('TALKWRITER8', 'NNP'), ('(', '('), ('17.4', 'CD'), ('%', 'NN'), (')', ')'), ('INTERFACES', 'NNP'), ('(', '('), ('el.4', 'FW'), ('%', 'NN'), (')', ')'), ('Figure', 'NN'), ('4-1', 'JJ'), (':', ':'), ('NLP', 'NNP'), ('Applicmtlona-Market', 'NNP'), ('Share', 'NNP'), (',', ','), ('USA', 'NNP'), (',', ','), ('1987', 'CD'), ('Area', 'NNP'), ('1985', 'CD'), ('[', 'NNP'), ('987', 'CD'), ('1989', 'CD'), ('1991', 'CD'), ('!', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['(', '8.1', "'", 'TALKWRITER8', '(', '17.4', '%', ')', 'INTERFACES', '(', 'el.4', '%', ')', 'Figure', '4-1', ':', 'NLP', 'Applicmtlona-Market', 'Share', ',', 'USA', ',', '1987', 'Area', '1985', '[', '987', '1989', '1991', '!']

 TOTAL FILTERED TOKENS ==>  30

 ---- POST FOR FILTERED TOKENS ----

 [('(', '('), ('8.1', 'CD'), ("'", "''"), ('TALKWRITER8', 'NNP'), ('(', '('), ('17.4', 'CD'), ('%', 'NN'), (')', ')'), ('INTERFACES', 'NNP'), ('(', '('), ('el.4', 'FW'), ('%', 'NN'), (')', ')'), ('Figure', 'NN'), ('4-1', 'JJ'), (':', ':'), ('NLP', 'NNP'), ('Applicmtlona-Market', 'NNP'), ('Share', 'NNP'), (',', ','), ('USA', 'NNP'), (',', ','), ('1987', 'CD'), ('Area', 'NNP'), ('1985', 'CD'), ('[', 'NNP'), ('987', 'CD'), ('1989', 'CD'), ('1991', 'CD'), ('!', '.')] 



 ---- BI-GRAMS ---- 

 ['( 8.1', "8.1 '", "' TALKWRITER8", 'TALKWRITER8 (', '( 17.4', '17.4 %', '% )', ') INTERFACES', 'INTERFACES (', '( el.4', 'el.4 %', '% )', ') Figure', 'Figure 4-1', '4-1 :', ': NLP', 'NLP Applicmtlona-Market', 'Applicmtlona-Market Share', 'Share ,', ', USA', 'USA ,', ', 1987', '1987 Area', 'Area 1985', '1985 [', '[ 987', '987 1989', '1989 1991', '1991 !'] 

 TOTAL BIGRAMS --> 29 



 ---- TRI-GRAMS ---- 

 ["( 8.1 '", "8.1 ' TALKWRITER8", "' TALKWRITER8 (", 'TALKWRITER8 ( 17.4', '( 17.4 %', '17.4 % )', '% ) INTERFACES', ') INTERFACES (', 'INTERFACES ( el.4', '( el.4 %', 'el.4 % )', '% ) Figure', ') Figure 4-1', 'Figure 4-1 :', '4-1 : NLP', ': NLP Applicmtlona-Market', 'NLP Applicmtlona-Market Share', 'Applicmtlona-Market Share ,', 'Share , USA', ', USA ,', 'USA , 1987', ', 1987 Area', '1987 Area 1985', 'Area 1985 [', '1985 [ 987', '[ 987 1989', '987 1989 1991', '1989 1991 !'] 

 TOTAL TRIGRAMS --> 28 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 []

 ---- PORTER STEMMING ----

['(', '8.1', "'", 'talkwriter8', '(', '17.4', '%', ')', 'interfac', '(', 'el.4', '%', ')', 'figur', '4-1', ':', 'nlp', 'applicmtlona-market', 'share', ',', 'usa', ',', '1987', 'area', '1985', '[', '987', '1989', '1991', '!']

 TOTAL PORTER STEM WORDS ==> 30



 ---- SNOWBALL STEMMING ----

['(', '8.1', "'", 'talkwriter8', '(', '17.4', '%', ')', 'interfac', '(', 'el.4', '%', ')', 'figur', '4-1', ':', 'nlp', 'applicmtlona-market', 'share', ',', 'usa', ',', '1987', 'area', '1985', '[', '987', '1989', '1991', '!']

 TOTAL SNOWBALL STEM WORDS ==> 30



 ---- LEMMATIZATION ----

['(', '8.1', "'", 'TALKWRITER8', '(', '17.4', '%', ')', 'INTERFACES', '(', 'el.4', '%', ')', 'Figure', '4-1', ':', 'NLP', 'Applicmtlona-Market', 'Share', ',', 'USA', ',', '1987', 'Area', '1985', '[', '987', '1989', '1991', '!']

 TOTAL LEMMATIZE WORDS ==> 30

************************************************************************************************************************

304 --> 993 1995  Interfaces 12. t 2[.7 36.3 64.4 137.4 254.4  Machine Translation 2.3 1.7 2.9 8.2 9.6 t4.4  Content Scanning 0.7 1.7 5. l I 1.0 20.4 39. 


 ---- TOKENS ----

 ['993', '1995', 'Interfaces', '12.', 't', '2', '[', '.7', '36.3', '64.4', '137.4', '254.4', 'Machine', 'Translation', '2.3', '1.7', '2.9', '8.2', '9.6', 't4.4', 'Content', 'Scanning', '0.7', '1.7', '5.', 'l', 'I', '1.0', '20.4', '39', '.'] 

 TOTAL TOKENS ==> 31

 ---- POST ----

 [('993', 'CD'), ('1995', 'CD'), ('Interfaces', 'NNS'), ('12.', 'CD'), ('t', 'JJ'), ('2', 'CD'), ('[', 'JJ'), ('.7', 'VBD'), ('36.3', 'CD'), ('64.4', 'CD'), ('137.4', 'CD'), ('254.4', 'CD'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('2.3', 'CD'), ('1.7', 'CD'), ('2.9', 'CD'), ('8.2', 'CD'), ('9.6', 'CD'), ('t4.4', 'NN'), ('Content', 'NNP'), ('Scanning', 'NNP'), ('0.7', 'CD'), ('1.7', 'CD'), ('5.', 'CD'), ('l', 'NN'), ('I', 'PRP'), ('1.0', 'CD'), ('20.4', 'CD'), ('39', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['993', '1995', 'Interfaces', '12.', '2', '[', '.7', '36.3', '64.4', '137.4', '254.4', 'Machine', 'Translation', '2.3', '1.7', '2.9', '8.2', '9.6', 't4.4', 'Content', 'Scanning', '0.7', '1.7', '5.', 'l', '1.0', '20.4', '39', '.']

 TOTAL FILTERED TOKENS ==>  29

 ---- POST FOR FILTERED TOKENS ----

 [('993', 'CD'), ('1995', 'CD'), ('Interfaces', 'NNS'), ('12.', 'CD'), ('2', 'CD'), ('[', 'NN'), ('.7', 'VBD'), ('36.3', 'CD'), ('64.4', 'CD'), ('137.4', 'CD'), ('254.4', 'CD'), ('Machine', 'NNP'), ('Translation', 'NNP'), ('2.3', 'CD'), ('1.7', 'CD'), ('2.9', 'CD'), ('8.2', 'CD'), ('9.6', 'CD'), ('t4.4', 'NN'), ('Content', 'NNP'), ('Scanning', 'NNP'), ('0.7', 'CD'), ('1.7', 'CD'), ('5.', 'CD'), ('l', 'NN'), ('1.0', 'CD'), ('20.4', 'CD'), ('39', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['993 1995', '1995 Interfaces', 'Interfaces 12.', '12. 2', '2 [', '[ .7', '.7 36.3', '36.3 64.4', '64.4 137.4', '137.4 254.4', '254.4 Machine', 'Machine Translation', 'Translation 2.3', '2.3 1.7', '1.7 2.9', '2.9 8.2', '8.2 9.6', '9.6 t4.4', 't4.4 Content', 'Content Scanning', 'Scanning 0.7', '0.7 1.7', '1.7 5.', '5. l', 'l 1.0', '1.0 20.4', '20.4 39', '39 .'] 

 TOTAL BIGRAMS --> 28 



 ---- TRI-GRAMS ---- 

 ['993 1995 Interfaces', '1995 Interfaces 12.', 'Interfaces 12. 2', '12. 2 [', '2 [ .7', '[ .7 36.3', '.7 36.3 64.4', '36.3 64.4 137.4', '64.4 137.4 254.4', '137.4 254.4 Machine', '254.4 Machine Translation', 'Machine Translation 2.3', 'Translation 2.3 1.7', '2.3 1.7 2.9', '1.7 2.9 8.2', '2.9 8.2 9.6', '8.2 9.6 t4.4', '9.6 t4.4 Content', 't4.4 Content Scanning', 'Content Scanning 0.7', 'Scanning 0.7 1.7', '0.7 1.7 5.', '1.7 5. l', '5. l 1.0', 'l 1.0 20.4', '1.0 20.4 39', '20.4 39 .'] 

 TOTAL TRIGRAMS --> 27 



 ---- NOUN PHRASES ---- 

 ['[', 't4.4', 'l'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> ['Content']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Machine']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['993', '1995', 'interfac', '12.', '2', '[', '.7', '36.3', '64.4', '137.4', '254.4', 'machin', 'translat', '2.3', '1.7', '2.9', '8.2', '9.6', 't4.4', 'content', 'scan', '0.7', '1.7', '5.', 'l', '1.0', '20.4', '39', '.']

 TOTAL PORTER STEM WORDS ==> 29



 ---- SNOWBALL STEMMING ----

['993', '1995', 'interfac', '12.', '2', '[', '.7', '36.3', '64.4', '137.4', '254.4', 'machin', 'translat', '2.3', '1.7', '2.9', '8.2', '9.6', 't4.4', 'content', 'scan', '0.7', '1.7', '5.', 'l', '1.0', '20.4', '39', '.']

 TOTAL SNOWBALL STEM WORDS ==> 29



 ---- LEMMATIZATION ----

['993', '1995', 'Interfaces', '12.', '2', '[', '.7', '36.3', '64.4', '137.4', '254.4', 'Machine', 'Translation', '2.3', '1.7', '2.9', '8.2', '9.6', 't4.4', 'Content', 'Scanning', '0.7', '1.7', '5.', 'l', '1.0', '20.4', '39', '.']

 TOTAL LEMMATIZE WORDS ==> 29

************************************************************************************************************************

305 --> I  Talkwriter 0.0 5.7 22.0 68.8 177 306  Other 0.5 2.0 2.0 9.4 25.4 90.0  Figure 4-2: Forecasts for Natural Language Products by Application in Millions of Dollars 3  We believe a secondary effect of the Strategic Computing Program has been greater industrial R&D effort  in natural language technology. 


 ---- TOKENS ----

 ['I', 'Talkwriter', '0.0', '5.7', '22.0', '68.8', '177', '306', 'Other', '0.5', '2.0', '2.0', '9.4', '25.4', '90.0', 'Figure', '4-2', ':', 'Forecasts', 'for', 'Natural', 'Language', 'Products', 'by', 'Application', 'in', 'Millions', 'of', 'Dollars', '3', 'We', 'believe', 'a', 'secondary', 'effect', 'of', 'the', 'Strategic', 'Computing', 'Program', 'has', 'been', 'greater', 'industrial', 'R', '&', 'D', 'effort', 'in', 'natural', 'language', 'technology', '.'] 

 TOTAL TOKENS ==> 53

 ---- POST ----

 [('I', 'PRP'), ('Talkwriter', 'VBP'), ('0.0', 'CD'), ('5.7', 'CD'), ('22.0', 'CD'), ('68.8', 'CD'), ('177', 'CD'), ('306', 'CD'), ('Other', 'JJ'), ('0.5', 'CD'), ('2.0', 'CD'), ('2.0', 'CD'), ('9.4', 'CD'), ('25.4', 'CD'), ('90.0', 'CD'), ('Figure', 'NN'), ('4-2', 'JJ'), (':', ':'), ('Forecasts', 'NNS'), ('for', 'IN'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Products', 'NNPS'), ('by', 'IN'), ('Application', 'NNP'), ('in', 'IN'), ('Millions', 'NNP'), ('of', 'IN'), ('Dollars', 'NNP'), ('3', 'CD'), ('We', 'PRP'), ('believe', 'VBP'), ('a', 'DT'), ('secondary', 'JJ'), ('effect', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Strategic', 'NNP'), ('Computing', 'NNP'), ('Program', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('greater', 'JJR'), ('industrial', 'JJ'), ('R', 'NNP'), ('&', 'CC'), ('D', 'NNP'), ('effort', 'NN'), ('in', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('technology', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Talkwriter', '0.0', '5.7', '22.0', '68.8', '177', '306', '0.5', '2.0', '2.0', '9.4', '25.4', '90.0', 'Figure', '4-2', ':', 'Forecasts', 'Natural', 'Language', 'Products', 'Application', 'Millions', 'Dollars', '3', 'believe', 'secondary', 'effect', 'Strategic', 'Computing', 'Program', 'greater', 'industrial', 'R', '&', 'effort', 'natural', 'language', 'technology', '.']

 TOTAL FILTERED TOKENS ==>  39

 ---- POST FOR FILTERED TOKENS ----

 [('Talkwriter', 'RB'), ('0.0', 'CD'), ('5.7', 'CD'), ('22.0', 'CD'), ('68.8', 'CD'), ('177', 'CD'), ('306', 'CD'), ('0.5', 'CD'), ('2.0', 'CD'), ('2.0', 'CD'), ('9.4', 'CD'), ('25.4', 'CD'), ('90.0', 'CD'), ('Figure', 'NN'), ('4-2', 'JJ'), (':', ':'), ('Forecasts', 'NNS'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Products', 'NNPS'), ('Application', 'NNP'), ('Millions', 'NNP'), ('Dollars', 'NNP'), ('3', 'CD'), ('believe', 'VBP'), ('secondary', 'JJ'), ('effect', 'NN'), ('Strategic', 'NNP'), ('Computing', 'NNP'), ('Program', 'NNP'), ('greater', 'JJR'), ('industrial', 'JJ'), ('R', 'NNP'), ('&', 'CC'), ('effort', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('technology', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Talkwriter 0.0', '0.0 5.7', '5.7 22.0', '22.0 68.8', '68.8 177', '177 306', '306 0.5', '0.5 2.0', '2.0 2.0', '2.0 9.4', '9.4 25.4', '25.4 90.0', '90.0 Figure', 'Figure 4-2', '4-2 :', ': Forecasts', 'Forecasts Natural', 'Natural Language', 'Language Products', 'Products Application', 'Application Millions', 'Millions Dollars', 'Dollars 3', '3 believe', 'believe secondary', 'secondary effect', 'effect Strategic', 'Strategic Computing', 'Computing Program', 'Program greater', 'greater industrial', 'industrial R', 'R &', '& effort', 'effort natural', 'natural language', 'language technology', 'technology .'] 

 TOTAL BIGRAMS --> 38 



 ---- TRI-GRAMS ---- 

 ['Talkwriter 0.0 5.7', '0.0 5.7 22.0', '5.7 22.0 68.8', '22.0 68.8 177', '68.8 177 306', '177 306 0.5', '306 0.5 2.0', '0.5 2.0 2.0', '2.0 2.0 9.4', '2.0 9.4 25.4', '9.4 25.4 90.0', '25.4 90.0 Figure', '90.0 Figure 4-2', 'Figure 4-2 :', '4-2 : Forecasts', ': Forecasts Natural', 'Forecasts Natural Language', 'Natural Language Products', 'Language Products Application', 'Products Application Millions', 'Application Millions Dollars', 'Millions Dollars 3', 'Dollars 3 believe', '3 believe secondary', 'believe secondary effect', 'secondary effect Strategic', 'effect Strategic Computing', 'Strategic Computing Program', 'Computing Program greater', 'Program greater industrial', 'greater industrial R', 'industrial R &', 'R & effort', '& effort natural', 'effort natural language', 'natural language technology', 'language technology .'] 

 TOTAL TRIGRAMS --> 37 



 ---- NOUN PHRASES ---- 

 ['Figure', 'secondary effect', 'effort', 'natural language', 'technology'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['Natural Language Products Application Millions']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> ['Strategic Computing Program']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['talkwrit', '0.0', '5.7', '22.0', '68.8', '177', '306', '0.5', '2.0', '2.0', '9.4', '25.4', '90.0', 'figur', '4-2', ':', 'forecast', 'natur', 'languag', 'product', 'applic', 'million', 'dollar', '3', 'believ', 'secondari', 'effect', 'strateg', 'comput', 'program', 'greater', 'industri', 'r', '&', 'effort', 'natur', 'languag', 'technolog', '.']

 TOTAL PORTER STEM WORDS ==> 39



 ---- SNOWBALL STEMMING ----

['talkwrit', '0.0', '5.7', '22.0', '68.8', '177', '306', '0.5', '2.0', '2.0', '9.4', '25.4', '90.0', 'figur', '4-2', ':', 'forecast', 'natur', 'languag', 'product', 'applic', 'million', 'dollar', '3', 'believ', 'secondari', 'effect', 'strateg', 'comput', 'program', 'greater', 'industri', 'r', '&', 'effort', 'natur', 'languag', 'technolog', '.']

 TOTAL SNOWBALL STEM WORDS ==> 39



 ---- LEMMATIZATION ----

['Talkwriter', '0.0', '5.7', '22.0', '68.8', '177', '306', '0.5', '2.0', '2.0', '9.4', '25.4', '90.0', 'Figure', '4-2', ':', 'Forecasts', 'Natural', 'Language', 'Products', 'Application', 'Millions', 'Dollars', '3', 'believe', 'secondary', 'effect', 'Strategic', 'Computing', 'Program', 'greater', 'industrial', 'R', '&', 'effort', 'natural', 'language', 'technology', '.']

 TOTAL LEMMATIZE WORDS ==> 39

************************************************************************************************************************

306 --> Government investment in technology transfer can further prime the pump of  industrial investment. 


 ---- TOKENS ----

 ['Government', 'investment', 'in', 'technology', 'transfer', 'can', 'further', 'prime', 'the', 'pump', 'of', 'industrial', 'investment', '.'] 

 TOTAL TOKENS ==> 14

 ---- POST ----

 [('Government', 'NNP'), ('investment', 'NN'), ('in', 'IN'), ('technology', 'NN'), ('transfer', 'NN'), ('can', 'MD'), ('further', 'VB'), ('prime', 'VB'), ('the', 'DT'), ('pump', 'NN'), ('of', 'IN'), ('industrial', 'JJ'), ('investment', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Government', 'investment', 'technology', 'transfer', 'prime', 'pump', 'industrial', 'investment', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Government', 'NNP'), ('investment', 'NN'), ('technology', 'NN'), ('transfer', 'NN'), ('prime', 'JJ'), ('pump', 'NN'), ('industrial', 'JJ'), ('investment', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Government investment', 'investment technology', 'technology transfer', 'transfer prime', 'prime pump', 'pump industrial', 'industrial investment', 'investment .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Government investment technology', 'investment technology transfer', 'technology transfer prime', 'transfer prime pump', 'prime pump industrial', 'pump industrial investment', 'industrial investment .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['investment', 'technology', 'transfer', 'prime pump', 'industrial investment'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['govern', 'invest', 'technolog', 'transfer', 'prime', 'pump', 'industri', 'invest', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['govern', 'invest', 'technolog', 'transfer', 'prime', 'pump', 'industri', 'invest', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Government', 'investment', 'technology', 'transfer', 'prime', 'pump', 'industrial', 'investment', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

307 --> Judging when a laboratory system is ready for transfer to the real world is difficult. 


 ---- TOKENS ----

 ['Judging', 'when', 'a', 'laboratory', 'system', 'is', 'ready', 'for', 'transfer', 'to', 'the', 'real', 'world', 'is', 'difficult', '.'] 

 TOTAL TOKENS ==> 16

 ---- POST ----

 [('Judging', 'VBG'), ('when', 'WRB'), ('a', 'DT'), ('laboratory', 'NN'), ('system', 'NN'), ('is', 'VBZ'), ('ready', 'JJ'), ('for', 'IN'), ('transfer', 'NN'), ('to', 'TO'), ('the', 'DT'), ('real', 'JJ'), ('world', 'NN'), ('is', 'VBZ'), ('difficult', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Judging', 'laboratory', 'system', 'ready', 'transfer', 'real', 'world', 'difficult', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('Judging', 'VBG'), ('laboratory', 'NN'), ('system', 'NN'), ('ready', 'JJ'), ('transfer', 'NN'), ('real', 'JJ'), ('world', 'NN'), ('difficult', 'JJ'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Judging laboratory', 'laboratory system', 'system ready', 'ready transfer', 'transfer real', 'real world', 'world difficult', 'difficult .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['Judging laboratory system', 'laboratory system ready', 'system ready transfer', 'ready transfer real', 'transfer real world', 'real world difficult', 'world difficult .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['laboratory', 'system', 'ready transfer', 'real world'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['judg', 'laboratori', 'system', 'readi', 'transfer', 'real', 'world', 'difficult', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['judg', 'laboratori', 'system', 'readi', 'transfer', 'real', 'world', 'difficult', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['Judging', 'laboratory', 'system', 'ready', 'transfer', 'real', 'world', 'difficult', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

308 --> One approach to  e~/aluating whether a system is ready is to measure the effort requited to achieve some specified level of  performance m a new application domain. 


 ---- TOKENS ----

 ['One', 'approach', 'to', 'e~/aluating', 'whether', 'a', 'system', 'is', 'ready', 'is', 'to', 'measure', 'the', 'effort', 'requited', 'to', 'achieve', 'some', 'specified', 'level', 'of', 'performance', 'm', 'a', 'new', 'application', 'domain', '.'] 

 TOTAL TOKENS ==> 28

 ---- POST ----

 [('One', 'CD'), ('approach', 'NN'), ('to', 'TO'), ('e~/aluating', 'VBG'), ('whether', 'IN'), ('a', 'DT'), ('system', 'NN'), ('is', 'VBZ'), ('ready', 'JJ'), ('is', 'VBZ'), ('to', 'TO'), ('measure', 'VB'), ('the', 'DT'), ('effort', 'NN'), ('requited', 'VBD'), ('to', 'TO'), ('achieve', 'VB'), ('some', 'DT'), ('specified', 'JJ'), ('level', 'NN'), ('of', 'IN'), ('performance', 'NN'), ('m', 'FW'), ('a', 'DT'), ('new', 'JJ'), ('application', 'NN'), ('domain', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['One', 'approach', 'e~/aluating', 'whether', 'system', 'ready', 'measure', 'effort', 'requited', 'achieve', 'specified', 'level', 'performance', 'new', 'application', 'domain', '.']

 TOTAL FILTERED TOKENS ==>  17

 ---- POST FOR FILTERED TOKENS ----

 [('One', 'CD'), ('approach', 'NN'), ('e~/aluating', 'VBG'), ('whether', 'IN'), ('system', 'NN'), ('ready', 'JJ'), ('measure', 'NN'), ('effort', 'NN'), ('requited', 'VBD'), ('achieve', 'RB'), ('specified', 'VBN'), ('level', 'NN'), ('performance', 'NN'), ('new', 'JJ'), ('application', 'NN'), ('domain', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['One approach', 'approach e~/aluating', 'e~/aluating whether', 'whether system', 'system ready', 'ready measure', 'measure effort', 'effort requited', 'requited achieve', 'achieve specified', 'specified level', 'level performance', 'performance new', 'new application', 'application domain', 'domain .'] 

 TOTAL BIGRAMS --> 16 



 ---- TRI-GRAMS ---- 

 ['One approach e~/aluating', 'approach e~/aluating whether', 'e~/aluating whether system', 'whether system ready', 'system ready measure', 'ready measure effort', 'measure effort requited', 'effort requited achieve', 'requited achieve specified', 'achieve specified level', 'specified level performance', 'level performance new', 'performance new application', 'new application domain', 'application domain .'] 

 TOTAL TRIGRAMS --> 15 



 ---- NOUN PHRASES ---- 

 ['approach', 'system', 'ready measure', 'effort', 'level', 'performance', 'new application', 'domain'] 

 TOTAL NOUN PHRASES --> 8 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['one', 'approach', 'e~/alu', 'whether', 'system', 'readi', 'measur', 'effort', 'requit', 'achiev', 'specifi', 'level', 'perform', 'new', 'applic', 'domain', '.']

 TOTAL PORTER STEM WORDS ==> 17



 ---- SNOWBALL STEMMING ----

['one', 'approach', 'e~/alu', 'whether', 'system', 'readi', 'measur', 'effort', 'requit', 'achiev', 'specifi', 'level', 'perform', 'new', 'applic', 'domain', '.']

 TOTAL SNOWBALL STEM WORDS ==> 17



 ---- LEMMATIZATION ----

['One', 'approach', 'e~/aluating', 'whether', 'system', 'ready', 'measure', 'effort', 'requited', 'achieve', 'specified', 'level', 'performance', 'new', 'application', 'domain', '.']

 TOTAL LEMMATIZE WORDS ==> 17

************************************************************************************************************************

309 --> Such a measure indicates not only the cost of applying the system but  also its degree of maturity. 


 ---- TOKENS ----

 ['Such', 'a', 'measure', 'indicates', 'not', 'only', 'the', 'cost', 'of', 'applying', 'the', 'system', 'but', 'also', 'its', 'degree', 'of', 'maturity', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Such', 'JJ'), ('a', 'DT'), ('measure', 'NN'), ('indicates', 'VBZ'), ('not', 'RB'), ('only', 'RB'), ('the', 'DT'), ('cost', 'NN'), ('of', 'IN'), ('applying', 'VBG'), ('the', 'DT'), ('system', 'NN'), ('but', 'CC'), ('also', 'RB'), ('its', 'PRP$'), ('degree', 'NN'), ('of', 'IN'), ('maturity', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['measure', 'indicates', 'cost', 'applying', 'system', 'also', 'degree', 'maturity', '.']

 TOTAL FILTERED TOKENS ==>  9

 ---- POST FOR FILTERED TOKENS ----

 [('measure', 'NN'), ('indicates', 'VBZ'), ('cost', 'NN'), ('applying', 'NN'), ('system', 'NN'), ('also', 'RB'), ('degree', 'JJ'), ('maturity', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['measure indicates', 'indicates cost', 'cost applying', 'applying system', 'system also', 'also degree', 'degree maturity', 'maturity .'] 

 TOTAL BIGRAMS --> 8 



 ---- TRI-GRAMS ---- 

 ['measure indicates cost', 'indicates cost applying', 'cost applying system', 'applying system also', 'system also degree', 'also degree maturity', 'degree maturity .'] 

 TOTAL TRIGRAMS --> 7 



 ---- NOUN PHRASES ---- 

 ['measure', 'cost', 'applying', 'system', 'degree maturity'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['measur', 'indic', 'cost', 'appli', 'system', 'also', 'degre', 'matur', '.']

 TOTAL PORTER STEM WORDS ==> 9



 ---- SNOWBALL STEMMING ----

['measur', 'indic', 'cost', 'appli', 'system', 'also', 'degre', 'matur', '.']

 TOTAL SNOWBALL STEM WORDS ==> 9



 ---- LEMMATIZATION ----

['measure', 'indicates', 'cost', 'applying', 'system', 'also', 'degree', 'maturity', '.']

 TOTAL LEMMATIZE WORDS ==> 9

************************************************************************************************************************

310 --> The reason such measures are critical is that a domain-independent lexical semantics and  domain-independent discourse processing are areas in which further scientific research is needed. 


 ---- TOKENS ----

 ['The', 'reason', 'such', 'measures', 'are', 'critical', 'is', 'that', 'a', 'domain-independent', 'lexical', 'semantics', 'and', 'domain-independent', 'discourse', 'processing', 'are', 'areas', 'in', 'which', 'further', 'scientific', 'research', 'is', 'needed', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('The', 'DT'), ('reason', 'NN'), ('such', 'JJ'), ('measures', 'NNS'), ('are', 'VBP'), ('critical', 'JJ'), ('is', 'VBZ'), ('that', 'IN'), ('a', 'DT'), ('domain-independent', 'JJ'), ('lexical', 'JJ'), ('semantics', 'NNS'), ('and', 'CC'), ('domain-independent', 'JJ'), ('discourse', 'NN'), ('processing', 'NN'), ('are', 'VBP'), ('areas', 'NNS'), ('in', 'IN'), ('which', 'WDT'), ('further', 'JJ'), ('scientific', 'JJ'), ('research', 'NN'), ('is', 'VBZ'), ('needed', 'VBN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['reason', 'measures', 'critical', 'domain-independent', 'lexical', 'semantics', 'domain-independent', 'discourse', 'processing', 'areas', 'scientific', 'research', 'needed', '.']

 TOTAL FILTERED TOKENS ==>  14

 ---- POST FOR FILTERED TOKENS ----

 [('reason', 'NN'), ('measures', 'NNS'), ('critical', 'JJ'), ('domain-independent', 'JJ'), ('lexical', 'JJ'), ('semantics', 'NNS'), ('domain-independent', 'JJ'), ('discourse', 'NN'), ('processing', 'NN'), ('areas', 'NNS'), ('scientific', 'JJ'), ('research', 'NN'), ('needed', 'VBN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['reason measures', 'measures critical', 'critical domain-independent', 'domain-independent lexical', 'lexical semantics', 'semantics domain-independent', 'domain-independent discourse', 'discourse processing', 'processing areas', 'areas scientific', 'scientific research', 'research needed', 'needed .'] 

 TOTAL BIGRAMS --> 13 



 ---- TRI-GRAMS ---- 

 ['reason measures critical', 'measures critical domain-independent', 'critical domain-independent lexical', 'domain-independent lexical semantics', 'lexical semantics domain-independent', 'semantics domain-independent discourse', 'domain-independent discourse processing', 'discourse processing areas', 'processing areas scientific', 'areas scientific research', 'scientific research needed', 'research needed .'] 

 TOTAL TRIGRAMS --> 12 



 ---- NOUN PHRASES ---- 

 ['reason', 'domain-independent discourse', 'processing', 'scientific research'] 

 TOTAL NOUN PHRASES --> 4 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['reason', 'measur', 'critic', 'domain-independ', 'lexic', 'semant', 'domain-independ', 'discours', 'process', 'area', 'scientif', 'research', 'need', '.']

 TOTAL PORTER STEM WORDS ==> 14



 ---- SNOWBALL STEMMING ----

['reason', 'measur', 'critic', 'domain-independ', 'lexic', 'semant', 'domain-independ', 'discours', 'process', 'area', 'scientif', 'research', 'need', '.']

 TOTAL SNOWBALL STEM WORDS ==> 14



 ---- LEMMATIZATION ----

['reason', 'measure', 'critical', 'domain-independent', 'lexical', 'semantics', 'domain-independent', 'discourse', 'processing', 'area', 'scientific', 'research', 'needed', '.']

 TOTAL LEMMATIZE WORDS ==> 14

************************************************************************************************************************

311 --> 3T~,m Johnsoe~ "Commercial markets for natural language proce~mg", talk presented at the Second Conference on Applied Natural Language  Proc¢~mg, Association for Computational Lmguiszics, Fet:~r~a,ry, |988. 


 ---- TOKENS ----

 ['3T~', ',', 'm', 'Johnsoe~', '``', 'Commercial', 'markets', 'for', 'natural', 'language', 'proce~mg', "''", ',', 'talk', 'presented', 'at', 'the', 'Second', 'Conference', 'on', 'Applied', 'Natural', 'Language', 'Proc¢~mg', ',', 'Association', 'for', 'Computational', 'Lmguiszics', ',', 'Fet', ':', '~r~a', ',', 'ry', ',', '|988', '.'] 

 TOTAL TOKENS ==> 38

 ---- POST ----

 [('3T~', 'CD'), (',', ','), ('m', 'NN'), ('Johnsoe~', 'NNP'), ('``', '``'), ('Commercial', 'JJ'), ('markets', 'NNS'), ('for', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('proce~mg', 'NN'), ("''", "''"), (',', ','), ('talk', 'NN'), ('presented', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('Second', 'NNP'), ('Conference', 'NNP'), ('on', 'IN'), ('Applied', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Proc¢~mg', 'NNP'), (',', ','), ('Association', 'NNP'), ('for', 'IN'), ('Computational', 'NNP'), ('Lmguiszics', 'NNP'), (',', ','), ('Fet', 'NNP'), (':', ':'), ('~r~a', 'NN'), (',', ','), ('ry', 'NN'), (',', ','), ('|988', 'NNP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3T~', ',', 'Johnsoe~', '``', 'Commercial', 'markets', 'natural', 'language', 'proce~mg', "''", ',', 'talk', 'presented', 'Second', 'Conference', 'Applied', 'Natural', 'Language', 'Proc¢~mg', ',', 'Association', 'Computational', 'Lmguiszics', ',', 'Fet', ':', '~r~a', ',', 'ry', ',', '|988', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('3T~', 'CD'), (',', ','), ('Johnsoe~', 'NNP'), ('``', '``'), ('Commercial', 'NNP'), ('markets', 'NNS'), ('natural', 'JJ'), ('language', 'NN'), ('proce~mg', 'NN'), ("''", "''"), (',', ','), ('talk', 'NN'), ('presented', 'VBD'), ('Second', 'NNP'), ('Conference', 'NNP'), ('Applied', 'NNP'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Proc¢~mg', 'NNP'), (',', ','), ('Association', 'NNP'), ('Computational', 'NNP'), ('Lmguiszics', 'NNP'), (',', ','), ('Fet', 'NNP'), (':', ':'), ('~r~a', 'NN'), (',', ','), ('ry', 'NN'), (',', ','), ('|988', 'NNP'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3T~ ,', ', Johnsoe~', 'Johnsoe~ ``', '`` Commercial', 'Commercial markets', 'markets natural', 'natural language', 'language proce~mg', "proce~mg ''", "'' ,", ', talk', 'talk presented', 'presented Second', 'Second Conference', 'Conference Applied', 'Applied Natural', 'Natural Language', 'Language Proc¢~mg', 'Proc¢~mg ,', ', Association', 'Association Computational', 'Computational Lmguiszics', 'Lmguiszics ,', ', Fet', 'Fet :', ': ~r~a', '~r~a ,', ', ry', 'ry ,', ', |988', '|988 .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['3T~ , Johnsoe~', ', Johnsoe~ ``', 'Johnsoe~ `` Commercial', '`` Commercial markets', 'Commercial markets natural', 'markets natural language', 'natural language proce~mg', "language proce~mg ''", "proce~mg '' ,", "'' , talk", ', talk presented', 'talk presented Second', 'presented Second Conference', 'Second Conference Applied', 'Conference Applied Natural', 'Applied Natural Language', 'Natural Language Proc¢~mg', 'Language Proc¢~mg ,', 'Proc¢~mg , Association', ', Association Computational', 'Association Computational Lmguiszics', 'Computational Lmguiszics ,', 'Lmguiszics , Fet', ', Fet :', 'Fet : ~r~a', ': ~r~a ,', '~r~a , ry', ', ry ,', 'ry , |988', ', |988 .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['natural language', 'proce~mg', 'talk', '~r~a', 'ry'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['Second Conference Applied Natural Language', 'Association Computational Lmguiszics']
 TOTAL ORGANIZATION ENTITY --> 2 


 PERSON ---> ['Fet']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3t~', ',', 'johnsoe~', '``', 'commerci', 'market', 'natur', 'languag', 'proce~mg', "''", ',', 'talk', 'present', 'second', 'confer', 'appli', 'natur', 'languag', 'proc¢~mg', ',', 'associ', 'comput', 'lmguiszic', ',', 'fet', ':', '~r~a', ',', 'ry', ',', '|988', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['3t~', ',', 'johnsoe~', '``', 'commerci', 'market', 'natur', 'languag', 'proce~mg', "''", ',', 'talk', 'present', 'second', 'confer', 'appli', 'natur', 'languag', 'proc¢~mg', ',', 'associ', 'comput', 'lmguiszic', ',', 'fet', ':', '~r~a', ',', 'ry', ',', '|988', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['3T~', ',', 'Johnsoe~', '``', 'Commercial', 'market', 'natural', 'language', 'proce~mg', "''", ',', 'talk', 'presented', 'Second', 'Conference', 'Applied', 'Natural', 'Language', 'Proc¢~mg', ',', 'Association', 'Computational', 'Lmguiszics', ',', 'Fet', ':', '~r~a', ',', 'ry', ',', '|988', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

312 --> 492   5. 


 ---- TOKENS ----

 ['492', '5', '.'] 

 TOTAL TOKENS ==> 3

 ---- POST ----

 [('492', 'CD'), ('5', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['492', '5', '.']

 TOTAL FILTERED TOKENS ==>  3

 ---- POST FOR FILTERED TOKENS ----

 [('492', 'CD'), ('5', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['492 5', '5 .'] 

 TOTAL BIGRAMS --> 2 



 ---- TRI-GRAMS ---- 

 ['492 5 .'] 

 TOTAL TRIGRAMS --> 1 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['492', '5', '.']

 TOTAL PORTER STEM WORDS ==> 3



 ---- SNOWBALL STEMMING ----

['492', '5', '.']

 TOTAL SNOWBALL STEM WORDS ==> 3



 ---- LEMMATIZATION ----

['492', '5', '.']

 TOTAL LEMMATIZE WORDS ==> 3

************************************************************************************************************************

313 --> C o n c l u s i o n s  a n d  R e c o m m e n d a t i o n s   The impact of a breakthrough in computer use of natural languages will have as profound an effect on  society as would breakthroughs in superconductors, inexpensive fusion, or genetic engineering. 


 ---- TOKENS ----

 ['C', 'o', 'n', 'c', 'l', 'u', 's', 'i', 'o', 'n', 's', 'a', 'n', 'd', 'R', 'e', 'c', 'o', 'm', 'm', 'e', 'n', 'd', 'a', 't', 'i', 'o', 'n', 's', 'The', 'impact', 'of', 'a', 'breakthrough', 'in', 'computer', 'use', 'of', 'natural', 'languages', 'will', 'have', 'as', 'profound', 'an', 'effect', 'on', 'society', 'as', 'would', 'breakthroughs', 'in', 'superconductors', ',', 'inexpensive', 'fusion', ',', 'or', 'genetic', 'engineering', '.'] 

 TOTAL TOKENS ==> 61

 ---- POST ----

 [('C', 'NNP'), ('o', 'MD'), ('n', 'VB'), ('c', 'JJ'), ('l', 'NN'), ('u', 'JJ'), ('s', 'NN'), ('i', 'NN'), ('o', 'VBP'), ('n', 'RB'), ('s', 'VBP'), ('a', 'DT'), ('n', 'JJ'), ('d', 'NN'), ('R', 'NNP'), ('e', 'VBZ'), ('c', 'JJ'), ('o', 'JJ'), ('m', 'NN'), ('m', 'NN'), ('e', 'NN'), ('n', 'JJ'), ('d', 'VBZ'), ('a', 'DT'), ('t', 'NN'), ('i', 'NN'), ('o', 'VBP'), ('n', 'RB'), ('s', 'VB'), ('The', 'DT'), ('impact', 'NN'), ('of', 'IN'), ('a', 'DT'), ('breakthrough', 'NN'), ('in', 'IN'), ('computer', 'NN'), ('use', 'NN'), ('of', 'IN'), ('natural', 'JJ'), ('languages', 'NNS'), ('will', 'MD'), ('have', 'VB'), ('as', 'RB'), ('profound', 'IN'), ('an', 'DT'), ('effect', 'NN'), ('on', 'IN'), ('society', 'NN'), ('as', 'IN'), ('would', 'MD'), ('breakthroughs', 'VB'), ('in', 'IN'), ('superconductors', 'NNS'), (',', ','), ('inexpensive', 'JJ'), ('fusion', 'NN'), (',', ','), ('or', 'CC'), ('genetic', 'JJ'), ('engineering', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['C', 'n', 'c', 'l', 'u', 'n', 'n', 'R', 'e', 'c', 'e', 'n', 'n', 'impact', 'breakthrough', 'computer', 'use', 'natural', 'languages', 'profound', 'effect', 'society', 'would', 'breakthroughs', 'superconductors', ',', 'inexpensive', 'fusion', ',', 'genetic', 'engineering', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('C', 'NNP'), ('n', 'CC'), ('c', 'JJ'), ('l', 'NN'), ('u', 'JJ'), ('n', 'NN'), ('n', 'JJ'), ('R', 'NNP'), ('e', 'NN'), ('c', 'NN'), ('e', 'NN'), ('n', 'JJ'), ('n', 'JJ'), ('impact', 'NN'), ('breakthrough', 'IN'), ('computer', 'NN'), ('use', 'NN'), ('natural', 'JJ'), ('languages', 'NNS'), ('profound', 'VBP'), ('effect', 'NN'), ('society', 'NN'), ('would', 'MD'), ('breakthroughs', 'VB'), ('superconductors', 'NNS'), (',', ','), ('inexpensive', 'JJ'), ('fusion', 'NN'), (',', ','), ('genetic', 'JJ'), ('engineering', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['C n', 'n c', 'c l', 'l u', 'u n', 'n n', 'n R', 'R e', 'e c', 'c e', 'e n', 'n n', 'n impact', 'impact breakthrough', 'breakthrough computer', 'computer use', 'use natural', 'natural languages', 'languages profound', 'profound effect', 'effect society', 'society would', 'would breakthroughs', 'breakthroughs superconductors', 'superconductors ,', ', inexpensive', 'inexpensive fusion', 'fusion ,', ', genetic', 'genetic engineering', 'engineering .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['C n c', 'n c l', 'c l u', 'l u n', 'u n n', 'n n R', 'n R e', 'R e c', 'e c e', 'c e n', 'e n n', 'n n impact', 'n impact breakthrough', 'impact breakthrough computer', 'breakthrough computer use', 'computer use natural', 'use natural languages', 'natural languages profound', 'languages profound effect', 'profound effect society', 'effect society would', 'society would breakthroughs', 'would breakthroughs superconductors', 'breakthroughs superconductors ,', 'superconductors , inexpensive', ', inexpensive fusion', 'inexpensive fusion ,', 'fusion , genetic', ', genetic engineering', 'genetic engineering .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['c l', 'u n', 'e', 'c', 'e', 'n n impact', 'computer', 'use', 'effect', 'society', 'inexpensive fusion', 'genetic engineering'] 

 TOTAL NOUN PHRASES --> 12 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['c', 'n', 'c', 'l', 'u', 'n', 'n', 'r', 'e', 'c', 'e', 'n', 'n', 'impact', 'breakthrough', 'comput', 'use', 'natur', 'languag', 'profound', 'effect', 'societi', 'would', 'breakthrough', 'superconductor', ',', 'inexpens', 'fusion', ',', 'genet', 'engin', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['c', 'n', 'c', 'l', 'u', 'n', 'n', 'r', 'e', 'c', 'e', 'n', 'n', 'impact', 'breakthrough', 'comput', 'use', 'natur', 'languag', 'profound', 'effect', 'societi', 'would', 'breakthrough', 'superconductor', ',', 'inexpens', 'fusion', ',', 'genet', 'engin', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['C', 'n', 'c', 'l', 'u', 'n', 'n', 'R', 'e', 'c', 'e', 'n', 'n', 'impact', 'breakthrough', 'computer', 'use', 'natural', 'language', 'profound', 'effect', 'society', 'would', 'breakthrough', 'superconductors', ',', 'inexpensive', 'fusion', ',', 'genetic', 'engineering', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

314 --> The impact of NLP  by machine will be even greater than the impact of microprocessor technology in the last 20 years. 


 ---- TOKENS ----

 ['The', 'impact', 'of', 'NLP', 'by', 'machine', 'will', 'be', 'even', 'greater', 'than', 'the', 'impact', 'of', 'microprocessor', 'technology', 'in', 'the', 'last', '20', 'years', '.'] 

 TOTAL TOKENS ==> 22

 ---- POST ----

 [('The', 'DT'), ('impact', 'NN'), ('of', 'IN'), ('NLP', 'NNP'), ('by', 'IN'), ('machine', 'NN'), ('will', 'MD'), ('be', 'VB'), ('even', 'RB'), ('greater', 'JJR'), ('than', 'IN'), ('the', 'DT'), ('impact', 'NN'), ('of', 'IN'), ('microprocessor', 'NN'), ('technology', 'NN'), ('in', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('20', 'CD'), ('years', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['impact', 'NLP', 'machine', 'even', 'greater', 'impact', 'microprocessor', 'technology', 'last', '20', 'years', '.']

 TOTAL FILTERED TOKENS ==>  12

 ---- POST FOR FILTERED TOKENS ----

 [('impact', 'NN'), ('NLP', 'NNP'), ('machine', 'NN'), ('even', 'RB'), ('greater', 'JJR'), ('impact', 'NN'), ('microprocessor', 'NN'), ('technology', 'NN'), ('last', 'JJ'), ('20', 'CD'), ('years', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['impact NLP', 'NLP machine', 'machine even', 'even greater', 'greater impact', 'impact microprocessor', 'microprocessor technology', 'technology last', 'last 20', '20 years', 'years .'] 

 TOTAL BIGRAMS --> 11 



 ---- TRI-GRAMS ---- 

 ['impact NLP machine', 'NLP machine even', 'machine even greater', 'even greater impact', 'greater impact microprocessor', 'impact microprocessor technology', 'microprocessor technology last', 'technology last 20', 'last 20 years', '20 years .'] 

 TOTAL TRIGRAMS --> 10 



 ---- NOUN PHRASES ---- 

 ['impact', 'machine', 'impact', 'microprocessor', 'technology'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['impact', 'nlp', 'machin', 'even', 'greater', 'impact', 'microprocessor', 'technolog', 'last', '20', 'year', '.']

 TOTAL PORTER STEM WORDS ==> 12



 ---- SNOWBALL STEMMING ----

['impact', 'nlp', 'machin', 'even', 'greater', 'impact', 'microprocessor', 'technolog', 'last', '20', 'year', '.']

 TOTAL SNOWBALL STEM WORDS ==> 12



 ---- LEMMATIZATION ----

['impact', 'NLP', 'machine', 'even', 'greater', 'impact', 'microprocessor', 'technology', 'last', '20', 'year', '.']

 TOTAL LEMMATIZE WORDS ==> 12

************************************************************************************************************************

315 --> The rationale is  simple: natural language is fundamental to almost all business, military, and social activities; therefore, the  applicability of NLP is almost limitless. 


 ---- TOKENS ----

 ['The', 'rationale', 'is', 'simple', ':', 'natural', 'language', 'is', 'fundamental', 'to', 'almost', 'all', 'business', ',', 'military', ',', 'and', 'social', 'activities', ';', 'therefore', ',', 'the', 'applicability', 'of', 'NLP', 'is', 'almost', 'limitless', '.'] 

 TOTAL TOKENS ==> 30

 ---- POST ----

 [('The', 'DT'), ('rationale', 'NN'), ('is', 'VBZ'), ('simple', 'JJ'), (':', ':'), ('natural', 'JJ'), ('language', 'NN'), ('is', 'VBZ'), ('fundamental', 'JJ'), ('to', 'TO'), ('almost', 'RB'), ('all', 'DT'), ('business', 'NN'), (',', ','), ('military', 'JJ'), (',', ','), ('and', 'CC'), ('social', 'JJ'), ('activities', 'NNS'), (';', ':'), ('therefore', 'RB'), (',', ','), ('the', 'DT'), ('applicability', 'NN'), ('of', 'IN'), ('NLP', 'NNP'), ('is', 'VBZ'), ('almost', 'RB'), ('limitless', 'JJ'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['rationale', 'simple', ':', 'natural', 'language', 'fundamental', 'almost', 'business', ',', 'military', ',', 'social', 'activities', ';', 'therefore', ',', 'applicability', 'NLP', 'almost', 'limitless', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('rationale', 'JJ'), ('simple', 'NN'), (':', ':'), ('natural', 'JJ'), ('language', 'NN'), ('fundamental', 'JJ'), ('almost', 'RB'), ('business', 'NN'), (',', ','), ('military', 'JJ'), (',', ','), ('social', 'JJ'), ('activities', 'NNS'), (';', ':'), ('therefore', 'RB'), (',', ','), ('applicability', 'NN'), ('NLP', 'NNP'), ('almost', 'RB'), ('limitless', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['rationale simple', 'simple :', ': natural', 'natural language', 'language fundamental', 'fundamental almost', 'almost business', 'business ,', ', military', 'military ,', ', social', 'social activities', 'activities ;', '; therefore', 'therefore ,', ', applicability', 'applicability NLP', 'NLP almost', 'almost limitless', 'limitless .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['rationale simple :', 'simple : natural', ': natural language', 'natural language fundamental', 'language fundamental almost', 'fundamental almost business', 'almost business ,', 'business , military', ', military ,', 'military , social', ', social activities', 'social activities ;', 'activities ; therefore', '; therefore ,', 'therefore , applicability', ', applicability NLP', 'applicability NLP almost', 'NLP almost limitless', 'almost limitless .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['rationale simple', 'natural language', 'business', 'applicability', 'limitless'] 

 TOTAL NOUN PHRASES --> 5 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['rational', 'simpl', ':', 'natur', 'languag', 'fundament', 'almost', 'busi', ',', 'militari', ',', 'social', 'activ', ';', 'therefor', ',', 'applic', 'nlp', 'almost', 'limitless', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['rational', 'simpl', ':', 'natur', 'languag', 'fundament', 'almost', 'busi', ',', 'militari', ',', 'social', 'activ', ';', 'therefor', ',', 'applic', 'nlp', 'almost', 'limitless', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['rationale', 'simple', ':', 'natural', 'language', 'fundamental', 'almost', 'business', ',', 'military', ',', 'social', 'activity', ';', 'therefore', ',', 'applicability', 'NLP', 'almost', 'limitless', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

316 --> NL analysis and generation could revolutionize our individual, institutional, and national ability to enter,  access, summarize, and translate textual reformation. 


 ---- TOKENS ----

 ['NL', 'analysis', 'and', 'generation', 'could', 'revolutionize', 'our', 'individual', ',', 'institutional', ',', 'and', 'national', 'ability', 'to', 'enter', ',', 'access', ',', 'summarize', ',', 'and', 'translate', 'textual', 'reformation', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('NL', 'NNP'), ('analysis', 'NN'), ('and', 'CC'), ('generation', 'NN'), ('could', 'MD'), ('revolutionize', 'VB'), ('our', 'PRP$'), ('individual', 'JJ'), (',', ','), ('institutional', 'JJ'), (',', ','), ('and', 'CC'), ('national', 'JJ'), ('ability', 'NN'), ('to', 'TO'), ('enter', 'VB'), (',', ','), ('access', 'NN'), (',', ','), ('summarize', 'VB'), (',', ','), ('and', 'CC'), ('translate', 'VB'), ('textual', 'JJ'), ('reformation', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['NL', 'analysis', 'generation', 'could', 'revolutionize', 'individual', ',', 'institutional', ',', 'national', 'ability', 'enter', ',', 'access', ',', 'summarize', ',', 'translate', 'textual', 'reformation', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('NL', 'NNP'), ('analysis', 'NN'), ('generation', 'NN'), ('could', 'MD'), ('revolutionize', 'VB'), ('individual', 'JJ'), (',', ','), ('institutional', 'JJ'), (',', ','), ('national', 'JJ'), ('ability', 'NN'), ('enter', 'NN'), (',', ','), ('access', 'NN'), (',', ','), ('summarize', 'VB'), (',', ','), ('translate', 'VB'), ('textual', 'JJ'), ('reformation', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['NL analysis', 'analysis generation', 'generation could', 'could revolutionize', 'revolutionize individual', 'individual ,', ', institutional', 'institutional ,', ', national', 'national ability', 'ability enter', 'enter ,', ', access', 'access ,', ', summarize', 'summarize ,', ', translate', 'translate textual', 'textual reformation', 'reformation .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['NL analysis generation', 'analysis generation could', 'generation could revolutionize', 'could revolutionize individual', 'revolutionize individual ,', 'individual , institutional', ', institutional ,', 'institutional , national', ', national ability', 'national ability enter', 'ability enter ,', 'enter , access', ', access ,', 'access , summarize', ', summarize ,', 'summarize , translate', ', translate textual', 'translate textual reformation', 'textual reformation .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['analysis', 'generation', 'national ability', 'enter', 'access', 'textual reformation'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['nl', 'analysi', 'gener', 'could', 'revolution', 'individu', ',', 'institut', ',', 'nation', 'abil', 'enter', ',', 'access', ',', 'summar', ',', 'translat', 'textual', 'reform', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['nl', 'analysi', 'generat', 'could', 'revolution', 'individu', ',', 'institut', ',', 'nation', 'abil', 'enter', ',', 'access', ',', 'summar', ',', 'translat', 'textual', 'reform', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['NL', 'analysis', 'generation', 'could', 'revolutionize', 'individual', ',', 'institutional', ',', 'national', 'ability', 'enter', ',', 'access', ',', 'summarize', ',', 'translate', 'textual', 'reformation', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

317 --> It can make interaction with machines as easy as interaction  between individuals. 


 ---- TOKENS ----

 ['It', 'can', 'make', 'interaction', 'with', 'machines', 'as', 'easy', 'as', 'interaction', 'between', 'individuals', '.'] 

 TOTAL TOKENS ==> 13

 ---- POST ----

 [('It', 'PRP'), ('can', 'MD'), ('make', 'VB'), ('interaction', 'NN'), ('with', 'IN'), ('machines', 'NNS'), ('as', 'RB'), ('easy', 'RB'), ('as', 'IN'), ('interaction', 'NN'), ('between', 'IN'), ('individuals', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['make', 'interaction', 'machines', 'easy', 'interaction', 'individuals', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('make', 'VB'), ('interaction', 'NN'), ('machines', 'NNS'), ('easy', 'JJ'), ('interaction', 'NN'), ('individuals', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['make interaction', 'interaction machines', 'machines easy', 'easy interaction', 'interaction individuals', 'individuals .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['make interaction machines', 'interaction machines easy', 'machines easy interaction', 'easy interaction individuals', 'interaction individuals .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 ['interaction', 'easy interaction'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['make', 'interact', 'machin', 'easi', 'interact', 'individu', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['make', 'interact', 'machin', 'easi', 'interact', 'individu', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['make', 'interaction', 'machine', 'easy', 'interaction', 'individual', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

318 --> The computer's linguistic proficiency may never be as great as a human's. 


 ---- TOKENS ----

 ['The', 'computer', "'s", 'linguistic', 'proficiency', 'may', 'never', 'be', 'as', 'great', 'as', 'a', 'human', "'s", '.'] 

 TOTAL TOKENS ==> 15

 ---- POST ----

 [('The', 'DT'), ('computer', 'NN'), ("'s", 'POS'), ('linguistic', 'JJ'), ('proficiency', 'NN'), ('may', 'MD'), ('never', 'RB'), ('be', 'VB'), ('as', 'RB'), ('great', 'JJ'), ('as', 'IN'), ('a', 'DT'), ('human', 'NN'), ("'s", 'POS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['computer', "'s", 'linguistic', 'proficiency', 'may', 'never', 'great', 'human', "'s", '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('computer', 'NN'), ("'s", 'POS'), ('linguistic', 'JJ'), ('proficiency', 'NN'), ('may', 'MD'), ('never', 'RB'), ('great', 'JJ'), ('human', 'NN'), ("'s", 'POS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ["computer 's", "'s linguistic", 'linguistic proficiency', 'proficiency may', 'may never', 'never great', 'great human', "human 's", "'s ."] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ["computer 's linguistic", "'s linguistic proficiency", 'linguistic proficiency may', 'proficiency may never', 'may never great', 'never great human', "great human 's", "human 's ."] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['computer', 'linguistic proficiency', 'great human'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['comput', "'s", 'linguist', 'profici', 'may', 'never', 'great', 'human', "'s", '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['comput', "'s", 'linguist', 'profici', 'may', 'never', 'great', 'human', "'s", '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['computer', "'s", 'linguistic', 'proficiency', 'may', 'never', 'great', 'human', "'s", '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

319 --> However, the existence and  use of current NL products and the market projections cited suggest that invesunent in this technology should lead to  useful spinoffs m the near term and mid-term. 


 ---- TOKENS ----

 ['However', ',', 'the', 'existence', 'and', 'use', 'of', 'current', 'NL', 'products', 'and', 'the', 'market', 'projections', 'cited', 'suggest', 'that', 'invesunent', 'in', 'this', 'technology', 'should', 'lead', 'to', 'useful', 'spinoffs', 'm', 'the', 'near', 'term', 'and', 'mid-term', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('However', 'RB'), (',', ','), ('the', 'DT'), ('existence', 'NN'), ('and', 'CC'), ('use', 'NN'), ('of', 'IN'), ('current', 'JJ'), ('NL', 'NNP'), ('products', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('market', 'NN'), ('projections', 'NNS'), ('cited', 'VBD'), ('suggest', 'JJS'), ('that', 'IN'), ('invesunent', 'NN'), ('in', 'IN'), ('this', 'DT'), ('technology', 'NN'), ('should', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('useful', 'JJ'), ('spinoffs', 'NNS'), ('m', 'VBP'), ('the', 'DT'), ('near', 'JJ'), ('term', 'NN'), ('and', 'CC'), ('mid-term', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['However', ',', 'existence', 'use', 'current', 'NL', 'products', 'market', 'projections', 'cited', 'suggest', 'invesunent', 'technology', 'lead', 'useful', 'spinoffs', 'near', 'term', 'mid-term', '.']

 TOTAL FILTERED TOKENS ==>  20

 ---- POST FOR FILTERED TOKENS ----

 [('However', 'RB'), (',', ','), ('existence', 'NN'), ('use', 'NN'), ('current', 'JJ'), ('NL', 'NNP'), ('products', 'NNS'), ('market', 'NN'), ('projections', 'NNS'), ('cited', 'VBD'), ('suggest', 'JJ'), ('invesunent', 'NN'), ('technology', 'NN'), ('lead', 'JJ'), ('useful', 'JJ'), ('spinoffs', 'NNS'), ('near', 'IN'), ('term', 'NN'), ('mid-term', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['However ,', ', existence', 'existence use', 'use current', 'current NL', 'NL products', 'products market', 'market projections', 'projections cited', 'cited suggest', 'suggest invesunent', 'invesunent technology', 'technology lead', 'lead useful', 'useful spinoffs', 'spinoffs near', 'near term', 'term mid-term', 'mid-term .'] 

 TOTAL BIGRAMS --> 19 



 ---- TRI-GRAMS ---- 

 ['However , existence', ', existence use', 'existence use current', 'use current NL', 'current NL products', 'NL products market', 'products market projections', 'market projections cited', 'projections cited suggest', 'cited suggest invesunent', 'suggest invesunent technology', 'invesunent technology lead', 'technology lead useful', 'lead useful spinoffs', 'useful spinoffs near', 'spinoffs near term', 'near term mid-term', 'term mid-term .'] 

 TOTAL TRIGRAMS --> 18 



 ---- NOUN PHRASES ---- 

 ['existence', 'use', 'market', 'suggest invesunent', 'technology', 'term', 'mid-term'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['howev', ',', 'exist', 'use', 'current', 'nl', 'product', 'market', 'project', 'cite', 'suggest', 'invesun', 'technolog', 'lead', 'use', 'spinoff', 'near', 'term', 'mid-term', '.']

 TOTAL PORTER STEM WORDS ==> 20



 ---- SNOWBALL STEMMING ----

['howev', ',', 'exist', 'use', 'current', 'nl', 'product', 'market', 'project', 'cite', 'suggest', 'invesun', 'technolog', 'lead', 'use', 'spinoff', 'near', 'term', 'mid-term', '.']

 TOTAL SNOWBALL STEM WORDS ==> 20



 ---- LEMMATIZATION ----

['However', ',', 'existence', 'use', 'current', 'NL', 'product', 'market', 'projection', 'cited', 'suggest', 'invesunent', 'technology', 'lead', 'useful', 'spinoffs', 'near', 'term', 'mid-term', '.']

 TOTAL LEMMATIZE WORDS ==> 20

************************************************************************************************************************

320 --> The technology stands at a turning point. 


 ---- TOKENS ----

 ['The', 'technology', 'stands', 'at', 'a', 'turning', 'point', '.'] 

 TOTAL TOKENS ==> 8

 ---- POST ----

 [('The', 'DT'), ('technology', 'NN'), ('stands', 'VBZ'), ('at', 'IN'), ('a', 'DT'), ('turning', 'VBG'), ('point', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['technology', 'stands', 'turning', 'point', '.']

 TOTAL FILTERED TOKENS ==>  5

 ---- POST FOR FILTERED TOKENS ----

 [('technology', 'NN'), ('stands', 'VBZ'), ('turning', 'VBG'), ('point', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['technology stands', 'stands turning', 'turning point', 'point .'] 

 TOTAL BIGRAMS --> 4 



 ---- TRI-GRAMS ---- 

 ['technology stands turning', 'stands turning point', 'turning point .'] 

 TOTAL TRIGRAMS --> 3 



 ---- NOUN PHRASES ---- 

 ['technology', 'point'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['technolog', 'stand', 'turn', 'point', '.']

 TOTAL PORTER STEM WORDS ==> 5



 ---- SNOWBALL STEMMING ----

['technolog', 'stand', 'turn', 'point', '.']

 TOTAL SNOWBALL STEM WORDS ==> 5



 ---- LEMMATIZATION ----

['technology', 'stand', 'turning', 'point', '.']

 TOTAL LEMMATIZE WORDS ==> 5

************************************************************************************************************************

321 --> New approaches (see Section 3,1) offer opportunities for  substantial progress in the next five years, and breakthroughs within 3 to 10 years. 


 ---- TOKENS ----

 ['New', 'approaches', '(', 'see', 'Section', '3,1', ')', 'offer', 'opportunities', 'for', 'substantial', 'progress', 'in', 'the', 'next', 'five', 'years', ',', 'and', 'breakthroughs', 'within', '3', 'to', '10', 'years', '.'] 

 TOTAL TOKENS ==> 26

 ---- POST ----

 [('New', 'NNP'), ('approaches', 'NNS'), ('(', '('), ('see', 'VB'), ('Section', 'NNP'), ('3,1', 'CD'), (')', ')'), ('offer', 'NN'), ('opportunities', 'NNS'), ('for', 'IN'), ('substantial', 'JJ'), ('progress', 'NN'), ('in', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('five', 'CD'), ('years', 'NNS'), (',', ','), ('and', 'CC'), ('breakthroughs', 'NNS'), ('within', 'IN'), ('3', 'CD'), ('to', 'TO'), ('10', 'CD'), ('years', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['New', 'approaches', '(', 'see', 'Section', '3,1', ')', 'offer', 'opportunities', 'substantial', 'progress', 'next', 'five', 'years', ',', 'breakthroughs', 'within', '3', '10', 'years', '.']

 TOTAL FILTERED TOKENS ==>  21

 ---- POST FOR FILTERED TOKENS ----

 [('New', 'NNP'), ('approaches', 'NNS'), ('(', '('), ('see', 'VB'), ('Section', 'NNP'), ('3,1', 'CD'), (')', ')'), ('offer', 'NN'), ('opportunities', 'VBZ'), ('substantial', 'JJ'), ('progress', 'NN'), ('next', 'IN'), ('five', 'CD'), ('years', 'NNS'), (',', ','), ('breakthroughs', 'NNS'), ('within', 'IN'), ('3', 'CD'), ('10', 'CD'), ('years', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['New approaches', 'approaches (', '( see', 'see Section', 'Section 3,1', '3,1 )', ') offer', 'offer opportunities', 'opportunities substantial', 'substantial progress', 'progress next', 'next five', 'five years', 'years ,', ', breakthroughs', 'breakthroughs within', 'within 3', '3 10', '10 years', 'years .'] 

 TOTAL BIGRAMS --> 20 



 ---- TRI-GRAMS ---- 

 ['New approaches (', 'approaches ( see', '( see Section', 'see Section 3,1', 'Section 3,1 )', '3,1 ) offer', ') offer opportunities', 'offer opportunities substantial', 'opportunities substantial progress', 'substantial progress next', 'progress next five', 'next five years', 'five years ,', 'years , breakthroughs', ', breakthroughs within', 'breakthroughs within 3', 'within 3 10', '3 10 years', '10 years .'] 

 TOTAL TRIGRAMS --> 19 



 ---- NOUN PHRASES ---- 

 ['offer', 'substantial progress'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['New']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['new', 'approach', '(', 'see', 'section', '3,1', ')', 'offer', 'opportun', 'substanti', 'progress', 'next', 'five', 'year', ',', 'breakthrough', 'within', '3', '10', 'year', '.']

 TOTAL PORTER STEM WORDS ==> 21



 ---- SNOWBALL STEMMING ----

['new', 'approach', '(', 'see', 'section', '3,1', ')', 'offer', 'opportun', 'substanti', 'progress', 'next', 'five', 'year', ',', 'breakthrough', 'within', '3', '10', 'year', '.']

 TOTAL SNOWBALL STEM WORDS ==> 21



 ---- LEMMATIZATION ----

['New', 'approach', '(', 'see', 'Section', '3,1', ')', 'offer', 'opportunity', 'substantial', 'progress', 'next', 'five', 'year', ',', 'breakthrough', 'within', '3', '10', 'year', '.']

 TOTAL LEMMATIZE WORDS ==> 21

************************************************************************************************************************

322 --> Given these conclusions, we have three recommendations:  I. 


 ---- TOKENS ----

 ['Given', 'these', 'conclusions', ',', 'we', 'have', 'three', 'recommendations', ':', 'I', '.'] 

 TOTAL TOKENS ==> 11

 ---- POST ----

 [('Given', 'VBN'), ('these', 'DT'), ('conclusions', 'NNS'), (',', ','), ('we', 'PRP'), ('have', 'VBP'), ('three', 'CD'), ('recommendations', 'NNS'), (':', ':'), ('I', 'PRP'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Given', 'conclusions', ',', 'three', 'recommendations', ':', '.']

 TOTAL FILTERED TOKENS ==>  7

 ---- POST FOR FILTERED TOKENS ----

 [('Given', 'VBN'), ('conclusions', 'NNS'), (',', ','), ('three', 'CD'), ('recommendations', 'NNS'), (':', ':'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Given conclusions', 'conclusions ,', ', three', 'three recommendations', 'recommendations :', ': .'] 

 TOTAL BIGRAMS --> 6 



 ---- TRI-GRAMS ---- 

 ['Given conclusions ,', 'conclusions , three', ', three recommendations', 'three recommendations :', 'recommendations : .'] 

 TOTAL TRIGRAMS --> 5 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['given', 'conclus', ',', 'three', 'recommend', ':', '.']

 TOTAL PORTER STEM WORDS ==> 7



 ---- SNOWBALL STEMMING ----

['given', 'conclus', ',', 'three', 'recommend', ':', '.']

 TOTAL SNOWBALL STEM WORDS ==> 7



 ---- LEMMATIZATION ----

['Given', 'conclusion', ',', 'three', 'recommendation', ':', '.']

 TOTAL LEMMATIZE WORDS ==> 7

************************************************************************************************************************

323 --> Support both component research and system integration designed to achieve successes in the near  term, i.e., the scientific breakthroughs and technology transfer projections made in Sections 1.3.1 and  1.3.2. 


 ---- TOKENS ----

 ['Support', 'both', 'component', 'research', 'and', 'system', 'integration', 'designed', 'to', 'achieve', 'successes', 'in', 'the', 'near', 'term', ',', 'i.e.', ',', 'the', 'scientific', 'breakthroughs', 'and', 'technology', 'transfer', 'projections', 'made', 'in', 'Sections', '1.3.1', 'and', '1.3.2', '.'] 

 TOTAL TOKENS ==> 32

 ---- POST ----

 [('Support', 'NNP'), ('both', 'DT'), ('component', 'JJ'), ('research', 'NN'), ('and', 'CC'), ('system', 'NN'), ('integration', 'NN'), ('designed', 'VBN'), ('to', 'TO'), ('achieve', 'VB'), ('successes', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('near', 'JJ'), ('term', 'NN'), (',', ','), ('i.e.', 'FW'), (',', ','), ('the', 'DT'), ('scientific', 'JJ'), ('breakthroughs', 'NN'), ('and', 'CC'), ('technology', 'NN'), ('transfer', 'NN'), ('projections', 'NNS'), ('made', 'VBN'), ('in', 'IN'), ('Sections', 'NNP'), ('1.3.1', 'CD'), ('and', 'CC'), ('1.3.2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Support', 'component', 'research', 'system', 'integration', 'designed', 'achieve', 'successes', 'near', 'term', ',', 'i.e.', ',', 'scientific', 'breakthroughs', 'technology', 'transfer', 'projections', 'made', 'Sections', '1.3.1', '1.3.2', '.']

 TOTAL FILTERED TOKENS ==>  23

 ---- POST FOR FILTERED TOKENS ----

 [('Support', 'NNP'), ('component', 'VBD'), ('research', 'NN'), ('system', 'NN'), ('integration', 'NN'), ('designed', 'VBN'), ('achieve', 'VBP'), ('successes', 'NNS'), ('near', 'IN'), ('term', 'NN'), (',', ','), ('i.e.', 'FW'), (',', ','), ('scientific', 'JJ'), ('breakthroughs', 'NN'), ('technology', 'NN'), ('transfer', 'NN'), ('projections', 'NNS'), ('made', 'VBD'), ('Sections', 'NNS'), ('1.3.1', 'CD'), ('1.3.2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Support component', 'component research', 'research system', 'system integration', 'integration designed', 'designed achieve', 'achieve successes', 'successes near', 'near term', 'term ,', ', i.e.', 'i.e. ,', ', scientific', 'scientific breakthroughs', 'breakthroughs technology', 'technology transfer', 'transfer projections', 'projections made', 'made Sections', 'Sections 1.3.1', '1.3.1 1.3.2', '1.3.2 .'] 

 TOTAL BIGRAMS --> 22 



 ---- TRI-GRAMS ---- 

 ['Support component research', 'component research system', 'research system integration', 'system integration designed', 'integration designed achieve', 'designed achieve successes', 'achieve successes near', 'successes near term', 'near term ,', 'term , i.e.', ', i.e. ,', 'i.e. , scientific', ', scientific breakthroughs', 'scientific breakthroughs technology', 'breakthroughs technology transfer', 'technology transfer projections', 'transfer projections made', 'projections made Sections', 'made Sections 1.3.1', 'Sections 1.3.1 1.3.2', '1.3.1 1.3.2 .'] 

 TOTAL TRIGRAMS --> 21 



 ---- NOUN PHRASES ---- 

 ['research', 'system', 'integration', 'term', 'scientific breakthroughs', 'technology', 'transfer'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> ['Support']
 TOTAL PERSON ENTITY --> 1 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['support', 'compon', 'research', 'system', 'integr', 'design', 'achiev', 'success', 'near', 'term', ',', 'i.e.', ',', 'scientif', 'breakthrough', 'technolog', 'transfer', 'project', 'made', 'section', '1.3.1', '1.3.2', '.']

 TOTAL PORTER STEM WORDS ==> 23



 ---- SNOWBALL STEMMING ----

['support', 'compon', 'research', 'system', 'integr', 'design', 'achiev', 'success', 'near', 'term', ',', 'i.e.', ',', 'scientif', 'breakthrough', 'technolog', 'transfer', 'project', 'made', 'section', '1.3.1', '1.3.2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 23



 ---- LEMMATIZATION ----

['Support', 'component', 'research', 'system', 'integration', 'designed', 'achieve', 'success', 'near', 'term', ',', 'i.e.', ',', 'scientific', 'breakthrough', 'technology', 'transfer', 'projection', 'made', 'Sections', '1.3.1', '1.3.2', '.']

 TOTAL LEMMATIZE WORDS ==> 23

************************************************************************************************************************

324 --> Some of these projects should produce demonstrable results m applications including (but not  resmcted to) machine lranslation, interactive dialogue systems for problem solving and consulting, and  text input/output. 


 ---- TOKENS ----

 ['Some', 'of', 'these', 'projects', 'should', 'produce', 'demonstrable', 'results', 'm', 'applications', 'including', '(', 'but', 'not', 'resmcted', 'to', ')', 'machine', 'lranslation', ',', 'interactive', 'dialogue', 'systems', 'for', 'problem', 'solving', 'and', 'consulting', ',', 'and', 'text', 'input/output', '.'] 

 TOTAL TOKENS ==> 33

 ---- POST ----

 [('Some', 'DT'), ('of', 'IN'), ('these', 'DT'), ('projects', 'NNS'), ('should', 'MD'), ('produce', 'VB'), ('demonstrable', 'JJ'), ('results', 'NNS'), ('m', 'VBP'), ('applications', 'NNS'), ('including', 'VBG'), ('(', '('), ('but', 'CC'), ('not', 'RB'), ('resmcted', 'VBN'), ('to', 'TO'), (')', ')'), ('machine', 'NN'), ('lranslation', 'NN'), (',', ','), ('interactive', 'JJ'), ('dialogue', 'NN'), ('systems', 'NNS'), ('for', 'IN'), ('problem', 'NN'), ('solving', 'NN'), ('and', 'CC'), ('consulting', 'NN'), (',', ','), ('and', 'CC'), ('text', 'JJ'), ('input/output', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['projects', 'produce', 'demonstrable', 'results', 'applications', 'including', '(', 'resmcted', ')', 'machine', 'lranslation', ',', 'interactive', 'dialogue', 'systems', 'problem', 'solving', 'consulting', ',', 'text', 'input/output', '.']

 TOTAL FILTERED TOKENS ==>  22

 ---- POST FOR FILTERED TOKENS ----

 [('projects', 'NNS'), ('produce', 'VBP'), ('demonstrable', 'JJ'), ('results', 'NNS'), ('applications', 'NNS'), ('including', 'VBG'), ('(', '('), ('resmcted', 'VBN'), (')', ')'), ('machine', 'NN'), ('lranslation', 'NN'), (',', ','), ('interactive', 'JJ'), ('dialogue', 'NN'), ('systems', 'NNS'), ('problem', 'NN'), ('solving', 'VBG'), ('consulting', 'NN'), (',', ','), ('text', 'JJ'), ('input/output', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['projects produce', 'produce demonstrable', 'demonstrable results', 'results applications', 'applications including', 'including (', '( resmcted', 'resmcted )', ') machine', 'machine lranslation', 'lranslation ,', ', interactive', 'interactive dialogue', 'dialogue systems', 'systems problem', 'problem solving', 'solving consulting', 'consulting ,', ', text', 'text input/output', 'input/output .'] 

 TOTAL BIGRAMS --> 21 



 ---- TRI-GRAMS ---- 

 ['projects produce demonstrable', 'produce demonstrable results', 'demonstrable results applications', 'results applications including', 'applications including (', 'including ( resmcted', '( resmcted )', 'resmcted ) machine', ') machine lranslation', 'machine lranslation ,', 'lranslation , interactive', ', interactive dialogue', 'interactive dialogue systems', 'dialogue systems problem', 'systems problem solving', 'problem solving consulting', 'solving consulting ,', 'consulting , text', ', text input/output', 'text input/output .'] 

 TOTAL TRIGRAMS --> 20 



 ---- NOUN PHRASES ---- 

 ['machine', 'lranslation', 'interactive dialogue', 'problem', 'consulting', 'text input'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['project', 'produc', 'demonstr', 'result', 'applic', 'includ', '(', 'resmct', ')', 'machin', 'lranslat', ',', 'interact', 'dialogu', 'system', 'problem', 'solv', 'consult', ',', 'text', 'input/output', '.']

 TOTAL PORTER STEM WORDS ==> 22



 ---- SNOWBALL STEMMING ----

['project', 'produc', 'demonstr', 'result', 'applic', 'includ', '(', 'resmct', ')', 'machin', 'lranslat', ',', 'interact', 'dialogu', 'system', 'problem', 'solv', 'consult', ',', 'text', 'input/output', '.']

 TOTAL SNOWBALL STEM WORDS ==> 22



 ---- LEMMATIZATION ----

['project', 'produce', 'demonstrable', 'result', 'application', 'including', '(', 'resmcted', ')', 'machine', 'lranslation', ',', 'interactive', 'dialogue', 'system', 'problem', 'solving', 'consulting', ',', 'text', 'input/output', '.']

 TOTAL LEMMATIZE WORDS ==> 22

************************************************************************************************************************

325 --> 2. 


 ---- TOKENS ----

 ['2', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('2', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['2', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('2', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['2 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['2', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['2', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['2', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

326 --> Invest in approaches to the azeas labeled further scientific work in Section 1.2.3, particularly in  high-payoff approaches. 


 ---- TOKENS ----

 ['Invest', 'in', 'approaches', 'to', 'the', 'azeas', 'labeled', 'further', 'scientific', 'work', 'in', 'Section', '1.2.3', ',', 'particularly', 'in', 'high-payoff', 'approaches', '.'] 

 TOTAL TOKENS ==> 19

 ---- POST ----

 [('Invest', 'NNP'), ('in', 'IN'), ('approaches', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('azeas', 'NNS'), ('labeled', 'VBD'), ('further', 'RBR'), ('scientific', 'JJ'), ('work', 'NN'), ('in', 'IN'), ('Section', 'NNP'), ('1.2.3', 'CD'), (',', ','), ('particularly', 'RB'), ('in', 'IN'), ('high-payoff', 'NN'), ('approaches', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Invest', 'approaches', 'azeas', 'labeled', 'scientific', 'work', 'Section', '1.2.3', ',', 'particularly', 'high-payoff', 'approaches', '.']

 TOTAL FILTERED TOKENS ==>  13

 ---- POST FOR FILTERED TOKENS ----

 [('Invest', 'NNP'), ('approaches', 'VBZ'), ('azeas', 'RB'), ('labeled', 'VBN'), ('scientific', 'JJ'), ('work', 'NN'), ('Section', 'NN'), ('1.2.3', 'CD'), (',', ','), ('particularly', 'RB'), ('high-payoff', 'NN'), ('approaches', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Invest approaches', 'approaches azeas', 'azeas labeled', 'labeled scientific', 'scientific work', 'work Section', 'Section 1.2.3', '1.2.3 ,', ', particularly', 'particularly high-payoff', 'high-payoff approaches', 'approaches .'] 

 TOTAL BIGRAMS --> 12 



 ---- TRI-GRAMS ---- 

 ['Invest approaches azeas', 'approaches azeas labeled', 'azeas labeled scientific', 'labeled scientific work', 'scientific work Section', 'work Section 1.2.3', 'Section 1.2.3 ,', '1.2.3 , particularly', ', particularly high-payoff', 'particularly high-payoff approaches', 'high-payoff approaches .'] 

 TOTAL TRIGRAMS --> 11 



 ---- NOUN PHRASES ---- 

 ['scientific work', 'Section', 'high-payoff'] 

 TOTAL NOUN PHRASES --> 3 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Invest']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['invest', 'approach', 'azea', 'label', 'scientif', 'work', 'section', '1.2.3', ',', 'particularli', 'high-payoff', 'approach', '.']

 TOTAL PORTER STEM WORDS ==> 13



 ---- SNOWBALL STEMMING ----

['invest', 'approach', 'azea', 'label', 'scientif', 'work', 'section', '1.2.3', ',', 'particular', 'high-payoff', 'approach', '.']

 TOTAL SNOWBALL STEM WORDS ==> 13



 ---- LEMMATIZATION ----

['Invest', 'approach', 'azeas', 'labeled', 'scientific', 'work', 'Section', '1.2.3', ',', 'particularly', 'high-payoff', 'approach', '.']

 TOTAL LEMMATIZE WORDS ==> 13

************************************************************************************************************************

327 --> The goal is the creation and fostering of seminal ideas that could lead to  long-term breakthroughs. 


 ---- TOKENS ----

 ['The', 'goal', 'is', 'the', 'creation', 'and', 'fostering', 'of', 'seminal', 'ideas', 'that', 'could', 'lead', 'to', 'long-term', 'breakthroughs', '.'] 

 TOTAL TOKENS ==> 17

 ---- POST ----

 [('The', 'DT'), ('goal', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('creation', 'NN'), ('and', 'CC'), ('fostering', 'NN'), ('of', 'IN'), ('seminal', 'JJ'), ('ideas', 'NNS'), ('that', 'WDT'), ('could', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('long-term', 'JJ'), ('breakthroughs', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['goal', 'creation', 'fostering', 'seminal', 'ideas', 'could', 'lead', 'long-term', 'breakthroughs', '.']

 TOTAL FILTERED TOKENS ==>  10

 ---- POST FOR FILTERED TOKENS ----

 [('goal', 'NN'), ('creation', 'NN'), ('fostering', 'VBG'), ('seminal', 'JJ'), ('ideas', 'NNS'), ('could', 'MD'), ('lead', 'VB'), ('long-term', 'JJ'), ('breakthroughs', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['goal creation', 'creation fostering', 'fostering seminal', 'seminal ideas', 'ideas could', 'could lead', 'lead long-term', 'long-term breakthroughs', 'breakthroughs .'] 

 TOTAL BIGRAMS --> 9 



 ---- TRI-GRAMS ---- 

 ['goal creation fostering', 'creation fostering seminal', 'fostering seminal ideas', 'seminal ideas could', 'ideas could lead', 'could lead long-term', 'lead long-term breakthroughs', 'long-term breakthroughs .'] 

 TOTAL TRIGRAMS --> 8 



 ---- NOUN PHRASES ---- 

 ['goal', 'creation'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['goal', 'creation', 'foster', 'semin', 'idea', 'could', 'lead', 'long-term', 'breakthrough', '.']

 TOTAL PORTER STEM WORDS ==> 10



 ---- SNOWBALL STEMMING ----

['goal', 'creation', 'foster', 'semin', 'idea', 'could', 'lead', 'long-term', 'breakthrough', '.']

 TOTAL SNOWBALL STEM WORDS ==> 10



 ---- LEMMATIZATION ----

['goal', 'creation', 'fostering', 'seminal', 'idea', 'could', 'lead', 'long-term', 'breakthrough', '.']

 TOTAL LEMMATIZE WORDS ==> 10

************************************************************************************************************************

328 --> 3. 


 ---- TOKENS ----

 ['3', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('3', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['3', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('3', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['3 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['3', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['3', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['3', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

329 --> Support infrastructure to leverage research, such as large annotated corpora, very large grammars,  theory-neutral lexicons containing tens of thousands of words, common-sense knowledge bases,  modular NLP systems, and application backends. 


 ---- TOKENS ----

 ['Support', 'infrastructure', 'to', 'leverage', 'research', ',', 'such', 'as', 'large', 'annotated', 'corpora', ',', 'very', 'large', 'grammars', ',', 'theory-neutral', 'lexicons', 'containing', 'tens', 'of', 'thousands', 'of', 'words', ',', 'common-sense', 'knowledge', 'bases', ',', 'modular', 'NLP', 'systems', ',', 'and', 'application', 'backends', '.'] 

 TOTAL TOKENS ==> 37

 ---- POST ----

 [('Support', 'NN'), ('infrastructure', 'NN'), ('to', 'TO'), ('leverage', 'VB'), ('research', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('large', 'JJ'), ('annotated', 'VBD'), ('corpora', 'NN'), (',', ','), ('very', 'RB'), ('large', 'JJ'), ('grammars', 'NNS'), (',', ','), ('theory-neutral', 'JJ'), ('lexicons', 'NNS'), ('containing', 'VBG'), ('tens', 'NNS'), ('of', 'IN'), ('thousands', 'NNS'), ('of', 'IN'), ('words', 'NNS'), (',', ','), ('common-sense', 'JJ'), ('knowledge', 'NN'), ('bases', 'NNS'), (',', ','), ('modular', 'JJ'), ('NLP', 'NNP'), ('systems', 'NNS'), (',', ','), ('and', 'CC'), ('application', 'NN'), ('backends', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Support', 'infrastructure', 'leverage', 'research', ',', 'large', 'annotated', 'corpora', ',', 'large', 'grammars', ',', 'theory-neutral', 'lexicons', 'containing', 'tens', 'thousands', 'words', ',', 'common-sense', 'knowledge', 'bases', ',', 'modular', 'NLP', 'systems', ',', 'application', 'backends', '.']

 TOTAL FILTERED TOKENS ==>  30

 ---- POST FOR FILTERED TOKENS ----

 [('Support', 'NNP'), ('infrastructure', 'NN'), ('leverage', 'NN'), ('research', 'NN'), (',', ','), ('large', 'JJ'), ('annotated', 'VBD'), ('corpora', 'NN'), (',', ','), ('large', 'JJ'), ('grammars', 'NNS'), (',', ','), ('theory-neutral', 'JJ'), ('lexicons', 'NNS'), ('containing', 'VBG'), ('tens', 'NNS'), ('thousands', 'NNS'), ('words', 'NNS'), (',', ','), ('common-sense', 'JJ'), ('knowledge', 'NN'), ('bases', 'NNS'), (',', ','), ('modular', 'JJ'), ('NLP', 'NNP'), ('systems', 'NNS'), (',', ','), ('application', 'NN'), ('backends', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Support infrastructure', 'infrastructure leverage', 'leverage research', 'research ,', ', large', 'large annotated', 'annotated corpora', 'corpora ,', ', large', 'large grammars', 'grammars ,', ', theory-neutral', 'theory-neutral lexicons', 'lexicons containing', 'containing tens', 'tens thousands', 'thousands words', 'words ,', ', common-sense', 'common-sense knowledge', 'knowledge bases', 'bases ,', ', modular', 'modular NLP', 'NLP systems', 'systems ,', ', application', 'application backends', 'backends .'] 

 TOTAL BIGRAMS --> 29 



 ---- TRI-GRAMS ---- 

 ['Support infrastructure leverage', 'infrastructure leverage research', 'leverage research ,', 'research , large', ', large annotated', 'large annotated corpora', 'annotated corpora ,', 'corpora , large', ', large grammars', 'large grammars ,', 'grammars , theory-neutral', ', theory-neutral lexicons', 'theory-neutral lexicons containing', 'lexicons containing tens', 'containing tens thousands', 'tens thousands words', 'thousands words ,', 'words , common-sense', ', common-sense knowledge', 'common-sense knowledge bases', 'knowledge bases ,', 'bases , modular', ', modular NLP', 'modular NLP systems', 'NLP systems ,', 'systems , application', ', application backends', 'application backends .'] 

 TOTAL TRIGRAMS --> 28 



 ---- NOUN PHRASES ---- 

 ['infrastructure', 'leverage', 'research', 'corpora', 'common-sense knowledge', 'application'] 

 TOTAL NOUN PHRASES --> 6 



 ---- NER ----

 
 ORGANIZATION ---> ['NLP']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Support']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['support', 'infrastructur', 'leverag', 'research', ',', 'larg', 'annot', 'corpora', ',', 'larg', 'grammar', ',', 'theory-neutr', 'lexicon', 'contain', 'ten', 'thousand', 'word', ',', 'common-sens', 'knowledg', 'base', ',', 'modular', 'nlp', 'system', ',', 'applic', 'backend', '.']

 TOTAL PORTER STEM WORDS ==> 30



 ---- SNOWBALL STEMMING ----

['support', 'infrastructur', 'leverag', 'research', ',', 'larg', 'annot', 'corpora', ',', 'larg', 'grammar', ',', 'theory-neutr', 'lexicon', 'contain', 'ten', 'thousand', 'word', ',', 'common-sens', 'knowledg', 'base', ',', 'modular', 'nlp', 'system', ',', 'applic', 'backend', '.']

 TOTAL SNOWBALL STEM WORDS ==> 30



 ---- LEMMATIZATION ----

['Support', 'infrastructure', 'leverage', 'research', ',', 'large', 'annotated', 'corpus', ',', 'large', 'grammar', ',', 'theory-neutral', 'lexicon', 'containing', 'ten', 'thousand', 'word', ',', 'common-sense', 'knowledge', 'base', ',', 'modular', 'NLP', 'system', ',', 'application', 'backends', '.']

 TOTAL LEMMATIZE WORDS ==> 30

************************************************************************************************************************

330 --> 4. 


 ---- TOKENS ----

 ['4', '.'] 

 TOTAL TOKENS ==> 2

 ---- POST ----

 [('4', 'CD'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4', '.']

 TOTAL FILTERED TOKENS ==>  2

 ---- POST FOR FILTERED TOKENS ----

 [('4', 'CD'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4 .'] 

 TOTAL BIGRAMS --> 1 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4', '.']

 TOTAL PORTER STEM WORDS ==> 2



 ---- SNOWBALL STEMMING ----

['4', '.']

 TOTAL SNOWBALL STEM WORDS ==> 2



 ---- LEMMATIZATION ----

['4', '.']

 TOTAL LEMMATIZE WORDS ==> 2

************************************************************************************************************************

331 --> Increase overall funding for NL research, since two new challenges face the U.S. First, the need for  NL processing to support intelligence analysis is alreadl¢ clear, will only grow in the next decade, and  has not been addressed by previous DARPA programs. 


 ---- TOKENS ----

 ['Increase', 'overall', 'funding', 'for', 'NL', 'research', ',', 'since', 'two', 'new', 'challenges', 'face', 'the', 'U.S.', 'First', ',', 'the', 'need', 'for', 'NL', 'processing', 'to', 'support', 'intelligence', 'analysis', 'is', 'alreadl¢', 'clear', ',', 'will', 'only', 'grow', 'in', 'the', 'next', 'decade', ',', 'and', 'has', 'not', 'been', 'addressed', 'by', 'previous', 'DARPA', 'programs', '.'] 

 TOTAL TOKENS ==> 47

 ---- POST ----

 [('Increase', 'NNP'), ('overall', 'JJ'), ('funding', 'NN'), ('for', 'IN'), ('NL', 'NNP'), ('research', 'NN'), (',', ','), ('since', 'IN'), ('two', 'CD'), ('new', 'JJ'), ('challenges', 'NNS'), ('face', 'VBP'), ('the', 'DT'), ('U.S.', 'NNP'), ('First', 'NNP'), (',', ','), ('the', 'DT'), ('need', 'NN'), ('for', 'IN'), ('NL', 'NNP'), ('processing', 'NN'), ('to', 'TO'), ('support', 'VB'), ('intelligence', 'NN'), ('analysis', 'NN'), ('is', 'VBZ'), ('alreadl¢', 'JJ'), ('clear', 'JJ'), (',', ','), ('will', 'MD'), ('only', 'RB'), ('grow', 'VB'), ('in', 'IN'), ('the', 'DT'), ('next', 'JJ'), ('decade', 'NN'), (',', ','), ('and', 'CC'), ('has', 'VBZ'), ('not', 'RB'), ('been', 'VBN'), ('addressed', 'VBN'), ('by', 'IN'), ('previous', 'JJ'), ('DARPA', 'NNP'), ('programs', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['Increase', 'overall', 'funding', 'NL', 'research', ',', 'since', 'two', 'new', 'challenges', 'face', 'U.S.', 'First', ',', 'need', 'NL', 'processing', 'support', 'intelligence', 'analysis', 'alreadl¢', 'clear', ',', 'grow', 'next', 'decade', ',', 'addressed', 'previous', 'DARPA', 'programs', '.']

 TOTAL FILTERED TOKENS ==>  32

 ---- POST FOR FILTERED TOKENS ----

 [('Increase', 'NNP'), ('overall', 'JJ'), ('funding', 'NN'), ('NL', 'NNP'), ('research', 'NN'), (',', ','), ('since', 'IN'), ('two', 'CD'), ('new', 'JJ'), ('challenges', 'NNS'), ('face', 'VBP'), ('U.S.', 'NNP'), ('First', 'NNP'), (',', ','), ('need', 'VBP'), ('NL', 'NNP'), ('processing', 'VBG'), ('support', 'NN'), ('intelligence', 'NN'), ('analysis', 'NN'), ('alreadl¢', 'NN'), ('clear', 'JJ'), (',', ','), ('grow', 'JJ'), ('next', 'JJ'), ('decade', 'NN'), (',', ','), ('addressed', 'VBD'), ('previous', 'JJ'), ('DARPA', 'NNP'), ('programs', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['Increase overall', 'overall funding', 'funding NL', 'NL research', 'research ,', ', since', 'since two', 'two new', 'new challenges', 'challenges face', 'face U.S.', 'U.S. First', 'First ,', ', need', 'need NL', 'NL processing', 'processing support', 'support intelligence', 'intelligence analysis', 'analysis alreadl¢', 'alreadl¢ clear', 'clear ,', ', grow', 'grow next', 'next decade', 'decade ,', ', addressed', 'addressed previous', 'previous DARPA', 'DARPA programs', 'programs .'] 

 TOTAL BIGRAMS --> 31 



 ---- TRI-GRAMS ---- 

 ['Increase overall funding', 'overall funding NL', 'funding NL research', 'NL research ,', 'research , since', ', since two', 'since two new', 'two new challenges', 'new challenges face', 'challenges face U.S.', 'face U.S. First', 'U.S. First ,', 'First , need', ', need NL', 'need NL processing', 'NL processing support', 'processing support intelligence', 'support intelligence analysis', 'intelligence analysis alreadl¢', 'analysis alreadl¢ clear', 'alreadl¢ clear ,', 'clear , grow', ', grow next', 'grow next decade', 'next decade ,', 'decade , addressed', ', addressed previous', 'addressed previous DARPA', 'previous DARPA programs', 'DARPA programs .'] 

 TOTAL TRIGRAMS --> 30 



 ---- NOUN PHRASES ---- 

 ['overall funding', 'research', 'support', 'intelligence', 'analysis', 'alreadl¢', 'grow next decade'] 

 TOTAL NOUN PHRASES --> 7 



 ---- NER ----

 
 ORGANIZATION ---> ['DARPA']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Increase', 'U.S.']
 TOTAL GPE ENTITY --> 2 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['increas', 'overal', 'fund', 'nl', 'research', ',', 'sinc', 'two', 'new', 'challeng', 'face', 'u.s.', 'first', ',', 'need', 'nl', 'process', 'support', 'intellig', 'analysi', 'alreadl¢', 'clear', ',', 'grow', 'next', 'decad', ',', 'address', 'previou', 'darpa', 'program', '.']

 TOTAL PORTER STEM WORDS ==> 32



 ---- SNOWBALL STEMMING ----

['increas', 'overal', 'fund', 'nl', 'research', ',', 'sinc', 'two', 'new', 'challeng', 'face', 'u.s.', 'first', ',', 'need', 'nl', 'process', 'support', 'intellig', 'analysi', 'alreadl¢', 'clear', ',', 'grow', 'next', 'decad', ',', 'address', 'previous', 'darpa', 'program', '.']

 TOTAL SNOWBALL STEM WORDS ==> 32



 ---- LEMMATIZATION ----

['Increase', 'overall', 'funding', 'NL', 'research', ',', 'since', 'two', 'new', 'challenge', 'face', 'U.S.', 'First', ',', 'need', 'NL', 'processing', 'support', 'intelligence', 'analysis', 'alreadl¢', 'clear', ',', 'grow', 'next', 'decade', ',', 'addressed', 'previous', 'DARPA', 'program', '.']

 TOTAL LEMMATIZE WORDS ==> 32

************************************************************************************************************************

332 --> '~ Second, Japanese successes in machine  tramlation of text and the Japanese emphasis on simultaneous translation (of speech) suggest the  desirability of a program that supports approaches to machine translation that offer promise of  scientific breakthroughs and progress on the long-term objectives identified in Section 1: reading and  writing text, translation, and interactive dialogue. 


 ---- TOKENS ----

 ["'~", 'Second', ',', 'Japanese', 'successes', 'in', 'machine', 'tramlation', 'of', 'text', 'and', 'the', 'Japanese', 'emphasis', 'on', 'simultaneous', 'translation', '(', 'of', 'speech', ')', 'suggest', 'the', 'desirability', 'of', 'a', 'program', 'that', 'supports', 'approaches', 'to', 'machine', 'translation', 'that', 'offer', 'promise', 'of', 'scientific', 'breakthroughs', 'and', 'progress', 'on', 'the', 'long-term', 'objectives', 'identified', 'in', 'Section', '1', ':', 'reading', 'and', 'writing', 'text', ',', 'translation', ',', 'and', 'interactive', 'dialogue', '.'] 

 TOTAL TOKENS ==> 61

 ---- POST ----

 [("'~", 'JJ'), ('Second', 'NNP'), (',', ','), ('Japanese', 'JJ'), ('successes', 'NNS'), ('in', 'IN'), ('machine', 'NN'), ('tramlation', 'NN'), ('of', 'IN'), ('text', 'NN'), ('and', 'CC'), ('the', 'DT'), ('Japanese', 'JJ'), ('emphasis', 'NN'), ('on', 'IN'), ('simultaneous', 'JJ'), ('translation', 'NN'), ('(', '('), ('of', 'IN'), ('speech', 'NN'), (')', ')'), ('suggest', 'VBP'), ('the', 'DT'), ('desirability', 'NN'), ('of', 'IN'), ('a', 'DT'), ('program', 'NN'), ('that', 'WDT'), ('supports', 'VBZ'), ('approaches', 'NNS'), ('to', 'TO'), ('machine', 'NN'), ('translation', 'NN'), ('that', 'WDT'), ('offer', 'VBP'), ('promise', 'NN'), ('of', 'IN'), ('scientific', 'JJ'), ('breakthroughs', 'NNS'), ('and', 'CC'), ('progress', 'NN'), ('on', 'IN'), ('the', 'DT'), ('long-term', 'JJ'), ('objectives', 'NNS'), ('identified', 'VBN'), ('in', 'IN'), ('Section', 'NN'), ('1', 'CD'), (':', ':'), ('reading', 'NN'), ('and', 'CC'), ('writing', 'VBG'), ('text', 'NN'), (',', ','), ('translation', 'NN'), (',', ','), ('and', 'CC'), ('interactive', 'JJ'), ('dialogue', 'NN'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ["'~", 'Second', ',', 'Japanese', 'successes', 'machine', 'tramlation', 'text', 'Japanese', 'emphasis', 'simultaneous', 'translation', '(', 'speech', ')', 'suggest', 'desirability', 'program', 'supports', 'approaches', 'machine', 'translation', 'offer', 'promise', 'scientific', 'breakthroughs', 'progress', 'long-term', 'objectives', 'identified', 'Section', '1', ':', 'reading', 'writing', 'text', ',', 'translation', ',', 'interactive', 'dialogue', '.']

 TOTAL FILTERED TOKENS ==>  42

 ---- POST FOR FILTERED TOKENS ----

 [("'~", 'JJ'), ('Second', 'NNP'), (',', ','), ('Japanese', 'JJ'), ('successes', 'NNS'), ('machine', 'NN'), ('tramlation', 'NN'), ('text', 'IN'), ('Japanese', 'JJ'), ('emphasis', 'NN'), ('simultaneous', 'JJ'), ('translation', 'NN'), ('(', '('), ('speech', 'NN'), (')', ')'), ('suggest', 'VBP'), ('desirability', 'NN'), ('program', 'NN'), ('supports', 'NNS'), ('approaches', 'VBZ'), ('machine', 'NN'), ('translation', 'NN'), ('offer', 'VBP'), ('promise', 'NN'), ('scientific', 'JJ'), ('breakthroughs', 'VBZ'), ('progress', 'JJ'), ('long-term', 'JJ'), ('objectives', 'NNS'), ('identified', 'VBN'), ('Section', 'NN'), ('1', 'CD'), (':', ':'), ('reading', 'NN'), ('writing', 'VBG'), ('text', 'NN'), (',', ','), ('translation', 'NN'), (',', ','), ('interactive', 'JJ'), ('dialogue', 'NN'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ["'~ Second", 'Second ,', ', Japanese', 'Japanese successes', 'successes machine', 'machine tramlation', 'tramlation text', 'text Japanese', 'Japanese emphasis', 'emphasis simultaneous', 'simultaneous translation', 'translation (', '( speech', 'speech )', ') suggest', 'suggest desirability', 'desirability program', 'program supports', 'supports approaches', 'approaches machine', 'machine translation', 'translation offer', 'offer promise', 'promise scientific', 'scientific breakthroughs', 'breakthroughs progress', 'progress long-term', 'long-term objectives', 'objectives identified', 'identified Section', 'Section 1', '1 :', ': reading', 'reading writing', 'writing text', 'text ,', ', translation', 'translation ,', ', interactive', 'interactive dialogue', 'dialogue .'] 

 TOTAL BIGRAMS --> 41 



 ---- TRI-GRAMS ---- 

 ["'~ Second ,", 'Second , Japanese', ', Japanese successes', 'Japanese successes machine', 'successes machine tramlation', 'machine tramlation text', 'tramlation text Japanese', 'text Japanese emphasis', 'Japanese emphasis simultaneous', 'emphasis simultaneous translation', 'simultaneous translation (', 'translation ( speech', '( speech )', 'speech ) suggest', ') suggest desirability', 'suggest desirability program', 'desirability program supports', 'program supports approaches', 'supports approaches machine', 'approaches machine translation', 'machine translation offer', 'translation offer promise', 'offer promise scientific', 'promise scientific breakthroughs', 'scientific breakthroughs progress', 'breakthroughs progress long-term', 'progress long-term objectives', 'long-term objectives identified', 'objectives identified Section', 'identified Section 1', 'Section 1 :', '1 : reading', ': reading writing', 'reading writing text', 'writing text ,', 'text , translation', ', translation ,', 'translation , interactive', ', interactive dialogue', 'interactive dialogue .'] 

 TOTAL TRIGRAMS --> 40 



 ---- NOUN PHRASES ---- 

 ['machine', 'tramlation', 'Japanese emphasis', 'simultaneous translation', 'desirability', 'program', 'machine', 'translation', 'promise', 'Section', 'reading', 'text', 'translation', 'interactive dialogue'] 

 TOTAL NOUN PHRASES --> 14 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['Japanese', 'Japanese']
 TOTAL GPE ENTITY --> 2 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

["'~", 'second', ',', 'japanes', 'success', 'machin', 'tramlat', 'text', 'japanes', 'emphasi', 'simultan', 'translat', '(', 'speech', ')', 'suggest', 'desir', 'program', 'support', 'approach', 'machin', 'translat', 'offer', 'promis', 'scientif', 'breakthrough', 'progress', 'long-term', 'object', 'identifi', 'section', '1', ':', 'read', 'write', 'text', ',', 'translat', ',', 'interact', 'dialogu', '.']

 TOTAL PORTER STEM WORDS ==> 42



 ---- SNOWBALL STEMMING ----

["'~", 'second', ',', 'japanes', 'success', 'machin', 'tramlat', 'text', 'japanes', 'emphasi', 'simultan', 'translat', '(', 'speech', ')', 'suggest', 'desir', 'program', 'support', 'approach', 'machin', 'translat', 'offer', 'promis', 'scientif', 'breakthrough', 'progress', 'long-term', 'object', 'identifi', 'section', '1', ':', 'read', 'write', 'text', ',', 'translat', ',', 'interact', 'dialogu', '.']

 TOTAL SNOWBALL STEM WORDS ==> 42



 ---- LEMMATIZATION ----

["'~", 'Second', ',', 'Japanese', 'success', 'machine', 'tramlation', 'text', 'Japanese', 'emphasis', 'simultaneous', 'translation', '(', 'speech', ')', 'suggest', 'desirability', 'program', 'support', 'approach', 'machine', 'translation', 'offer', 'promise', 'scientific', 'breakthrough', 'progress', 'long-term', 'objective', 'identified', 'Section', '1', ':', 'reading', 'writing', 'text', ',', 'translation', ',', 'interactive', 'dialogue', '.']

 TOTAL LEMMATIZE WORDS ==> 42

************************************************************************************************************************

333 --> 4Previous DARPA programs have focused on English, whereas tl'~ needs m the in~lligcnc~ community embrace several critical languages. 


 ---- TOKENS ----

 ['4Previous', 'DARPA', 'programs', 'have', 'focused', 'on', 'English', ',', 'whereas', "tl'~", 'needs', 'm', 'the', 'in~lligcnc~', 'community', 'embrace', 'several', 'critical', 'languages', '.'] 

 TOTAL TOKENS ==> 20

 ---- POST ----

 [('4Previous', 'JJ'), ('DARPA', 'NNP'), ('programs', 'NNS'), ('have', 'VBP'), ('focused', 'VBN'), ('on', 'IN'), ('English', 'NNP'), (',', ','), ('whereas', 'JJ'), ("tl'~", 'NN'), ('needs', 'NNS'), ('m', 'VBP'), ('the', 'DT'), ('in~lligcnc~', 'NN'), ('community', 'NN'), ('embrace', 'VBP'), ('several', 'JJ'), ('critical', 'JJ'), ('languages', 'NNS'), ('.', '.')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['4Previous', 'DARPA', 'programs', 'focused', 'English', ',', 'whereas', "tl'~", 'needs', 'in~lligcnc~', 'community', 'embrace', 'several', 'critical', 'languages', '.']

 TOTAL FILTERED TOKENS ==>  16

 ---- POST FOR FILTERED TOKENS ----

 [('4Previous', 'JJ'), ('DARPA', 'NNP'), ('programs', 'NNS'), ('focused', 'VBD'), ('English', 'NNP'), (',', ','), ('whereas', 'JJ'), ("tl'~", 'NN'), ('needs', 'NNS'), ('in~lligcnc~', 'VBP'), ('community', 'NN'), ('embrace', 'VBP'), ('several', 'JJ'), ('critical', 'JJ'), ('languages', 'NNS'), ('.', '.')] 



 ---- BI-GRAMS ---- 

 ['4Previous DARPA', 'DARPA programs', 'programs focused', 'focused English', 'English ,', ', whereas', "whereas tl'~", "tl'~ needs", 'needs in~lligcnc~', 'in~lligcnc~ community', 'community embrace', 'embrace several', 'several critical', 'critical languages', 'languages .'] 

 TOTAL BIGRAMS --> 15 



 ---- TRI-GRAMS ---- 

 ['4Previous DARPA programs', 'DARPA programs focused', 'programs focused English', 'focused English ,', 'English , whereas', ", whereas tl'~", "whereas tl'~ needs", "tl'~ needs in~lligcnc~", 'needs in~lligcnc~ community', 'in~lligcnc~ community embrace', 'community embrace several', 'embrace several critical', 'several critical languages', 'critical languages .'] 

 TOTAL TRIGRAMS --> 14 



 ---- NOUN PHRASES ---- 

 ["whereas tl'~", 'community'] 

 TOTAL NOUN PHRASES --> 2 



 ---- NER ----

 
 ORGANIZATION ---> ['DARPA']
 TOTAL ORGANIZATION ENTITY --> 1 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> ['English']
 TOTAL GPE ENTITY --> 1 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['4previou', 'darpa', 'program', 'focus', 'english', ',', 'wherea', "tl'~", 'need', 'in~lligcnc~', 'commun', 'embrac', 'sever', 'critic', 'languag', '.']

 TOTAL PORTER STEM WORDS ==> 16



 ---- SNOWBALL STEMMING ----

['4previous', 'darpa', 'program', 'focus', 'english', ',', 'wherea', "tl'~", 'need', 'in~lligcnc~', 'communiti', 'embrac', 'sever', 'critic', 'languag', '.']

 TOTAL SNOWBALL STEM WORDS ==> 16



 ---- LEMMATIZATION ----

['4Previous', 'DARPA', 'program', 'focused', 'English', ',', 'whereas', "tl'~", 'need', 'in~lligcnc~', 'community', 'embrace', 'several', 'critical', 'language', '.']

 TOTAL LEMMATIZE WORDS ==> 16

************************************************************************************************************************

334 --> 493 


 ---- TOKENS ----

 ['493'] 

 TOTAL TOKENS ==> 1

 ---- POST ----

 [('493', 'CD')] 



 ---- TOKENS AFTER STOP-WORDS REMOVAL ---- 

 ['493']

 TOTAL FILTERED TOKENS ==>  1

 ---- POST FOR FILTERED TOKENS ----

 [('493', 'CD')] 



 ---- BI-GRAMS ---- 

 [] 

 TOTAL BIGRAMS --> 0 



 ---- TRI-GRAMS ---- 

 [] 

 TOTAL TRIGRAMS --> 0 



 ---- NOUN PHRASES ---- 

 [] 

 TOTAL NOUN PHRASES --> 0 



 ---- NER ----

 
 ORGANIZATION ---> []
 TOTAL ORGANIZATION ENTITY --> 0 


 PERSON ---> []
 TOTAL PERSON ENTITY --> 0 


 GPE ---> []
 TOTAL GPE ENTITY --> 0 


 DATE ---> []
 TOTAL DATE ENTITY --> 0 



 ---- PORTER STEMMING ----

['493']

 TOTAL PORTER STEM WORDS ==> 1



 ---- SNOWBALL STEMMING ----

['493']

 TOTAL SNOWBALL STEM WORDS ==> 1



 ---- LEMMATIZATION ----

['493']

 TOTAL LEMMATIZE WORDS ==> 1

************************************************************************************************************************

